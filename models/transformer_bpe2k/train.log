2024-05-19 16:17:23,500 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2024-05-19 16:17:23,505 - INFO - joeynmt.helpers -                           cfg.name : transformer_bpe2k
2024-05-19 16:17:23,509 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2024-05-19 16:17:23,512 - INFO - joeynmt.helpers -                     cfg.data.train : data/subsampled/train
2024-05-19 16:17:23,521 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev.test/dev
2024-05-19 16:17:23,521 - INFO - joeynmt.helpers -                      cfg.data.test : data/dev.test/test
2024-05-19 16:17:23,521 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2024-05-19 16:17:23,522 - INFO - joeynmt.helpers -                  cfg.data.src.lang : nl
2024-05-19 16:17:23,522 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2024-05-19 16:17:23,522 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2024-05-19 16:17:23,522 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2024-05-19 16:17:23,522 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/joint_vocab2k_clean.txt
2024-05-19 16:17:23,522 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2024-05-19 16:17:23,522 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : none
2024-05-19 16:17:23,523 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 2000
2024-05-19 16:17:23,523 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/codes2000.bpe
2024-05-19 16:17:23,523 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en
2024-05-19 16:17:23,523 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2024-05-19 16:17:23,523 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2024-05-19 16:17:23,523 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2024-05-19 16:17:23,533 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/joint_vocab2k_clean.txt
2024-05-19 16:17:23,533 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2024-05-19 16:17:23,533 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : none
2024-05-19 16:17:23,534 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 2000
2024-05-19 16:17:23,534 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/codes2000.bpe
2024-05-19 16:17:23,534 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2024-05-19 16:17:23,534 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2024-05-19 16:17:23,534 - INFO - joeynmt.helpers -           cfg.testing.eval_metrics : ['bleu']
2024-05-19 16:17:23,534 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2024-05-19 16:17:23,534 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2024-05-19 16:17:23,535 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2024-05-19 16:17:23,535 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2024-05-19 16:17:23,535 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2024-05-19 16:17:23,535 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2024-05-19 16:17:23,535 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2024-05-19 16:17:23,535 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2024-05-19 16:17:23,535 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2024-05-19 16:17:23,535 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2024-05-19 16:17:23,535 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2024-05-19 16:17:23,536 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2024-05-19 16:17:23,536 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2024-05-19 16:17:23,536 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2024-05-19 16:17:23,536 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2024-05-19 16:17:23,536 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2024-05-19 16:17:23,536 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2024-05-19 16:17:23,536 - INFO - joeynmt.helpers -             cfg.training.model_dir : ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k
2024-05-19 16:17:23,536 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2024-05-19 16:17:23,536 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2024-05-19 16:17:23,537 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2024-05-19 16:17:23,537 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2024-05-19 16:17:23,537 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2024-05-19 16:17:23,537 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2024-05-19 16:17:23,537 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2024-05-19 16:17:23,537 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2024-05-19 16:17:23,537 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2024-05-19 16:17:23,537 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2024-05-19 16:17:23,537 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2024-05-19 16:17:23,538 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2024-05-19 16:17:23,538 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2024-05-19 16:17:23,538 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2024-05-19 16:17:23,538 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2024-05-19 16:17:23,538 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2024-05-19 16:17:23,538 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2024-05-19 16:17:23,538 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2024-05-19 16:17:23,538 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2024-05-19 16:17:23,538 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2024-05-19 16:17:23,539 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2024-05-19 16:17:23,540 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2024-05-19 16:17:23,815 - INFO - joeynmt.data - Building tokenizer...
2024-05-19 16:17:23,834 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-19 16:17:23,835 - INFO - joeynmt.tokenizers - en tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-19 16:17:23,836 - INFO - joeynmt.data - Loading train set...
2024-05-19 16:17:24,635 - INFO - joeynmt.data - Building vocabulary...
2024-05-19 16:17:24,786 - INFO - joeynmt.data - Loading dev set...
2024-05-19 16:17:24,794 - INFO - joeynmt.data - Loading test set...
2024-05-19 16:17:24,803 - INFO - joeynmt.data - Data loaded.
2024-05-19 16:17:24,804 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=nl, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-19 16:17:24,804 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1003, src_lang=nl, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-19 16:17:24,804 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1777, src_lang=nl, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-19 16:17:24,805 - INFO - joeynmt.data - First training example:
	[SRC] A@@ l G@@ or@@ e over het af@@ w@@ en@@ den van de k@@ li@@ maa@@ t@@ cr@@ is@@ is
	[TRG] A@@ l G@@ or@@ e@@ : A@@ ver@@ ting the c@@ lim@@ ate cr@@ is@@ is
2024-05-19 16:17:24,805 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) en (6) een (7) het (8) van (9) is
2024-05-19 16:17:24,805 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) en (6) een (7) het (8) van (9) is
2024-05-19 16:17:24,805 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2003
2024-05-19 16:17:24,806 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2003
2024-05-19 16:17:24,816 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-19 16:17:24,891 - INFO - joeynmt.model - Enc-dec model built.
2024-05-19 16:17:28,969 - DEBUG - tensorflow - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2024-05-19 16:17:29,462 - DEBUG - h5py._conv - Creating converter from 7 to 5
2024-05-19 16:17:29,463 - DEBUG - h5py._conv - Creating converter from 5 to 7
2024-05-19 16:17:29,463 - DEBUG - h5py._conv - Creating converter from 7 to 5
2024-05-19 16:17:29,463 - DEBUG - h5py._conv - Creating converter from 5 to 7
2024-05-19 16:17:30,760 - DEBUG - jax._src.path - etils.epath found. Using etils.epath for file I/O.
2024-05-19 16:17:32,117 - INFO - joeynmt.model - Total params: 3411968
2024-05-19 16:17:32,118 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2024-05-19 16:17:32,119 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2003),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2003),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2024-05-19 16:17:33,213 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2024-05-19 16:17:33,213 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2024-05-19 16:17:33,214 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2024-05-19 16:17:33,214 - INFO - joeynmt.training - EPOCH 1
2024-05-19 16:17:40,156 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.989577, Batch Acc: 0.040912, Tokens per Sec:    10720, Lr: 0.000300
2024-05-19 16:17:43,597 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.849695, Batch Acc: 0.065718, Tokens per Sec:    21323, Lr: 0.000300
2024-05-19 16:17:46,953 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.683004, Batch Acc: 0.081390, Tokens per Sec:    22215, Lr: 0.000300
2024-05-19 16:17:51,181 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.656252, Batch Acc: 0.092069, Tokens per Sec:    17396, Lr: 0.000300
2024-05-19 16:17:54,872 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.541083, Batch Acc: 0.103589, Tokens per Sec:    20240, Lr: 0.000300
2024-05-19 16:17:54,872 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:17:54,872 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:18:08,404 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:18:08,405 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   0.04, loss:   3.57, ppl:  35.63, acc:   0.10, generation: 13.2514[sec], evaluation: 0.2501[sec]
2024-05-19 16:18:08,406 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:18:08,642 - INFO - joeynmt.training - Example #0
2024-05-19 16:18:08,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:18:08,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:18:08,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'be', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 's@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@']
2024-05-19 16:18:08,645 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:18:08,645 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:18:08,645 - INFO - joeynmt.training - 	Hypothesis: And I be the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the sooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
2024-05-19 16:18:08,646 - INFO - joeynmt.training - Example #1
2024-05-19 16:18:08,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:18:08,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:18:08,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'is', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'f@@', 'o@@', 'o@@', '.', '</s>']
2024-05-19 16:18:08,647 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:18:08,647 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:18:08,647 - INFO - joeynmt.training - 	Hypothesis: But is the the the the the the the the the the the the the the the the the the the the the the the the the foo.
2024-05-19 16:18:08,647 - INFO - joeynmt.training - Example #2
2024-05-19 16:18:08,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:18:08,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:18:08,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'f@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', '.', '</s>']
2024-05-19 16:18:08,648 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:18:08,648 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:18:08,649 - INFO - joeynmt.training - 	Hypothesis: And the the the the the the the fooooooooooooooooooooooooooo.
2024-05-19 16:18:08,649 - INFO - joeynmt.training - Example #3
2024-05-19 16:18:08,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:18:08,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:18:08,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'f@@', 'o@@', 'o@@', 'o@@', 'o@@', '.', '</s>']
2024-05-19 16:18:08,650 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:18:08,650 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:18:08,650 - INFO - joeynmt.training - 	Hypothesis: It the the the the the the the the the the the the the the foooo.
2024-05-19 16:18:08,650 - INFO - joeynmt.training - Example #4
2024-05-19 16:18:08,651 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:18:08,651 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:18:08,651 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'f@@', 'o@@', '.', '</s>']
2024-05-19 16:18:08,651 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:18:08,652 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:18:08,652 - INFO - joeynmt.training - 	Hypothesis: And I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the fo.
2024-05-19 16:18:11,926 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.443689, Batch Acc: 0.112751, Tokens per Sec:    20978, Lr: 0.000300
2024-05-19 16:18:15,316 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.325852, Batch Acc: 0.121489, Tokens per Sec:    21908, Lr: 0.000300
2024-05-19 16:18:19,679 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.349965, Batch Acc: 0.133038, Tokens per Sec:    16782, Lr: 0.000300
2024-05-19 16:18:23,393 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.370131, Batch Acc: 0.144317, Tokens per Sec:    19928, Lr: 0.000300
2024-05-19 16:18:26,707 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.105179, Batch Acc: 0.162902, Tokens per Sec:    21889, Lr: 0.000300
2024-05-19 16:18:26,707 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:18:26,708 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:18:40,313 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:18:40,313 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   0.27, loss:   3.25, ppl:  25.68, acc:   0.16, generation: 13.3499[sec], evaluation: 0.2342[sec]
2024-05-19 16:18:40,314 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:18:40,530 - INFO - joeynmt.training - Example #0
2024-05-19 16:18:40,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:18:40,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:18:40,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'of', 'the', 'first', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'of', 'the', 'first', 'first', 'of', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'of', 'the', 'first', 'first', 'first', 'first', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'of', 'the', 'world.', '</s>']
2024-05-19 16:18:40,532 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:18:40,532 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:18:40,533 - INFO - joeynmt.training - 	Hypothesis: And the first of the first first of the first of the first first first first first first first first first first of the first first of the world the world the world the world the world the world the world the world of the first first first first first of the first of the first of the first of the first first first first first first first first first first first of the world.
2024-05-19 16:18:40,533 - INFO - joeynmt.training - Example #1
2024-05-19 16:18:40,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:18:40,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:18:40,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'of', 'the', 'first', 'of', 'the', 'first', 'first', 'first', 'of', 'the', 'first', 'first', 'of', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'the', 'world', 'of', 'the', 'world', 'the', 'world', 'of', 'the', 'world', 'the', 'world', 'the', 'world.', '</s>']
2024-05-19 16:18:40,534 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:18:40,534 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:18:40,534 - INFO - joeynmt.training - 	Hypothesis: But this is the first first first first first first first first first of the first of the first first first of the first first of the world the world the world the world the world the world the world the world the world of the world the world of the world the world the world.
2024-05-19 16:18:40,534 - INFO - joeynmt.training - Example #2
2024-05-19 16:18:40,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:18:40,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:18:40,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'is', 'the', 'first', 'first', 'is', 'the', 'first', 'first', 'first', 'first', 'first', 'is', 'the', 'first', 'first', 'first', 'first', 'in', 'the', 'first', 'of', 'the', 'first', 'of', 'the', 's@@', 's@@', 's@@', 's@@', 's@@', 'ell@@', '.', '</s>']
2024-05-19 16:18:40,535 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:18:40,535 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:18:40,536 - INFO - joeynmt.training - 	Hypothesis: The first first is the first first is the first first first first first is the first first first first in the first of the first of the sssssell.
2024-05-19 16:18:40,536 - INFO - joeynmt.training - Example #3
2024-05-19 16:18:40,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:18:40,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:18:40,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'the', 'first', 'first', 'in', 'the', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'in', 'the', 'world.', '</s>']
2024-05-19 16:18:40,537 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:18:40,537 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:18:40,537 - INFO - joeynmt.training - 	Hypothesis: It's the first first in the first first first first first first first first first first first first first first first first in the world.
2024-05-19 16:18:40,537 - INFO - joeynmt.training - Example #4
2024-05-19 16:18:40,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:18:40,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:18:40,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'the', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first', 'first']
2024-05-19 16:18:40,538 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:18:40,538 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:18:40,538 - INFO - joeynmt.training - 	Hypothesis: The first first first first first first first is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first
2024-05-19 16:18:43,859 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.066628, Batch Acc: 0.174852, Tokens per Sec:    20714, Lr: 0.000300
2024-05-19 16:18:48,420 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.989242, Batch Acc: 0.189452, Tokens per Sec:    16059, Lr: 0.000300
2024-05-19 16:18:51,834 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.953101, Batch Acc: 0.201892, Tokens per Sec:    20968, Lr: 0.000300
2024-05-19 16:18:55,474 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.833510, Batch Acc: 0.213826, Tokens per Sec:    20078, Lr: 0.000300
2024-05-19 16:18:59,024 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.794929, Batch Acc: 0.225009, Tokens per Sec:    20757, Lr: 0.000300
2024-05-19 16:18:59,025 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:18:59,025 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:19:13,336 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:19:13,337 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   1.10, loss:   2.92, ppl:  18.54, acc:   0.21, generation: 13.9337[sec], evaluation: 0.3468[sec]
2024-05-19 16:19:13,338 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:19:13,593 - INFO - joeynmt.training - Example #0
2024-05-19 16:19:13,594 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:19:13,595 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:19:13,595 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'first', 'first', 'first', 'first', 'time', 'I', 'think', 'this', 'gu@@', 'ys', 'to', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'was', 'the', 'world', 'to', 'the', 'world', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:19:13,596 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:19:13,597 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:19:13,597 - INFO - joeynmt.training - 	Hypothesis: And the first first first first time I think this guys to the world and the world and the world and the world of the world of the world was the world to the world of the U.S.
2024-05-19 16:19:13,597 - INFO - joeynmt.training - Example #1
2024-05-19 16:19:13,597 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:19:13,597 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:19:13,597 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'c@@', 'ou@@', 't,', 'the', 'p@@', 'le', 'of', 'this', 'p@@', 'le', 'of', 'the', 'world', 'that', 'the', 'same', 'same', 'same', 'same', 'thing', 'of', 'the', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'same', 'th@@', 'th@@', 'th@@', 'y', 'of', 'the', 'world.', '</s>']
2024-05-19 16:19:13,598 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:19:13,598 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:19:13,598 - INFO - joeynmt.training - 	Hypothesis: But this is the cout, the ple of this ple of the world that the same same same same thing of the same same same same same same same same thththy of the world.
2024-05-19 16:19:13,599 - INFO - joeynmt.training - Example #2
2024-05-19 16:19:13,599 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:19:13,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:19:13,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'a@@', 'way', 'on', 'the', 'N@@', 'N@@', 'N@@', 'N@@', 'N@@', 'or@@', 'or@@', 'or@@', 'or@@', 'e', 'in', 'the', 'f@@', 'ol@@', 'ol@@', 'd@@', 'one', 'of', 'the', 'p@@', 'le', 'of', 'the', 'p@@', 'le', 'of', 'the', 'f@@', 'ol@@', 'd.', '</s>']
2024-05-19 16:19:13,600 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:19:13,600 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:19:13,600 - INFO - joeynmt.training - 	Hypothesis: The first away on the NNNNNorororore in the fololdone of the ple of the ple of the fold.
2024-05-19 16:19:13,600 - INFO - joeynmt.training - Example #3
2024-05-19 16:19:13,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:19:13,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:19:13,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'a', 'little', 'bit', 'of', 'the', 'p@@', 'le', 'of', 'the', 'p@@', 'le', 'of', 'the', 'p@@', 'le', 'of', 'the', 'world.', '</s>']
2024-05-19 16:19:13,601 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:19:13,601 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:19:13,601 - INFO - joeynmt.training - 	Hypothesis: It's a little bit of the ple of the ple of the ple of the world.
2024-05-19 16:19:13,602 - INFO - joeynmt.training - Example #4
2024-05-19 16:19:13,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:19:13,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:19:13,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'of', 'the', 'world', 'I', 'think', 'I', 'think', 'of', 'a', 'little', 'bit', 'of', 'the', 'world', 'of', 'the', '2@@', '00', 'years', 'ago@@', ',', 'and', 'the', '2@@', '00', 'years', 'ago@@', '.', '</s>']
2024-05-19 16:19:13,603 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:19:13,603 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:19:13,603 - INFO - joeynmt.training - 	Hypothesis: The first first of the world I think I think of a little bit of the world of the 200 years ago, and the 200 years ago.
2024-05-19 16:19:17,742 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.693408, Batch Acc: 0.237125, Tokens per Sec:    16847, Lr: 0.000300
2024-05-19 16:19:21,109 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.671519, Batch Acc: 0.249571, Tokens per Sec:    21788, Lr: 0.000300
2024-05-19 16:19:24,610 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.647816, Batch Acc: 0.258163, Tokens per Sec:    21337, Lr: 0.000300
2024-05-19 16:19:28,505 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.640038, Batch Acc: 0.272336, Tokens per Sec:    18852, Lr: 0.000300
2024-05-19 16:19:32,315 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.708171, Batch Acc: 0.276286, Tokens per Sec:    18687, Lr: 0.000300
2024-05-19 16:19:32,315 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:19:32,315 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:19:44,736 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:19:44,737 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   2.21, loss:   2.71, ppl:  15.09, acc:   0.25, generation: 12.2269[sec], evaluation: 0.1785[sec]
2024-05-19 16:19:44,737 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:19:44,960 - INFO - joeynmt.training - Example #0
2024-05-19 16:19:44,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:19:44,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:19:44,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or', 'a', 'years', 'I', 'was', 'a', 'little', 'b@@', 'it@@', 'ed', 'to', 'the', 'c@@', 'lu@@', 'c@@', 'k', 'and', 'the', 'p@@', 'ho@@', 'to@@', 'gra@@', 'p@@', 'le', 'of', 'the', 'million', 'million', 'years', 'ago@@', ',', 'the', 'year@@', 's,', 'the', 'last', 'year@@', 's,', 'the', 'last', 'year@@', 's,', 'the', 'U@@', 'nit@@', 'ed', 'S@@', 'h@@', 'igh@@', 't@@', 't@@', 't@@', 't@@', 't@@', 'om@@', '.', '</s>']
2024-05-19 16:19:44,962 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:19:44,962 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:19:44,962 - INFO - joeynmt.training - 	Hypothesis: For a years I was a little bited to the cluck and the photograple of the million million years ago, the years, the last years, the last years, the United Shightttttom.
2024-05-19 16:19:44,963 - INFO - joeynmt.training - Example #1
2024-05-19 16:19:44,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:19:44,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:19:44,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'c@@', 'lu@@', 'c@@', 'k', 'of', 'this', 'is', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm', 'because', 'the', 'proble@@', 'm', 'of', 'the', 'w@@', 'rit@@', 'e', 'of', 'the', 'w@@', 'rit@@', 'e', 'of', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm.', '</s>']
2024-05-19 16:19:44,964 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:19:44,964 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:19:44,964 - INFO - joeynmt.training - 	Hypothesis: But this is the cluck of this is the problem of the problem because the problem of the write of the write of the problem of the problem of the problem of the problem of the problem.
2024-05-19 16:19:44,964 - INFO - joeynmt.training - Example #2
2024-05-19 16:19:44,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:19:44,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:19:44,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'g@@', 'ine', 'of', 'the', 'N@@', 'N@@', 'ig@@', 'h', 'is', 'the', 'N@@', 'ig@@', 'h', 'is', 'in', 'the', 'N@@', 'ig@@', 'h', 'of', 'the', 'p@@', 'ho@@', 'to@@', 'gra@@', 'p@@', 'le', 'of', 'our', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', 'new', '--', '</s>']
2024-05-19 16:19:44,966 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:19:44,966 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:19:44,966 - INFO - joeynmt.training - 	Hypothesis: The gine of the NNigh is the Nigh is in the Nigh of the photograple of our new new new new new new new new new new new new new new new new --
2024-05-19 16:19:44,966 - INFO - joeynmt.training - Example #3
2024-05-19 16:19:44,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:19:44,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:19:44,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'a', 's@@', 'et', 'of', 'the', 'f@@', 'our', 'c@@', 'lu@@', 'c@@', 'k', 'in', 'the', 'b@@', 'ig@@', 'h', 'in', 'the', 'b@@', 'ig@@', 'ge@@', 'd', 'in', 'the', 'c@@', 'all@@', '.', '</s>']
2024-05-19 16:19:44,967 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:19:44,967 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:19:44,967 - INFO - joeynmt.training - 	Hypothesis: It was a set of the four cluck in the bigh in the bigged in the call.
2024-05-19 16:19:44,968 - INFO - joeynmt.training - Example #4
2024-05-19 16:19:44,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:19:44,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:19:44,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'to', 'the', 'next', 'is', 'a', 'little', 'little', 'b@@', 'ig@@', 'h', 'of', 'the', 'f@@', 'lo@@', 've', 'of', 'the', 'last', 'year@@', 's,', 'the', 'year@@', 's,', 'the', 'year@@', 's,', '</s>']
2024-05-19 16:19:44,969 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:19:44,969 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:19:44,969 - INFO - joeynmt.training - 	Hypothesis: The next next to the next is a little little bigh of the flove of the last years, the years, the years,
2024-05-19 16:19:48,382 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.446817, Batch Acc: 0.286362, Tokens per Sec:    20269, Lr: 0.000300
2024-05-19 16:19:51,836 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.489446, Batch Acc: 0.294341, Tokens per Sec:    21131, Lr: 0.000300
2024-05-19 16:19:55,725 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.287866, Batch Acc: 0.308064, Tokens per Sec:    19214, Lr: 0.000300
2024-05-19 16:19:59,720 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.642482, Batch Acc: 0.318376, Tokens per Sec:    17721, Lr: 0.000300
2024-05-19 16:20:03,140 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.471349, Batch Acc: 0.334708, Tokens per Sec:    21841, Lr: 0.000300
2024-05-19 16:20:03,141 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:20:03,141 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:20:16,300 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:20:16,301 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   3.34, loss:   2.55, ppl:  12.86, acc:   0.29, generation: 12.9569[sec], evaluation: 0.1860[sec]
2024-05-19 16:20:16,302 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:20:16,522 - INFO - joeynmt.training - Example #0
2024-05-19 16:20:16,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:20:16,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:20:16,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'years', 'I', 'was', 'this', 'two', 'di@@', 'a@@', "'s", 'two', 'years', 'to', 'see', 'the', 'p@@', 'ho@@', 'to@@', 'gra@@', 'p@@', 's', 'that', 'the', 'p@@', 'ir@@', 'd', 'of', 'the', 'three', 'million', 'years', 'of', 'the', 'three', 'years', 'of', 'the', 'gr@@', 'ou@@', 'p@@', 'le', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'er', 'was', 'about', '4@@', '0@@', '-@@', 'h@@', 'igh@@', 't.', '</s>']
2024-05-19 16:20:16,524 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:20:16,525 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:20:16,525 - INFO - joeynmt.training - 	Hypothesis: Fore years I was this two dia's two years to see the photograps that the pird of the three million years of the three years of the grouple of the United States of the United Stater was about 40-hight.
2024-05-19 16:20:16,525 - INFO - joeynmt.training - Example #1
2024-05-19 16:20:16,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:20:16,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:20:16,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'po@@', 'int', 'of', 'this', 'is', 'the', 'proble@@', 'm', 'because', 'the', 'proble@@', 'm', 'because', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm', 'because', 'the', 'proble@@', 'm', 'because', 'the', 'proble@@', 'm', 'because', 'the', 'proble@@', 'm', 'of', 'this', 'proble@@', 'm', 'because', 'the', 'proble@@', 'm', 'of', 'this', 'is', 'the', 'proble@@', 'm', 'of', 'the', 'proble@@', 'm.', '</s>']
2024-05-19 16:20:16,527 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:20:16,527 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:20:16,527 - INFO - joeynmt.training - 	Hypothesis: But this is the point of this is the problem because the problem because the problem of the problem of the problem of the problem of the problem of the problem because the problem because the problem because the problem of this problem because the problem of this is the problem of the problem.
2024-05-19 16:20:16,527 - INFO - joeynmt.training - Example #2
2024-05-19 16:20:16,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:20:16,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:20:16,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'g@@', 'ine', 'is', 'on', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'the', 'c@@', 'op@@', 'er@@', 'ate', 'of', 'our', 'g@@', 'lob@@', 'al', 'system@@', '.', '</s>']
2024-05-19 16:20:16,528 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:20:16,529 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:20:16,529 - INFO - joeynmt.training - 	Hypothesis: The gine is on the North is in the North is in the coperate of our global system.
2024-05-19 16:20:16,529 - INFO - joeynmt.training - Example #3
2024-05-19 16:20:16,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:20:16,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:20:16,530 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'win@@', 'ter', 'of', 'the', 'win@@', 'ter', 'and', 'in', 'the', 's@@', 'om@@', 'e.', '</s>']
2024-05-19 16:20:16,530 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:20:16,530 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:20:16,530 - INFO - joeynmt.training - 	Hypothesis: It was in the winter of the winter and in the some.
2024-05-19 16:20:16,530 - INFO - joeynmt.training - Example #4
2024-05-19 16:20:16,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:20:16,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:20:16,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'to', 'show', 'the', 'di@@', 'se@@', 'ver@@', 'sion', 'is', 'a', 'f@@', 'el@@', 't', 'of', 'what', 'the', 's@@', 'ha@@', 'vi@@', 'l', '2@@', '5', 'years', 'of', 'the', 'last', 'year@@', '.', '</s>']
2024-05-19 16:20:16,532 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:20:16,532 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:20:16,532 - INFO - joeynmt.training - 	Hypothesis: The next next to show the diseversion is a felt of what the shavil 25 years of the last year.
2024-05-19 16:20:19,949 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.292567, Batch Acc: 0.345675, Tokens per Sec:    20607, Lr: 0.000300
2024-05-19 16:20:23,913 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.469335, Batch Acc: 0.349687, Tokens per Sec:    18352, Lr: 0.000300
2024-05-19 16:20:27,911 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.175365, Batch Acc: 0.353939, Tokens per Sec:    18028, Lr: 0.000300
2024-05-19 16:20:31,311 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.233447, Batch Acc: 0.372769, Tokens per Sec:    21754, Lr: 0.000300
2024-05-19 16:20:34,689 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.336380, Batch Acc: 0.375143, Tokens per Sec:    22309, Lr: 0.000300
2024-05-19 16:20:34,689 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:20:34,690 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:20:48,290 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:20:48,290 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   4.44, loss:   2.41, ppl:  11.09, acc:   0.33, generation: 13.3924[sec], evaluation: 0.1910[sec]
2024-05-19 16:20:48,291 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:20:48,527 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/500.ckpt
2024-05-19 16:20:48,542 - INFO - joeynmt.training - Example #0
2024-05-19 16:20:48,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:20:48,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:20:48,544 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'years', 'a@@', 'go', 'this', 'two', 'di@@', 'a@@', "'s", 'two', 'million', 'years', 'to', 'get', 'the', 'p@@', 'ho@@', 'to@@', 'gra@@', 'p@@', 'es', 'that', 'the', 'last', 'last', 'last', 'million', 'years', 'in', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:20:48,545 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:20:48,545 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:20:48,545 - INFO - joeynmt.training - 	Hypothesis: Fore years ago this two dia's two million years to get the photograpes that the last last last million years in the U.S.
2024-05-19 16:20:48,545 - INFO - joeynmt.training - Example #1
2024-05-19 16:20:48,546 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:20:48,546 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:20:48,546 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'h@@', 'un@@', 'dre@@', 'ds', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'the', 'de@@', 'ca@@', 'r', 'of', 'the', 'he@@', 'a@@', 'th@@', ',', '</s>']
2024-05-19 16:20:48,546 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:20:48,547 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:20:48,547 - INFO - joeynmt.training - 	Hypothesis: But this is the hundreds of this specific problem because the decar of the heath,
2024-05-19 16:20:48,547 - INFO - joeynmt.training - Example #2
2024-05-19 16:20:48,547 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:20:48,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:20:48,548 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'o@@', 'il@@', 'e', 'of', 'the', 'N@@', 'or@@', 'th', 'of', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'the', 'c@@', 'lim@@', 'ate', 'of', 'our', 'he@@', 'ar@@', 't', 'of', 'us', 'system@@', '.', '</s>']
2024-05-19 16:20:48,548 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:20:48,548 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:20:48,548 - INFO - joeynmt.training - 	Hypothesis: The oile of the North of the North is in the climate of our heart of us system.
2024-05-19 16:20:48,549 - INFO - joeynmt.training - Example #3
2024-05-19 16:20:48,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:20:48,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:20:48,549 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'a', 's@@', 'et', 'of', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'win@@', 'ter', 'of', 'the', 's@@', 'om@@', '.', '</s>']
2024-05-19 16:20:48,550 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:20:48,550 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:20:48,550 - INFO - joeynmt.training - 	Hypothesis: It was a set of the winter and crimpt in the winter of the som.
2024-05-19 16:20:48,550 - INFO - joeynmt.training - Example #4
2024-05-19 16:20:48,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:20:48,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:20:48,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'next', 'di@@', 'a', 'that', 'I', 'can', 'see', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'to', 'see', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 's.', '</s>']
2024-05-19 16:20:48,551 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:20:48,551 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:20:48,552 - INFO - joeynmt.training - 	Hypothesis: And the next dia that I can see a version of what the version of what the last 25 years is happened to see the last 25 years is happens.
2024-05-19 16:20:52,526 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.174183, Batch Acc: 0.385507, Tokens per Sec:    17755, Lr: 0.000300
2024-05-19 16:20:56,398 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.113207, Batch Acc: 0.396241, Tokens per Sec:    19378, Lr: 0.000300
2024-05-19 16:20:59,994 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.097552, Batch Acc: 0.393197, Tokens per Sec:    20731, Lr: 0.000300
2024-05-19 16:21:03,400 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.041751, Batch Acc: 0.406949, Tokens per Sec:    22110, Lr: 0.000300
2024-05-19 16:21:07,511 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.182968, Batch Acc: 0.406048, Tokens per Sec:    17942, Lr: 0.000300
2024-05-19 16:21:07,512 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:21:07,512 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:21:20,886 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:21:20,886 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   5.43, loss:   2.30, ppl:   9.99, acc:   0.36, generation: 12.9931[sec], evaluation: 0.3463[sec]
2024-05-19 16:21:20,887 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:21:21,155 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/1000.ckpt
2024-05-19 16:21:21,184 - INFO - joeynmt.training - Example #0
2024-05-19 16:21:21,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:21:21,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:21:21,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'years', 'I', 'was', 'this', 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 'p@@', 'ool@@', 's', 'that', 'the', 'p@@', 'ool@@', 's', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'U@@', 'nit@@', 'ed', 'of', 'the', 'U@@', 'nit@@', 'ed', 'of', 'the', 'V@@', ',', 'with', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:21:21,186 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:21:21,187 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:21:21,187 - INFO - joeynmt.training - 	Hypothesis: Fore years I was this two dia's two dia's two dia's pools that the pools the pool, which was the United of the United of the V, with 40-percent of the United United States,
2024-05-19 16:21:21,187 - INFO - joeynmt.training - Example #1
2024-05-19 16:21:21,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:21:21,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:21:21,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'er@@', 'r@@', 'ate', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'because', 'it', "doesn't", 'the', 'di@@', 'ed', 'of', 'the', 'same', 'di@@', 'ed', 'of', 'the', 'hi@@', 'm', 'of', 'the', 'hi@@', 'm', 'of', 'the', 'hi@@', 'm', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'because', 'it', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'of', 'the', 'same', 'of', 'the', 'di@@', 'di@@', 'di@@', 'd@@', 'd@@', 'n@@', 'n@@', 'n@@', 'n@@', 'n@@', 'ame', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'of', 'the', 'p@@', 'ul@@', 'ti@@', 'c']
2024-05-19 16:21:21,188 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:21:21,189 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:21:21,189 - INFO - joeynmt.training - 	Hypothesis: But this is the errate of this specific problebecause it doesn't the died of the same died of the him of the him of the him of this specific problebecause it of this specific problem because it of this specific problem because it of this specific problem because it of this specific problem because it of the same of the didididdnnnnname of this specific problem because it of the pultic
2024-05-19 16:21:21,189 - INFO - joeynmt.training - Example #2
2024-05-19 16:21:21,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:21:21,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:21:21,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ex@@', 'cit@@', 'ing', 'on', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'se@@', 'a', 'se@@', 'qu@@', 'ar@@', 'ch', 'in', 'the', 'se@@', 'ar@@', 'ch', 'of', 'g@@', 'lob@@', 'al', 'he@@', 'al@@', 'th@@', 'ough', 'of', 'g@@', 'lob@@', 'al', 'syste@@', 'm', 'of', 'g@@', 'lob@@', 'al', 'syste@@', 'm', '</s>']
2024-05-19 16:21:21,190 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:21:21,191 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:21:21,191 - INFO - joeynmt.training - 	Hypothesis: The exciting on the North is in sea sequarch in the search of global healthough of global system of global system
2024-05-19 16:21:21,191 - INFO - joeynmt.training - Example #3
2024-05-19 16:21:21,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:21:21,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:21:21,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 's@@', 'et', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 's@@', 'om@@', '.', '</s>']
2024-05-19 16:21:21,192 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:21:21,192 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:21:21,192 - INFO - joeynmt.training - 	Hypothesis: It was set in the winter and crimpt in the som.
2024-05-19 16:21:21,193 - INFO - joeynmt.training - Example #4
2024-05-19 16:21:21,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:21:21,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:21:21,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'an@@', 'im@@', 'a', 'that', 'I', 'think', 'is', 'a', 'f@@', 're@@', 'e', 'of', 'what', 'the', 'f@@', 're@@', 'e', 'was', 'a', 'f@@', 'ar@@', 'mer@@', 'ci@@', 'al', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '</s>']
2024-05-19 16:21:21,194 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:21:21,195 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:21:21,195 - INFO - joeynmt.training - 	Hypothesis: The next anima that I think is a free of what the free was a farmercial 25 years is happened
2024-05-19 16:21:24,942 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     1.967337, Batch Acc: 0.413210, Tokens per Sec:    18647, Lr: 0.000300
2024-05-19 16:21:28,470 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.245725, Batch Acc: 0.416824, Tokens per Sec:    21347, Lr: 0.000300
2024-05-19 16:21:31,906 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.373841, Batch Acc: 0.413454, Tokens per Sec:    21356, Lr: 0.000300
2024-05-19 16:21:36,224 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.098831, Batch Acc: 0.423838, Tokens per Sec:    17171, Lr: 0.000300
2024-05-19 16:21:38,548 - INFO - joeynmt.training - Epoch   1: total training loss 10883.83
2024-05-19 16:21:38,548 - INFO - joeynmt.training - EPOCH 2
2024-05-19 16:21:39,674 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     2.250817, Batch Acc: 0.444156, Tokens per Sec:    22236, Lr: 0.000300
2024-05-19 16:21:39,675 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:21:39,675 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:21:52,140 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:21:52,141 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   6.66, loss:   2.23, ppl:   9.32, acc:   0.38, generation: 12.2342[sec], evaluation: 0.2122[sec]
2024-05-19 16:21:52,141 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:21:52,354 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/1500.ckpt
2024-05-19 16:21:52,369 - INFO - joeynmt.training - Example #0
2024-05-19 16:21:52,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:21:52,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:21:52,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'I', 'was', 'going', 'to', 'see', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'et', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 's', 'that', 'the', 'p@@', 'ool@@', 's', 'that', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', '4@@', '0@@', '0@@', '-@@', 'percent', 'of', 'the', 'U@@', '.@@', '0@@', '.', '</s>']
2024-05-19 16:21:52,371 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:21:52,372 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:21:52,372 - INFO - joeynmt.training - 	Hypothesis: Fore I was going to see this two dia's set to show that the pools that the pools that the last three million years of the U.S, with 40-percent of the U.S, with 400-percent of the U.0.
2024-05-19 16:21:52,372 - INFO - joeynmt.training - Example #1
2024-05-19 16:21:52,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:21:52,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:21:52,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'sc@@', 'en@@', 'e', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'because', 'the', 'f@@', 'ic', 'proble@@', 'because', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'the', 'se@@', 'a@@', 'way', 'of', 'the', 'the', 'se@@', 'e@@', 'ing', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'the', 'f@@', 'ar@@', 't', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'the', 'the', 'f@@', 'ar@@', 't', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'the', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'the', 'proble@@', 'm', 'because', 'the', 'f@@', 'ar@@', 't', 'of', 'the', 'the', 'proble@@', 'm', 'because', 'the', 'di@@', 'di@@', 'di@@', 'di@@', 'di@@', 'di@@', 'di@@', 's@@', 's@@', 'ent', 'of', 'this', 'proble@@', 'm', 'because', 'the', 'f@@', 'ic', 'proble@@', 'm']
2024-05-19 16:21:52,373 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:21:52,374 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:21:52,374 - INFO - joeynmt.training - 	Hypothesis: But this is the scene of this specific problebecause the fic problebecause the didness of the the seaway of the the seeing of this specific problem because the fart of this specific problem because the the fart of this specific problem because the specific problem because the problem because the fart of the the problem because the dididididididissent of this problem because the fic problem
2024-05-19 16:21:52,374 - INFO - joeynmt.training - Example #2
2024-05-19 16:21:52,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:21:52,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:21:52,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'i@@', 'f@@', 'ar', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ho@@', 't', 'is', 'in', 'the', 'N@@', 'or@@', 'th', 'in', 'the', 'c@@', 'lim@@', 'ate', 'of', 'us', 'he@@', 'ar@@', 't', 'of', 'us', 'and', 'he@@', 'ar@@', 't', 'system@@', '.', '</s>']
2024-05-19 16:21:52,375 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:21:52,375 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:21:52,375 - INFO - joeynmt.training - 	Hypothesis: The ifar on the North phot is in the North in the climate of us heart of us and heart system.
2024-05-19 16:21:52,375 - INFO - joeynmt.training - Example #3
2024-05-19 16:21:52,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:21:52,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:21:52,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 's@@', 'our@@', 'ce', 'in', 'the', 's@@', 'our@@', '.', '</s>']
2024-05-19 16:21:52,377 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:21:52,377 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:21:52,377 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crimpt and crimpt in the source in the sour.
2024-05-19 16:21:52,377 - INFO - joeynmt.training - Example #4
2024-05-19 16:21:52,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:21:52,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:21:52,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a', 'that', 'I', 'just', 'just', 'just', 'a', 'f@@', 're@@', 'e', 'of', 'what', 'the', 'de@@', 'ad', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'the', 'last', '2@@', '5', 'years', 'is', 'going', 'to', 'happ@@', 'en', 'is', 'happen@@', 'ed.', '</s>']
2024-05-19 16:21:52,378 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:21:52,379 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:21:52,379 - INFO - joeynmt.training - 	Hypothesis: The next dia that I just just just a free of what the dead of what the last 25 years is the last 25 years is going to happen is happened.
2024-05-19 16:21:55,675 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     1.998774, Batch Acc: 0.444836, Tokens per Sec:    20487, Lr: 0.000300
2024-05-19 16:21:59,186 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     1.938806, Batch Acc: 0.441411, Tokens per Sec:    20935, Lr: 0.000300
2024-05-19 16:22:03,241 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     1.917767, Batch Acc: 0.444288, Tokens per Sec:    18707, Lr: 0.000300
2024-05-19 16:22:06,813 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     1.848072, Batch Acc: 0.449931, Tokens per Sec:    20464, Lr: 0.000300
2024-05-19 16:22:10,053 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.835766, Batch Acc: 0.453018, Tokens per Sec:    22052, Lr: 0.000300
2024-05-19 16:22:10,054 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:22:10,054 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:22:22,296 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:22:22,296 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   7.63, loss:   2.19, ppl:   8.90, acc:   0.39, generation: 12.0139[sec], evaluation: 0.2117[sec]
2024-05-19 16:22:22,297 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:22:22,518 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/2000.ckpt
2024-05-19 16:22:22,533 - INFO - joeynmt.training - Example #0
2024-05-19 16:22:22,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:22:22,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:22:22,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'ye@@', 'ar', 'I', 'was', 'this', 'two', 'di@@', 'a@@', "'s", 'going', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 's', 'that', 'the', 'p@@', 'ool@@', 's', 'that', 'the', 'last', 'three', 'million', 'years', 'about', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'V@@', 'V@@', 'S@@', ',', 'with', '4@@', '0@@', ',', 'with', '4@@', '0@@', '0@@', '-@@', 'percent', 'c@@', 'ro@@', 'm@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:22:22,534 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:22:22,535 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:22:22,535 - INFO - joeynmt.training - 	Hypothesis: And I was a year I was this two dia's going to show that the pools that the pools that the last three million years about the last three million years of the VVS, with 40, with 400-percent cromroms.
2024-05-19 16:22:22,535 - INFO - joeynmt.training - Example #1
2024-05-19 16:22:22,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:22:22,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:22:22,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'n@@', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'because', 'the', 'same', 'thing', 'because', 'the', 'di@@', 'd@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'sa@@', 'w', 'of', 'the', 'sa@@', 'w', 'of', 'the', 'sa@@', 'w', 'of', 'the', 'sa@@', 'w', 'of', 'the', 'the', 'di@@', 'd@@', 'd@@', 'n@@', 'at@@', '.', '</s>']
2024-05-19 16:22:22,536 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:22:22,536 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:22:22,536 - INFO - joeynmt.training - 	Hypothesis: But this is the nice of this specific problebecause the same thing because the diddness of the saw of the saw of the saw of the saw of the the diddnat.
2024-05-19 16:22:22,537 - INFO - joeynmt.training - Example #2
2024-05-19 16:22:22,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:22:22,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:22:22,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'i@@', 'f@@', 'ar', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ool', 'is', 'in', 'se@@', 'x', 'is', 'in', 'the', 'cl@@', 'op@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'us', 'g@@', 'lob@@', 'al', 'he@@', 'ar@@', 't', 'of', 'us', 'g@@', 'lob@@', 'al', 'c@@', 'li@@', 'mat@@', 'e.', '</s>']
2024-05-19 16:22:22,538 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:22:22,538 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:22:22,538 - INFO - joeynmt.training - 	Hypothesis: The ifar on the North pool is in sex is in the cloping heart of us global heart of us global climate.
2024-05-19 16:22:22,538 - INFO - joeynmt.training - Example #3
2024-05-19 16:22:22,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:22:22,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:22:22,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'like', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 's@@', 'om@@', '.', '</s>']
2024-05-19 16:22:22,539 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:22:22,539 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:22:22,539 - INFO - joeynmt.training - 	Hypothesis: It looks like the winter and crimpt in the winter and crimpt in the som.
2024-05-19 16:22:22,540 - INFO - joeynmt.training - Example #4
2024-05-19 16:22:22,540 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:22:22,540 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:22:22,540 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'next', 'di@@', 'a', 'I', 'show', 'show', 'you', 'a', 'qu@@', 'ic@@', 'k', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'to', 'happ@@', 'y.', '</s>']
2024-05-19 16:22:22,541 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:22:22,541 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:22:22,541 - INFO - joeynmt.training - 	Hypothesis: And the next dia I show show you a quick of what the last 25 years is the last 25 years is happened to happy.
2024-05-19 16:22:25,781 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     2.197023, Batch Acc: 0.444965, Tokens per Sec:    21178, Lr: 0.000300
2024-05-19 16:22:29,344 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.981770, Batch Acc: 0.452050, Tokens per Sec:    20587, Lr: 0.000300
2024-05-19 16:22:33,547 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.945339, Batch Acc: 0.457720, Tokens per Sec:    17834, Lr: 0.000300
2024-05-19 16:22:36,880 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.029330, Batch Acc: 0.456009, Tokens per Sec:    22121, Lr: 0.000300
2024-05-19 16:22:40,145 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.801047, Batch Acc: 0.459390, Tokens per Sec:    22716, Lr: 0.000300
2024-05-19 16:22:40,146 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:22:40,146 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:22:51,653 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:22:51,653 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   7.87, loss:   2.15, ppl:   8.54, acc:   0.40, generation: 10.9750[sec], evaluation: 0.5169[sec]
2024-05-19 16:22:51,654 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:22:51,876 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/2500.ckpt
2024-05-19 16:22:51,890 - INFO - joeynmt.training - Example #0
2024-05-19 16:22:51,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:22:51,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:22:51,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'year@@', ',', 'I', 'was', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'et', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 's', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'last', 'three', 'million', 'years', 'about', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'V@@', 'S@@', ',', 'with', '4@@', '0@@', '-@@', 'percent', 'c@@', 'ro@@', 'm@@', 'p', 'of', 'the', 'V@@', 'S@@', ',', 'with', '4@@', '0@@', 's', 'of', 'the', 'U@@', '.@@', '.', '</s>']
2024-05-19 16:22:51,892 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:22:51,892 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:22:51,892 - INFO - joeynmt.training - 	Hypothesis: And I was a year, I was this two dia's set to show that the pools the pool, who had the last three million years about the vast three million years of the VS, with 40-percent cromp of the VS, with 40s of the U..
2024-05-19 16:22:51,892 - INFO - joeynmt.training - Example #1
2024-05-19 16:22:51,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:22:51,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:22:51,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'er@@', 'r@@', 'ate', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'because', 'the', 'same', 'thing', 'that', 'it', "didn't", 'see', 'the', 'ic@@', 'k@@', 's.', '</s>']
2024-05-19 16:22:51,893 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:22:51,893 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:22:51,893 - INFO - joeynmt.training - 	Hypothesis: But this is actually the errate of this specific problebecause the same thing that it didn't see the icks.
2024-05-19 16:22:51,894 - INFO - joeynmt.training - Example #2
2024-05-19 16:22:51,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:22:51,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:22:51,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'k', 'of', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ool', 'is', 'in', 'the', 'cl@@', 'op@@', 'e', 'in', 'the', 'cl@@', 'op@@', 's', 'of', 'our', 'g@@', 'lob@@', 'al', 'co@@', 'al', 'system@@', '.', '</s>']
2024-05-19 16:22:51,894 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:22:51,894 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:22:51,895 - INFO - joeynmt.training - 	Hypothesis: The ick of the North pool is in the clope in the clops of our global coal system.
2024-05-19 16:22:51,895 - INFO - joeynmt.training - Example #3
2024-05-19 16:22:51,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:22:51,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:22:51,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'si@@', 'x', 'in', 'the', 'si@@', 'x', 'in', 'the', 'si@@', 'x', 'of', 'the', 'z@@', 'om@@', 'e.', '</s>']
2024-05-19 16:22:51,895 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:22:51,896 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:22:51,896 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crimpt in the six in the six in the six of the zome.
2024-05-19 16:22:51,896 - INFO - joeynmt.training - Example #4
2024-05-19 16:22:51,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:22:51,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:22:51,896 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a', 'I', 'sho@@', 'ws', 'that', 'I', 'see', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:22:51,897 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:22:51,897 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:22:51,897 - INFO - joeynmt.training - 	Hypothesis: The next dia I shows that I see is a version of what the last 25 years.
2024-05-19 16:22:55,258 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.849867, Batch Acc: 0.460012, Tokens per Sec:    20531, Lr: 0.000300
2024-05-19 16:22:59,606 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.773961, Batch Acc: 0.465352, Tokens per Sec:    17097, Lr: 0.000300
2024-05-19 16:23:03,097 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.841118, Batch Acc: 0.466238, Tokens per Sec:    21529, Lr: 0.000300
2024-05-19 16:23:06,434 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.885223, Batch Acc: 0.472561, Tokens per Sec:    22721, Lr: 0.000300
2024-05-19 16:23:09,692 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.029148, Batch Acc: 0.467934, Tokens per Sec:    22468, Lr: 0.000300
2024-05-19 16:23:09,692 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:23:09,693 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:23:22,780 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:23:22,780 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   7.57, loss:   2.11, ppl:   8.25, acc:   0.41, generation: 12.8876[sec], evaluation: 0.1833[sec]
2024-05-19 16:23:22,781 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:23:23,016 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/3000.ckpt
2024-05-19 16:23:23,032 - INFO - joeynmt.training - Example #0
2024-05-19 16:23:23,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:23:23,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:23:23,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'ig', 'year@@', ',', 'I', 'was', 'this', 'two', 'di@@', 'a@@', "'s", 'show', 'that', 'the', 'p@@', 'ool@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'of', 'the', 'V@@', 'S@@', ',', 'with', '4@@', '0@@', ',', 'with', '4@@', '0@@', ',', 'with', '4@@', '0@@', ',', 'with', '4@@', '0@@', ',', '</s>']
2024-05-19 16:23:23,034 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:23:23,034 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:23:23,034 - INFO - joeynmt.training - 	Hypothesis: Forig year, I was this two dia's show that the pools to show that the pool, which was the last three million years of the United of the VS, with 40, with 40, with 40, with 40,
2024-05-19 16:23:23,034 - INFO - joeynmt.training - Example #1
2024-05-19 16:23:23,034 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:23:23,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:23:23,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'en@@', 'ti@@', 're', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'the', 'de@@', 'ser@@', 't', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm.', '</s>']
2024-05-19 16:23:23,035 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:23:23,035 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:23:23,036 - INFO - joeynmt.training - 	Hypothesis: But this is the entire of this specific problem because it doesn't the desert of the ice of the ice of the ice of the ice of this specific problem.
2024-05-19 16:23:23,036 - INFO - joeynmt.training - Example #2
2024-05-19 16:23:23,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:23:23,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:23:23,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'k', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ool', 'is', 'in', 'a', 'se@@', 'c@@', 'k', 'in', 'the', 'cl@@', 'op@@', 'p@@', 'le', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'li@@', 'mat@@', 'ter.', '</s>']
2024-05-19 16:23:23,037 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:23:23,037 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:23:23,037 - INFO - joeynmt.training - 	Hypothesis: The ick on the North pool is in a seck in the clopple of our global climatter.
2024-05-19 16:23:23,037 - INFO - joeynmt.training - Example #3
2024-05-19 16:23:23,037 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:23:23,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:23:23,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'like', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'si@@', 'de.', '</s>']
2024-05-19 16:23:23,038 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:23:23,038 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:23:23,038 - INFO - joeynmt.training - 	Hypothesis: It's like the winter and crimpt in the crimpt in the side.
2024-05-19 16:23:23,039 - INFO - joeynmt.training - Example #4
2024-05-19 16:23:23,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:23:23,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:23:23,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'next', 'di@@', 'a', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'very', 'qu@@', 'ic@@', 'k@@', 'ly', 'ex@@', 'pla@@', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'to', 'happ@@', 'en.', '</s>']
2024-05-19 16:23:23,040 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:23:23,040 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:23:23,040 - INFO - joeynmt.training - 	Hypothesis: And the next dia that I shows is a very quickly explain the last 25 years is happened 25 years is happened to happen.
2024-05-19 16:23:26,979 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     1.843892, Batch Acc: 0.468560, Tokens per Sec:    17599, Lr: 0.000300
2024-05-19 16:23:30,577 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     2.028884, Batch Acc: 0.472416, Tokens per Sec:    20482, Lr: 0.000300
2024-05-19 16:23:34,104 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     1.910190, Batch Acc: 0.471415, Tokens per Sec:    20976, Lr: 0.000300
2024-05-19 16:23:37,415 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     1.897506, Batch Acc: 0.476365, Tokens per Sec:    22071, Lr: 0.000300
2024-05-19 16:23:41,571 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.723660, Batch Acc: 0.475149, Tokens per Sec:    17898, Lr: 0.000300
2024-05-19 16:23:41,572 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:23:41,572 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:23:54,109 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:23:54,109 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   8.67, loss:   2.08, ppl:   8.00, acc:   0.42, generation: 12.1918[sec], evaluation: 0.3157[sec]
2024-05-19 16:23:54,110 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:23:54,377 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/3500.ckpt
2024-05-19 16:23:54,395 - INFO - joeynmt.training - Example #0
2024-05-19 16:23:54,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:23:54,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:23:54,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'year@@', ',', 'I', 'was', 'a', 'few', 'year@@', 's,', 'I', 'think', 'about', 'two', 'di@@', 'a@@', "'s", 's@@', 'et', 'of', 'the', 'p@@', 'ool@@', 's', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'b@@', 'ig@@', '.', '</s>']
2024-05-19 16:23:54,397 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:23:54,398 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:23:54,398 - INFO - joeynmt.training - 	Hypothesis: Fore year, I was a few years, I think about two dia's set of the pools of the last three million years of the last three million years of the big.
2024-05-19 16:23:54,398 - INFO - joeynmt.training - Example #1
2024-05-19 16:23:54,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:23:54,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:23:54,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'en@@', 'ti@@', 're', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'see', 'the', 'de@@', 'ser@@', 't', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:23:54,400 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:23:54,400 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:23:54,400 - INFO - joeynmt.training - 	Hypothesis: But this is actually the entire of this specific problem because it doesn't see the desert of the ice.
2024-05-19 16:23:54,400 - INFO - joeynmt.training - Example #2
2024-05-19 16:23:54,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:23:54,401 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:23:54,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'sk@@', 'in', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ool', 'is', 'in', 'se@@', 'c@@', 'li@@', 'mat@@', 'ter', 'in', 'the', 'cl@@', 'op@@', 'p@@', 'ing', 'of', 'us', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:23:54,401 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:23:54,402 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:23:54,402 - INFO - joeynmt.training - 	Hypothesis: The ice of skin the North pool is in seclimatter in the clopping of us global climate system.
2024-05-19 16:23:54,402 - INFO - joeynmt.training - Example #3
2024-05-19 16:23:54,402 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:23:54,402 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:23:54,402 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'going', 'to', 'be', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'si@@', 'z@@', 'er@@', 'o@@', '.', '</s>']
2024-05-19 16:23:54,403 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:23:54,403 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:23:54,403 - INFO - joeynmt.training - 	Hypothesis: It was going to be in the winter and crimpt in the sizero.
2024-05-19 16:23:54,403 - INFO - joeynmt.training - Example #4
2024-05-19 16:23:54,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:23:54,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:23:54,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'f@@', 'oun@@', 'd,', 'I', 'sho@@', 'ws', 'a', 's@@', 'qu@@', 'are', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'to', 'happ@@', 'en.', '</s>']
2024-05-19 16:23:54,405 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:23:54,405 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:23:54,405 - INFO - joeynmt.training - 	Hypothesis: The next found, I shows a square is a version of what the last 25 years is happened 25 years is happened to happen.
2024-05-19 16:23:59,446 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.854216, Batch Acc: 0.483348, Tokens per Sec:    13769, Lr: 0.000300
2024-05-19 16:24:02,892 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     1.908742, Batch Acc: 0.483958, Tokens per Sec:    21599, Lr: 0.000300
2024-05-19 16:24:06,251 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.637079, Batch Acc: 0.480604, Tokens per Sec:    21971, Lr: 0.000300
2024-05-19 16:24:10,052 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.980453, Batch Acc: 0.479454, Tokens per Sec:    19242, Lr: 0.000300
2024-05-19 16:24:13,790 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     1.808526, Batch Acc: 0.488956, Tokens per Sec:    19033, Lr: 0.000300
2024-05-19 16:24:13,790 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:24:13,791 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:24:26,188 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:24:26,188 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   8.70, loss:   2.06, ppl:   7.82, acc:   0.43, generation: 12.1813[sec], evaluation: 0.1994[sec]
2024-05-19 16:24:26,189 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:24:26,408 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/4000.ckpt
2024-05-19 16:24:26,436 - INFO - joeynmt.training - Example #0
2024-05-19 16:24:26,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:24:26,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:24:26,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'y', 'year@@', ',', 'I', 'sho@@', 't', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'et', 'that', 'the', 'p@@', 'ool@@', 's', 'of', 'the', 'p@@', 'ool@@', ',', 'who', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'was', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'va@@', 'il@@', 'able', 'of', 'the', 'V@@', 'S@@', ',', 'with', '4@@', '0@@', ',', 'with', '4@@', '0@@', ',', 'with', '4@@', '0@@', '-@@', 'cen@@', 'ter', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'V@@', 'or@@', 'ig', 'year@@', 's.', '</s>']
2024-05-19 16:24:26,438 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:24:26,438 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:24:26,438 - INFO - joeynmt.training - 	Hypothesis: Fory year, I shot this two dia's set that the pools of the pool, who was the pool, who was the last three million years of the vailable of the VS, with 40, with 40, with 40-center of the United States of the Vorig years.
2024-05-19 16:24:26,438 - INFO - joeynmt.training - Example #1
2024-05-19 16:24:26,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:24:26,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:24:26,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'su@@', 'p@@', 'po@@', 's@@', 'ed', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 's@@', 'li@@', 'de', 'of', 'the', 'ice', 'of', 'the', 'ear@@', 'ly', 'of', 'the', 'ear@@', 'ly', 'of', 'the', 'ear@@', 'ly', 'of', 'the', 'ear@@', 'ly', 'of', 'the', 'ear@@', 'ly', 'of', 'the', 'ear@@', 'ly', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'was', 'going', 'to', 'be', 'the', 'de@@', 'ser@@', 't', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm.', '</s>']
2024-05-19 16:24:26,439 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:24:26,440 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:24:26,440 - INFO - joeynmt.training - 	Hypothesis: But this is actually the supposed of this particular problem because it doesn't have the slide of the ice of the early of the early of the early of the early of the early of the early of this specific problem because it was going to be the desert of this specific problem.
2024-05-19 16:24:26,440 - INFO - joeynmt.training - Example #2
2024-05-19 16:24:26,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:24:26,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:24:26,441 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ool', 'in', 'se@@', 'qu@@', 'ence', 'in', 'a', 'sen@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:24:26,441 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:24:26,441 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:24:26,441 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North pool in sequence in a sense of our global climate system.
2024-05-19 16:24:26,442 - INFO - joeynmt.training - Example #3
2024-05-19 16:24:26,442 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:24:26,442 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:24:26,442 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 's@@', 'ha@@', 'p@@', 'e.', '</s>']
2024-05-19 16:24:26,443 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:24:26,443 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:24:26,443 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crimpt in the shape.
2024-05-19 16:24:26,443 - INFO - joeynmt.training - Example #4
2024-05-19 16:24:26,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:24:26,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:24:26,444 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'de@@', 'ser@@', 't', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'de@@', 'al', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed.', '</s>']
2024-05-19 16:24:26,444 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:24:26,444 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:24:26,444 - INFO - joeynmt.training - 	Hypothesis: The next desert that I shows is a version of what the deal of what the last 25 years is happened.
2024-05-19 16:24:29,759 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     1.876466, Batch Acc: 0.485643, Tokens per Sec:    20993, Lr: 0.000300
2024-05-19 16:24:33,167 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     1.872658, Batch Acc: 0.487063, Tokens per Sec:    21213, Lr: 0.000300
2024-05-19 16:24:36,768 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.798400, Batch Acc: 0.483786, Tokens per Sec:    19838, Lr: 0.000300
2024-05-19 16:24:40,718 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     1.724184, Batch Acc: 0.489637, Tokens per Sec:    18445, Lr: 0.000300
2024-05-19 16:24:44,011 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     1.853330, Batch Acc: 0.487918, Tokens per Sec:    22296, Lr: 0.000300
2024-05-19 16:24:44,012 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:24:44,012 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:24:56,102 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:24:56,102 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   9.61, loss:   2.03, ppl:   7.61, acc:   0.43, generation: 11.8857[sec], evaluation: 0.1881[sec]
2024-05-19 16:24:56,103 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:24:56,320 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/4500.ckpt
2024-05-19 16:24:56,337 - INFO - joeynmt.training - Example #0
2024-05-19 16:24:56,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:24:56,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:24:56,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'I', 'was', 'sho@@', 'wing', 'this', 'two', 'an@@', 'im@@', 'als', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 's', 'of', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'fa@@', 'st@@', 'ly', 'of', 'the', 'V@@', 'S@@', ',', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:24:56,339 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:24:56,339 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:24:56,339 - INFO - joeynmt.training - 	Hypothesis: Fore I was showing this two animals to show that the pools of the pool, who had the pool, who had the last three million years of the fastly of the VS, with 40 percent of the U.S.
2024-05-19 16:24:56,339 - INFO - joeynmt.training - Example #1
2024-05-19 16:24:56,340 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:24:56,340 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:24:56,340 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'en@@', 'ter@@', 'n@@', 'al', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'an@@', 'im@@', 'als', 'of', 'the', 'ic@@', 'le@@', 's.', '</s>']
2024-05-19 16:24:56,340 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:24:56,341 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:24:56,341 - INFO - joeynmt.training - 	Hypothesis: But this is actually the enternal problem because it doesn't have the animals of the icles.
2024-05-19 16:24:56,341 - INFO - joeynmt.training - Example #2
2024-05-19 16:24:56,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:24:56,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:24:56,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ool', 'is', 'in', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ool', 'in', 'the', 'cl@@', 'op@@', 'p@@', 'le', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:24:56,342 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:24:56,342 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:24:56,342 - INFO - joeynmt.training - 	Hypothesis: The ice of the North pool is in the North pool in the clopple of our global climate system.
2024-05-19 16:24:56,343 - INFO - joeynmt.training - Example #3
2024-05-19 16:24:56,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:24:56,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:24:56,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'called', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:24:56,344 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:24:56,344 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:24:56,344 - INFO - joeynmt.training - 	Hypothesis: It's called the winter and crimpt in the sumer and crimpt in the summer.
2024-05-19 16:24:56,344 - INFO - joeynmt.training - Example #4
2024-05-19 16:24:56,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:24:56,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:24:56,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'an@@', 'im@@', 'a', 'that', 'I', 'show', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'de@@', 'p@@', 'pl@@', 'ant', 'is', 'a', 'f@@', 'ast', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ing.', '</s>']
2024-05-19 16:24:56,345 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:24:56,345 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:24:56,345 - INFO - joeynmt.training - 	Hypothesis: The next anima that I show is a version of what the depplant is a fast 25 years is happened 25 years is happening.
2024-05-19 16:24:59,629 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     1.777554, Batch Acc: 0.488108, Tokens per Sec:    20619, Lr: 0.000300
2024-05-19 16:25:02,979 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     1.772116, Batch Acc: 0.489563, Tokens per Sec:    21781, Lr: 0.000300
2024-05-19 16:25:07,303 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     1.651927, Batch Acc: 0.498564, Tokens per Sec:    17237, Lr: 0.000300
2024-05-19 16:25:10,638 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     1.768728, Batch Acc: 0.489649, Tokens per Sec:    22165, Lr: 0.000300
2024-05-19 16:25:13,954 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     2.058502, Batch Acc: 0.495229, Tokens per Sec:    21621, Lr: 0.000300
2024-05-19 16:25:13,955 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:25:13,955 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:25:26,886 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:25:26,886 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   9.50, loss:   2.01, ppl:   7.46, acc:   0.44, generation: 12.7320[sec], evaluation: 0.1831[sec]
2024-05-19 16:25:26,887 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:25:27,110 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/5000.ckpt
2024-05-19 16:25:27,125 - INFO - joeynmt.training - Example #0
2024-05-19 16:25:27,126 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:25:27,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:25:27,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'sho@@', 'wing', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'a@@', "'s", 's@@', 'li@@', 'p', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 's', 'that', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'fa@@', 'st@@', 'ly', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:25:27,127 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:25:27,127 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:25:27,128 - INFO - joeynmt.training - 	Hypothesis: And I was showing this two dia's sa's slip to show that the pools that the last three million years of the last three million years of the fastly three million years of the United States,
2024-05-19 16:25:27,128 - INFO - joeynmt.training - Example #1
2024-05-19 16:25:27,128 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:25:27,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:25:27,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'en@@', 'ti@@', 're', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm.', '</s>']
2024-05-19 16:25:27,129 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:25:27,129 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:25:27,129 - INFO - joeynmt.training - 	Hypothesis: But this is actually the entire of this specific problem because it doesn't have the didness of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of this specific problem.
2024-05-19 16:25:27,129 - INFO - joeynmt.training - Example #2
2024-05-19 16:25:27,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:25:27,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:25:27,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'is', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'il', 'is', 'in', 'a', 'sen@@', 'se', 'of', 's@@', 'qu@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:25:27,130 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:25:27,131 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:25:27,131 - INFO - joeynmt.training - 	Hypothesis: The ice is on the North Poil is in a sense of squart of our global climate system.
2024-05-19 16:25:27,131 - INFO - joeynmt.training - Example #3
2024-05-19 16:25:27,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:25:27,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:25:27,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'called', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'si@@', 'x', 'in', 'the', 'si@@', 'x', 'in', 'the', 'si@@', 'x@@', '.', '</s>']
2024-05-19 16:25:27,132 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:25:27,132 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:25:27,132 - INFO - joeynmt.training - 	Hypothesis: It's called in the winter and crimpt in the six in the six in the six.
2024-05-19 16:25:27,132 - INFO - joeynmt.training - Example #4
2024-05-19 16:25:27,133 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:25:27,133 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:25:27,133 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'o,', 'I', 'show', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'to', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed.', '</s>']
2024-05-19 16:25:27,133 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:25:27,134 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:25:27,134 - INFO - joeynmt.training - 	Hypothesis: The next so, I show is a version of what happened is a version of what happened to the last 25 years is happened.
2024-05-19 16:25:30,436 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     1.903776, Batch Acc: 0.493946, Tokens per Sec:    19990, Lr: 0.000300
2024-05-19 16:25:34,728 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     1.878204, Batch Acc: 0.496138, Tokens per Sec:    17013, Lr: 0.000300
2024-05-19 16:25:38,221 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     1.665625, Batch Acc: 0.506017, Tokens per Sec:    21274, Lr: 0.000300
2024-05-19 16:25:41,590 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     1.530479, Batch Acc: 0.498557, Tokens per Sec:    21287, Lr: 0.000300
2024-05-19 16:25:43,387 - INFO - joeynmt.training - Epoch   2: total training loss 7409.35
2024-05-19 16:25:43,388 - INFO - joeynmt.training - EPOCH 3
2024-05-19 16:25:44,905 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     1.767156, Batch Acc: 0.526358, Tokens per Sec:    22060, Lr: 0.000300
2024-05-19 16:25:44,905 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:25:44,906 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:25:57,817 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:25:57,817 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   9.00, loss:   1.98, ppl:   7.26, acc:   0.44, generation: 12.7081[sec], evaluation: 0.1854[sec]
2024-05-19 16:25:57,818 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:25:58,047 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/5500.ckpt
2024-05-19 16:25:58,064 - INFO - joeynmt.training - Example #0
2024-05-19 16:25:58,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:25:58,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:25:58,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'years', 'I', 'was', 'sho@@', 'wing', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'et', 'that', 'the', 'p@@', 'ool@@', 's', 'the', 'p@@', 'ool@@', ',', 'who', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'h', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0@@', '-@@', 'percent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:25:58,066 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:25:58,066 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:25:58,066 - INFO - joeynmt.training - 	Hypothesis: Fore years I was showing these two dia's set that the pools the pool, who was the pool, who had the last three million years of the United Stath of the United States, with 40-percent croms.
2024-05-19 16:25:58,066 - INFO - joeynmt.training - Example #1
2024-05-19 16:25:58,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:25:58,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:25:58,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'en@@', 'gin@@', 'eer@@', 'ing', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'because', 'it', "doesn't", 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'proble@@', 'm', 'because', 'it', 'is', 'the', 'di@@', 'd@@', 'n@@', 'at@@', 'ure', 'of', 'the', 'ice', 'of', 'the']
2024-05-19 16:25:58,068 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:25:58,068 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:25:58,068 - INFO - joeynmt.training - 	Hypothesis: But this is actually the engineering of this particular problebecause it doesn't the didness of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice problem because it is the didnature of the ice of the
2024-05-19 16:25:58,068 - INFO - joeynmt.training - Example #2
2024-05-19 16:25:58,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:25:58,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:25:58,069 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'ice', 'ice', 'is', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ool', 'is', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'cl@@', 'op@@', 'p@@', 'ing', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'li@@', 'mat@@', 'ter', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'li@@', 'mat@@', 'e.', '</s>']
2024-05-19 16:25:58,069 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:25:58,069 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:25:58,069 - INFO - joeynmt.training - 	Hypothesis: The ice ice ice is on the North pool is in a sense of the clopping of our global climatter of our global climate.
2024-05-19 16:25:58,070 - INFO - joeynmt.training - Example #3
2024-05-19 16:25:58,070 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:25:58,070 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:25:58,070 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'called', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'sen@@', 'se', 'in', 'the', 'si@@', 'mil@@', 'ar', 'in', 'the', 'si@@', 'mil@@', 'ar@@', '.', '</s>']
2024-05-19 16:25:58,070 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:25:58,070 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:25:58,071 - INFO - joeynmt.training - 	Hypothesis: It's called the winter and crimpt in the sense in the similar in the similar.
2024-05-19 16:25:58,071 - INFO - joeynmt.training - Example #4
2024-05-19 16:25:58,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:25:58,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:25:58,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a', 'that', 'I', 'sho@@', 'ws', 'that', 'I', 'sho@@', 'ws', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'to', 'happ@@', 'en.', '</s>']
2024-05-19 16:25:58,071 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:25:58,071 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:25:58,072 - INFO - joeynmt.training - 	Hypothesis: The next dia that I shows that I shows a version of what the last 25 years is happened to happen.
2024-05-19 16:26:02,046 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     1.974744, Batch Acc: 0.515137, Tokens per Sec:    17296, Lr: 0.000300
2024-05-19 16:26:05,666 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     1.635437, Batch Acc: 0.517572, Tokens per Sec:    20600, Lr: 0.000300
2024-05-19 16:26:09,127 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     1.686640, Batch Acc: 0.517721, Tokens per Sec:    22007, Lr: 0.000300
2024-05-19 16:26:12,418 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     1.680502, Batch Acc: 0.517827, Tokens per Sec:    22855, Lr: 0.000300
2024-05-19 16:26:16,652 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     1.849571, Batch Acc: 0.514439, Tokens per Sec:    17169, Lr: 0.000300
2024-05-19 16:26:16,656 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:26:16,657 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:26:27,809 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:26:27,810 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.60, loss:   1.97, ppl:   7.20, acc:   0.44, generation: 10.7983[sec], evaluation: 0.3216[sec]
2024-05-19 16:26:27,811 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:26:28,077 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/6000.ckpt
2024-05-19 16:26:28,106 - INFO - joeynmt.training - Example #0
2024-05-19 16:26:28,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:26:28,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:26:28,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'li@@', 'p@@', ',', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'fa@@', 'st@@', 'ly', 'of', 'the', 'fa@@', 'st@@', 'ly', 'of', 'the', 'V@@', 'S@@', 'S@@', ',', 'with', '4@@', '0@@', '-@@', '4@@', '0', 'percent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:26:28,108 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:26:28,108 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:26:28,108 - INFO - joeynmt.training - 	Hypothesis: And I was a year I showed this two dia's slip, that the pool, who the pool, who had the last three million years of the fastly of the fastly of the VSS, with 40-40 percent croms.
2024-05-19 16:26:28,108 - INFO - joeynmt.training - Example #1
2024-05-19 16:26:28,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:26:28,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:26:28,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'er@@', 'n@@', 's', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'the', 'di@@', 'sa@@', 'p@@', 'pe@@', 'ar@@', 'ing', 'the', 'di@@', 'sa@@', 'p@@', 'pe@@', 'ar@@', 'ing', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'di@@', 'sa@@', 'p@@', 'pe@@', 'ac@@', 'e.', '</s>']
2024-05-19 16:26:28,110 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:26:28,110 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:26:28,110 - INFO - joeynmt.training - 	Hypothesis: But this is actually the erns of this particular problem because it doesn't the disappearing the disappearing the ice of the ice of the ice of the ice of the ice of the ice of the disappeace.
2024-05-19 16:26:28,110 - INFO - joeynmt.training - Example #2
2024-05-19 16:26:28,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:26:28,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:26:28,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'is', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'il@@', 'l', 'is', 'in', 'a', 'se@@', 'qu@@', 'ence', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:26:28,111 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:26:28,112 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:26:28,112 - INFO - joeynmt.training - 	Hypothesis: The ice is the North Poill is in a sequence of our global climate system.
2024-05-19 16:26:28,112 - INFO - joeynmt.training - Example #3
2024-05-19 16:26:28,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:26:28,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:26:28,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'si@@', 'x@@', '.', '</s>']
2024-05-19 16:26:28,113 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:26:28,113 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:26:28,113 - INFO - joeynmt.training - 	Hypothesis: It is in the winter and crimpt in the six.
2024-05-19 16:26:28,113 - INFO - joeynmt.training - Example #4
2024-05-19 16:26:28,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:26:28,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:26:28,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a', 'that', 'I', 'sho@@', 'ws', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:26:28,114 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:26:28,115 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:26:28,115 - INFO - joeynmt.training - 	Hypothesis: The next dia that I shows that I shows is a version of what the last 25 years.
2024-05-19 16:26:32,089 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     1.536460, Batch Acc: 0.518062, Tokens per Sec:    17113, Lr: 0.000300
2024-05-19 16:26:35,380 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     1.620230, Batch Acc: 0.516808, Tokens per Sec:    22591, Lr: 0.000300
2024-05-19 16:26:38,824 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     1.665163, Batch Acc: 0.522611, Tokens per Sec:    21757, Lr: 0.000300
2024-05-19 16:26:42,520 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.547946, Batch Acc: 0.514781, Tokens per Sec:    19923, Lr: 0.000300
2024-05-19 16:26:46,401 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.693216, Batch Acc: 0.515068, Tokens per Sec:    18563, Lr: 0.000300
2024-05-19 16:26:46,402 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:26:46,402 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:26:59,128 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:26:59,129 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   9.72, loss:   1.96, ppl:   7.13, acc:   0.45, generation: 12.5153[sec], evaluation: 0.1952[sec]
2024-05-19 16:26:59,130 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:26:59,348 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/6500.ckpt
2024-05-19 16:26:59,376 - INFO - joeynmt.training - Example #0
2024-05-19 16:26:59,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:26:59,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:26:59,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'ig', 'years', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'va@@', 'il@@', 'able', 'of', 'the', 'V@@', 'S@@', ',', 'with', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'S@@', ',', 'with', '4@@', '0@@', '-@@', 'percent', 'c@@', 'ro@@', 'm@@', 'p', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:26:59,378 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:26:59,378 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:26:59,379 - INFO - joeynmt.training - 	Hypothesis: Forig years I showed these two dia's to show that the pool, which was the pool, who had the last three million years of the vailable of the VS, with 40-percent of the S, with 40-percent cromp of the U.S.
2024-05-19 16:26:59,379 - INFO - joeynmt.training - Example #1
2024-05-19 16:26:59,379 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:26:59,379 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:26:59,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'is', 'actually', 'the', 'first', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'because', 'it', "doesn't", 'have', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'proble@@', 'm.', '</s>']
2024-05-19 16:26:59,380 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:26:59,380 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:26:59,380 - INFO - joeynmt.training - 	Hypothesis: But this particular is actually the first of this particular problebecause it doesn't have the didness of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice problem.
2024-05-19 16:26:59,381 - INFO - joeynmt.training - Example #2
2024-05-19 16:26:59,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:26:59,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:26:59,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'ice', 'is', 'in', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'se', 'is', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'cl@@', 'op@@', 'p@@', 'ing', 'of', 'our', 'g@@', 'lob@@', 'al', 'system@@', '.', '</s>']
2024-05-19 16:26:59,382 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:26:59,382 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:26:59,382 - INFO - joeynmt.training - 	Hypothesis: The ice of ice is in the North Pose is in a sense of the clopping of our global system.
2024-05-19 16:26:59,382 - INFO - joeynmt.training - Example #3
2024-05-19 16:26:59,383 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:26:59,383 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:26:59,383 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'called', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'sen@@', 'se.', '</s>']
2024-05-19 16:26:59,383 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:26:59,384 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:26:59,384 - INFO - joeynmt.training - 	Hypothesis: It's called the winter and crimpt in the sense.
2024-05-19 16:26:59,384 - INFO - joeynmt.training - Example #4
2024-05-19 16:26:59,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:26:59,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:26:59,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'di@@', 'a', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ing.', '</s>']
2024-05-19 16:26:59,385 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:26:59,385 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:26:59,385 - INFO - joeynmt.training - 	Hypothesis: The next dia that I shows is a version of what the last 25 years is happened 25 years is happened 25 years is happened 25 years is happening.
2024-05-19 16:27:02,678 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.692695, Batch Acc: 0.518193, Tokens per Sec:    20732, Lr: 0.000300
2024-05-19 16:27:05,968 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.553059, Batch Acc: 0.522012, Tokens per Sec:    22886, Lr: 0.000300
2024-05-19 16:27:09,596 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.671944, Batch Acc: 0.525664, Tokens per Sec:    19782, Lr: 0.000300
2024-05-19 16:27:13,646 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     1.657104, Batch Acc: 0.522697, Tokens per Sec:    18416, Lr: 0.000300
2024-05-19 16:27:16,974 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     1.712016, Batch Acc: 0.523348, Tokens per Sec:    21852, Lr: 0.000300
2024-05-19 16:27:16,974 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:27:16,975 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:27:30,075 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:27:30,075 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.20, loss:   1.95, ppl:   7.01, acc:   0.45, generation: 12.8955[sec], evaluation: 0.1887[sec]
2024-05-19 16:27:30,076 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:27:30,297 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/7000.ckpt
2024-05-19 16:27:30,313 - INFO - joeynmt.training - Example #0
2024-05-19 16:27:30,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:27:30,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:27:30,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'ig', 'year@@', ',', 'I', 'just', 'sho@@', 'w@@', 'ed', 'this', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ate', 'of', 'the', 'V@@', 'S@@', ',', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', '4@@', '0', 'percent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:27:30,314 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:27:30,315 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:27:30,315 - INFO - joeynmt.training - 	Hypothesis: Forig year, I just showed this two dia's to show that the pools to show that the pool, who had the last three million years of the vastate of the VS, with 40 percent of the United States of the United States was 40 percent croms.
2024-05-19 16:27:30,315 - INFO - joeynmt.training - Example #1
2024-05-19 16:27:30,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:27:30,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:27:30,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ex@@', 'tra@@', 'or@@', 'din@@', 'ary', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'an@@', 'im@@', 'al@@', 's.', '</s>']
2024-05-19 16:27:30,316 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:27:30,316 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:27:30,317 - INFO - joeynmt.training - 	Hypothesis: But this is actually the extraordinary problem because it doesn't have the animals.
2024-05-19 16:27:30,317 - INFO - joeynmt.training - Example #2
2024-05-19 16:27:30,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:27:30,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:27:30,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'i@@', 'an', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'se', 'is', 'in', 'a', 'sen@@', 'se,', 'in', 'the', 'cl@@', 'op@@', 'p@@', 'le', 'is', 'in', 'the', 'cl@@', 'op@@', 'p@@', 'ed', 'of', 'our', 'g@@', 'lob@@', 'al', 'syste@@', 'm', '</s>']
2024-05-19 16:27:30,318 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:27:30,318 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:27:30,318 - INFO - joeynmt.training - 	Hypothesis: The ician on the North Pose is in a sense, in the clopple is in the clopped of our global system
2024-05-19 16:27:30,318 - INFO - joeynmt.training - Example #3
2024-05-19 16:27:30,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:27:30,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:27:30,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'just', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 's', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', 's', 'in', 'the', 's@@', 'ha@@', 'p@@', 'e.', '</s>']
2024-05-19 16:27:30,320 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:27:30,320 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:27:30,320 - INFO - joeynmt.training - 	Hypothesis: It's just in the winter and crimpt in the summer and crimps in the summer and crimpt in the summer and crimpt in the summers in the shape.
2024-05-19 16:27:30,320 - INFO - joeynmt.training - Example #4
2024-05-19 16:27:30,321 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:27:30,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:27:30,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'de@@', 'f@@', 'er', 'of', 'what', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', '</s>']
2024-05-19 16:27:30,321 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:27:30,322 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:27:30,322 - INFO - joeynmt.training - 	Hypothesis: And the next slide I show is a version of what happened the defer of what happened 25 years is happened 25 years is happened 25 years is happened 25 years
2024-05-19 16:27:33,646 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     1.554339, Batch Acc: 0.524573, Tokens per Sec:    20636, Lr: 0.000300
2024-05-19 16:27:37,059 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     1.675789, Batch Acc: 0.524837, Tokens per Sec:    21996, Lr: 0.000300
2024-05-19 16:27:41,393 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     1.782176, Batch Acc: 0.522173, Tokens per Sec:    17016, Lr: 0.000300
2024-05-19 16:27:44,728 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.550380, Batch Acc: 0.525654, Tokens per Sec:    21887, Lr: 0.000300
2024-05-19 16:27:48,059 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     1.625858, Batch Acc: 0.524399, Tokens per Sec:    22132, Lr: 0.000300
2024-05-19 16:27:48,059 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:27:48,060 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:28:00,940 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:28:00,940 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.75, loss:   1.93, ppl:   6.92, acc:   0.45, generation: 12.6741[sec], evaluation: 0.1870[sec]
2024-05-19 16:28:00,941 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:28:01,159 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/7500.ckpt
2024-05-19 16:28:01,172 - INFO - joeynmt.training - Example #0
2024-05-19 16:28:01,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:28:01,173 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:28:01,173 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de', 'of', 'the', 'p@@', 'ool@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 's', 'the', 'p@@', 'ool@@', 's', 'of', 'the', 'last', 'three', 'million', 'years', 'about', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ate', 'of', 'the', 'V@@', 'S@@', ',', 'with', '4@@', '0', 'percent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:28:01,174 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:28:01,174 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:28:01,174 - INFO - joeynmt.training - 	Hypothesis: And I showed these two slide of the pools to show that the pools the pools of the last three million years about the last three million years of the vastate of the VS, with 40 percent croms.
2024-05-19 16:28:01,174 - INFO - joeynmt.training - Example #1
2024-05-19 16:28:01,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:28:01,175 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:28:01,175 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'en@@', 'ter@@', 'ed', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'get', 'the', 's@@', 'li@@', 'de', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'thing', 'that', 'we', 'do', 'the', 'di@@', 'd.', '</s>']
2024-05-19 16:28:01,175 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:28:01,176 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:28:01,176 - INFO - joeynmt.training - 	Hypothesis: But this is actually the entered of this specific problem because it doesn't get the slide of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice thing that we do the did.
2024-05-19 16:28:01,176 - INFO - joeynmt.training - Example #2
2024-05-19 16:28:01,176 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:28:01,176 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:28:01,177 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'li@@', 'mat@@', 'ing', 'he@@', 'ar@@', 't', 'system@@', '.', '</s>']
2024-05-19 16:28:01,177 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:28:01,177 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:28:01,177 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a sense of our global climating heart system.
2024-05-19 16:28:01,177 - INFO - joeynmt.training - Example #3
2024-05-19 16:28:01,178 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:28:01,178 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:28:01,178 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'going', 'to', 'get', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'si@@', 'x@@', '.', '</s>']
2024-05-19 16:28:01,179 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:28:01,179 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:28:01,179 - INFO - joeynmt.training - 	Hypothesis: It's going to get in the winter and crimpt in the six.
2024-05-19 16:28:01,179 - INFO - joeynmt.training - Example #4
2024-05-19 16:28:01,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:28:01,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:28:01,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:28:01,180 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:28:01,180 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:28:01,180 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a version of what happened the last 25 years.
2024-05-19 16:28:04,464 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     1.480922, Batch Acc: 0.525536, Tokens per Sec:    20860, Lr: 0.000300
2024-05-19 16:28:09,007 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     1.513830, Batch Acc: 0.525331, Tokens per Sec:    16379, Lr: 0.000300
2024-05-19 16:28:12,348 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.807961, Batch Acc: 0.529655, Tokens per Sec:    21403, Lr: 0.000300
2024-05-19 16:28:15,734 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     1.588344, Batch Acc: 0.523383, Tokens per Sec:    21751, Lr: 0.000300
2024-05-19 16:28:19,298 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.646617, Batch Acc: 0.526068, Tokens per Sec:    20783, Lr: 0.000300
2024-05-19 16:28:19,298 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:28:19,298 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:28:30,139 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:28:30,139 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.76, loss:   1.92, ppl:   6.80, acc:   0.46, generation: 10.6279[sec], evaluation: 0.1968[sec]
2024-05-19 16:28:30,140 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:28:30,361 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/8000.ckpt
2024-05-19 16:28:30,374 - INFO - joeynmt.training - Example #0
2024-05-19 16:28:30,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:28:30,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:28:30,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'ig', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'li@@', 'p', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'p@@', 'ool@@', 's', 'of', 'the', 'va@@', 'il@@', 'able', 'of', 'the', 'va@@', 'st@@', 'able', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'S@@', ',', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:28:30,376 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:28:30,376 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:28:30,376 - INFO - joeynmt.training - 	Hypothesis: Forig year I showed these two dia's slip to show that the pool, who had the pools of the vailable of the vastable of the U.S, with 40 percent of the U.S. S, with 40 percent of the U.S.
2024-05-19 16:28:30,376 - INFO - joeynmt.training - Example #1
2024-05-19 16:28:30,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:28:30,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:28:30,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'sc@@', 'at', 'the', 'first', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'the', 'an@@', 'im@@', 'als', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:28:30,378 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:28:30,378 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:28:30,378 - INFO - joeynmt.training - 	Hypothesis: But this is the scat the first of this specific problem because it doesn't the animals of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice.
2024-05-19 16:28:30,378 - INFO - joeynmt.training - Example #2
2024-05-19 16:28:30,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:28:30,379 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:28:30,379 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 's@@', 'he@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'sen@@', 'se', 'of', 'the', 's@@', 'qu@@', 'are', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:28:30,379 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:28:30,379 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:28:30,379 - INFO - joeynmt.training - 	Hypothesis: The ice sheap on the North Pole is in a sense of the square of our global climate system.
2024-05-19 16:28:30,380 - INFO - joeynmt.training - Example #3
2024-05-19 16:28:30,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:28:30,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:28:30,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'called', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 's', 'in', 'the', 's@@', 'he@@', 'at@@', '.', '</s>']
2024-05-19 16:28:30,381 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:28:30,381 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:28:30,381 - INFO - joeynmt.training - 	Hypothesis: It's called in the winter and crimps in the sheat.
2024-05-19 16:28:30,381 - INFO - joeynmt.training - Example #4
2024-05-19 16:28:30,382 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:28:30,382 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:28:30,382 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de@@', 's', 'I', 'sho@@', 'wing', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'is', 'happen@@', 'ing', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ing.', '</s>']
2024-05-19 16:28:30,382 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:28:30,382 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:28:30,383 - INFO - joeynmt.training - 	Hypothesis: The next slides I showing is a version of what is happening the last 25 years is happening 25 years is happened 25 years is happening.
2024-05-19 16:28:34,029 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.467361, Batch Acc: 0.527753, Tokens per Sec:    19141, Lr: 0.000300
2024-05-19 16:28:38,125 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     1.620010, Batch Acc: 0.531928, Tokens per Sec:    17995, Lr: 0.000300
2024-05-19 16:28:41,615 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     1.678863, Batch Acc: 0.528297, Tokens per Sec:    21107, Lr: 0.000300
2024-05-19 16:28:45,101 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     1.544114, Batch Acc: 0.528864, Tokens per Sec:    21734, Lr: 0.000300
2024-05-19 16:28:49,982 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     1.692146, Batch Acc: 0.534028, Tokens per Sec:    15207, Lr: 0.000300
2024-05-19 16:28:49,982 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:28:49,982 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:29:01,970 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:29:01,971 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.78, loss:   1.91, ppl:   6.77, acc:   0.46, generation: 11.7377[sec], evaluation: 0.2340[sec]
2024-05-19 16:29:01,972 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:29:02,246 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/8500.ckpt
2024-05-19 16:29:02,265 - INFO - joeynmt.training - Example #0
2024-05-19 16:29:02,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:29:02,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:29:02,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'p@@', 'ul@@', 'l', 'of', 'the', 'va@@', 'st@@', 'ate', 'of', 'the', 'va@@', 'a@@', 'st@@', 'om@@', 's', 'of', 'the', 'va@@', 'a@@', 'st@@', 'om@@', '.', '</s>']
2024-05-19 16:29:02,268 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:29:02,268 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:29:02,268 - INFO - joeynmt.training - 	Hypothesis: And I showed these two dia's to show that the pool, that the pool, who had the pool, who had the pull of the vastate of the vaastoms of the vaastom.
2024-05-19 16:29:02,268 - INFO - joeynmt.training - Example #1
2024-05-19 16:29:02,269 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:29:02,269 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:29:02,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'di@@', 'd@@', 'ded', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:29:02,270 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:29:02,270 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:29:02,270 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this particular problem because it doesn't have the didded of the ice of the ice of the ice of the ice.
2024-05-19 16:29:02,270 - INFO - joeynmt.training - Example #2
2024-05-19 16:29:02,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:29:02,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:29:02,271 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'in', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'cl@@', 'op@@', 'p@@', 'ing', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:29:02,271 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:29:02,271 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:29:02,272 - INFO - joeynmt.training - 	Hypothesis: The ice skin on the North Pole, in a sense of the clopping of our global climate system.
2024-05-19 16:29:02,272 - INFO - joeynmt.training - Example #3
2024-05-19 16:29:02,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:29:02,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:29:02,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'going', 'to', 'be', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'ing', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'ing', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 's@@', 'un@@', '.', '</s>']
2024-05-19 16:29:02,273 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:29:02,273 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:29:02,273 - INFO - joeynmt.training - 	Hypothesis: It was going to be in the winter and crimpt in the summer and crimpt in the summer and crimpt in the summing and crimpt in the summing and crimpt in the sun.
2024-05-19 16:29:02,273 - INFO - joeynmt.training - Example #4
2024-05-19 16:29:02,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:29:02,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:29:02,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'to', 'be', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing.', '</s>']
2024-05-19 16:29:02,274 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:29:02,275 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:29:02,275 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a version of what happened the last 25 years is happened 25 years is happened to be happened in the last 25 years is happening.
2024-05-19 16:29:06,532 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     1.675125, Batch Acc: 0.532158, Tokens per Sec:    16282, Lr: 0.000300
2024-05-19 16:29:10,038 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.558721, Batch Acc: 0.528600, Tokens per Sec:    21224, Lr: 0.000300
2024-05-19 16:29:13,382 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     1.774822, Batch Acc: 0.534839, Tokens per Sec:    22032, Lr: 0.000300
2024-05-19 16:29:16,976 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     1.658233, Batch Acc: 0.532818, Tokens per Sec:    19980, Lr: 0.000300
2024-05-19 16:29:21,016 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     1.674008, Batch Acc: 0.538443, Tokens per Sec:    18148, Lr: 0.000300
2024-05-19 16:29:21,017 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:29:21,017 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:29:33,958 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:29:33,958 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.02, loss:   1.90, ppl:   6.67, acc:   0.46, generation: 12.7264[sec], evaluation: 0.1855[sec]
2024-05-19 16:29:33,959 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:29:34,185 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/9000.ckpt
2024-05-19 16:29:34,201 - INFO - joeynmt.training - Example #0
2024-05-19 16:29:34,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:29:34,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:29:34,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'sho@@', 'wing', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'to', 'show', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es.', '</s>']
2024-05-19 16:29:34,204 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:29:34,204 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:29:34,204 - INFO - joeynmt.training - 	Hypothesis: And I was showing these two dia's slides to show that the past three million years to show the last three million years of the last three million years of the vast three million years of the United States, with 40 percent of the United States.
2024-05-19 16:29:34,205 - INFO - joeynmt.training - Example #1
2024-05-19 16:29:34,205 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:29:34,205 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:29:34,205 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'sc@@', 're@@', 'e', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'di@@', 'd@@', 'ded', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:29:34,206 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:29:34,206 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:29:34,206 - INFO - joeynmt.training - 	Hypothesis: But this is the scree of this particular problem because it doesn't have the didded of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice.
2024-05-19 16:29:34,206 - INFO - joeynmt.training - Example #2
2024-05-19 16:29:34,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:29:34,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:29:34,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'l', 'is', 'in', 'the', 'cl@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:29:34,208 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:29:34,208 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:29:34,208 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pol is in the clopping heart of our global climate system.
2024-05-19 16:29:34,208 - INFO - joeynmt.training - Example #3
2024-05-19 16:29:34,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:29:34,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:29:34,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'called', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:29:34,209 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:29:34,210 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:29:34,210 - INFO - joeynmt.training - 	Hypothesis: It's called in the winter and crimpt in the summer.
2024-05-19 16:29:34,210 - INFO - joeynmt.training - Example #4
2024-05-19 16:29:34,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:29:34,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:29:34,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de@@', 's', 'I', 'show', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'to', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed.', '</s>']
2024-05-19 16:29:34,211 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:29:34,212 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:29:34,212 - INFO - joeynmt.training - 	Hypothesis: The next slides I show is a version of what happened the last 25 years is happened to the last 25 years is happened.
2024-05-19 16:29:37,539 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     1.775220, Batch Acc: 0.533604, Tokens per Sec:    20637, Lr: 0.000300
2024-05-19 16:29:40,959 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     1.706538, Batch Acc: 0.529731, Tokens per Sec:    20771, Lr: 0.000300
2024-05-19 16:29:44,440 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     1.415298, Batch Acc: 0.539644, Tokens per Sec:    20992, Lr: 0.000300
2024-05-19 16:29:48,618 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     1.541916, Batch Acc: 0.540917, Tokens per Sec:    17738, Lr: 0.000300
2024-05-19 16:29:49,643 - INFO - joeynmt.training - Epoch   3: total training loss 6595.81
2024-05-19 16:29:49,644 - INFO - joeynmt.training - EPOCH 4
2024-05-19 16:29:51,936 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     1.542568, Batch Acc: 0.554494, Tokens per Sec:    21151, Lr: 0.000300
2024-05-19 16:29:51,937 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:29:51,937 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:30:04,262 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:30:04,263 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.35, loss:   1.89, ppl:   6.61, acc:   0.47, generation: 12.1281[sec], evaluation: 0.1801[sec]
2024-05-19 16:30:04,264 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:30:04,484 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/9500.ckpt
2024-05-19 16:30:04,499 - INFO - joeynmt.training - Example #0
2024-05-19 16:30:04,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:30:04,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:30:04,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'ig', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'about', 'the', 'fa@@', 'il@@', ',', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'mi@@', 'x@@', '.', '</s>']
2024-05-19 16:30:04,501 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:30:04,501 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:30:04,501 - INFO - joeynmt.training - 	Hypothesis: Forig year, I showed these two dia's to show that the pool, who was the pool, who was the past three million years of about the fail, with 40 percent of the United States, with 40 percent of mix.
2024-05-19 16:30:04,502 - INFO - joeynmt.training - Example #1
2024-05-19 16:30:04,502 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:30:04,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:30:04,502 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'su@@', 'ch', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'di@@', 'd@@', 'n@@', 'es@@', 's.', '</s>']
2024-05-19 16:30:04,503 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:30:04,503 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:30:04,503 - INFO - joeynmt.training - 	Hypothesis: But this is the such of this particular problem because it doesn't have the didness.
2024-05-19 16:30:04,503 - INFO - joeynmt.training - Example #2
2024-05-19 16:30:04,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:30:04,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:30:04,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'in', 'the', 'cl@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:30:04,504 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:30:04,505 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:30:04,505 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole is in a certain in the clopping heart of our global climate system.
2024-05-19 16:30:04,505 - INFO - joeynmt.training - Example #3
2024-05-19 16:30:04,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:30:04,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:30:04,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'going', 'to', 'be', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'ma@@', 'g@@', 'ine', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'stor@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'stor@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'stor@@', 'e.', '</s>']
2024-05-19 16:30:04,506 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:30:04,506 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:30:04,506 - INFO - joeynmt.training - 	Hypothesis: It was going to be in the winter and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the magine and crimpt in the storter and crimpt in the storter and crimpt in the store.
2024-05-19 16:30:04,506 - INFO - joeynmt.training - Example #4
2024-05-19 16:30:04,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:30:04,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:30:04,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 're@@', 'sp@@', 'on@@', 'se', 'of', 'what', 'happen@@', 'ed', 'the', 'last', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:30:04,508 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:30:04,508 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:30:04,508 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a response of what happened the last last 25 years.
2024-05-19 16:30:07,858 - INFO - joeynmt.training - Epoch   4, Step:    12100, Batch Loss:     1.620319, Batch Acc: 0.555128, Tokens per Sec:    20445, Lr: 0.000300
2024-05-19 16:30:11,188 - INFO - joeynmt.training - Epoch   4, Step:    12200, Batch Loss:     1.862867, Batch Acc: 0.552807, Tokens per Sec:    22453, Lr: 0.000300
2024-05-19 16:30:15,631 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     1.546773, Batch Acc: 0.553753, Tokens per Sec:    16896, Lr: 0.000300
2024-05-19 16:30:18,995 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     1.432922, Batch Acc: 0.557830, Tokens per Sec:    21986, Lr: 0.000300
2024-05-19 16:30:22,270 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     1.476436, Batch Acc: 0.551222, Tokens per Sec:    22326, Lr: 0.000300
2024-05-19 16:30:22,270 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:30:22,271 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:30:33,964 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:30:33,964 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.73, loss:   1.89, ppl:   6.59, acc:   0.47, generation: 11.4954[sec], evaluation: 0.1825[sec]
2024-05-19 16:30:33,965 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:30:34,190 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/10000.ckpt
2024-05-19 16:30:34,205 - INFO - joeynmt.training - Example #0
2024-05-19 16:30:34,206 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:30:34,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:30:34,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'li@@', 'p', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ate', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:30:34,208 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:30:34,208 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:30:34,208 - INFO - joeynmt.training - 	Hypothesis: And I was a year I showed these two dia's slip that the pool, who had the pool, who had the last three million years of the vastate of the United States, with 40 percent of the United States,
2024-05-19 16:30:34,208 - INFO - joeynmt.training - Example #1
2024-05-19 16:30:34,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:30:34,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:30:34,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'su@@', 'ch', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'an@@', 'im@@', 'als', 'because', 'it', "doesn't", 'show', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:30:34,210 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:30:34,210 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:30:34,210 - INFO - joeynmt.training - 	Hypothesis: But this is the such of this specific problem because it doesn't show the animals because it doesn't show the ice.
2024-05-19 16:30:34,210 - INFO - joeynmt.training - Example #2
2024-05-19 16:30:34,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:30:34,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:30:34,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'ice', 'of', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'N@@', 'or@@', 'th', 'sen@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:30:34,211 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:30:34,212 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:30:34,212 - INFO - joeynmt.training - 	Hypothesis: The ice ice of the North Pole, in a sense of the North sense of our global climate system.
2024-05-19 16:30:34,212 - INFO - joeynmt.training - Example #3
2024-05-19 16:30:34,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:30:34,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:30:34,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'it', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:30:34,213 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:30:34,213 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:30:34,213 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summit in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer.
2024-05-19 16:30:34,214 - INFO - joeynmt.training - Example #4
2024-05-19 16:30:34,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:30:34,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:30:34,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'last', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'to', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'to', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'was', 'happen@@', 'ing.', '</s>']
2024-05-19 16:30:34,215 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:30:34,215 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:30:34,215 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a version of what the last last 25 years is happening to the last 25 years is happening to the last 25 years of what happened was happening.
2024-05-19 16:30:37,582 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     1.590077, Batch Acc: 0.554530, Tokens per Sec:    20159, Lr: 0.000300
2024-05-19 16:30:41,561 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     1.362753, Batch Acc: 0.554980, Tokens per Sec:    18355, Lr: 0.000300
2024-05-19 16:30:45,360 - INFO - joeynmt.training - Epoch   4, Step:    12800, Batch Loss:     1.511674, Batch Acc: 0.552331, Tokens per Sec:    19788, Lr: 0.000300
2024-05-19 16:30:48,643 - INFO - joeynmt.training - Epoch   4, Step:    12900, Batch Loss:     1.664672, Batch Acc: 0.552416, Tokens per Sec:    21891, Lr: 0.000300
2024-05-19 16:30:51,945 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     1.455537, Batch Acc: 0.554154, Tokens per Sec:    22828, Lr: 0.000300
2024-05-19 16:30:51,946 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:30:51,946 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:31:03,746 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:31:03,746 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.21, loss:   1.88, ppl:   6.53, acc:   0.47, generation: 11.6004[sec], evaluation: 0.1831[sec]
2024-05-19 16:31:03,747 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:31:03,979 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/10500.ckpt
2024-05-19 16:31:03,995 - INFO - joeynmt.training - Example #0
2024-05-19 16:31:03,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:31:03,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:31:03,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'just', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'ice', 'ice', 'ice', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'who', 'had', 'about', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:31:03,997 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:31:03,998 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:31:03,998 - INFO - joeynmt.training - 	Hypothesis: And I just showed these two dia's slide to show that the Poice ice ice ice of the United States, who had about the last three million years of the United Statand 40 percent of the United States,
2024-05-19 16:31:03,998 - INFO - joeynmt.training - Example #1
2024-05-19 16:31:03,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:31:03,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:31:03,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'the', 'di@@', 's@@', 'ser@@', 'v@@', 'ic@@', 'e.', '</s>']
2024-05-19 16:31:03,999 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:31:03,999 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:31:03,999 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this particular problem because it doesn't the disservice.
2024-05-19 16:31:04,000 - INFO - joeynmt.training - Example #2
2024-05-19 16:31:04,000 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:31:04,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:31:04,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'in', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'sen@@', 'se,', 'in', 'the', 'cl@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'li@@', 'mat@@', 'h', 'system@@', '.', '</s>']
2024-05-19 16:31:04,001 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:31:04,001 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:31:04,001 - INFO - joeynmt.training - 	Hypothesis: The ice skin on the North Pole is in a sense, in the clopping heart of our global climath system.
2024-05-19 16:31:04,001 - INFO - joeynmt.training - Example #3
2024-05-19 16:31:04,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:31:04,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:31:04,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'just', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'si@@', 'de.', '</s>']
2024-05-19 16:31:04,002 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:31:04,003 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:31:04,003 - INFO - joeynmt.training - 	Hypothesis: It's just in the winter and crimpt in the summer and crimpt in the side.
2024-05-19 16:31:04,003 - INFO - joeynmt.training - Example #4
2024-05-19 16:31:04,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:31:04,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:31:04,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'about', '2@@', '5', 'years', 'is', 'happen@@', 'ing', '2@@', '5', 'years', 'of', 'happen@@', 'ing', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'to', 'be', 'happen@@', 'ed', 'to', 'the', 'next', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'to', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'to', 'be', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'that', 'I', 'sho@@', 'wing', 'you', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@']
2024-05-19 16:31:04,004 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:31:04,004 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:31:04,004 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a version of what the last 25 years is happening about 25 years is happening 25 years of happening in the last 25 years is happening to be happened to the next 25 years is happening version of what the last 25 years is happening to the last 25 years is happening the last 25 years is happening to be the last 25 years is happening that I showing you is a version of what the last 2
2024-05-19 16:31:07,338 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     1.562430, Batch Acc: 0.549259, Tokens per Sec:    20268, Lr: 0.000300
2024-05-19 16:31:11,814 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     1.470312, Batch Acc: 0.550159, Tokens per Sec:    16360, Lr: 0.000300
2024-05-19 16:31:15,196 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     1.693517, Batch Acc: 0.553868, Tokens per Sec:    21661, Lr: 0.000300
2024-05-19 16:31:18,539 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     1.464092, Batch Acc: 0.551579, Tokens per Sec:    22197, Lr: 0.000300
2024-05-19 16:31:21,910 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     1.446758, Batch Acc: 0.553977, Tokens per Sec:    22138, Lr: 0.000300
2024-05-19 16:31:21,911 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:31:21,911 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:31:33,537 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:31:33,538 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.80, loss:   1.87, ppl:   6.47, acc:   0.47, generation: 11.4301[sec], evaluation: 0.1809[sec]
2024-05-19 16:31:33,539 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:31:33,757 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/11000.ckpt
2024-05-19 16:31:33,770 - INFO - joeynmt.training - Example #0
2024-05-19 16:31:33,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:31:33,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:31:33,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'ally', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:31:33,772 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:31:33,772 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:31:33,773 - INFO - joeynmt.training - 	Hypothesis: Forally I showed these two dia's to show that the pool, which was the pool, who was the pool, who had the past three million years of the vast three million years with 40 percent of the United States of the United States of the United States,
2024-05-19 16:31:33,773 - INFO - joeynmt.training - Example #1
2024-05-19 16:31:33,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:31:33,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:31:33,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'n@@', 'est', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'ice', 'sho@@', 'wing', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:31:33,774 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:31:33,774 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:31:33,774 - INFO - joeynmt.training - 	Hypothesis: But this is the nest of this specific problem because it doesn't have the didness of the ice of the ice of the ice of ice showing the ice.
2024-05-19 16:31:33,774 - INFO - joeynmt.training - Example #2
2024-05-19 16:31:33,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:31:33,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:31:33,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'in', 'a', 'sen@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:31:33,776 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:31:33,776 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:31:33,776 - INFO - joeynmt.training - 	Hypothesis: The ice of the North Pole, in a certain in a sense of our global climate system.
2024-05-19 16:31:33,776 - INFO - joeynmt.training - Example #3
2024-05-19 16:31:33,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:31:33,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:31:33,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:31:33,777 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:31:33,777 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:31:33,777 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crimpt in the summer.
2024-05-19 16:31:33,778 - INFO - joeynmt.training - Example #4
2024-05-19 16:31:33,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:31:33,778 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:31:33,778 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'the', 'p@@', 'ast', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'to', 'the', 'p@@', 'ast', '2@@', '5', 'years', '</s>']
2024-05-19 16:31:33,779 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:31:33,779 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:31:33,779 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what the past 25 years is happening to the past 25 years
2024-05-19 16:31:37,564 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     1.482981, Batch Acc: 0.558208, Tokens per Sec:    18545, Lr: 0.000300
2024-05-19 16:31:41,564 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     1.544492, Batch Acc: 0.557697, Tokens per Sec:    18051, Lr: 0.000300
2024-05-19 16:31:44,928 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     1.419161, Batch Acc: 0.548491, Tokens per Sec:    22000, Lr: 0.000300
2024-05-19 16:31:48,270 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.562126, Batch Acc: 0.551835, Tokens per Sec:    22282, Lr: 0.000300
2024-05-19 16:31:52,217 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.437893, Batch Acc: 0.550348, Tokens per Sec:    18889, Lr: 0.000300
2024-05-19 16:31:52,218 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:31:52,218 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:32:04,981 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:32:04,981 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.72, loss:   1.86, ppl:   6.44, acc:   0.47, generation: 12.4011[sec], evaluation: 0.3306[sec]
2024-05-19 16:32:04,982 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:32:05,282 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/11500.ckpt
2024-05-19 16:32:05,301 - INFO - joeynmt.training - Example #0
2024-05-19 16:32:05,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:32:05,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:32:05,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'able', 'to', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', '4@@', '0', 'percent', 'c@@', 'ro@@', 'm@@', 'p', 'of', 'the', 'U@@', 'nit@@', 'ed', 'of', 'the', 'U@@', 'nit@@', 'ed', 'of', 'the', 'U@@', 'nit@@', 'ed', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'va@@', 'st@@', 'ate', 'of', 'the', 'da@@', 'y.', '</s>']
2024-05-19 16:32:05,303 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:32:05,304 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:32:05,304 - INFO - joeynmt.training - 	Hypothesis: I showed these two dia's two dia's to show that the pool, which the pool, who had about the past three million years of the vastable to the size of the United States of the United States was 40 percent cromp of the United of the United of the United of the United States was about the size of the United States of the vastate of the day.
2024-05-19 16:32:05,304 - INFO - joeynmt.training - Example #1
2024-05-19 16:32:05,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:32:05,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:32:05,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'st', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:32:05,305 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:32:05,305 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:32:05,305 - INFO - joeynmt.training - 	Hypothesis: But this is actually the rest of this specific problem because it doesn't have the didness of the ice.
2024-05-19 16:32:05,305 - INFO - joeynmt.training - Example #2
2024-05-19 16:32:05,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:32:05,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:32:05,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'the', 'way,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'the', 'cl@@', 'as@@', 's', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'li@@', 'mat@@', 'h', 'system@@', '.', '</s>']
2024-05-19 16:32:05,307 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:32:05,307 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:32:05,307 - INFO - joeynmt.training - 	Hypothesis: The ice skp on the North Pole is in a certain the way, in a certain the class of our global climath system.
2024-05-19 16:32:05,307 - INFO - joeynmt.training - Example #3
2024-05-19 16:32:05,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:32:05,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:32:05,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:32:05,308 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:32:05,308 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:32:05,308 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crimpt in the summer.
2024-05-19 16:32:05,309 - INFO - joeynmt.training - Example #4
2024-05-19 16:32:05,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:32:05,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:32:05,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'is', 'a', 'qu@@', 'ic@@', 'k@@', 'ly', 'about', 'what', 'is', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'is', 'happen@@', 'ing', 'is', 'happen@@', 'ing', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'is', 'happen@@', 'ing', 'is', 'happen@@', 'ing', 'about', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'is', 'happen@@', 'ing', 'is', 'happen@@', 'ing', 'about', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'to', 'see', 'is', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'the', 'last', '2@@', '5']
2024-05-19 16:32:05,310 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:32:05,311 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:32:05,311 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a quickly about what is happened the last 25 years is happening 25 years is happened in the last 25 years is happened in the last 25 years of what happened is happening is happening the last 25 years of what happened is happening is happening about the last 25 years of what happened is happening is happening about the last 25 years is happened to see is the last 25 years of what the last 25
2024-05-19 16:32:09,176 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.443161, Batch Acc: 0.557480, Tokens per Sec:    17290, Lr: 0.000300
2024-05-19 16:32:12,491 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.520003, Batch Acc: 0.553751, Tokens per Sec:    21979, Lr: 0.000300
2024-05-19 16:32:15,958 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     1.680225, Batch Acc: 0.557183, Tokens per Sec:    21489, Lr: 0.000300
2024-05-19 16:32:19,813 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     1.476834, Batch Acc: 0.553519, Tokens per Sec:    19843, Lr: 0.000300
2024-05-19 16:32:23,560 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     1.655961, Batch Acc: 0.558574, Tokens per Sec:    20026, Lr: 0.000300
2024-05-19 16:32:23,560 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:32:23,560 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:32:35,752 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:32:35,753 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.84, loss:   1.85, ppl:   6.37, acc:   0.47, generation: 11.9936[sec], evaluation: 0.1816[sec]
2024-05-19 16:32:35,754 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:32:35,966 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/12000.ckpt
2024-05-19 16:32:35,981 - INFO - joeynmt.training - Example #0
2024-05-19 16:32:35,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:32:35,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:32:35,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'for', 'a', 'few', 'year@@', 's,', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'p@@', 'ool@@', ',', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'three', 'million', 'years', 'about', 'the', 'last', 'three', 'million', 'years', 'about', 'the', 'pre@@', 's@@', 'ent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', '4@@', '0', 'percent', 'k@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:32:35,982 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:32:35,983 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:32:35,983 - INFO - joeynmt.training - 	Hypothesis: And for a few years, I showed these two dia's pool, to show that the pool, who had about three million years about the last three million years about the present of the United Statand 40 percent kroms.
2024-05-19 16:32:35,983 - INFO - joeynmt.training - Example #1
2024-05-19 16:32:35,983 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:32:35,984 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:32:35,984 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'su@@', 'pp@@', 'or@@', 't', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'because', 'it', "doesn't", 'have', 'the', 'di@@', 'd@@', 'n@@', 'es@@', 's.', '</s>']
2024-05-19 16:32:35,984 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:32:35,984 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:32:35,985 - INFO - joeynmt.training - 	Hypothesis: But this is actually the support of this specific problebecause it doesn't have the didness.
2024-05-19 16:32:35,985 - INFO - joeynmt.training - Example #2
2024-05-19 16:32:35,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:32:35,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:32:35,985 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'in', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'in', 'the', 'se@@', 'c@@', 'k', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:32:35,986 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:32:35,986 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:32:35,986 - INFO - joeynmt.training - 	Hypothesis: The ice skin on the North Pole, in a certain in the seck heart of our global climate system.
2024-05-19 16:32:35,986 - INFO - joeynmt.training - Example #3
2024-05-19 16:32:35,987 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:32:35,987 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:32:35,987 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:32:35,987 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:32:35,988 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:32:35,988 - INFO - joeynmt.training - 	Hypothesis: It set out in the winter and crimpt in the summer and crimpt in the summer.
2024-05-19 16:32:35,988 - INFO - joeynmt.training - Example #4
2024-05-19 16:32:35,988 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:32:35,988 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:32:35,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'ver@@', 'sion', 'of', 'what', 'is', 'happen@@', 'ing', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:32:35,989 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:32:35,989 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:32:35,989 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what is happening version of what the last 25 years.
2024-05-19 16:32:39,292 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.620247, Batch Acc: 0.554895, Tokens per Sec:    20252, Lr: 0.000300
2024-05-19 16:32:42,656 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.517725, Batch Acc: 0.548364, Tokens per Sec:    21534, Lr: 0.000300
2024-05-19 16:32:46,267 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.917410, Batch Acc: 0.551936, Tokens per Sec:    19846, Lr: 0.000300
2024-05-19 16:32:50,438 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     1.376279, Batch Acc: 0.555350, Tokens per Sec:    17886, Lr: 0.000300
2024-05-19 16:32:53,791 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.539602, Batch Acc: 0.558141, Tokens per Sec:    22089, Lr: 0.000300
2024-05-19 16:32:53,791 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:32:53,791 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:33:05,127 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:33:05,127 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.62, loss:   1.83, ppl:   6.26, acc:   0.48, generation: 11.1380[sec], evaluation: 0.1822[sec]
2024-05-19 16:33:05,128 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:33:05,347 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/12500.ckpt
2024-05-19 16:33:05,359 - INFO - joeynmt.training - Example #0
2024-05-19 16:33:05,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:33:05,360 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:33:05,360 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'able', 'of', 'the', 'fa@@', 'st@@', 'er', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:33:05,361 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:33:05,361 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:33:05,361 - INFO - joeynmt.training - 	Hypothesis: Last year I showed this two dia's slide to show that the pool, that the pool, who had the last three million years of the vastable of the faster of the United States, with 40 percent of the U.S.
2024-05-19 16:33:05,361 - INFO - joeynmt.training - Example #1
2024-05-19 16:33:05,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:33:05,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:33:05,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'in@@', 'de@@', 'ed', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'de@@', 'al', 'the', 'an@@', 'im@@', 'al@@', 's.', '</s>']
2024-05-19 16:33:05,363 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:33:05,363 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:33:05,363 - INFO - joeynmt.training - 	Hypothesis: But this is the indeed of this specific problem because it doesn't deal the animals.
2024-05-19 16:33:05,363 - INFO - joeynmt.training - Example #2
2024-05-19 16:33:05,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:33:05,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:33:05,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'in', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'st', 'is', 'in', 'a', 'sen@@', 'se', 'in', 'a', 'sen@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:33:05,364 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:33:05,364 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:33:05,365 - INFO - joeynmt.training - 	Hypothesis: The ice skin on the North Post is in a sense in a sense of our global climate system.
2024-05-19 16:33:05,365 - INFO - joeynmt.training - Example #3
2024-05-19 16:33:05,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:33:05,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:33:05,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'it.', '</s>']
2024-05-19 16:33:05,366 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:33:05,366 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:33:05,366 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summit.
2024-05-19 16:33:05,366 - INFO - joeynmt.training - Example #4
2024-05-19 16:33:05,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:33:05,367 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:33:05,367 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'qu@@', 'ic@@', 'k@@', 'ly', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'to', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'to', 'be', 'happen@@', 'ed', 'to', 'be', 'happen@@', 'ed', 'to', 'be', 'happen@@', 'ed', 'to', 'be', 'happen@@', 'ed', 'to', 'be', 'happen@@', 'ed', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'to', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'to', 'be', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'to', 'the', 'next', 's@@', 'li@@', 'de', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'to', 'the', 'next', '2@@', '5', 'years', '</s>']
2024-05-19 16:33:05,367 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:33:05,367 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:33:05,368 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a quickly version of what happened to the last 25 years is happening to be happened to be happened to be happened to be happened to be happened version of what happened to the last 25 years of what happened the last 25 years is happening to be the last 25 years of what happened to the next slide of what happened the last 25 years of what happened to the next 25 years
2024-05-19 16:33:08,711 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.438570, Batch Acc: 0.552509, Tokens per Sec:    20316, Lr: 0.000300
2024-05-19 16:33:12,010 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     1.518128, Batch Acc: 0.557115, Tokens per Sec:    22550, Lr: 0.000300
2024-05-19 16:33:16,087 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.495134, Batch Acc: 0.559109, Tokens per Sec:    18501, Lr: 0.000300
2024-05-19 16:33:19,743 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.508967, Batch Acc: 0.553167, Tokens per Sec:    19995, Lr: 0.000300
2024-05-19 16:33:23,087 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.594935, Batch Acc: 0.557048, Tokens per Sec:    22021, Lr: 0.000300
2024-05-19 16:33:23,087 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:33:23,088 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:33:36,194 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:33:36,195 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.04, loss:   1.83, ppl:   6.25, acc:   0.48, generation: 12.9061[sec], evaluation: 0.1853[sec]
2024-05-19 16:33:36,196 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:33:36,415 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/13000.ckpt
2024-05-19 16:33:36,434 - INFO - joeynmt.training - Example #0
2024-05-19 16:33:36,435 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:33:36,435 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:33:36,435 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'V@@', 'S@@', ',', 'had', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0@@', '-@@', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es.', '</s>']
2024-05-19 16:33:36,436 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:33:36,436 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:33:36,437 - INFO - joeynmt.training - 	Hypothesis: And I was a year I showed these two dia's to show that the pool, which the pool, who had about the size of the VS, had 40 percent of the United States, with 40-percent of the United States.
2024-05-19 16:33:36,437 - INFO - joeynmt.training - Example #1
2024-05-19 16:33:36,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:33:36,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:33:36,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'rec@@', 'or@@', 'd', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'ice', 'that', 'ice', 'sho@@', 'ws', 'the', 'di@@', 'd@@', 'n@@', 'es@@', 's.', '</s>']
2024-05-19 16:33:36,438 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:33:36,438 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:33:36,438 - INFO - joeynmt.training - 	Hypothesis: But this is actually the record of this particular problem because it doesn't show the didness of the ice of the ice of ice that ice shows the didness.
2024-05-19 16:33:36,439 - INFO - joeynmt.training - Example #2
2024-05-19 16:33:36,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:33:36,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:33:36,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'ice', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se,', 's@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:33:36,440 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:33:36,440 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:33:36,440 - INFO - joeynmt.training - 	Hypothesis: The ice of ice on the North Pole is in a sense, in a sense, sing heart of our global climate system.
2024-05-19 16:33:36,441 - INFO - joeynmt.training - Example #3
2024-05-19 16:33:36,441 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:33:36,441 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:33:36,441 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 's@@', 'o@@', '.', '</s>']
2024-05-19 16:33:36,442 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:33:36,442 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:33:36,442 - INFO - joeynmt.training - 	Hypothesis: It set out in the winter and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and so.
2024-05-19 16:33:36,442 - INFO - joeynmt.training - Example #4
2024-05-19 16:33:36,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:33:36,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:33:36,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'qu@@', 'ic@@', 'k@@', 'ly', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'about', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing.', '</s>']
2024-05-19 16:33:36,444 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:33:36,444 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:33:36,444 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a quickly version of what the last 25 years is happening about the last 25 years is happening.
2024-05-19 16:33:39,773 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.538502, Batch Acc: 0.560737, Tokens per Sec:    20097, Lr: 0.000300
2024-05-19 16:33:43,875 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     1.524537, Batch Acc: 0.551781, Tokens per Sec:    17463, Lr: 0.000300
2024-05-19 16:33:47,626 - INFO - joeynmt.training - Epoch   4, Step:    15800, Batch Loss:     1.589865, Batch Acc: 0.553615, Tokens per Sec:    19728, Lr: 0.000300
2024-05-19 16:33:51,038 - INFO - joeynmt.training - Epoch   4, Step:    15900, Batch Loss:     1.637579, Batch Acc: 0.554841, Tokens per Sec:    22004, Lr: 0.000300
2024-05-19 16:33:51,378 - INFO - joeynmt.training - Epoch   4: total training loss 6167.61
2024-05-19 16:33:51,379 - INFO - joeynmt.training - EPOCH 5
2024-05-19 16:33:54,334 - INFO - joeynmt.training - Epoch   5, Step:    16000, Batch Loss:     1.492981, Batch Acc: 0.580734, Tokens per Sec:    21982, Lr: 0.000300
2024-05-19 16:33:54,335 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:33:54,335 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:34:05,610 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:34:05,611 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.45, loss:   1.83, ppl:   6.25, acc:   0.48, generation: 11.0818[sec], evaluation: 0.1775[sec]
2024-05-19 16:34:05,612 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:34:05,822 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/13500.ckpt
2024-05-19 16:34:05,838 - INFO - joeynmt.training - Example #0
2024-05-19 16:34:05,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:34:05,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:34:05,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'di@@', 'a@@', "'s", 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'had', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:34:05,840 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:34:05,841 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:34:05,841 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two sdia's slides to show that the pool, who was the pool, who had been the size of the United Statand had 40 percent of the United States, with 40 percent of the U.S.
2024-05-19 16:34:05,841 - INFO - joeynmt.training - Example #1
2024-05-19 16:34:05,841 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:34:05,841 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:34:05,842 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'su@@', 'ch', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'd@@', 'n@@', '@@', 't', 'sho@@', 'wing', 'the', 'ice', 'of', 'ice', 'sho@@', 'wing', 'the', 'ice', 'of', 'ice', 'proble@@', 'm.', '</s>']
2024-05-19 16:34:05,842 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:34:05,842 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:34:05,842 - INFO - joeynmt.training - 	Hypothesis: But this is actually the such of this particular problem because it doesn't show the didnt showing the ice of ice showing the ice of ice problem.
2024-05-19 16:34:05,843 - INFO - joeynmt.training - Example #2
2024-05-19 16:34:05,843 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:34:05,843 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:34:05,843 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'ice', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'way,', '</s>']
2024-05-19 16:34:05,844 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:34:05,844 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:34:05,844 - INFO - joeynmt.training - 	Hypothesis: The ice ap on the North Poice is in a certain sense, in a certain sense, in a way,
2024-05-19 16:34:05,844 - INFO - joeynmt.training - Example #3
2024-05-19 16:34:05,844 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:34:05,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:34:05,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:34:05,845 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:34:05,845 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:34:05,846 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crimpt in the summer.
2024-05-19 16:34:05,846 - INFO - joeynmt.training - Example #4
2024-05-19 16:34:05,846 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:34:05,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:34:05,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'wing', 'is', 'a', 'qu@@', 'ic@@', 'k', 'ver@@', 'sion', 'of', 'what', 'happen@@', 's', 'happen@@', 'ed', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing.', '</s>']
2024-05-19 16:34:05,847 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:34:05,847 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:34:05,847 - INFO - joeynmt.training - 	Hypothesis: The next slide I showing is a quick version of what happens happened version of what happened in the last 25 years is happening.
2024-05-19 16:34:09,239 - INFO - joeynmt.training - Epoch   5, Step:    16100, Batch Loss:     1.389262, Batch Acc: 0.574477, Tokens per Sec:    20766, Lr: 0.000300
2024-05-19 16:34:13,478 - INFO - joeynmt.training - Epoch   5, Step:    16200, Batch Loss:     1.470463, Batch Acc: 0.579405, Tokens per Sec:    17089, Lr: 0.000300
2024-05-19 16:34:17,042 - INFO - joeynmt.training - Epoch   5, Step:    16300, Batch Loss:     1.392222, Batch Acc: 0.574978, Tokens per Sec:    20781, Lr: 0.000300
2024-05-19 16:34:20,532 - INFO - joeynmt.training - Epoch   5, Step:    16400, Batch Loss:     1.548241, Batch Acc: 0.578417, Tokens per Sec:    20468, Lr: 0.000300
2024-05-19 16:34:24,120 - INFO - joeynmt.training - Epoch   5, Step:    16500, Batch Loss:     1.579888, Batch Acc: 0.571984, Tokens per Sec:    20223, Lr: 0.000300
2024-05-19 16:34:24,121 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:34:24,121 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:34:35,483 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:34:35,484 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.43, loss:   1.83, ppl:   6.25, acc:   0.48, generation: 10.7748[sec], evaluation: 0.5718[sec]
2024-05-19 16:34:35,701 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/14000.ckpt
2024-05-19 16:34:35,714 - INFO - joeynmt.training - Example #0
2024-05-19 16:34:35,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:34:35,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:34:35,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'p@@', 'ool@@', ',', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'last', 'three', 'million', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:34:35,716 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:34:35,716 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:34:35,716 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dia's pool, that the pool, which the pool, who had about the last three million years about the size of the vast three million years of the United States, with 40 percent croms.
2024-05-19 16:34:35,716 - INFO - joeynmt.training - Example #1
2024-05-19 16:34:35,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:34:35,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:34:35,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'st', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'ic@@', 'k@@', 'n@@', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'd.', '</s>']
2024-05-19 16:34:35,717 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:34:35,717 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:34:35,718 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nst of this specific problem because it doesn't show the icknice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of this specific problem because it doesn't show the did.
2024-05-19 16:34:35,718 - INFO - joeynmt.training - Example #2
2024-05-19 16:34:35,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:34:35,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:34:35,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'way,', 'from', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:34:35,719 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:34:35,719 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:34:35,719 - INFO - joeynmt.training - 	Hypothesis: The ice ap on the North Pole, in a certain sense, in a way, from our global climate system.
2024-05-19 16:34:35,719 - INFO - joeynmt.training - Example #3
2024-05-19 16:34:35,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:34:35,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:34:35,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'from', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 's', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 's', 'in', 'the', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:34:35,721 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:34:35,721 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:34:35,721 - INFO - joeynmt.training - 	Hypothesis: It's from the winter and crimps in the summer and crimps in the summer.
2024-05-19 16:34:35,721 - INFO - joeynmt.training - Example #4
2024-05-19 16:34:35,721 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:34:35,721 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:34:35,722 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'show', 'is', 'a', 'sp@@', 'ee@@', 'ch@@', ',', 'a', 'sp@@', 'ee@@', 'ch@@', ',', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:34:35,722 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:34:35,722 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:34:35,722 - INFO - joeynmt.training - 	Hypothesis: The next slide that I show is a speech, a speech, the last 25 years.
2024-05-19 16:34:39,679 - INFO - joeynmt.training - Epoch   5, Step:    16600, Batch Loss:     1.415567, Batch Acc: 0.574391, Tokens per Sec:    17670, Lr: 0.000300
2024-05-19 16:34:43,585 - INFO - joeynmt.training - Epoch   5, Step:    16700, Batch Loss:     1.581071, Batch Acc: 0.572964, Tokens per Sec:    19413, Lr: 0.000300
2024-05-19 16:34:47,039 - INFO - joeynmt.training - Epoch   5, Step:    16800, Batch Loss:     1.565363, Batch Acc: 0.578383, Tokens per Sec:    21074, Lr: 0.000300
2024-05-19 16:34:50,440 - INFO - joeynmt.training - Epoch   5, Step:    16900, Batch Loss:     1.565338, Batch Acc: 0.572784, Tokens per Sec:    21510, Lr: 0.000300
2024-05-19 16:34:54,736 - INFO - joeynmt.training - Epoch   5, Step:    17000, Batch Loss:     1.448817, Batch Acc: 0.572385, Tokens per Sec:    16870, Lr: 0.000300
2024-05-19 16:34:54,737 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:34:54,737 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:35:05,713 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:35:05,714 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.75, loss:   1.82, ppl:   6.16, acc:   0.49, generation: 10.6144[sec], evaluation: 0.3258[sec]
2024-05-19 16:35:05,715 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:35:05,972 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/14500.ckpt
2024-05-19 16:35:06,000 - INFO - joeynmt.training - Example #0
2024-05-19 16:35:06,000 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:35:06,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:35:06,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es.', '</s>']
2024-05-19 16:35:06,001 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:35:06,002 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:35:06,002 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two dia's to show that the pool, which the pool, who had the pool, who had about the last three million years of the United States, with 40 percent of the United States.
2024-05-19 16:35:06,002 - INFO - joeynmt.training - Example #1
2024-05-19 16:35:06,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:35:06,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:35:06,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'd@@', 'n@@', '@@', 't', 'see', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:35:06,003 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:35:06,004 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:35:06,004 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this specific problem because it doesn't show the didnt see the ice.
2024-05-19 16:35:06,004 - INFO - joeynmt.training - Example #2
2024-05-19 16:35:06,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:35:06,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:35:06,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'ice', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:35:06,005 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:35:06,005 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:35:06,006 - INFO - joeynmt.training - 	Hypothesis: The ice of ice on the North Pole, in a certain sense, in a sense of our global climate system.
2024-05-19 16:35:06,006 - INFO - joeynmt.training - Example #3
2024-05-19 16:35:06,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:35:06,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:35:06,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'it.', '</s>']
2024-05-19 16:35:06,007 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:35:06,007 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:35:06,007 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summit.
2024-05-19 16:35:06,007 - INFO - joeynmt.training - Example #4
2024-05-19 16:35:06,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:35:06,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:35:06,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'is', 'a', 'qu@@', 'ic@@', 'k', 'of', 'what', 'happen@@', 'ed', 'to', 'see', 'is', 'a', 'de@@', 'sp@@', 'er@@', 'al', 'of', 'what', 'happen@@', 'ed', 'to', 'be', 'happen@@', 'ed', 'by', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:35:06,008 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:35:06,008 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:35:06,009 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a quick of what happened to see is a desperal of what happened to be happened by the last 25 years.
2024-05-19 16:35:10,252 - INFO - joeynmt.training - Epoch   5, Step:    17100, Batch Loss:     1.574195, Batch Acc: 0.572440, Tokens per Sec:    16372, Lr: 0.000300
2024-05-19 16:35:13,711 - INFO - joeynmt.training - Epoch   5, Step:    17200, Batch Loss:     1.418448, Batch Acc: 0.572953, Tokens per Sec:    21379, Lr: 0.000300
2024-05-19 16:35:17,199 - INFO - joeynmt.training - Epoch   5, Step:    17300, Batch Loss:     1.383176, Batch Acc: 0.574187, Tokens per Sec:    21606, Lr: 0.000300
2024-05-19 16:35:21,140 - INFO - joeynmt.training - Epoch   5, Step:    17400, Batch Loss:     1.566172, Batch Acc: 0.573020, Tokens per Sec:    18777, Lr: 0.000300
2024-05-19 16:35:25,137 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     1.596413, Batch Acc: 0.572093, Tokens per Sec:    18570, Lr: 0.000300
2024-05-19 16:35:25,137 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:35:25,137 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:35:36,958 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:35:36,958 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.56, loss:   1.82, ppl:   6.15, acc:   0.49, generation: 11.4563[sec], evaluation: 0.3355[sec]
2024-05-19 16:35:36,959 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:35:37,208 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/15000.ckpt
2024-05-19 16:35:37,224 - INFO - joeynmt.training - Example #0
2024-05-19 16:35:37,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:35:37,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:35:37,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'was', 'a', 'little', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'cap@@', ',', 'who', 'was', 'the', 'P@@', 'o@@', 'ice', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ate', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:35:37,226 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:35:37,226 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:35:37,227 - INFO - joeynmt.training - 	Hypothesis: I was a little year, I showed these two dia's to show that the Poice cap, who was the Poice was the past three million years of the vastate of the United States, 40 percent of the United States, 40 percent of the United States,
2024-05-19 16:35:37,227 - INFO - joeynmt.training - Example #1
2024-05-19 16:35:37,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:35:37,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:35:37,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:35:37,228 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:35:37,228 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:35:37,228 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this specific problem because it doesn't show the ice.
2024-05-19 16:35:37,229 - INFO - joeynmt.training - Example #2
2024-05-19 16:35:37,229 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:35:37,229 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:35:37,229 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'the', 'cl@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:35:37,230 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:35:37,230 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:35:37,230 - INFO - joeynmt.training - 	Hypothesis: The ice ap on the North Pole is in a certain sense, in the clopping heart of our global climate system.
2024-05-19 16:35:37,230 - INFO - joeynmt.training - Example #3
2024-05-19 16:35:37,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:35:37,231 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:35:37,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'su@@', 'm@@', 'mer@@', ',', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:35:37,231 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:35:37,231 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:35:37,232 - INFO - joeynmt.training - 	Hypothesis: It turns out in the summer, and crimpt in the summer.
2024-05-19 16:35:37,232 - INFO - joeynmt.training - Example #4
2024-05-19 16:35:37,232 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:35:37,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:35:37,232 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'wing', 'is', 'a', 'de@@', 'st@@', 'er', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'for', '2@@', '5', 'years', 'is', 'happen@@', 'ing.', '</s>']
2024-05-19 16:35:37,233 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:35:37,233 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:35:37,233 - INFO - joeynmt.training - 	Hypothesis: The next slide I showing is a dester version of what happened the last 25 years is happening for 25 years is happening.
2024-05-19 16:35:40,708 - INFO - joeynmt.training - Epoch   5, Step:    17600, Batch Loss:     1.425207, Batch Acc: 0.571962, Tokens per Sec:    19637, Lr: 0.000300
2024-05-19 16:35:44,224 - INFO - joeynmt.training - Epoch   5, Step:    17700, Batch Loss:     1.576703, Batch Acc: 0.569460, Tokens per Sec:    20712, Lr: 0.000300
2024-05-19 16:35:47,662 - INFO - joeynmt.training - Epoch   5, Step:    17800, Batch Loss:     1.683858, Batch Acc: 0.568783, Tokens per Sec:    21771, Lr: 0.000300
2024-05-19 16:35:51,867 - INFO - joeynmt.training - Epoch   5, Step:    17900, Batch Loss:     1.450702, Batch Acc: 0.573573, Tokens per Sec:    17743, Lr: 0.000300
2024-05-19 16:35:55,218 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     1.442103, Batch Acc: 0.571171, Tokens per Sec:    22475, Lr: 0.000300
2024-05-19 16:35:55,219 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:35:55,219 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:36:06,747 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:36:06,748 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.69, loss:   1.82, ppl:   6.14, acc:   0.48, generation: 11.3241[sec], evaluation: 0.1855[sec]
2024-05-19 16:36:06,748 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:36:06,976 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/15500.ckpt
2024-05-19 16:36:06,991 - INFO - joeynmt.training - Example #0
2024-05-19 16:36:06,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:36:06,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:36:06,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'di@@', 'a@@', "'s", 'p@@', 'id@@', '-@@', 'p@@', 'ool@@', ',', 'which', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'by', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'was', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:36:06,993 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:36:06,994 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:36:06,994 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two dia's dia's pid-pool, which the pool, who had about the pool, who had about 40 percent of the United States, with 40 percent of the United States, by 40 percent of the United was croms.
2024-05-19 16:36:06,994 - INFO - joeynmt.training - Example #1
2024-05-19 16:36:06,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:36:06,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:36:06,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'est', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'di@@', 'ed', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:36:06,995 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:36:06,996 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:36:06,996 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nest of this particular problem because it doesn't have the died of the ice.
2024-05-19 16:36:06,996 - INFO - joeynmt.training - Example #2
2024-05-19 16:36:06,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:36:06,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:36:06,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'ice', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'cl@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:36:06,997 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:36:06,997 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:36:06,997 - INFO - joeynmt.training - 	Hypothesis: The ice of ice on the North Pole, in a certain sense, in a clopping heart of our global climate system.
2024-05-19 16:36:06,998 - INFO - joeynmt.training - Example #3
2024-05-19 16:36:06,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:36:06,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:36:06,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ro@@', 'ss@@', 'ing', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:36:06,999 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:36:06,999 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:36:06,999 - INFO - joeynmt.training - 	Hypothesis: It's in the winter and crossing in the summer.
2024-05-19 16:36:06,999 - INFO - joeynmt.training - Example #4
2024-05-19 16:36:07,000 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:36:07,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:36:07,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'a', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'qu@@', 'ic@@', 'k', 'ver@@', 'sion', 'of', 'what', 'the', 'p@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:36:07,001 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:36:07,001 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:36:07,001 - INFO - joeynmt.training - 	Hypothesis: The next slia that I shows is a quick version of what the past 25 years.
2024-05-19 16:36:10,425 - INFO - joeynmt.training - Epoch   5, Step:    18100, Batch Loss:     1.342229, Batch Acc: 0.572019, Tokens per Sec:    20614, Lr: 0.000300
2024-05-19 16:36:14,008 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.644671, Batch Acc: 0.576391, Tokens per Sec:    21572, Lr: 0.000300
2024-05-19 16:36:17,951 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.505268, Batch Acc: 0.572828, Tokens per Sec:    18311, Lr: 0.000300
2024-05-19 16:36:21,673 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.409087, Batch Acc: 0.574230, Tokens per Sec:    19734, Lr: 0.000300
2024-05-19 16:36:25,029 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.290633, Batch Acc: 0.575693, Tokens per Sec:    22443, Lr: 0.000300
2024-05-19 16:36:25,029 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:36:25,030 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:36:35,853 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:36:35,853 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.69, loss:   1.80, ppl:   6.07, acc:   0.49, generation: 10.6256[sec], evaluation: 0.1828[sec]
2024-05-19 16:36:35,854 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:36:36,074 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/16500.ckpt
2024-05-19 16:36:36,091 - INFO - joeynmt.training - Example #0
2024-05-19 16:36:36,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:36:36,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:36:36,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'as', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'the', 'p@@', 'ool@@', ',', 'which', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ate', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'da@@', 'y.', '</s>']
2024-05-19 16:36:36,093 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:36:36,093 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:36:36,093 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two diaas to show that the pool, which the pool, which the pool, who had about the past three million years of the vastate of the United States with 40 percent of the United States with 40 percent of the United States with 40 percent of the day.
2024-05-19 16:36:36,093 - INFO - joeynmt.training - Example #1
2024-05-19 16:36:36,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:36:36,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:36:36,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'allo@@', 'w', 'the', 'di@@', 'd@@', 'n@@', '@@', 't', 'sho@@', 't', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:36:36,094 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:36:36,095 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:36:36,095 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this particular problem because it doesn't allow the didnt shot the ice.
2024-05-19 16:36:36,095 - INFO - joeynmt.training - Example #2
2024-05-19 16:36:36,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:36:36,095 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:36:36,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'ice', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'the', 's@@', 'us@@', 'pen@@', 'ded', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:36:36,096 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:36:36,096 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:36:36,097 - INFO - joeynmt.training - 	Hypothesis: The ice of ice on the North Pole is in a certain the suspended heart of our global climate system.
2024-05-19 16:36:36,097 - INFO - joeynmt.training - Example #3
2024-05-19 16:36:36,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:36:36,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:36:36,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:36:36,098 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:36:36,098 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:36:36,098 - INFO - joeynmt.training - 	Hypothesis: It's in the summer and crimpt in the summer.
2024-05-19 16:36:36,098 - INFO - joeynmt.training - Example #4
2024-05-19 16:36:36,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:36:36,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:36:36,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'con@@', 'si@@', 'der', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', '</s>']
2024-05-19 16:36:36,099 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:36:36,100 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:36:36,100 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a consider of what happened the last 25 years is happened in the last 25 years is happened in the last 25 years is happened in the last 25 years
2024-05-19 16:36:39,404 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.606935, Batch Acc: 0.572657, Tokens per Sec:    20546, Lr: 0.000300
2024-05-19 16:36:42,674 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.605766, Batch Acc: 0.573421, Tokens per Sec:    22778, Lr: 0.000300
2024-05-19 16:36:47,125 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.703489, Batch Acc: 0.574479, Tokens per Sec:    16315, Lr: 0.000300
2024-05-19 16:36:50,454 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.493527, Batch Acc: 0.574705, Tokens per Sec:    22635, Lr: 0.000300
2024-05-19 16:36:53,810 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.322365, Batch Acc: 0.576074, Tokens per Sec:    21392, Lr: 0.000300
2024-05-19 16:36:53,810 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:36:53,810 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:37:05,018 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:37:05,019 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.29, loss:   1.80, ppl:   6.06, acc:   0.49, generation: 10.9965[sec], evaluation: 0.1959[sec]
2024-05-19 16:37:05,019 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:37:05,250 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/16000.ckpt
2024-05-19 16:37:05,265 - INFO - joeynmt.training - Example #0
2024-05-19 16:37:05,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:37:05,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:37:05,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'I', 'sho@@', 'w@@', 'ed', 'that', 'the', 'p@@', 'ool@@', 's', 'that', 'the', 'p@@', 'ool@@', 's', 'that', 'the', 'p@@', 'ool@@', 's', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es.', '</s>']
2024-05-19 16:37:05,267 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:37:05,267 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:37:05,268 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these two dias, I showed that the pools that the pools that the pools had about the past three million years of the vast three million years with 40 percent of the United States with 40 percent of the United States.
2024-05-19 16:37:05,268 - INFO - joeynmt.training - Example #1
2024-05-19 16:37:05,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:37:05,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:37:05,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'first', 'thing', 'that', 'is', 'the', 'most', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'not', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ice', 'of', 'ice', 'proble@@', 'm.', '</s>']
2024-05-19 16:37:05,269 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:37:05,269 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:37:05,269 - INFO - joeynmt.training - 	Hypothesis: But this is actually the first thing that is the most of this specific problem because it not the didness of the ice of ice problem.
2024-05-19 16:37:05,269 - INFO - joeynmt.training - Example #2
2024-05-19 16:37:05,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:37:05,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:37:05,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'he@@', 'ar@@', 't', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se', 'of', 'the', 's@@', 'ing@@', 'le', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:37:05,271 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:37:05,271 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:37:05,271 - INFO - joeynmt.training - 	Hypothesis: The ice heart is in a certain sense, in a sense of the single heart of our global climate system.
2024-05-19 16:37:05,271 - INFO - joeynmt.training - Example #3
2024-05-19 16:37:05,271 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:37:05,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:37:05,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ro@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'at@@', 'ch@@', 'ed', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 's@@', 'it', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 's@@', 'at', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ro@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 's@@', 'un@@', '.', '</s>']
2024-05-19 16:37:05,272 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:37:05,272 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:37:05,273 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crompt in the summer and catched in the summer and sit in the summer and crimpt in the summer and sat the summer and crompt in the summer and sun.
2024-05-19 16:37:05,273 - INFO - joeynmt.training - Example #4
2024-05-19 16:37:05,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:37:05,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:37:05,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'qu@@', 'ic@@', 'ted', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', '2@@', '5', 'years', '</s>']
2024-05-19 16:37:05,274 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:37:05,274 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:37:05,274 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a quicted version of what the last 25 years is happening 25 years
2024-05-19 16:37:08,647 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.538791, Batch Acc: 0.574676, Tokens per Sec:    20544, Lr: 0.000300
2024-05-19 16:37:12,207 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.378487, Batch Acc: 0.568600, Tokens per Sec:    20801, Lr: 0.000300
2024-05-19 16:37:16,344 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.450585, Batch Acc: 0.577088, Tokens per Sec:    17662, Lr: 0.000300
2024-05-19 16:37:19,650 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.411538, Batch Acc: 0.569069, Tokens per Sec:    21635, Lr: 0.000300
2024-05-19 16:37:22,996 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.454640, Batch Acc: 0.573643, Tokens per Sec:    22137, Lr: 0.000300
2024-05-19 16:37:22,996 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:37:22,997 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:37:35,276 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:37:35,276 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.19, loss:   1.79, ppl:   6.01, acc:   0.49, generation: 12.0728[sec], evaluation: 0.1912[sec]
2024-05-19 16:37:35,277 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:37:35,500 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/17000.ckpt
2024-05-19 16:37:35,515 - INFO - joeynmt.training - Example #0
2024-05-19 16:37:35,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:37:35,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:37:35,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'il@@', 'e', 'of', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'million', 'years', 'of', 'the', 'da@@', 'y@@', "'s", 's@@', 'ha@@', 'p@@', 'ing', 'the', 'p@@', 'id@@', 'er']
2024-05-19 16:37:35,518 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:37:35,518 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:37:35,518 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two sdia's to show that the Poile of the pool, who had about the last three million years of the vast three million years of the United States with 40 percent of the United States with 40 percent of the United States with 40 percent of the United States with 40 percent of the United States with 40 million years of the day's shaping the pider
2024-05-19 16:37:35,518 - INFO - joeynmt.training - Example #1
2024-05-19 16:37:35,518 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:37:35,519 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:37:35,519 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'st', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'he@@', 'd', 'of', 'the', 'ice', 'of', 'ice', 'to', 'show', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:37:35,519 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:37:35,519 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:37:35,520 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nst of this particular problem because it doesn't show the dished of the ice of ice to show the ice.
2024-05-19 16:37:35,520 - INFO - joeynmt.training - Example #2
2024-05-19 16:37:35,520 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:37:35,520 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:37:35,521 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'pol@@', 'ar', 's@@', 'et', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'o@@', 'l', 'is', 'in', 'a', 's@@', 'ha@@', 'pe', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:37:35,521 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:37:35,521 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:37:35,521 - INFO - joeynmt.training - 	Hypothesis: The polar set on the North Pool is in a shape heart of our global climate system.
2024-05-19 16:37:35,522 - INFO - joeynmt.training - Example #3
2024-05-19 16:37:35,522 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:37:35,522 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:37:35,522 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:37:35,523 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:37:35,523 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:37:35,523 - INFO - joeynmt.training - 	Hypothesis: It set out in the summer and crimpt in the summer and crimpt in the summer.
2024-05-19 16:37:35,523 - INFO - joeynmt.training - Example #4
2024-05-19 16:37:35,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:37:35,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:37:35,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'l', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:37:35,525 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:37:35,525 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:37:35,525 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a accell version of what the last 25 years.
2024-05-19 16:37:38,852 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.503276, Batch Acc: 0.575166, Tokens per Sec:    20615, Lr: 0.000300
2024-05-19 16:37:43,126 - INFO - joeynmt.training - Epoch   5, Step:    19700, Batch Loss:     1.366856, Batch Acc: 0.569607, Tokens per Sec:    16915, Lr: 0.000300
2024-05-19 16:37:46,577 - INFO - joeynmt.training - Epoch   5, Step:    19800, Batch Loss:     1.358534, Batch Acc: 0.584331, Tokens per Sec:    21657, Lr: 0.000300
2024-05-19 16:37:49,249 - INFO - joeynmt.training - Epoch   5: total training loss 5857.72
2024-05-19 16:37:49,250 - INFO - joeynmt.training - EPOCH 6
2024-05-19 16:37:49,884 - INFO - joeynmt.training - Epoch   6, Step:    19900, Batch Loss:     1.440907, Batch Acc: 0.591075, Tokens per Sec:    20734, Lr: 0.000300
2024-05-19 16:37:53,323 - INFO - joeynmt.training - Epoch   6, Step:    20000, Batch Loss:     1.407093, Batch Acc: 0.599362, Tokens per Sec:    21257, Lr: 0.000300
2024-05-19 16:37:53,323 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:37:53,325 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:38:04,481 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:38:04,481 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.33, loss:   1.79, ppl:   6.02, acc:   0.49, generation: 10.9309[sec], evaluation: 0.2079[sec]
2024-05-19 16:38:04,688 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/17500.ckpt
2024-05-19 16:38:04,700 - INFO - joeynmt.training - Example #0
2024-05-19 16:38:04,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:38:04,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:38:04,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'v@@', 'est', 'was', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es.', '</s>']
2024-05-19 16:38:04,701 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:38:04,702 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:38:04,702 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the pool, which was the pool, which was the past three million years of the vest was about the size of the United States, 40 percent of the United States.
2024-05-19 16:38:04,702 - INFO - joeynmt.training - Example #1
2024-05-19 16:38:04,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:38:04,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:38:04,703 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'est', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'sho@@', 'w@@', 'ed', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'th@@', 'es@@', 'e.', '</s>']
2024-05-19 16:38:04,703 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:38:04,703 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:38:04,704 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nest of this specific problem because it doesn't showed the didness of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of these.
2024-05-19 16:38:04,704 - INFO - joeynmt.training - Example #2
2024-05-19 16:38:04,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:38:04,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:38:04,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se', 'har@@', 't', 'har@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:38:04,705 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:38:04,705 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:38:04,705 - INFO - joeynmt.training - 	Hypothesis: The ice of the North Pole, in a certain sense, in a sense hart hart of our global climate system.
2024-05-19 16:38:04,705 - INFO - joeynmt.training - Example #3
2024-05-19 16:38:04,706 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:38:04,706 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:38:04,706 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'su@@', 'm@@', 'mer@@', 's', 'and', 'c@@', 'ro@@', 'p@@', 'ed', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:38:04,707 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:38:04,707 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:38:04,707 - INFO - joeynmt.training - 	Hypothesis: It's in the summers and croped in the summer.
2024-05-19 16:38:04,707 - INFO - joeynmt.training - Example #4
2024-05-19 16:38:04,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:38:04,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:38:04,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'sp@@', 'ee@@', 'ch@@', ',', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:38:04,708 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:38:04,708 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:38:04,709 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a speech, a accelerated version of what happened the last 25 years.
2024-05-19 16:38:08,271 - INFO - joeynmt.training - Epoch   6, Step:    20100, Batch Loss:     1.716393, Batch Acc: 0.597228, Tokens per Sec:    19401, Lr: 0.000300
2024-05-19 16:38:12,366 - INFO - joeynmt.training - Epoch   6, Step:    20200, Batch Loss:     1.531335, Batch Acc: 0.590698, Tokens per Sec:    17947, Lr: 0.000300
2024-05-19 16:38:15,834 - INFO - joeynmt.training - Epoch   6, Step:    20300, Batch Loss:     1.365653, Batch Acc: 0.594120, Tokens per Sec:    21579, Lr: 0.000300
2024-05-19 16:38:19,170 - INFO - joeynmt.training - Epoch   6, Step:    20400, Batch Loss:     1.466509, Batch Acc: 0.591144, Tokens per Sec:    22017, Lr: 0.000300
2024-05-19 16:38:23,454 - INFO - joeynmt.training - Epoch   6, Step:    20500, Batch Loss:     1.586741, Batch Acc: 0.592497, Tokens per Sec:    17233, Lr: 0.000300
2024-05-19 16:38:23,455 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:38:23,455 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:38:34,814 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:38:34,814 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.06, loss:   1.79, ppl:   6.01, acc:   0.49, generation: 11.1489[sec], evaluation: 0.1938[sec]
2024-05-19 16:38:35,017 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/18000.ckpt
2024-05-19 16:38:35,033 - INFO - joeynmt.training - Example #0
2024-05-19 16:38:35,034 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:38:35,034 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:38:35,034 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'cap@@', ',', 'who', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'about', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ant', 'was', 'about', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', '4@@', '0', 'percent', 'of', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:38:35,035 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:38:35,035 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:38:35,035 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dia's to show that the Poice cap, who was the past three million years of about the last three million years of the vastant was about 40 percent of the United States with 40 percent of the United States was 40 percent of croms.
2024-05-19 16:38:35,036 - INFO - joeynmt.training - Example #1
2024-05-19 16:38:35,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:38:35,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:38:35,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'have', 'the', 'an@@', 'im@@', 'al@@', 's.', '</s>']
2024-05-19 16:38:35,037 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:38:35,037 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:38:35,037 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this particular problem because it doesn't have the animals.
2024-05-19 16:38:35,037 - INFO - joeynmt.training - Example #2
2024-05-19 16:38:35,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:38:35,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:38:35,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:38:35,039 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:38:35,039 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:38:35,039 - INFO - joeynmt.training - 	Hypothesis: The ice of the North Pole, is in a certain sense, in a certain sense of our global climate system.
2024-05-19 16:38:35,039 - INFO - joeynmt.training - Example #3
2024-05-19 16:38:35,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:38:35,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:38:35,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 's@@', 'et', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:38:35,041 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:38:35,041 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:38:35,041 - INFO - joeynmt.training - 	Hypothesis: It's set out in the winter and crimpt in the summer and crimpt in the summer.
2024-05-19 16:38:35,041 - INFO - joeynmt.training - Example #4
2024-05-19 16:38:35,041 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:38:35,041 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:38:35,042 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 're@@', 'sp@@', 'on@@', 'se', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:38:35,042 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:38:35,042 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:38:35,042 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a response version of what happened the last 25 years.
2024-05-19 16:38:38,521 - INFO - joeynmt.training - Epoch   6, Step:    20600, Batch Loss:     1.573100, Batch Acc: 0.590334, Tokens per Sec:    20443, Lr: 0.000300
2024-05-19 16:38:42,610 - INFO - joeynmt.training - Epoch   6, Step:    20700, Batch Loss:     1.209549, Batch Acc: 0.588661, Tokens per Sec:    17827, Lr: 0.000300
2024-05-19 16:38:46,083 - INFO - joeynmt.training - Epoch   6, Step:    20800, Batch Loss:     1.436429, Batch Acc: 0.591106, Tokens per Sec:    21134, Lr: 0.000300
2024-05-19 16:38:49,367 - INFO - joeynmt.training - Epoch   6, Step:    20900, Batch Loss:     1.304639, Batch Acc: 0.585664, Tokens per Sec:    22728, Lr: 0.000300
2024-05-19 16:38:53,074 - INFO - joeynmt.training - Epoch   6, Step:    21000, Batch Loss:     1.391313, Batch Acc: 0.586627, Tokens per Sec:    19810, Lr: 0.000300
2024-05-19 16:38:53,075 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:38:53,075 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:39:05,042 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:39:05,042 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.75, loss:   1.79, ppl:   5.99, acc:   0.49, generation: 11.7431[sec], evaluation: 0.2079[sec]
2024-05-19 16:39:05,043 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:39:05,265 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/18500.ckpt
2024-05-19 16:39:05,278 - INFO - joeynmt.training - Example #0
2024-05-19 16:39:05,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:39:05,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:39:05,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ic@@', 'e,', 'who', 'had', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:39:05,280 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:39:05,280 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:39:05,280 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the Poice, who had the past three million years of the U.S, with 40 percent of the U.S, with 40 percent of the U.S, with 40 percent of the U.S.
2024-05-19 16:39:05,280 - INFO - joeynmt.training - Example #1
2024-05-19 16:39:05,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:39:05,281 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:39:05,281 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'er@@', 'r@@', 'ies', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'make', 'the', 'de@@', 'ca@@', 'de@@', 's', 'of', 'the', 'ice', 'of', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'thing', 'that', 'is', 'actually', 'sho@@', 'wing', 'the', 'di@@', 's@@', 'gu@@', 'a@@', 'ge.', '</s>']
2024-05-19 16:39:05,282 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:39:05,282 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:39:05,282 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nerries of this specific problem because it doesn't make the decades of the ice of ice of the ice of the ice of thing that is actually showing the disguage.
2024-05-19 16:39:05,282 - INFO - joeynmt.training - Example #2
2024-05-19 16:39:05,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:39:05,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:39:05,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'ap@@', 'p@@', 'le', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'way,', 'in', 'a', 'way,', 'in', 'a', 'way,', 'from', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:39:05,283 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:39:05,284 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:39:05,284 - INFO - joeynmt.training - 	Hypothesis: The ice skapple on the North Pole, in a way, in a way, in a way, from our global climate system.
2024-05-19 16:39:05,284 - INFO - joeynmt.training - Example #3
2024-05-19 16:39:05,284 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:39:05,284 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:39:05,284 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:39:05,285 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:39:05,285 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:39:05,285 - INFO - joeynmt.training - 	Hypothesis: It turns out in the summer.
2024-05-19 16:39:05,285 - INFO - joeynmt.training - Example #4
2024-05-19 16:39:05,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:39:05,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:39:05,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'fa@@', 'st@@', 'er', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:39:05,287 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:39:05,287 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:39:05,287 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a faster version of what happened the last 25 years.
2024-05-19 16:39:09,744 - INFO - joeynmt.training - Epoch   6, Step:    21100, Batch Loss:     1.323581, Batch Acc: 0.587448, Tokens per Sec:    15606, Lr: 0.000300
2024-05-19 16:39:13,072 - INFO - joeynmt.training - Epoch   6, Step:    21200, Batch Loss:     1.444041, Batch Acc: 0.590243, Tokens per Sec:    22511, Lr: 0.000300
2024-05-19 16:39:16,553 - INFO - joeynmt.training - Epoch   6, Step:    21300, Batch Loss:     1.507547, Batch Acc: 0.591622, Tokens per Sec:    21346, Lr: 0.000300
2024-05-19 16:39:19,959 - INFO - joeynmt.training - Epoch   6, Step:    21400, Batch Loss:     1.477396, Batch Acc: 0.587266, Tokens per Sec:    21585, Lr: 0.000300
2024-05-19 16:39:24,274 - INFO - joeynmt.training - Epoch   6, Step:    21500, Batch Loss:     1.295011, Batch Acc: 0.585344, Tokens per Sec:    17763, Lr: 0.000300
2024-05-19 16:39:24,275 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:39:24,275 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:39:34,901 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:39:34,902 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.88, loss:   1.78, ppl:   5.92, acc:   0.50, generation: 10.2554[sec], evaluation: 0.3417[sec]
2024-05-19 16:39:34,902 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:39:35,183 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/19000.ckpt
2024-05-19 16:39:35,207 - INFO - joeynmt.training - Example #0
2024-05-19 16:39:35,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:39:35,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:39:35,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ant', 'was', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'fi@@', 'x', 'of', 'the', 'fi@@', 'x@@', '-@@', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'and', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:39:35,209 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:39:35,209 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:39:35,210 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two dia's to show that the pool, which was the pool, which was the last three million years of the vastant was about the size of the fix of the fix-percent of the U.S. and 40 percent of the U.S.
2024-05-19 16:39:35,210 - INFO - joeynmt.training - Example #1
2024-05-19 16:39:35,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:39:35,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:39:35,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'way', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'clo@@', 's@@', 'er', 'to', 'the', 'an@@', 'ima@@', 'l', 'of', 'the', 'ice', 'of', 'ice', 'that', 'ice', 'is', 'not', 'sho@@', 'wing', 'the', 'di@@', 's@@', 'k.', '</s>']
2024-05-19 16:39:35,211 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:39:35,211 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:39:35,211 - INFO - joeynmt.training - 	Hypothesis: But this is the way this particular problem because it doesn't show the closer to the animal of the ice of ice that ice is not showing the disk.
2024-05-19 16:39:35,211 - INFO - joeynmt.training - Example #2
2024-05-19 16:39:35,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:39:35,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:39:35,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'way,', 'in', 'a', 'way,', 'in', 'the', 'clo@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:39:35,213 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:39:35,213 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:39:35,213 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole is in a way, in a way, in the close of our global climate system.
2024-05-19 16:39:35,213 - INFO - joeynmt.training - Example #3
2024-05-19 16:39:35,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:39:35,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:39:35,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'ned', 'out', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:39:35,214 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:39:35,214 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:39:35,215 - INFO - joeynmt.training - 	Hypothesis: It turned out in the summer and crimpt in the summer.
2024-05-19 16:39:35,215 - INFO - joeynmt.training - Example #4
2024-05-19 16:39:35,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:39:35,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:39:35,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:39:35,216 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:39:35,216 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:39:35,216 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a accelerated version of what happened the last 25 years.
2024-05-19 16:39:39,166 - INFO - joeynmt.training - Epoch   6, Step:    21600, Batch Loss:     1.619225, Batch Acc: 0.585639, Tokens per Sec:    17289, Lr: 0.000300
2024-05-19 16:39:42,462 - INFO - joeynmt.training - Epoch   6, Step:    21700, Batch Loss:     1.384169, Batch Acc: 0.587126, Tokens per Sec:    22133, Lr: 0.000300
2024-05-19 16:39:45,934 - INFO - joeynmt.training - Epoch   6, Step:    21800, Batch Loss:     1.544580, Batch Acc: 0.585963, Tokens per Sec:    20989, Lr: 0.000300
2024-05-19 16:39:49,655 - INFO - joeynmt.training - Epoch   6, Step:    21900, Batch Loss:     1.337291, Batch Acc: 0.582484, Tokens per Sec:    19606, Lr: 0.000300
2024-05-19 16:39:53,513 - INFO - joeynmt.training - Epoch   6, Step:    22000, Batch Loss:     1.419754, Batch Acc: 0.586381, Tokens per Sec:    19110, Lr: 0.000300
2024-05-19 16:39:53,513 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:39:53,514 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:40:05,647 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:40:05,647 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.55, loss:   1.78, ppl:   5.91, acc:   0.50, generation: 11.7342[sec], evaluation: 0.3708[sec]
2024-05-19 16:40:05,648 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:40:05,895 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/20000.ckpt
2024-05-19 16:40:05,911 - INFO - joeynmt.training - Example #0
2024-05-19 16:40:05,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:40:05,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:40:05,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'is', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ed', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'in', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:40:05,913 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:40:05,913 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:40:05,913 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the pool, which is the past three million years of the past three million years of the vasted United Statand of the United States, in 40 percent of the United States,
2024-05-19 16:40:05,913 - INFO - joeynmt.training - Example #1
2024-05-19 16:40:05,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:40:05,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:40:05,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'se@@', 'ver@@', 'al', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'you', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm.', '</s>']
2024-05-19 16:40:05,915 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:40:05,916 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:40:05,916 - INFO - joeynmt.training - 	Hypothesis: But this is actually the several problem because it doesn't show you the didness of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of this particular problem.
2024-05-19 16:40:05,916 - INFO - joeynmt.training - Example #2
2024-05-19 16:40:05,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:40:05,918 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:40:05,918 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:40:05,919 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:40:05,919 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:40:05,919 - INFO - joeynmt.training - 	Hypothesis: The ice on the North Pole in a certain sense, in a sense of our global climate system.
2024-05-19 16:40:05,919 - INFO - joeynmt.training - Example #3
2024-05-19 16:40:05,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:40:05,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:40:05,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'at@@', 'ch', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:40:05,922 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:40:05,922 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:40:05,922 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and catch in the summer.
2024-05-19 16:40:05,923 - INFO - joeynmt.training - Example #4
2024-05-19 16:40:05,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:40:05,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:40:05,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'is', 'a', 'c@@', 'el@@', 'led', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', '</s>']
2024-05-19 16:40:05,924 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:40:05,924 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:40:05,924 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a celled version of what happened the last 25 years is happened in the last 25 years is happened
2024-05-19 16:40:09,313 - INFO - joeynmt.training - Epoch   6, Step:    22100, Batch Loss:     1.490419, Batch Acc: 0.586555, Tokens per Sec:    20172, Lr: 0.000300
2024-05-19 16:40:12,598 - INFO - joeynmt.training - Epoch   6, Step:    22200, Batch Loss:     1.323256, Batch Acc: 0.585201, Tokens per Sec:    22343, Lr: 0.000300
2024-05-19 16:40:16,225 - INFO - joeynmt.training - Epoch   6, Step:    22300, Batch Loss:     1.249088, Batch Acc: 0.586154, Tokens per Sec:    20805, Lr: 0.000300
2024-05-19 16:40:20,405 - INFO - joeynmt.training - Epoch   6, Step:    22400, Batch Loss:     1.391042, Batch Acc: 0.594255, Tokens per Sec:    17177, Lr: 0.000300
2024-05-19 16:40:23,739 - INFO - joeynmt.training - Epoch   6, Step:    22500, Batch Loss:     1.350896, Batch Acc: 0.587416, Tokens per Sec:    22474, Lr: 0.000300
2024-05-19 16:40:23,739 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:40:23,740 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:40:34,506 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:40:34,507 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.48, loss:   1.77, ppl:   5.89, acc:   0.50, generation: 10.5485[sec], evaluation: 0.2021[sec]
2024-05-19 16:40:34,508 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:40:34,726 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/20500.ckpt
2024-05-19 16:40:34,738 - INFO - joeynmt.training - Example #0
2024-05-19 16:40:34,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:40:34,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:40:34,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ic@@', 'e,', 'which', 'the', 'pol@@', 'l@@', 'ine', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:40:34,741 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:40:34,741 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:40:34,741 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the police, which the polline of the vast three million years of the vast three million years of the vast three million years with 40 percent of the United States, 40 percent of the United States,
2024-05-19 16:40:34,741 - INFO - joeynmt.training - Example #1
2024-05-19 16:40:34,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:40:34,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:40:34,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'is', 'the', 'n@@', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'make', 'the', 'di@@', 'v@@', 'ic@@', 'e.', '</s>']
2024-05-19 16:40:34,742 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:40:34,743 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:40:34,743 - INFO - joeynmt.training - 	Hypothesis: But this particular problem is the nice of this specific problem because it doesn't make the divice.
2024-05-19 16:40:34,743 - INFO - joeynmt.training - Example #2
2024-05-19 16:40:34,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:40:34,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:40:34,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'a@@', 'p@@', 'ur@@', 'po@@', 'se', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'is', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 's@@', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:40:34,744 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:40:34,744 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:40:34,744 - INFO - joeynmt.training - 	Hypothesis: The ice apurpose is in a certain sense, is a certain sense, sheart of our global climate system.
2024-05-19 16:40:34,745 - INFO - joeynmt.training - Example #3
2024-05-19 16:40:34,745 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:40:34,745 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:40:34,745 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:40:34,746 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:40:34,746 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:40:34,746 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crimpt in the summer.
2024-05-19 16:40:34,746 - INFO - joeynmt.training - Example #4
2024-05-19 16:40:34,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:40:34,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:40:34,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'c@@', 'el@@', 'led', 'ver@@', 'sion', 'of', 'what', 'the', 'p@@', 'ast', '2@@', '5', 'years', 'is', 'happen@@', 'ing', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:40:34,747 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:40:34,748 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:40:34,748 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a celled version of what the past 25 years is happening 25 years.
2024-05-19 16:40:38,049 - INFO - joeynmt.training - Epoch   6, Step:    22600, Batch Loss:     1.369723, Batch Acc: 0.584988, Tokens per Sec:    20905, Lr: 0.000300
2024-05-19 16:40:41,442 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.405540, Batch Acc: 0.589038, Tokens per Sec:    21759, Lr: 0.000300
2024-05-19 16:40:45,315 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.343158, Batch Acc: 0.592227, Tokens per Sec:    19023, Lr: 0.000300
2024-05-19 16:40:49,317 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.276109, Batch Acc: 0.587717, Tokens per Sec:    18576, Lr: 0.000300
2024-05-19 16:40:52,704 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.188821, Batch Acc: 0.585192, Tokens per Sec:    21826, Lr: 0.000300
2024-05-19 16:40:52,704 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:40:52,705 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:41:04,328 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:41:04,328 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.49, loss:   1.76, ppl:   5.83, acc:   0.50, generation: 11.4159[sec], evaluation: 0.1916[sec]
2024-05-19 16:41:04,329 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:41:04,545 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/19500.ckpt
2024-05-19 16:41:04,560 - INFO - joeynmt.training - Example #0
2024-05-19 16:41:04,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:41:04,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:41:04,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'cap@@', ',', 'which', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ant', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'f@@', 're@@', 'e', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'going', 'to', 'be', 'a', 'lot', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:41:04,562 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:41:04,562 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:41:04,563 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dia's to show that the Poice cap, which the past three million years of the vast three million years of the vastant of the vast three million years with 40 percent of the United States, with 40 percent of the United States was free of the United States was going to be a lot of the size of the United States,
2024-05-19 16:41:04,563 - INFO - joeynmt.training - Example #1
2024-05-19 16:41:04,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:41:04,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:41:04,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'su@@', 'p@@', 'po@@', 's@@', 'ed', 'the', 'n@@', 'ar@@', 'r@@', 'ati@@', 'c', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'be@@', 'at', 'the', 'di@@', 'vi@@', 'de', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'sho@@', 'ws', 'the', 'di@@', 'vi@@', 'de', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'vi@@', 'de', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm.', '</s>']
2024-05-19 16:41:04,564 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:41:04,564 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:41:04,565 - INFO - joeynmt.training - 	Hypothesis: But this supposed the narratic problem because it doesn't show the disbeat the divide of the ice of the ice of the ice of the ice of the ice of the ice of this specific problem because it doesn't shows the divide of this specific problem because it doesn't show the divide of this specific problem.
2024-05-19 16:41:04,565 - INFO - joeynmt.training - Example #2
2024-05-19 16:41:04,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:41:04,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:41:04,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se,', 'in', 'the', 's@@', 'lu@@', 'c@@', 'k@@', 'y', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:41:04,566 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:41:04,566 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:41:04,566 - INFO - joeynmt.training - 	Hypothesis: The ice skp on the North Pole, in a sense, in a sense, in the slucky heart of our global climate system.
2024-05-19 16:41:04,566 - INFO - joeynmt.training - Example #3
2024-05-19 16:41:04,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:41:04,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:41:04,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'ned', 'out', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ro@@', 'p', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:41:04,567 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:41:04,568 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:41:04,568 - INFO - joeynmt.training - 	Hypothesis: It turned out in the summer and crop in the summer.
2024-05-19 16:41:04,568 - INFO - joeynmt.training - Example #4
2024-05-19 16:41:04,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:41:04,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:41:04,569 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'sp@@', 'ee@@', 'd@@', '-@@', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:41:04,569 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:41:04,569 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:41:04,569 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a speed-accelerated version of what happened the last 25 years.
2024-05-19 16:41:08,051 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.381592, Batch Acc: 0.587227, Tokens per Sec:    19674, Lr: 0.000300
2024-05-19 16:41:11,330 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     1.445769, Batch Acc: 0.590114, Tokens per Sec:    21870, Lr: 0.000300
2024-05-19 16:41:15,841 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.400568, Batch Acc: 0.585914, Tokens per Sec:    16090, Lr: 0.000300
2024-05-19 16:41:19,142 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.599365, Batch Acc: 0.582662, Tokens per Sec:    21792, Lr: 0.000300
2024-05-19 16:41:22,485 - INFO - joeynmt.training - Epoch   6, Step:    23500, Batch Loss:     1.424789, Batch Acc: 0.584276, Tokens per Sec:    21648, Lr: 0.000300
2024-05-19 16:41:22,485 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:41:22,485 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:41:34,182 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:41:34,182 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.17, loss:   1.76, ppl:   5.83, acc:   0.50, generation: 11.4936[sec], evaluation: 0.1872[sec]
2024-05-19 16:41:34,183 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:41:34,398 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/21000.ckpt
2024-05-19 16:41:34,417 - INFO - joeynmt.training - Example #0
2024-05-19 16:41:34,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:41:34,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:41:34,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'was', 'about', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'about', 'a', 'p@@', 'ool@@', ',', '</s>']
2024-05-19 16:41:34,419 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:41:34,419 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:41:34,419 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the pool, which was the pool, who had about three million years of the size of the United States with 40 percent of the United States with 40 percent of the United States was 40 percent of the United States was was about 40 percent of the United States was about a pool,
2024-05-19 16:41:34,419 - INFO - joeynmt.training - Example #1
2024-05-19 16:41:34,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:41:34,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:41:34,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'n@@', 'st', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'proble@@']
2024-05-19 16:41:34,420 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:41:34,420 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:41:34,420 - INFO - joeynmt.training - 	Hypothesis: But this particular problem because it doesn't show the nst of this specific problem because it doesn't show the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the proble
2024-05-19 16:41:34,420 - INFO - joeynmt.training - Example #2
2024-05-19 16:41:34,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:41:34,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:41:34,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'he@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se', 'of', 'the', 's@@', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:41:34,421 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:41:34,421 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:41:34,421 - INFO - joeynmt.training - 	Hypothesis: The ice heap on the North Pole, in a sense of the sheart of our global climate system.
2024-05-19 16:41:34,422 - INFO - joeynmt.training - Example #3
2024-05-19 16:41:34,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:41:34,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:41:34,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ra@@', 'z@@', 'y.', '</s>']
2024-05-19 16:41:34,422 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:41:34,422 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:41:34,422 - INFO - joeynmt.training - 	Hypothesis: It set out in the winter and crazy.
2024-05-19 16:41:34,423 - INFO - joeynmt.training - Example #4
2024-05-19 16:41:34,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:41:34,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:41:34,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'show', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'is', 'happen@@', 'ing', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'to', 'be', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'is', 'happen@@', 'ing', 'in', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ed', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'is', 'happen@@', 'ed', 'to', 'be', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'next', 's@@']
2024-05-19 16:41:34,423 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:41:34,423 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:41:34,424 - INFO - joeynmt.training - 	Hypothesis: The next slide that I show is a accelated version of what happened is happening in the last 25 years is happened in the last 25 years is happened in the last 25 years is happened in the last 25 years is happened to be a accelerated version of what happened is happening in the last 25 years is happened version of what happened is happened to be a accelerated version of what happened the next s
2024-05-19 16:41:37,725 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.508191, Batch Acc: 0.589266, Tokens per Sec:    21342, Lr: 0.000300
2024-05-19 16:41:41,369 - INFO - joeynmt.training - Epoch   6, Step:    23700, Batch Loss:     1.354431, Batch Acc: 0.584493, Tokens per Sec:    19645, Lr: 0.000300
2024-05-19 16:41:45,546 - INFO - joeynmt.training - Epoch   6, Step:    23800, Batch Loss:     1.357389, Batch Acc: 0.587792, Tokens per Sec:    18099, Lr: 0.000300
2024-05-19 16:41:47,486 - INFO - joeynmt.training - Epoch   6: total training loss 5642.22
2024-05-19 16:41:47,487 - INFO - joeynmt.training - EPOCH 7
2024-05-19 16:41:48,938 - INFO - joeynmt.training - Epoch   7, Step:    23900, Batch Loss:     1.313425, Batch Acc: 0.596746, Tokens per Sec:    21436, Lr: 0.000300
2024-05-19 16:41:52,268 - INFO - joeynmt.training - Epoch   7, Step:    24000, Batch Loss:     1.330117, Batch Acc: 0.611600, Tokens per Sec:    22613, Lr: 0.000300
2024-05-19 16:41:52,268 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:41:52,269 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:42:04,014 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:42:04,014 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.27, loss:   1.77, ppl:   5.85, acc:   0.50, generation: 11.5374[sec], evaluation: 0.1905[sec]
2024-05-19 16:42:04,232 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/21500.ckpt
2024-05-19 16:42:04,244 - INFO - joeynmt.training - Example #0
2024-05-19 16:42:04,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:42:04,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:42:04,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 'y', 'cap@@', ',', 'who', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ant', 'had', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'f@@', 'lo@@', 'wing', 'up', 'the', 'p@@', 'ool@@', 'ij@@', 'u@@', 'm@@', 'p', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:42:04,247 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:42:04,247 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:42:04,247 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dia's to show that the pooly cap, who was the pool, who had about three million years of the vastant had about the size of the United States with 40 percent of the United States with 40 percent of the United States was flowing up the poolijump of the United States,
2024-05-19 16:42:04,247 - INFO - joeynmt.training - Example #1
2024-05-19 16:42:04,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:42:04,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:42:04,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'is', 'the', 'n@@', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'allo@@', 'ws', 'the', 'ice', 'of', 'ice', 'of', 'the', 'ice', 'of', 'ice', 'of', 'ice', 'that', 'ice', 'is', 'that', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'ice', 'of', 'ice', 'proble@@', 'm.', '</s>']
2024-05-19 16:42:04,249 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:42:04,249 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:42:04,249 - INFO - joeynmt.training - 	Hypothesis: But this particular problem is the nice of this particular problem because it doesn't allows the ice of ice of the ice of ice of ice that ice is that the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of ice of the ice of the ice of ice of ice problem.
2024-05-19 16:42:04,249 - INFO - joeynmt.training - Example #2
2024-05-19 16:42:04,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:42:04,250 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:42:04,250 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'the', 's@@', 'hel@@', 'l', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:42:04,250 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:42:04,250 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:42:04,251 - INFO - joeynmt.training - 	Hypothesis: The ice skp on the North Pole is in a certain sense, in the shell of our global climate system.
2024-05-19 16:42:04,251 - INFO - joeynmt.training - Example #3
2024-05-19 16:42:04,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:42:04,251 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:42:04,251 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:42:04,252 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:42:04,252 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:42:04,252 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crimpt in summer and crimpt in summer.
2024-05-19 16:42:04,252 - INFO - joeynmt.training - Example #4
2024-05-19 16:42:04,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:42:04,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:42:04,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'c@@', 'ro@@', 'w@@', 'd', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:42:04,253 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:42:04,254 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:42:04,254 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a crowd version of what happened the last 25 years is happening in the last 25 years.
2024-05-19 16:42:07,642 - INFO - joeynmt.training - Epoch   7, Step:    24100, Batch Loss:     1.470079, Batch Acc: 0.604237, Tokens per Sec:    20345, Lr: 0.000300
2024-05-19 16:42:12,083 - INFO - joeynmt.training - Epoch   7, Step:    24200, Batch Loss:     1.354087, Batch Acc: 0.602994, Tokens per Sec:    16427, Lr: 0.000300
2024-05-19 16:42:15,443 - INFO - joeynmt.training - Epoch   7, Step:    24300, Batch Loss:     1.501953, Batch Acc: 0.605907, Tokens per Sec:    21741, Lr: 0.000300
2024-05-19 16:42:18,797 - INFO - joeynmt.training - Epoch   7, Step:    24400, Batch Loss:     1.200099, Batch Acc: 0.602560, Tokens per Sec:    21995, Lr: 0.000300
2024-05-19 16:42:22,160 - INFO - joeynmt.training - Epoch   7, Step:    24500, Batch Loss:     1.547967, Batch Acc: 0.600664, Tokens per Sec:    22121, Lr: 0.000300
2024-05-19 16:42:22,160 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:42:22,160 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:42:32,344 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:42:32,345 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.39, loss:   1.76, ppl:   5.82, acc:   0.50, generation: 9.9697[sec], evaluation: 0.1993[sec]
2024-05-19 16:42:32,346 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:42:32,562 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/22000.ckpt
2024-05-19 16:42:32,578 - INFO - joeynmt.training - Example #0
2024-05-19 16:42:32,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:42:32,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:42:32,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'years', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ic@@', 'y', 'cap@@', 'it@@', 'al', 'cap@@', 'it@@', 'al,', 'who', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ed', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'had', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'f@@', 'lo@@', 'wing', 'the', 'p@@', 'ool@@', 'ic@@', 's.', '</s>']
2024-05-19 16:42:32,580 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:42:32,580 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:42:32,581 - INFO - joeynmt.training - 	Hypothesis: Last years I showed these two slides to show that the policy capital capital, who had about the past three million years of the vasted United Statand had 40 percent of the United States of the United States of the United States of the United States was flowing the poolics.
2024-05-19 16:42:32,581 - INFO - joeynmt.training - Example #1
2024-05-19 16:42:32,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:42:32,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:42:32,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'su@@', 'mm@@', 'it', 'actually', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'lea@@', 've', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'di@@', 's@@', 'k.', '</s>']
2024-05-19 16:42:32,582 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:42:32,582 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:42:32,582 - INFO - joeynmt.training - 	Hypothesis: But this is the summit actually actually the nice of this particular problem because it doesn't leave the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the disk.
2024-05-19 16:42:32,583 - INFO - joeynmt.training - Example #2
2024-05-19 16:42:32,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:42:32,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:42:32,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'in', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'sen@@', 'se', 'of', 'the', 's@@', 'hel@@', 'p', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:42:32,584 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:42:32,584 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:42:32,584 - INFO - joeynmt.training - 	Hypothesis: The ice skin on the North Pole is in a sense of the shelp of our global climate system.
2024-05-19 16:42:32,584 - INFO - joeynmt.training - Example #3
2024-05-19 16:42:32,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:42:32,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:42:32,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'su@@', 'm@@', 'mer@@', ',', 'and', 's@@', "he's", 'c@@', 'ro@@', 'p@@', 'ed', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:42:32,585 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:42:32,585 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:42:32,586 - INFO - joeynmt.training - 	Hypothesis: It's in the summer, and she's croped in the summer.
2024-05-19 16:42:32,586 - INFO - joeynmt.training - Example #4
2024-05-19 16:42:32,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:42:32,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:42:32,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'ed', 'ver@@', 'sion', 'of', 'what', 'happen@@', 's', 'is', 'happen@@', 'ing', 'the', 'p@@', 'ast', '2@@', '5', 'years', 'is', 'happen@@', 'ed.', '</s>']
2024-05-19 16:42:32,587 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:42:32,587 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:42:32,587 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a acceled version of what happens is happening the past 25 years is happened.
2024-05-19 16:42:35,918 - INFO - joeynmt.training - Epoch   7, Step:    24600, Batch Loss:     1.324050, Batch Acc: 0.602721, Tokens per Sec:    19958, Lr: 0.000300
2024-05-19 16:42:40,439 - INFO - joeynmt.training - Epoch   7, Step:    24700, Batch Loss:     1.480070, Batch Acc: 0.598105, Tokens per Sec:    15925, Lr: 0.000300
2024-05-19 16:42:43,751 - INFO - joeynmt.training - Epoch   7, Step:    24800, Batch Loss:     1.382776, Batch Acc: 0.599077, Tokens per Sec:    22167, Lr: 0.000300
2024-05-19 16:42:47,063 - INFO - joeynmt.training - Epoch   7, Step:    24900, Batch Loss:     1.398499, Batch Acc: 0.603638, Tokens per Sec:    22752, Lr: 0.000300
2024-05-19 16:42:50,386 - INFO - joeynmt.training - Epoch   7, Step:    25000, Batch Loss:     1.253247, Batch Acc: 0.606372, Tokens per Sec:    22198, Lr: 0.000300
2024-05-19 16:42:50,387 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:42:50,387 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:43:01,243 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:43:01,243 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.42, loss:   1.76, ppl:   5.83, acc:   0.50, generation: 10.6494[sec], evaluation: 0.1903[sec]
2024-05-19 16:43:01,453 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/22500.ckpt
2024-05-19 16:43:01,468 - INFO - joeynmt.training - Example #0
2024-05-19 16:43:01,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:43:01,469 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:43:01,469 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 'cap@@', ',', 'which', 'the', 'pol@@', 'ar', 'cap@@', ',', 'which', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ed', 'St@@', 'an@@', 'd,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'with', 'f@@', 'our', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'f@@', 'ar', 'ar', 'ar', 'ye@@', 'ar', 'as', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'a', '4@@', '0', 'year@@', '.', '</s>']
2024-05-19 16:43:01,469 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:43:01,470 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:43:01,470 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the polar cap, which the polar cap, which was the past three million years of the vasted Stand, with 40 percent of the United States with 40 percent of the United States with four percent of the United States was far ar ar year as the size of the United States was a 40 year.
2024-05-19 16:43:01,470 - INFO - joeynmt.training - Example #1
2024-05-19 16:43:01,470 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:43:01,470 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:43:01,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'going', 'to', 'show', 'the', 'di@@', 's@@', 'k', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:43:01,471 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:43:01,471 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:43:01,472 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it is not going to show the disk of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice.
2024-05-19 16:43:01,472 - INFO - joeynmt.training - Example #2
2024-05-19 16:43:01,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:43:01,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:43:01,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'of', 'the', 'ice', 'of', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'sen@@', 'se', 'of', 'the', 's@@', 'ing@@', 'le', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:43:01,473 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:43:01,473 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:43:01,473 - INFO - joeynmt.training - 	Hypothesis: The ice of the ice of the North Pole is in a sense of the single heart of our global climate system.
2024-05-19 16:43:01,474 - INFO - joeynmt.training - Example #3
2024-05-19 16:43:01,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:43:01,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:43:01,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ro@@', 'p@@', 'ed', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ra@@', 'z@@', 'y.', '</s>']
2024-05-19 16:43:01,475 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:43:01,475 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:43:01,475 - INFO - joeynmt.training - 	Hypothesis: It's in the winter and croped in the summer and crazy.
2024-05-19 16:43:01,475 - INFO - joeynmt.training - Example #4
2024-05-19 16:43:01,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:43:01,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:43:01,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'sp@@', 'ee@@', 'd@@', '-@@', 'sp@@', 'ent', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:43:01,476 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:43:01,476 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:43:01,477 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a speed-spent version of what happened the last 25 years.
2024-05-19 16:43:04,920 - INFO - joeynmt.training - Epoch   7, Step:    25100, Batch Loss:     1.340946, Batch Acc: 0.600945, Tokens per Sec:    20044, Lr: 0.000300
2024-05-19 16:43:10,141 - INFO - joeynmt.training - Epoch   7, Step:    25200, Batch Loss:     1.288236, Batch Acc: 0.598236, Tokens per Sec:    14230, Lr: 0.000300
2024-05-19 16:43:14,061 - INFO - joeynmt.training - Epoch   7, Step:    25300, Batch Loss:     1.420670, Batch Acc: 0.604640, Tokens per Sec:    18970, Lr: 0.000300
2024-05-19 16:43:17,387 - INFO - joeynmt.training - Epoch   7, Step:    25400, Batch Loss:     1.526088, Batch Acc: 0.599965, Tokens per Sec:    22197, Lr: 0.000300
2024-05-19 16:43:20,943 - INFO - joeynmt.training - Epoch   7, Step:    25500, Batch Loss:     1.308305, Batch Acc: 0.598982, Tokens per Sec:    21151, Lr: 0.000300
2024-05-19 16:43:20,944 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:43:20,944 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:43:31,001 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:43:31,002 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.37, loss:   1.75, ppl:   5.78, acc:   0.50, generation: 9.8596[sec], evaluation: 0.1828[sec]
2024-05-19 16:43:31,003 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:43:31,228 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/24000.ckpt
2024-05-19 16:43:31,243 - INFO - joeynmt.training - Example #0
2024-05-19 16:43:31,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:43:31,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:43:31,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ic@@', 'y', 'cap@@', ',', 'which', 'the', 'pol@@', 'ic@@', 'y', 'cap@@', ',', 'who', 'had', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'f@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:43:31,245 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:43:31,245 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:43:31,246 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the policy cap, which the policy cap, who had about the size of the United Statand of the United States, with 40 percent of the United States was froms.
2024-05-19 16:43:31,246 - INFO - joeynmt.training - Example #1
2024-05-19 16:43:31,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:43:31,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:43:31,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'lea@@', 've', 'the', 'di@@', 's@@', 'gu@@', 'st@@', 'ing', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'lea@@', 've', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:43:31,247 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:43:31,247 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:43:31,247 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this particular problem because it doesn't leave the disgusting of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of this particular problem because it doesn't leave the ice.
2024-05-19 16:43:31,248 - INFO - joeynmt.training - Example #2
2024-05-19 16:43:31,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:43:31,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:43:31,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'g@@', 'lob@@', 'al', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:43:31,249 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:43:31,249 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:43:31,249 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole is in a sense of the global heart of our global climate system.
2024-05-19 16:43:31,249 - INFO - joeynmt.training - Example #3
2024-05-19 16:43:31,250 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:43:31,250 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:43:31,250 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'su@@', 'm@@', 'mer@@', ',', 'and', 's@@', 'ac@@', 'red', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:43:31,250 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:43:31,250 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:43:31,251 - INFO - joeynmt.training - 	Hypothesis: It turns out in the summer, and sacred in the summer.
2024-05-19 16:43:31,251 - INFO - joeynmt.training - Example #4
2024-05-19 16:43:31,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:43:31,251 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:43:31,251 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'year@@', 's.', '</s>']
2024-05-19 16:43:31,252 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:43:31,252 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:43:31,252 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a accelerated version of what happened the last 25 years of what happened in the last 25 years of years.
2024-05-19 16:43:34,873 - INFO - joeynmt.training - Epoch   7, Step:    25600, Batch Loss:     1.520392, Batch Acc: 0.597901, Tokens per Sec:    19303, Lr: 0.000300
2024-05-19 16:43:38,991 - INFO - joeynmt.training - Epoch   7, Step:    25700, Batch Loss:     1.327627, Batch Acc: 0.601599, Tokens per Sec:    17716, Lr: 0.000300
2024-05-19 16:43:42,491 - INFO - joeynmt.training - Epoch   7, Step:    25800, Batch Loss:     1.358756, Batch Acc: 0.603103, Tokens per Sec:    21382, Lr: 0.000300
2024-05-19 16:43:45,749 - INFO - joeynmt.training - Epoch   7, Step:    25900, Batch Loss:     1.515587, Batch Acc: 0.598463, Tokens per Sec:    22409, Lr: 0.000300
2024-05-19 16:43:49,512 - INFO - joeynmt.training - Epoch   7, Step:    26000, Batch Loss:     1.473814, Batch Acc: 0.599345, Tokens per Sec:    19874, Lr: 0.000300
2024-05-19 16:43:49,513 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:43:49,513 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:44:01,083 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:44:01,083 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.01, loss:   1.75, ppl:   5.78, acc:   0.50, generation: 11.3533[sec], evaluation: 0.2003[sec]
2024-05-19 16:44:01,289 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/23000.ckpt
2024-05-19 16:44:01,305 - INFO - joeynmt.training - Example #0
2024-05-19 16:44:01,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:44:01,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:44:01,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ic@@', 'y', 'cap@@', ',', 'which', 'was', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'about', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ated', 'St@@', 'and', 'of', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', '4@@', '0', 'percent', 'of', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:44:01,306 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:44:01,306 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:44:01,307 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the policy cap, which was the pool, which was about the last three million years of the vastated Stand of 40 percent of the United Statand of 40 percent of roms.
2024-05-19 16:44:01,307 - INFO - joeynmt.training - Example #1
2024-05-19 16:44:01,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:44:01,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:44:01,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'n@@', 'at@@', 'ure', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'ic@@', 'e@@', '-@@', 'sho@@', 'wing', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e@@', '-@@', 'di@@', 's@@', 'k.', '</s>']
2024-05-19 16:44:01,308 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:44:01,308 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:44:01,308 - INFO - joeynmt.training - 	Hypothesis: But this particular problem because it doesn't show the nature of this specific problem because it doesn't show the ice-showing the ice of the ice of the ice of the ice of the ice of the ice of the ice-disk.
2024-05-19 16:44:01,309 - INFO - joeynmt.training - Example #2
2024-05-19 16:44:01,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:44:01,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:44:01,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'o@@', 'le,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 's@@', 'it', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:44:01,310 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:44:01,310 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:44:01,310 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Poole, in a certain sense, sit of our global climate system.
2024-05-19 16:44:01,310 - INFO - joeynmt.training - Example #3
2024-05-19 16:44:01,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:44:01,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:44:01,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 'ed', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:44:01,311 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:44:01,311 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:44:01,311 - INFO - joeynmt.training - 	Hypothesis: It set out in the winter and crimped in the summer.
2024-05-19 16:44:01,312 - INFO - joeynmt.training - Example #4
2024-05-19 16:44:01,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:44:01,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:44:01,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'ing', 'ver@@', 'sion', 'of', 'what', 'happen@@', 's', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'happen@@', 'ing', 'for', 'the', 'last', '2@@', '5', 'years', '</s>']
2024-05-19 16:44:01,313 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:44:01,313 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:44:01,313 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a acceling version of what happens in the last 25 years of happening for the last 25 years
2024-05-19 16:44:05,530 - INFO - joeynmt.training - Epoch   7, Step:    26100, Batch Loss:     1.314101, Batch Acc: 0.597700, Tokens per Sec:    16605, Lr: 0.000300
2024-05-19 16:44:09,079 - INFO - joeynmt.training - Epoch   7, Step:    26200, Batch Loss:     1.405717, Batch Acc: 0.600397, Tokens per Sec:    20876, Lr: 0.000300
2024-05-19 16:44:12,575 - INFO - joeynmt.training - Epoch   7, Step:    26300, Batch Loss:     1.284074, Batch Acc: 0.591506, Tokens per Sec:    21343, Lr: 0.000300
2024-05-19 16:44:15,953 - INFO - joeynmt.training - Epoch   7, Step:    26400, Batch Loss:     1.408234, Batch Acc: 0.597960, Tokens per Sec:    21367, Lr: 0.000300
2024-05-19 16:44:20,178 - INFO - joeynmt.training - Epoch   7, Step:    26500, Batch Loss:     1.326264, Batch Acc: 0.603188, Tokens per Sec:    17328, Lr: 0.000300
2024-05-19 16:44:20,179 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:44:20,179 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:44:31,299 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:44:31,300 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.63, loss:   1.76, ppl:   5.79, acc:   0.50, generation: 10.7606[sec], evaluation: 0.3325[sec]
2024-05-19 16:44:31,539 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/25000.ckpt
2024-05-19 16:44:31,583 - INFO - joeynmt.training - Example #0
2024-05-19 16:44:31,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:44:31,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:44:31,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 'cap@@', ',', 'which', 'was', 'the', 'pol@@', 'ar', 'cap@@', ',', 'who', 'had', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'ac@@', 'tion', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '4@@', '0', 'percent', 'was', 'c@@', 'ro@@', 'w@@', 's.', '</s>']
2024-05-19 16:44:31,585 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:44:31,586 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:44:31,586 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the polar cap, which was the polar cap, who had about the size of the vaction of the United Statand 40 percent of the United States, 40 percent was crows.
2024-05-19 16:44:31,586 - INFO - joeynmt.training - Example #1
2024-05-19 16:44:31,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:44:31,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:44:31,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'st', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'de@@', 'v@@', 'ic@@', 'es', 'of', 'the', 'ice', 'of', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:44:31,587 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:44:31,587 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:44:31,587 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nst of this particular problem because it doesn't show the devices of the ice of ice of the ice.
2024-05-19 16:44:31,587 - INFO - joeynmt.training - Example #2
2024-05-19 16:44:31,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:44:31,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:44:31,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'is', 'the', 'clo@@', 's@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:44:31,589 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:44:31,589 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:44:31,589 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a certain sense, is the closing heart of our global climate system.
2024-05-19 16:44:31,589 - INFO - joeynmt.training - Example #3
2024-05-19 16:44:31,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:44:31,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:44:31,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:44:31,590 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:44:31,590 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:44:31,591 - INFO - joeynmt.training - 	Hypothesis: It's in the summer and crimpt in the summer and crimpt in the summer.
2024-05-19 16:44:31,591 - INFO - joeynmt.training - Example #4
2024-05-19 16:44:31,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:44:31,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:44:31,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ate', 'ver@@', 'sion', 'of', 'what', 'happen@@', 's', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:44:31,592 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:44:31,592 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:44:31,592 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a accelerate version of what happens is happened in the last 25 years.
2024-05-19 16:44:35,439 - INFO - joeynmt.training - Epoch   7, Step:    26600, Batch Loss:     1.390311, Batch Acc: 0.597458, Tokens per Sec:    18026, Lr: 0.000300
2024-05-19 16:44:38,879 - INFO - joeynmt.training - Epoch   7, Step:    26700, Batch Loss:     1.365911, Batch Acc: 0.600366, Tokens per Sec:    21440, Lr: 0.000300
2024-05-19 16:44:42,317 - INFO - joeynmt.training - Epoch   7, Step:    26800, Batch Loss:     1.491606, Batch Acc: 0.597736, Tokens per Sec:    21074, Lr: 0.000300
2024-05-19 16:44:46,245 - INFO - joeynmt.training - Epoch   7, Step:    26900, Batch Loss:     1.494415, Batch Acc: 0.600789, Tokens per Sec:    18657, Lr: 0.000300
2024-05-19 16:44:49,917 - INFO - joeynmt.training - Epoch   7, Step:    27000, Batch Loss:     1.551871, Batch Acc: 0.596201, Tokens per Sec:    20450, Lr: 0.000300
2024-05-19 16:44:49,917 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:44:49,917 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:45:00,944 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:45:00,945 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.53, loss:   1.74, ppl:   5.72, acc:   0.50, generation: 10.6511[sec], evaluation: 0.3415[sec]
2024-05-19 16:45:00,946 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:45:01,223 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/23500.ckpt
2024-05-19 16:45:01,252 - INFO - joeynmt.training - Example #0
2024-05-19 16:45:01,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:45:01,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:45:01,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'y', 'cap@@', ',', 'who', 'had', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'ma@@', 'j@@', 'or', 'had', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:45:01,254 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:45:01,254 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:45:01,254 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the Poy cap, who had the past three million years of the major had been the size of the U.S.
2024-05-19 16:45:01,255 - INFO - joeynmt.training - Example #1
2024-05-19 16:45:01,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:45:01,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:45:01,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'vi@@', 'de', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e@@', '-@@', 'c@@', 'at@@', 'ch', 'proble@@', 'm.', '</s>']
2024-05-19 16:45:01,256 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:45:01,256 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:45:01,256 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this specific problem because it doesn't show the divide of the ice of the ice of the ice of the ice of the ice of the ice-catch problem.
2024-05-19 16:45:01,257 - INFO - joeynmt.training - Example #2
2024-05-19 16:45:01,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:45:01,257 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:45:01,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'way,', 's@@', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:45:01,258 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:45:01,258 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:45:01,258 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a way, sheart of our global climate system.
2024-05-19 16:45:01,259 - INFO - joeynmt.training - Example #3
2024-05-19 16:45:01,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:45:01,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:45:01,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:45:01,260 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:45:01,260 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:45:01,260 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crimpt in the summer.
2024-05-19 16:45:01,260 - INFO - joeynmt.training - Example #4
2024-05-19 16:45:01,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:45:01,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:45:01,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'con@@', 'c@@', 'lu@@', 'de', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:45:01,262 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:45:01,262 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:45:01,262 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a conclude version of what happened the last 25 years.
2024-05-19 16:45:04,596 - INFO - joeynmt.training - Epoch   7, Step:    27100, Batch Loss:     1.355394, Batch Acc: 0.596259, Tokens per Sec:    20472, Lr: 0.000300
2024-05-19 16:45:07,961 - INFO - joeynmt.training - Epoch   7, Step:    27200, Batch Loss:     1.429751, Batch Acc: 0.598177, Tokens per Sec:    22368, Lr: 0.000300
2024-05-19 16:45:11,594 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     1.602477, Batch Acc: 0.595120, Tokens per Sec:    20336, Lr: 0.000300
2024-05-19 16:45:15,766 - INFO - joeynmt.training - Epoch   7, Step:    27400, Batch Loss:     1.335498, Batch Acc: 0.597782, Tokens per Sec:    17426, Lr: 0.000300
2024-05-19 16:45:19,050 - INFO - joeynmt.training - Epoch   7, Step:    27500, Batch Loss:     1.525238, Batch Acc: 0.598668, Tokens per Sec:    21855, Lr: 0.000300
2024-05-19 16:45:19,050 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:45:19,051 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:45:29,528 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:45:29,529 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.76, loss:   1.74, ppl:   5.71, acc:   0.50, generation: 10.2659[sec], evaluation: 0.1948[sec]
2024-05-19 16:45:29,529 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:45:29,742 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/24500.ckpt
2024-05-19 16:45:29,756 - INFO - joeynmt.training - Example #0
2024-05-19 16:45:29,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:45:29,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:45:29,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'y', 'cap@@', ',', 'which', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'about', 'the', 'last', 'three', 'million', 'years', 'about', 'the', 'de@@', 'ca@@', 'de@@', 's', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:45:29,758 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:45:29,758 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:45:29,758 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the Poy cap, which was the past three million years about the last three million years about the decades of the U.S. with 40 percent of the U.S.
2024-05-19 16:45:29,759 - INFO - joeynmt.training - Example #1
2024-05-19 16:45:29,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:45:29,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:45:29,759 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'gu@@', 'st@@', 'ing', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'gu@@', 'st@@', 'ing', 'the', 'di@@', 's@@', 'k.', '</s>']
2024-05-19 16:45:29,760 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:45:29,760 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:45:29,760 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it doesn't show the disgusting because it doesn't show the disgusting the disk.
2024-05-19 16:45:29,760 - INFO - joeynmt.training - Example #2
2024-05-19 16:45:29,760 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:45:29,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:45:29,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'sen@@', 'se,', 'in', 'a', 'way,', 'the', 'de@@', 'cl@@', 'ine', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:45:29,761 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:45:29,761 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:45:29,762 - INFO - joeynmt.training - 	Hypothesis: The ice skp on the North Pole is in a sense, in a way, the decline heart of our global climate system.
2024-05-19 16:45:29,762 - INFO - joeynmt.training - Example #3
2024-05-19 16:45:29,762 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:45:29,762 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:45:29,762 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:45:29,763 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:45:29,763 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:45:29,763 - INFO - joeynmt.training - 	Hypothesis: It's in the winter and crimpt in the summer and crimpt in the summer and crimpt in the summer.
2024-05-19 16:45:29,763 - INFO - joeynmt.training - Example #4
2024-05-19 16:45:29,763 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:45:29,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:45:29,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'sp@@', 'ee@@', 'ch@@', ',', 'a', 'sp@@', 'ee@@', 'ch@@', ',', '</s>']
2024-05-19 16:45:29,764 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:45:29,764 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:45:29,764 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a speech, a speech,
2024-05-19 16:45:33,129 - INFO - joeynmt.training - Epoch   7, Step:    27600, Batch Loss:     1.270373, Batch Acc: 0.598853, Tokens per Sec:    20339, Lr: 0.000300
2024-05-19 16:45:36,441 - INFO - joeynmt.training - Epoch   7, Step:    27700, Batch Loss:     1.400915, Batch Acc: 0.598243, Tokens per Sec:    22409, Lr: 0.000300
2024-05-19 16:45:40,090 - INFO - joeynmt.training - Epoch   7, Step:    27800, Batch Loss:     1.446522, Batch Acc: 0.591489, Tokens per Sec:    19680, Lr: 0.000300
2024-05-19 16:45:41,553 - INFO - joeynmt.training - Epoch   7: total training loss 5470.63
2024-05-19 16:45:41,554 - INFO - joeynmt.training - EPOCH 8
2024-05-19 16:45:44,270 - INFO - joeynmt.training - Epoch   8, Step:    27900, Batch Loss:     1.334562, Batch Acc: 0.620550, Tokens per Sec:    18793, Lr: 0.000300
2024-05-19 16:45:47,629 - INFO - joeynmt.training - Epoch   8, Step:    28000, Batch Loss:     1.170791, Batch Acc: 0.614492, Tokens per Sec:    22076, Lr: 0.000300
2024-05-19 16:45:47,630 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:45:47,630 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:45:59,092 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:45:59,092 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.59, loss:   1.75, ppl:   5.77, acc:   0.51, generation: 11.2544[sec], evaluation: 0.1914[sec]
2024-05-19 16:45:59,308 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/26500.ckpt
2024-05-19 16:45:59,329 - INFO - joeynmt.training - Example #0
2024-05-19 16:45:59,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:45:59,331 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:45:59,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'cap@@', ',', 'who', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'va@@', 'st@@', 'ant', 'was', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'was', 'was', 'going', 'to', 'show', 'you', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'ye@@', 'ar', 'ye@@', 'ar', 'and', 'the', 'si@@', 'ze', 'of', 'the', 'da@@', 'y@@', "'s", 'ye@@', 'ar', 'and', 'the', 'p@@', 'ool@@', ',']
2024-05-19 16:45:59,332 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:45:59,332 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:45:59,332 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the Poice cap, who was the past three million years of the size of the vastant was about the size of the United Statand of the United Statand of the United Statand of the United Statand was was going to show you the size of the United year year and the size of the day's year and the pool,
2024-05-19 16:45:59,333 - INFO - joeynmt.training - Example #1
2024-05-19 16:45:59,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:45:59,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:45:59,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'first', 'first', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'de@@', 'al', 'with', 'the', 'ic@@', 'e@@', ':', '</s>']
2024-05-19 16:45:59,334 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:45:59,334 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:45:59,334 - INFO - joeynmt.training - 	Hypothesis: But this is actually the first first of this specific problem because it doesn't deal with the ice:
2024-05-19 16:45:59,335 - INFO - joeynmt.training - Example #2
2024-05-19 16:45:59,335 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:45:59,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:45:59,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se,', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:45:59,336 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:45:59,336 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:45:59,336 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole is in a sense, in a sense, heart of our global climate system.
2024-05-19 16:45:59,337 - INFO - joeynmt.training - Example #3
2024-05-19 16:45:59,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:45:59,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:45:59,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:45:59,337 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:45:59,338 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:45:59,338 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crimpt in the summer.
2024-05-19 16:45:59,338 - INFO - joeynmt.training - Example #4
2024-05-19 16:45:59,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:45:59,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:45:59,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'show', 'is', 'a', 'c@@', 'ro@@', 'w@@', 'd', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:45:59,339 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:45:59,339 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:45:59,339 - INFO - joeynmt.training - 	Hypothesis: The next slide that I show is a crowd version of what happened the last 25 years.
2024-05-19 16:46:02,762 - INFO - joeynmt.training - Epoch   8, Step:    28100, Batch Loss:     1.440044, Batch Acc: 0.613717, Tokens per Sec:    20138, Lr: 0.000300
2024-05-19 16:46:06,153 - INFO - joeynmt.training - Epoch   8, Step:    28200, Batch Loss:     1.283392, Batch Acc: 0.618325, Tokens per Sec:    21937, Lr: 0.000300
2024-05-19 16:46:10,672 - INFO - joeynmt.training - Epoch   8, Step:    28300, Batch Loss:     1.373592, Batch Acc: 0.614633, Tokens per Sec:    16336, Lr: 0.000300
2024-05-19 16:46:14,390 - INFO - joeynmt.training - Epoch   8, Step:    28400, Batch Loss:     1.273901, Batch Acc: 0.614014, Tokens per Sec:    20202, Lr: 0.000300
2024-05-19 16:46:17,814 - INFO - joeynmt.training - Epoch   8, Step:    28500, Batch Loss:     1.645680, Batch Acc: 0.618460, Tokens per Sec:    21404, Lr: 0.000300
2024-05-19 16:46:17,815 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:46:17,815 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:46:30,519 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:46:30,519 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.02, loss:   1.75, ppl:   5.75, acc:   0.51, generation: 12.4917[sec], evaluation: 0.1943[sec]
2024-05-19 16:46:30,740 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/26000.ckpt
2024-05-19 16:46:30,758 - INFO - joeynmt.training - Example #0
2024-05-19 16:46:30,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:46:30,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:46:30,760 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'l@@', 'ing', 'cap@@', ',', 'which', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'va@@', 'st@@', 'ated', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'da@@', 'y@@', "'s", 'ma@@', 'y.', '</s>']
2024-05-19 16:46:30,760 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:46:30,760 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:46:30,761 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the polling cap, which was the past three million years of the vastated of the U.S. with 40 percent of the United States, with 40 percent percent of the United States, with 40 percent of the day's may.
2024-05-19 16:46:30,761 - INFO - joeynmt.training - Example #1
2024-05-19 16:46:30,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:46:30,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:46:30,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 'tion', 'is', 'the', 'n@@', 'est', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'k', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'v@@', 'ast', 'the', 'di@@', 'v@@', 'id@@', 'ing', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'v@@', 'id@@', 'ing', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'v@@', 'id@@', 'ing', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'k.']
2024-05-19 16:46:30,762 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:46:30,762 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:46:30,762 - INFO - joeynmt.training - 	Hypothesis: But this distinction is the nest of this specific problem because it doesn't show the disk of the ice of the ice of the ice of the ice of the ice of the ice of this specific problem because it doesn't show the divast the dividing of this specific problem because it doesn't show the dividing of this specific problem because it doesn't show the dividing of this specific problem because it doesn't show the disk.
2024-05-19 16:46:30,763 - INFO - joeynmt.training - Example #2
2024-05-19 16:46:30,763 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:46:30,763 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:46:30,763 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'ma@@', 'in', 'the', 's@@', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:46:30,764 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:46:30,764 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:46:30,764 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a sense of the main the sheart of our global climate system.
2024-05-19 16:46:30,764 - INFO - joeynmt.training - Example #3
2024-05-19 16:46:30,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:46:30,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:46:30,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 'ed', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't']
2024-05-19 16:46:30,766 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:46:30,766 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:46:30,766 - INFO - joeynmt.training - 	Hypothesis: It's in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimped in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt
2024-05-19 16:46:30,766 - INFO - joeynmt.training - Example #4
2024-05-19 16:46:30,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:46:30,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:46:30,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ating', 'what', 'happen@@', 's', 'is', 'happen@@', 'ing', 'to', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:46:30,768 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:46:30,768 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:46:30,768 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a accelerating what happens is happening to the last 25 years.
2024-05-19 16:46:34,267 - INFO - joeynmt.training - Epoch   8, Step:    28600, Batch Loss:     1.366762, Batch Acc: 0.614682, Tokens per Sec:    19272, Lr: 0.000300
2024-05-19 16:46:38,614 - INFO - joeynmt.training - Epoch   8, Step:    28700, Batch Loss:     1.250138, Batch Acc: 0.612027, Tokens per Sec:    16933, Lr: 0.000300
2024-05-19 16:46:42,408 - INFO - joeynmt.training - Epoch   8, Step:    28800, Batch Loss:     1.226431, Batch Acc: 0.604673, Tokens per Sec:    19147, Lr: 0.000300
2024-05-19 16:46:45,793 - INFO - joeynmt.training - Epoch   8, Step:    28900, Batch Loss:     1.262927, Batch Acc: 0.610802, Tokens per Sec:    22352, Lr: 0.000300
2024-05-19 16:46:49,180 - INFO - joeynmt.training - Epoch   8, Step:    29000, Batch Loss:     1.358478, Batch Acc: 0.610632, Tokens per Sec:    21774, Lr: 0.000300
2024-05-19 16:46:49,181 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:46:49,181 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:47:00,122 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:47:00,123 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.16, loss:   1.75, ppl:   5.74, acc:   0.51, generation: 10.2579[sec], evaluation: 0.6662[sec]
2024-05-19 16:47:00,337 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/25500.ckpt
2024-05-19 16:47:00,352 - INFO - joeynmt.training - Example #0
2024-05-19 16:47:00,353 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:47:00,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:47:00,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'pol@@', 'ic@@', 'y', 'of', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'been', 'ta@@', 'ken', 'about', 'the', 'va@@', 'st@@', 'ed', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'ates', 'was', 'f@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:47:00,354 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:47:00,354 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:47:00,354 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the pool, which was the policy of the pool, who had been taken about the vasted of the United States was froms.
2024-05-19 16:47:00,355 - INFO - joeynmt.training - Example #1
2024-05-19 16:47:00,355 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:47:00,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:47:00,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'an@@', 'th@@', 'ous@@', 'and', 'because', 'it', "doesn't", 'show', 'the', 'an@@', 'im@@', 'ated', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'an@@', 'ger@@', ',', '</s>']
2024-05-19 16:47:00,356 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:47:00,356 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:47:00,356 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this particular problem because it doesn't show the anthousand because it doesn't show the animated of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice problem because it doesn't show the anger,
2024-05-19 16:47:00,356 - INFO - joeynmt.training - Example #2
2024-05-19 16:47:00,357 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:47:00,357 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:47:00,357 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'he@@', 'ar@@', 'ing', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'way,', 'is', 'in', 'a', 'way,', 'the', 's@@', 'hel@@', 'p', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:47:00,358 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:47:00,358 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:47:00,358 - INFO - joeynmt.training - 	Hypothesis: The ice hearing on the North Pole, in a way, is in a way, the shelp of our global climate system.
2024-05-19 16:47:00,358 - INFO - joeynmt.training - Example #3
2024-05-19 16:47:00,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:47:00,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:47:00,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'y.', '</s>']
2024-05-19 16:47:00,359 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:47:00,360 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:47:00,360 - INFO - joeynmt.training - 	Hypothesis: It's in the winter and crimpt in the summer and crimpt in the summer and crimpt in the summer and crimpt in the summy.
2024-05-19 16:47:00,360 - INFO - joeynmt.training - Example #4
2024-05-19 16:47:00,360 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:47:00,360 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:47:00,360 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de@@', 'a', 'that', 'I', 'show', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'led', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:47:00,361 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:47:00,361 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:47:00,361 - INFO - joeynmt.training - 	Hypothesis: The next slidea that I show is a accelled version of what the last 25 years.
2024-05-19 16:47:03,940 - INFO - joeynmt.training - Epoch   8, Step:    29100, Batch Loss:     1.590408, Batch Acc: 0.612090, Tokens per Sec:    19194, Lr: 0.000300
2024-05-19 16:47:08,331 - INFO - joeynmt.training - Epoch   8, Step:    29200, Batch Loss:     1.248387, Batch Acc: 0.607623, Tokens per Sec:    16777, Lr: 0.000300
2024-05-19 16:47:11,927 - INFO - joeynmt.training - Epoch   8, Step:    29300, Batch Loss:     1.387229, Batch Acc: 0.608518, Tokens per Sec:    20157, Lr: 0.000300
2024-05-19 16:47:15,424 - INFO - joeynmt.training - Epoch   8, Step:    29400, Batch Loss:     1.225340, Batch Acc: 0.610692, Tokens per Sec:    21601, Lr: 0.000300
2024-05-19 16:47:19,275 - INFO - joeynmt.training - Epoch   8, Step:    29500, Batch Loss:     1.354568, Batch Acc: 0.612930, Tokens per Sec:    19235, Lr: 0.000300
2024-05-19 16:47:19,276 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:47:19,276 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:47:31,376 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:47:31,376 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.19, loss:   1.74, ppl:   5.72, acc:   0.51, generation: 11.8904[sec], evaluation: 0.1912[sec]
2024-05-19 16:47:31,608 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/28000.ckpt
2024-05-19 16:47:31,636 - INFO - joeynmt.training - Example #0
2024-05-19 16:47:31,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:47:31,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:47:31,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'cap@@', 'ture', 'of', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:47:31,638 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:47:31,638 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:47:31,638 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dias, to show that the Poice capture of the pool, who had about the past three million years about the size of the United States, with 40 percent of the United States,
2024-05-19 16:47:31,638 - INFO - joeynmt.training - Example #1
2024-05-19 16:47:31,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:47:31,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:47:31,639 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'ice', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'd@@', 'n@@', 'ess', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:47:31,640 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:47:31,640 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:47:31,640 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nice of this specific problem because it doesn't show the didness of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice.
2024-05-19 16:47:31,640 - INFO - joeynmt.training - Example #2
2024-05-19 16:47:31,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:47:31,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:47:31,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'he@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'is', 'the', 's@@', 'lu@@', 'm@@', 'p', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:47:31,642 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:47:31,642 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:47:31,642 - INFO - joeynmt.training - 	Hypothesis: The ice heap on the North Pole is in a certain sense, is the slump heart of our global climate system.
2024-05-19 16:47:31,644 - INFO - joeynmt.training - Example #3
2024-05-19 16:47:31,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:47:31,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:47:31,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'su@@', 'm@@', 'mer@@', ',', 'and', "it's", 'c@@', 'ri@@', 'mp@@', 'ing', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:47:31,645 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:47:31,645 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:47:31,645 - INFO - joeynmt.training - 	Hypothesis: It's in the summer, and it's crimping in the summer.
2024-05-19 16:47:31,645 - INFO - joeynmt.training - Example #4
2024-05-19 16:47:31,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:47:31,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:47:31,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 't', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'to', 'be', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'happen@@', 'ed', '</s>']
2024-05-19 16:47:31,649 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:47:31,649 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:47:31,649 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shot is a accelerated version of what happened the last 25 years of what happened to be happened in the last 25 years of happened
2024-05-19 16:47:36,038 - INFO - joeynmt.training - Epoch   8, Step:    29600, Batch Loss:     1.136008, Batch Acc: 0.609413, Tokens per Sec:    15962, Lr: 0.000300
2024-05-19 16:47:39,564 - INFO - joeynmt.training - Epoch   8, Step:    29700, Batch Loss:     1.478713, Batch Acc: 0.609823, Tokens per Sec:    20319, Lr: 0.000300
2024-05-19 16:47:43,019 - INFO - joeynmt.training - Epoch   8, Step:    29800, Batch Loss:     1.258106, Batch Acc: 0.611856, Tokens per Sec:    21449, Lr: 0.000300
2024-05-19 16:47:46,864 - INFO - joeynmt.training - Epoch   8, Step:    29900, Batch Loss:     1.184031, Batch Acc: 0.612984, Tokens per Sec:    19697, Lr: 0.000300
2024-05-19 16:47:51,255 - INFO - joeynmt.training - Epoch   8, Step:    30000, Batch Loss:     1.298497, Batch Acc: 0.604035, Tokens per Sec:    16496, Lr: 0.000300
2024-05-19 16:47:51,256 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:47:51,256 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:48:03,333 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:48:03,333 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.55, loss:   1.74, ppl:   5.69, acc:   0.50, generation: 11.8049[sec], evaluation: 0.2445[sec]
2024-05-19 16:48:03,334 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:48:03,549 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/28500.ckpt
2024-05-19 16:48:03,565 - INFO - joeynmt.training - Example #0
2024-05-19 16:48:03,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:48:03,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:48:03,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'was', 'the', 'p@@', 'ool@@', 'er', 'that', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'si@@', 'ze', 'of', 'the', 're@@', 'sp@@', 'on@@', 'se', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:48:03,567 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:48:03,567 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:48:03,567 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two sdias, to show that the pool, who was the pooler that the pool, who had about the size of the response of the United States, with 40 percent of the United States,
2024-05-19 16:48:03,567 - INFO - joeynmt.training - Example #1
2024-05-19 16:48:03,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:48:03,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:48:03,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'is', 'the', 'n@@', 'st', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'k.', '</s>']
2024-05-19 16:48:03,569 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:48:03,569 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:48:03,569 - INFO - joeynmt.training - 	Hypothesis: But this particular is the nst of this specific problem because it doesn't show the disk.
2024-05-19 16:48:03,569 - INFO - joeynmt.training - Example #2
2024-05-19 16:48:03,569 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:48:03,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:48:03,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', '</s>']
2024-05-19 16:48:03,570 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:48:03,570 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:48:03,570 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole is in a certain sense, in a certain sense,
2024-05-19 16:48:03,571 - INFO - joeynmt.training - Example #3
2024-05-19 16:48:03,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:48:03,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:48:03,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:48:03,572 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:48:03,572 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:48:03,572 - INFO - joeynmt.training - 	Hypothesis: It set out in the winter and crimpt in the summer.
2024-05-19 16:48:03,572 - INFO - joeynmt.training - Example #4
2024-05-19 16:48:03,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:48:03,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:48:03,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'sp@@', 'ent', 'ver@@', 'sion', 'of', 'what', 'the', 'last', '2@@', '5', 'years', 'is', 'happen@@', 'ing', 'is', 'happen@@', 'ing', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'happen@@', 'ed', '</s>']
2024-05-19 16:48:03,573 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:48:03,573 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:48:03,574 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a spent version of what the last 25 years is happening is happening in the last 25 years of happened
2024-05-19 16:48:07,072 - INFO - joeynmt.training - Epoch   8, Step:    30100, Batch Loss:     1.241241, Batch Acc: 0.605548, Tokens per Sec:    19964, Lr: 0.000300
2024-05-19 16:48:10,747 - INFO - joeynmt.training - Epoch   8, Step:    30200, Batch Loss:     1.380201, Batch Acc: 0.603988, Tokens per Sec:    19912, Lr: 0.000300
2024-05-19 16:48:14,495 - INFO - joeynmt.training - Epoch   8, Step:    30300, Batch Loss:     1.295042, Batch Acc: 0.608442, Tokens per Sec:    19752, Lr: 0.000300
2024-05-19 16:48:18,556 - INFO - joeynmt.training - Epoch   8, Step:    30400, Batch Loss:     1.333860, Batch Acc: 0.604408, Tokens per Sec:    17764, Lr: 0.000300
2024-05-19 16:48:22,038 - INFO - joeynmt.training - Epoch   8, Step:    30500, Batch Loss:     1.467391, Batch Acc: 0.607689, Tokens per Sec:    21131, Lr: 0.000300
2024-05-19 16:48:22,039 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:48:22,039 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:48:32,940 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:48:32,940 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.46, loss:   1.74, ppl:   5.71, acc:   0.51, generation: 10.6847[sec], evaluation: 0.2010[sec]
2024-05-19 16:48:33,147 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/29000.ckpt
2024-05-19 16:48:33,163 - INFO - joeynmt.training - Example #0
2024-05-19 16:48:33,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:48:33,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:48:33,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'was', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'million', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'c@@', 'ro@@', 'w@@', 's.', '</s>']
2024-05-19 16:48:33,164 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:48:33,164 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:48:33,165 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two dias, to show that the pool, which was the pool, who had the past three million years of the U.S. with 40 million years of the U.S. with 40 percent of the U.S. with 40 percent of crows.
2024-05-19 16:48:33,165 - INFO - joeynmt.training - Example #1
2024-05-19 16:48:33,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:48:33,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:48:33,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'is', 'the', 'n@@', 'est', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'k', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:48:33,166 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:48:33,166 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:48:33,166 - INFO - joeynmt.training - 	Hypothesis: But this particular problem is the nest of this particular problem because it doesn't show the disk of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice.
2024-05-19 16:48:33,166 - INFO - joeynmt.training - Example #2
2024-05-19 16:48:33,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:48:33,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:48:33,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'he@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'way,', 'the', 's@@', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:48:33,167 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:48:33,167 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:48:33,167 - INFO - joeynmt.training - 	Hypothesis: The ice heap on the North Pole, in a way, the sheart of our global climate system.
2024-05-19 16:48:33,167 - INFO - joeynmt.training - Example #3
2024-05-19 16:48:33,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:48:33,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:48:33,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'into', 'the', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:48:33,168 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:48:33,168 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:48:33,168 - INFO - joeynmt.training - 	Hypothesis: It's in the winter and crimpt into the summer.
2024-05-19 16:48:33,168 - INFO - joeynmt.training - Example #4
2024-05-19 16:48:33,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:48:33,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:48:33,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 't', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:48:33,169 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:48:33,169 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:48:33,169 - INFO - joeynmt.training - 	Hypothesis: The next slide I shot is a accelerated version of what happened the last 25 years.
2024-05-19 16:48:36,606 - INFO - joeynmt.training - Epoch   8, Step:    30600, Batch Loss:     1.418033, Batch Acc: 0.607599, Tokens per Sec:    20182, Lr: 0.000300
2024-05-19 16:48:40,194 - INFO - joeynmt.training - Epoch   8, Step:    30700, Batch Loss:     1.295505, Batch Acc: 0.607062, Tokens per Sec:    20543, Lr: 0.000300
2024-05-19 16:48:44,415 - INFO - joeynmt.training - Epoch   8, Step:    30800, Batch Loss:     1.364529, Batch Acc: 0.608734, Tokens per Sec:    17338, Lr: 0.000300
2024-05-19 16:48:48,092 - INFO - joeynmt.training - Epoch   8, Step:    30900, Batch Loss:     1.308738, Batch Acc: 0.609992, Tokens per Sec:    20482, Lr: 0.000300
2024-05-19 16:48:51,470 - INFO - joeynmt.training - Epoch   8, Step:    31000, Batch Loss:     1.297727, Batch Acc: 0.608004, Tokens per Sec:    21492, Lr: 0.000300
2024-05-19 16:48:51,470 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:48:51,470 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:49:03,198 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:49:03,198 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.59, loss:   1.73, ppl:   5.64, acc:   0.51, generation: 11.5170[sec], evaluation: 0.1948[sec]
2024-05-19 16:49:03,199 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:49:03,427 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/27000.ckpt
2024-05-19 16:49:03,440 - INFO - joeynmt.training - Example #0
2024-05-19 16:49:03,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:49:03,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:49:03,441 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', ',', 'which', 'the', 'p@@', 'ool@@', ',', 'who', 'had', 'about', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:49:03,442 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:49:03,442 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:49:03,442 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two dia's to show that the pool, which the pool, who had about the last three million years of the size of the U.S. with 40 percent of the U.S.
2024-05-19 16:49:03,442 - INFO - joeynmt.training - Example #1
2024-05-19 16:49:03,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:49:03,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:49:03,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'h', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:49:03,444 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:49:03,444 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:49:03,444 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem of this particular problebecause it doesn't show the dish of the ice.
2024-05-19 16:49:03,444 - INFO - joeynmt.training - Example #2
2024-05-19 16:49:03,445 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:49:03,445 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:49:03,445 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se', 'of', 'the', 's@@', 'w@@', 'oo@@', 'd@@', '-@@', 'he@@', 'ar@@', 't', 'system@@', '.', '</s>']
2024-05-19 16:49:03,446 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:49:03,446 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:49:03,446 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a sense of the swood-heart system.
2024-05-19 16:49:03,446 - INFO - joeynmt.training - Example #3
2024-05-19 16:49:03,446 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:49:03,446 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:49:03,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:49:03,447 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:49:03,447 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:49:03,447 - INFO - joeynmt.training - 	Hypothesis: It set out in the summer and crimpt in the summer.
2024-05-19 16:49:03,448 - INFO - joeynmt.training - Example #4
2024-05-19 16:49:03,448 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:49:03,448 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:49:03,448 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'l', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:49:03,449 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:49:03,449 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:49:03,449 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a accell version of what happened the last 25 years.
2024-05-19 16:49:06,880 - INFO - joeynmt.training - Epoch   8, Step:    31100, Batch Loss:     1.046308, Batch Acc: 0.600530, Tokens per Sec:    20076, Lr: 0.000300
2024-05-19 16:49:10,875 - INFO - joeynmt.training - Epoch   8, Step:    31200, Batch Loss:     1.443340, Batch Acc: 0.609160, Tokens per Sec:    18557, Lr: 0.000300
2024-05-19 16:49:15,120 - INFO - joeynmt.training - Epoch   8, Step:    31300, Batch Loss:     1.230141, Batch Acc: 0.607093, Tokens per Sec:    17914, Lr: 0.000300
2024-05-19 16:49:18,595 - INFO - joeynmt.training - Epoch   8, Step:    31400, Batch Loss:     1.398729, Batch Acc: 0.601955, Tokens per Sec:    21143, Lr: 0.000300
2024-05-19 16:49:22,028 - INFO - joeynmt.training - Epoch   8, Step:    31500, Batch Loss:     1.458096, Batch Acc: 0.603452, Tokens per Sec:    21252, Lr: 0.000300
2024-05-19 16:49:22,028 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:49:22,029 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:49:33,963 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:49:33,964 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.47, loss:   1.72, ppl:   5.60, acc:   0.51, generation: 11.7094[sec], evaluation: 0.2095[sec]
2024-05-19 16:49:33,965 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:49:34,180 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/29500.ckpt
2024-05-19 16:49:34,195 - INFO - joeynmt.training - Example #0
2024-05-19 16:49:34,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:49:34,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:49:34,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 'C@@', 'o@@', 'a@@', "'s", 'p@@', 'ool@@', ',', 'which', 'had', 'about', 'the', 'p@@', 'ool@@', 'y', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'was', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:49:34,197 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:49:34,197 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:49:34,198 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the polar Coa's pool, which had about the pooly of the United Statand of the United Statand was 40 percent of the United States,
2024-05-19 16:49:34,198 - INFO - joeynmt.training - Example #1
2024-05-19 16:49:34,198 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:49:34,198 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:49:34,198 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'ving', 'the', 'n@@', 'igh@@', 'ting', 'of', 'this', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'h', 'of', 'the', 'ice', 'of', 'ice', 'that', 'ice', "doesn't", 'show', 'the', 'di@@', 's@@', 'h', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice']
2024-05-19 16:49:34,199 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:49:34,199 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:49:34,199 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serving the nighting of this specific problem because it doesn't show the dish of the ice of ice that ice doesn't show the dish of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice
2024-05-19 16:49:34,199 - INFO - joeynmt.training - Example #2
2024-05-19 16:49:34,200 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:49:34,200 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:49:34,200 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'in', 'the', 'cl@@', 'op@@', 'per@@', 'i@@', 'o@@', 'd', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:49:34,200 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:49:34,201 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:49:34,201 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a certain sense, in the clopperiod of our global climate system.
2024-05-19 16:49:34,201 - INFO - joeynmt.training - Example #3
2024-05-19 16:49:34,201 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:49:34,201 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:49:34,201 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:49:34,202 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:49:34,202 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:49:34,202 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crimpt in summer.
2024-05-19 16:49:34,202 - INFO - joeynmt.training - Example #4
2024-05-19 16:49:34,203 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:49:34,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:49:34,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ating', 'what', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:49:34,203 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:49:34,204 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:49:34,204 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a accelerating what the last 25 years.
2024-05-19 16:49:37,647 - INFO - joeynmt.training - Epoch   8, Step:    31600, Batch Loss:     1.176030, Batch Acc: 0.606853, Tokens per Sec:    19608, Lr: 0.000300
2024-05-19 16:49:42,361 - INFO - joeynmt.training - Epoch   8, Step:    31700, Batch Loss:     1.418555, Batch Acc: 0.611689, Tokens per Sec:    15605, Lr: 0.000300
2024-05-19 16:49:45,779 - INFO - joeynmt.training - Epoch   8, Step:    31800, Batch Loss:     1.354311, Batch Acc: 0.607873, Tokens per Sec:    21215, Lr: 0.000300
2024-05-19 16:49:45,986 - INFO - joeynmt.training - Epoch   8: total training loss 5323.63
2024-05-19 16:49:45,987 - INFO - joeynmt.training - EPOCH 9
2024-05-19 16:49:49,221 - INFO - joeynmt.training - Epoch   9, Step:    31900, Batch Loss:     1.359977, Batch Acc: 0.624647, Tokens per Sec:    21674, Lr: 0.000300
2024-05-19 16:49:52,859 - INFO - joeynmt.training - Epoch   9, Step:    32000, Batch Loss:     1.405507, Batch Acc: 0.631008, Tokens per Sec:    20393, Lr: 0.000300
2024-05-19 16:49:52,859 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:49:52,860 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:50:04,170 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:50:04,170 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.20, loss:   1.73, ppl:   5.66, acc:   0.51, generation: 11.0970[sec], evaluation: 0.1920[sec]
2024-05-19 16:50:04,395 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/30500.ckpt
2024-05-19 16:50:04,409 - INFO - joeynmt.training - Example #0
2024-05-19 16:50:04,409 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:50:04,410 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:50:04,410 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ic@@', 'y', 'cap@@', ',', 'which', 'was', 'the', 'p@@', 'ool@@', 'y', 'three', 'million', 'years', 'about', 'the', 'si@@', 'ze', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'was', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:50:04,411 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:50:04,412 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:50:04,412 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the policy cap, which was the pooly three million years about the size three million years of the size of the United Statand was 40 percent of the United States, with 40 percent of the U.S.
2024-05-19 16:50:04,412 - INFO - joeynmt.training - Example #1
2024-05-19 16:50:04,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:50:04,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:50:04,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'is', 'the', 'ser@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'gu@@', 'st@@', 'ing', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:50:04,413 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:50:04,414 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:50:04,414 - INFO - joeynmt.training - 	Hypothesis: But this particular problem is the serific problem because it doesn't show the disgusting of the ice of the ice.
2024-05-19 16:50:04,414 - INFO - joeynmt.training - Example #2
2024-05-19 16:50:04,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:50:04,415 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:50:04,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se,', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:50:04,415 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:50:04,416 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:50:04,416 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a sense, in a sense, heart of our global climate system.
2024-05-19 16:50:04,416 - INFO - joeynmt.training - Example #3
2024-05-19 16:50:04,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:50:04,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:50:04,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:50:04,417 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:50:04,417 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:50:04,417 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crimpt in the summer.
2024-05-19 16:50:04,418 - INFO - joeynmt.training - Example #4
2024-05-19 16:50:04,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:50:04,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:50:04,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'has', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:50:04,419 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:50:04,419 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:50:04,419 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a accelerated version of what has happened the last 25 years.
2024-05-19 16:50:08,471 - INFO - joeynmt.training - Epoch   9, Step:    32100, Batch Loss:     1.398241, Batch Acc: 0.623988, Tokens per Sec:    17117, Lr: 0.000300
2024-05-19 16:50:12,597 - INFO - joeynmt.training - Epoch   9, Step:    32200, Batch Loss:     1.362295, Batch Acc: 0.626659, Tokens per Sec:    17731, Lr: 0.000300
2024-05-19 16:50:16,251 - INFO - joeynmt.training - Epoch   9, Step:    32300, Batch Loss:     1.233884, Batch Acc: 0.622821, Tokens per Sec:    20166, Lr: 0.000300
2024-05-19 16:50:19,733 - INFO - joeynmt.training - Epoch   9, Step:    32400, Batch Loss:     1.277968, Batch Acc: 0.621479, Tokens per Sec:    21172, Lr: 0.000300
2024-05-19 16:50:24,169 - INFO - joeynmt.training - Epoch   9, Step:    32500, Batch Loss:     1.259285, Batch Acc: 0.625958, Tokens per Sec:    16305, Lr: 0.000300
2024-05-19 16:50:24,170 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:50:24,170 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:50:34,321 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:50:34,322 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.38, loss:   1.74, ppl:   5.69, acc:   0.51, generation: 9.9430[sec], evaluation: 0.1926[sec]
2024-05-19 16:50:34,526 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/27500.ckpt
2024-05-19 16:50:34,542 - INFO - joeynmt.training - Example #0
2024-05-19 16:50:34,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:50:34,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:50:34,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 'y', 'cap@@', 'ture@@', ',', 'which', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'da@@', 'y.', '</s>']
2024-05-19 16:50:34,544 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:50:34,544 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:50:34,544 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the pooly capture, which had about the past three million years about the size of the day.
2024-05-19 16:50:34,544 - INFO - joeynmt.training - Example #1
2024-05-19 16:50:34,545 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:50:34,545 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:50:34,545 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'is', 'the', 'n@@', 'st', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'k.', '</s>']
2024-05-19 16:50:34,546 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:50:34,546 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:50:34,546 - INFO - joeynmt.training - 	Hypothesis: But this particular problem is the nst of this particular problem because it doesn't show the disk.
2024-05-19 16:50:34,546 - INFO - joeynmt.training - Example #2
2024-05-19 16:50:34,546 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:50:34,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:50:34,547 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'he@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'in', 'a', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se,', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:50:34,547 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:50:34,548 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:50:34,548 - INFO - joeynmt.training - 	Hypothesis: The ice heap on the North Pole in a sense, in a sense, heart of our global climate system.
2024-05-19 16:50:34,548 - INFO - joeynmt.training - Example #3
2024-05-19 16:50:34,548 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:50:34,548 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:50:34,548 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:50:34,549 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:50:34,549 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:50:34,549 - INFO - joeynmt.training - 	Hypothesis: It set out in the summer and crimpt in summer and crimpt in summer.
2024-05-19 16:50:34,549 - INFO - joeynmt.training - Example #4
2024-05-19 16:50:34,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:50:34,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:50:34,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:50:34,550 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:50:34,551 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:50:34,551 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a accelerated version of what happened the last 25 years.
2024-05-19 16:50:39,056 - INFO - joeynmt.training - Epoch   9, Step:    32600, Batch Loss:     1.265541, Batch Acc: 0.625107, Tokens per Sec:    15607, Lr: 0.000300
2024-05-19 16:50:42,580 - INFO - joeynmt.training - Epoch   9, Step:    32700, Batch Loss:     1.214546, Batch Acc: 0.622555, Tokens per Sec:    21161, Lr: 0.000300
2024-05-19 16:50:46,322 - INFO - joeynmt.training - Epoch   9, Step:    32800, Batch Loss:     1.235365, Batch Acc: 0.622056, Tokens per Sec:    19518, Lr: 0.000300
2024-05-19 16:50:50,103 - INFO - joeynmt.training - Epoch   9, Step:    32900, Batch Loss:     1.339051, Batch Acc: 0.618757, Tokens per Sec:    19220, Lr: 0.000300
2024-05-19 16:50:54,190 - INFO - joeynmt.training - Epoch   9, Step:    33000, Batch Loss:     1.358793, Batch Acc: 0.613124, Tokens per Sec:    18368, Lr: 0.000300
2024-05-19 16:50:54,191 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:50:54,191 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:51:05,972 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:51:05,972 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.14, loss:   1.73, ppl:   5.65, acc:   0.51, generation: 11.4005[sec], evaluation: 0.3503[sec]
2024-05-19 16:51:06,227 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/32500.ckpt
2024-05-19 16:51:06,253 - INFO - joeynmt.helpers - delete /content/drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/32500.ckpt
2024-05-19 16:51:06,254 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/32500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/32500.ckpt')
2024-05-19 16:51:06,259 - INFO - joeynmt.training - Example #0
2024-05-19 16:51:06,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:51:06,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:51:06,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 't', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'cap@@', 'ac@@', 'ity', 'of', 'the', 'P@@', 'o@@', 'ice', 'was', 'about', 'three', 'million', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:51:06,260 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:51:06,261 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:51:06,261 - INFO - joeynmt.training - 	Hypothesis: Last year, I shot these two dia's to show that the Poice capacity of the Poice was about three million years about the size of the vast three million years of the United States, with 40 percent of the United States,
2024-05-19 16:51:06,261 - INFO - joeynmt.training - Example #1
2024-05-19 16:51:06,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:51:06,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:51:06,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'con@@', 'nec@@', 't', 'to', 'see', 'the', 'ic@@', 'k', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 16:51:06,262 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:51:06,262 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:51:06,263 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it doesn't show the disconnect to see the ick of the ice of the ice of ice.
2024-05-19 16:51:06,263 - INFO - joeynmt.training - Example #2
2024-05-19 16:51:06,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:51:06,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:51:06,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se,', 'in', 'a', 'way,', 'the', 's@@', 'lu@@', 'm', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:51:06,264 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:51:06,264 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:51:06,265 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a sense, in a sense, in a way, the slum of our global climate system.
2024-05-19 16:51:06,265 - INFO - joeynmt.training - Example #3
2024-05-19 16:51:06,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:51:06,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:51:06,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:51:06,266 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:51:06,266 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:51:06,266 - INFO - joeynmt.training - 	Hypothesis: It set out in the winter and crimpt in the summer.
2024-05-19 16:51:06,267 - INFO - joeynmt.training - Example #4
2024-05-19 16:51:06,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:51:06,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:51:06,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'show', 'is', 'a', 'sp@@', 'o@@', 't', 'ver@@', 'sion', 'of', "what's", 'happen@@', 'ing', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:51:06,268 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:51:06,268 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:51:06,268 - INFO - joeynmt.training - 	Hypothesis: The next slide that I show is a spot version of what's happening the last 25 years.
2024-05-19 16:51:09,893 - INFO - joeynmt.training - Epoch   9, Step:    33100, Batch Loss:     1.389825, Batch Acc: 0.619944, Tokens per Sec:    18666, Lr: 0.000300
2024-05-19 16:51:13,364 - INFO - joeynmt.training - Epoch   9, Step:    33200, Batch Loss:     1.441103, Batch Acc: 0.616794, Tokens per Sec:    20630, Lr: 0.000300
2024-05-19 16:51:17,034 - INFO - joeynmt.training - Epoch   9, Step:    33300, Batch Loss:     1.239895, Batch Acc: 0.619748, Tokens per Sec:    19967, Lr: 0.000300
2024-05-19 16:51:21,363 - INFO - joeynmt.training - Epoch   9, Step:    33400, Batch Loss:     1.278609, Batch Acc: 0.615522, Tokens per Sec:    17187, Lr: 0.000300
2024-05-19 16:51:24,856 - INFO - joeynmt.training - Epoch   9, Step:    33500, Batch Loss:     1.461119, Batch Acc: 0.616080, Tokens per Sec:    21470, Lr: 0.000300
2024-05-19 16:51:24,857 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:51:24,857 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:51:36,083 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:51:36,083 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.59, loss:   1.74, ppl:   5.68, acc:   0.51, generation: 11.0026[sec], evaluation: 0.2074[sec]
2024-05-19 16:51:36,316 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/30000.ckpt
2024-05-19 16:51:36,334 - INFO - joeynmt.training - Example #0
2024-05-19 16:51:36,335 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:51:36,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:51:36,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 'cap@@', ',', 'who', 'had', 'the', 'pol@@', 'ar', 'cap@@', ',', 'who', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'had', '4@@', '0', 'percent', 'of', 'c@@', 'ro@@', 'p@@', 'he@@', 'd.', '</s>']
2024-05-19 16:51:36,336 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:51:36,336 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:51:36,336 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dias, to show that the polar cap, who had the polar cap, who had about the past three million years of the United Statand had 40 percent of crophed.
2024-05-19 16:51:36,337 - INFO - joeynmt.training - Example #1
2024-05-19 16:51:36,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:51:36,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:51:36,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'h', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:51:36,338 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:51:36,338 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:51:36,339 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it doesn't show the serious problem because it doesn't show the dish of the ice.
2024-05-19 16:51:36,339 - INFO - joeynmt.training - Example #2
2024-05-19 16:51:36,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:51:36,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:51:36,340 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se,', 'in', 'a', 'sen@@', 'se,', 'in', 'the', 's@@', 'lu@@', 'ding', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:51:36,340 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:51:36,340 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:51:36,341 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a sense, in a sense, in the sluding heart of our global climate system.
2024-05-19 16:51:36,341 - INFO - joeynmt.training - Example #3
2024-05-19 16:51:36,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:51:36,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:51:36,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'su@@', 'm@@', 'mer@@', ',', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:51:36,342 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:51:36,342 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:51:36,342 - INFO - joeynmt.training - 	Hypothesis: It turns out in the summer, and crimpt in the summer.
2024-05-19 16:51:36,342 - INFO - joeynmt.training - Example #4
2024-05-19 16:51:36,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:51:36,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:51:36,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ating', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:51:36,343 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:51:36,344 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:51:36,344 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a accelerating version of what happened the last 25 years.
2024-05-19 16:51:39,808 - INFO - joeynmt.training - Epoch   9, Step:    33600, Batch Loss:     1.440477, Batch Acc: 0.616553, Tokens per Sec:    19865, Lr: 0.000300
2024-05-19 16:51:43,329 - INFO - joeynmt.training - Epoch   9, Step:    33700, Batch Loss:     1.452877, Batch Acc: 0.614171, Tokens per Sec:    21076, Lr: 0.000300
2024-05-19 16:51:47,633 - INFO - joeynmt.training - Epoch   9, Step:    33800, Batch Loss:     1.451890, Batch Acc: 0.617250, Tokens per Sec:    17265, Lr: 0.000300
2024-05-19 16:51:51,513 - INFO - joeynmt.training - Epoch   9, Step:    33900, Batch Loss:     1.309143, Batch Acc: 0.620999, Tokens per Sec:    19035, Lr: 0.000300
2024-05-19 16:51:54,939 - INFO - joeynmt.training - Epoch   9, Step:    34000, Batch Loss:     1.383350, Batch Acc: 0.622043, Tokens per Sec:    21309, Lr: 0.000300
2024-05-19 16:51:54,940 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:51:54,940 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:52:06,058 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:52:06,058 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.20, loss:   1.72, ppl:   5.60, acc:   0.51, generation: 10.8906[sec], evaluation: 0.2104[sec]
2024-05-19 16:52:06,266 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/33500.ckpt
2024-05-19 16:52:06,275 - INFO - joeynmt.helpers - delete /content/drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/33500.ckpt
2024-05-19 16:52:06,276 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/33500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/33500.ckpt')
2024-05-19 16:52:06,281 - INFO - joeynmt.training - Example #0
2024-05-19 16:52:06,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:52:06,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:52:06,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 'ic@@', 's', 'that', 'the', 'p@@', 'ool@@', 'ic@@', 's', 'that', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'was', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'was', 'c@@', 'ro@@', 'w@@', 's.', '</s>']
2024-05-19 16:52:06,283 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:52:06,283 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:52:06,283 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two dia's to show that the poolics that the poolics that the last three million years of the size of the United Statand was 40 percent of the United Statand was crows.
2024-05-19 16:52:06,283 - INFO - joeynmt.training - Example #1
2024-05-19 16:52:06,284 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:52:06,284 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:52:06,284 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'v@@', 'ast', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:52:06,285 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:52:06,285 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:52:06,285 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it doesn't show the divast of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice.
2024-05-19 16:52:06,285 - INFO - joeynmt.training - Example #2
2024-05-19 16:52:06,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:52:06,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:52:06,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'ap@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se,', 'is', 'the', 's@@', 'qu@@', 'are', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:52:06,286 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:52:06,287 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:52:06,287 - INFO - joeynmt.training - 	Hypothesis: The ice skapp on the North Pole, in a sense, is the square of our global climate system.
2024-05-19 16:52:06,287 - INFO - joeynmt.training - Example #3
2024-05-19 16:52:06,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:52:06,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:52:06,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:52:06,288 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:52:06,288 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:52:06,288 - INFO - joeynmt.training - 	Hypothesis: It's in the summer and crimpt in the summer.
2024-05-19 16:52:06,288 - INFO - joeynmt.training - Example #4
2024-05-19 16:52:06,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:52:06,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:52:06,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'that', 'I', 'sho@@', 'ws', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', "what's", 'happen@@', 'ing', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:52:06,289 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:52:06,290 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:52:06,290 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a accelerated version of what's happening the last 25 years.
2024-05-19 16:52:09,829 - INFO - joeynmt.training - Epoch   9, Step:    34100, Batch Loss:     1.300920, Batch Acc: 0.612938, Tokens per Sec:    19473, Lr: 0.000300
2024-05-19 16:52:13,308 - INFO - joeynmt.training - Epoch   9, Step:    34200, Batch Loss:     1.307282, Batch Acc: 0.614764, Tokens per Sec:    21550, Lr: 0.000300
2024-05-19 16:52:17,908 - INFO - joeynmt.training - Epoch   9, Step:    34300, Batch Loss:     1.203866, Batch Acc: 0.615752, Tokens per Sec:    15998, Lr: 0.000300
2024-05-19 16:52:21,382 - INFO - joeynmt.training - Epoch   9, Step:    34400, Batch Loss:     1.369854, Batch Acc: 0.616780, Tokens per Sec:    21275, Lr: 0.000300
2024-05-19 16:52:24,871 - INFO - joeynmt.training - Epoch   9, Step:    34500, Batch Loss:     1.449537, Batch Acc: 0.614763, Tokens per Sec:    20774, Lr: 0.000300
2024-05-19 16:52:24,872 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:52:24,872 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:52:36,921 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:52:36,922 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.45, loss:   1.73, ppl:   5.63, acc:   0.51, generation: 11.8432[sec], evaluation: 0.1904[sec]
2024-05-19 16:52:37,133 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/32000.ckpt
2024-05-19 16:52:37,149 - INFO - joeynmt.training - Example #0
2024-05-19 16:52:37,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:52:37,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:52:37,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 'as', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 'ic@@', 'e,', 'which', 'was', 'the', 'p@@', 'ool@@', 'er', 'of', 'the', 'p@@', 'ool@@', 'er', 'had', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:52:37,151 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:52:37,151 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:52:37,151 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two diaas to show that the polar ice, which was the pooler of the pooler had three million years of the size of the U.S. with 40 percent of the U.S.
2024-05-19 16:52:37,151 - INFO - joeynmt.training - Example #1
2024-05-19 16:52:37,151 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:52:37,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:52:37,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'ser@@', 've', 'proble@@', 'm', 'because', 'it', "doesn't", 'sho@@', 'ws', 'the', 'di@@', 's@@', 'k.', '</s>']
2024-05-19 16:52:37,153 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:52:37,153 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:52:37,153 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it doesn't show the serve problem because it doesn't shows the disk.
2024-05-19 16:52:37,153 - INFO - joeynmt.training - Example #2
2024-05-19 16:52:37,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:52:37,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:52:37,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se,', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:52:37,154 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:52:37,154 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:52:37,155 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole, in a sense, heart of our global climate system.
2024-05-19 16:52:37,155 - INFO - joeynmt.training - Example #3
2024-05-19 16:52:37,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:52:37,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:52:37,155 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:52:37,156 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:52:37,156 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:52:37,156 - INFO - joeynmt.training - 	Hypothesis: It's in the summer and crimpt in the summer and crimpt in the summer.
2024-05-19 16:52:37,156 - INFO - joeynmt.training - Example #4
2024-05-19 16:52:37,157 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:52:37,157 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:52:37,157 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:52:37,158 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:52:37,158 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:52:37,158 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a accelerated version of what happened the last 25 years.
2024-05-19 16:52:40,611 - INFO - joeynmt.training - Epoch   9, Step:    34600, Batch Loss:     1.265227, Batch Acc: 0.618471, Tokens per Sec:    20094, Lr: 0.000300
2024-05-19 16:52:45,328 - INFO - joeynmt.training - Epoch   9, Step:    34700, Batch Loss:     1.329618, Batch Acc: 0.616510, Tokens per Sec:    15841, Lr: 0.000300
2024-05-19 16:52:48,916 - INFO - joeynmt.training - Epoch   9, Step:    34800, Batch Loss:     1.269033, Batch Acc: 0.616192, Tokens per Sec:    20626, Lr: 0.000300
2024-05-19 16:52:52,435 - INFO - joeynmt.training - Epoch   9, Step:    34900, Batch Loss:     1.292175, Batch Acc: 0.612129, Tokens per Sec:    21092, Lr: 0.000300
2024-05-19 16:52:56,134 - INFO - joeynmt.training - Epoch   9, Step:    35000, Batch Loss:     1.291603, Batch Acc: 0.609327, Tokens per Sec:    20186, Lr: 0.000300
2024-05-19 16:52:56,135 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:52:56,135 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:53:07,265 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:53:07,265 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.99, loss:   1.72, ppl:   5.57, acc:   0.51, generation: 10.9195[sec], evaluation: 0.1941[sec]
2024-05-19 16:53:07,266 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:53:07,491 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/33000.ckpt
2024-05-19 16:53:07,504 - INFO - joeynmt.training - Example #0
2024-05-19 16:53:07,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:53:07,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:53:07,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 'cap@@', 's,', 'which', 'was', 'the', 'p@@', 'ool@@', 'y', 'three', 'million', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:53:07,506 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:53:07,506 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:53:07,507 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the polar caps, which was the pooly three million years about the size of the United Statand of 40 percent of the United States, with 40 percent of the U.S.
2024-05-19 16:53:07,507 - INFO - joeynmt.training - Example #1
2024-05-19 16:53:07,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:53:07,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:53:07,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'way', 'that', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'was@@', "n't", 'sho@@', 'wing', 'the', 'di@@', 's@@', 'he@@', 'd', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'was@@', "n't", 'sho@@', 'wing', 'the', 'di@@', 's@@', 'he@@', 'at', 'the', 'pre@@', 's@@', 'ent', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm.', '</s>']
2024-05-19 16:53:07,508 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:53:07,509 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:53:07,509 - INFO - joeynmt.training - 	Hypothesis: But this is actually the way that this particular problem because it wasn't showing the dished of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of this particular problem because it wasn't showing the disheat the present of this particular problem.
2024-05-19 16:53:07,509 - INFO - joeynmt.training - Example #2
2024-05-19 16:53:07,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:53:07,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:53:07,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'v@@', 'oc@@', 'oc@@', 'c@@', 'up@@', 'ation', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'con@@', 'st@@', 'itu@@', 'tion', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:53:07,510 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:53:07,510 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:53:07,511 - INFO - joeynmt.training - 	Hypothesis: The vococcupation on the North Pole is in a constitution of our global climate system.
2024-05-19 16:53:07,511 - INFO - joeynmt.training - Example #3
2024-05-19 16:53:07,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:53:07,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:53:07,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'su@@', 'm@@', 'mer@@', ',', 'and', 'c@@', 'ra@@', 'z@@', 'y.', '</s>']
2024-05-19 16:53:07,512 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:53:07,512 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:53:07,512 - INFO - joeynmt.training - 	Hypothesis: It turns out in the summer, and crazy.
2024-05-19 16:53:07,512 - INFO - joeynmt.training - Example #4
2024-05-19 16:53:07,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:53:07,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:53:07,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'sp@@', 'ent', 'ver@@', 'sion', 'of', 'what', 'happen@@', 's', 'is', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:53:07,513 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:53:07,514 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:53:07,514 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a spent version of what happens is happened in the last 25 years.
2024-05-19 16:53:11,584 - INFO - joeynmt.training - Epoch   9, Step:    35100, Batch Loss:     1.383624, Batch Acc: 0.609134, Tokens per Sec:    17130, Lr: 0.000300
2024-05-19 16:53:15,769 - INFO - joeynmt.training - Epoch   9, Step:    35200, Batch Loss:     1.297904, Batch Acc: 0.612889, Tokens per Sec:    17824, Lr: 0.000300
2024-05-19 16:53:19,247 - INFO - joeynmt.training - Epoch   9, Step:    35300, Batch Loss:     1.270940, Batch Acc: 0.612466, Tokens per Sec:    21235, Lr: 0.000300
2024-05-19 16:53:22,657 - INFO - joeynmt.training - Epoch   9, Step:    35400, Batch Loss:     1.299777, Batch Acc: 0.614672, Tokens per Sec:    21734, Lr: 0.000300
2024-05-19 16:53:26,986 - INFO - joeynmt.training - Epoch   9, Step:    35500, Batch Loss:     1.349305, Batch Acc: 0.607361, Tokens per Sec:    16726, Lr: 0.000300
2024-05-19 16:53:26,987 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:53:26,987 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:53:37,568 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:53:37,568 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.54, loss:   1.72, ppl:   5.60, acc:   0.51, generation: 10.3743[sec], evaluation: 0.1898[sec]
2024-05-19 16:53:37,823 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/31000.ckpt
2024-05-19 16:53:37,854 - INFO - joeynmt.training - Example #0
2024-05-19 16:53:37,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:53:37,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:53:37,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 'y', 'cap@@', 'ture', 'cap@@', 'ture', 'cap@@', 'ture', 'cap@@', 'e,', 'which', 'had', 'been', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:53:37,856 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:53:37,856 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:53:37,856 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two dias, to show that the pooly capture capture capture cape, which had been the last three million years of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:53:37,857 - INFO - joeynmt.training - Example #1
2024-05-19 16:53:37,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:53:37,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:53:37,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'con@@', 'nec@@', 't', 'to', 'see', 'the', 'di@@', 's@@', 'gu@@', 'st@@', 'ing', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:53:37,858 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:53:37,859 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:53:37,859 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it doesn't show the disconnect to see the disgusting of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice.
2024-05-19 16:53:37,859 - INFO - joeynmt.training - Example #2
2024-05-19 16:53:37,859 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:53:37,859 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:53:37,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'W@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'way,', 'is', 'the', 's@@', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:53:37,860 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:53:37,860 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:53:37,861 - INFO - joeynmt.training - 	Hypothesis: The Worth Pole, the North Pole, in a way, is the sheart of our global climate system.
2024-05-19 16:53:37,861 - INFO - joeynmt.training - Example #3
2024-05-19 16:53:37,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:53:37,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:53:37,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ro@@', 'p', 'in', 'su@@', 'mm@@', 'er.', '</s>']
2024-05-19 16:53:37,862 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:53:37,862 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:53:37,862 - INFO - joeynmt.training - 	Hypothesis: It turns out in the summer and crop in summer.
2024-05-19 16:53:37,862 - INFO - joeynmt.training - Example #4
2024-05-19 16:53:37,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:53:37,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:53:37,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'ed', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'of', 'what', 'happen@@', 'ed', 'in', 'the', 's@@', 'li@@', 'de@@', 's', 'of', 'what', 'happen@@', 'ed', 'the', 's@@', 'li@@', 'de@@', 'a', 'that', 'I', 'sho@@', 'w.', '</s>']
2024-05-19 16:53:37,863 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:53:37,864 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:53:37,864 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a acceled version of what happened the last 25 years of what happened happened in the last 25 years of what happened in the last 25 years of what happened the last 25 years of what happened the last 25 years of what happened in the slides of what happened the slidea that I show.
2024-05-19 16:53:42,292 - INFO - joeynmt.training - Epoch   9, Step:    35600, Batch Loss:     1.370571, Batch Acc: 0.614050, Tokens per Sec:    15963, Lr: 0.000300
2024-05-19 16:53:45,924 - INFO - joeynmt.training - Epoch   9, Step:    35700, Batch Loss:     1.356094, Batch Acc: 0.613771, Tokens per Sec:    20033, Lr: 0.000300
2024-05-19 16:53:48,689 - INFO - joeynmt.training - Epoch   9: total training loss 5206.32
2024-05-19 16:53:48,689 - INFO - joeynmt.training - EPOCH 10
2024-05-19 16:53:49,437 - INFO - joeynmt.training - Epoch  10, Step:    35800, Batch Loss:     1.185985, Batch Acc: 0.629926, Tokens per Sec:    20604, Lr: 0.000300
2024-05-19 16:53:53,291 - INFO - joeynmt.training - Epoch  10, Step:    35900, Batch Loss:     1.322318, Batch Acc: 0.632541, Tokens per Sec:    19240, Lr: 0.000300
2024-05-19 16:53:57,335 - INFO - joeynmt.training - Epoch  10, Step:    36000, Batch Loss:     1.426833, Batch Acc: 0.635554, Tokens per Sec:    17951, Lr: 0.000300
2024-05-19 16:53:57,336 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:53:57,336 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:54:07,583 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:54:07,583 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.94, loss:   1.72, ppl:   5.59, acc:   0.51, generation: 9.9020[sec], evaluation: 0.3167[sec]
2024-05-19 16:54:07,815 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/34500.ckpt
2024-05-19 16:54:07,835 - INFO - joeynmt.training - Example #0
2024-05-19 16:54:07,835 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:54:07,836 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:54:07,836 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 'y', 'cap@@', 'ture', 'cap@@', 'ture', 'cap@@', 'ture', 'that', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:54:07,837 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:54:07,837 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:54:07,838 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dias, to show that the pooly capture capture capture that the past three million years about the size of the U.S. with 40 percent of the U.S.
2024-05-19 16:54:07,838 - INFO - joeynmt.training - Example #1
2024-05-19 16:54:07,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:54:07,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:54:07,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'h', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice']
2024-05-19 16:54:07,839 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:54:07,839 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:54:07,839 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it doesn't show the dish of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice
2024-05-19 16:54:07,839 - INFO - joeynmt.training - Example #2
2024-05-19 16:54:07,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:54:07,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:54:07,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'cap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'the', 'clo@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:54:07,841 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:54:07,841 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:54:07,841 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole is in a certain sense, the close of our global climate system.
2024-05-19 16:54:07,841 - INFO - joeynmt.training - Example #3
2024-05-19 16:54:07,841 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:54:07,841 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:54:07,842 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'of', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:54:07,842 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:54:07,842 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:54:07,843 - INFO - joeynmt.training - 	Hypothesis: It turns out of the winter and crimpt in summer.
2024-05-19 16:54:07,843 - INFO - joeynmt.training - Example #4
2024-05-19 16:54:07,843 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:54:07,843 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:54:07,843 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'has', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'has', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'years', 'of', 'year@@', 's.', '</s>']
2024-05-19 16:54:07,844 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:54:07,844 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:54:07,844 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a accelerated version of what has happened the last 25 years has happened in the last 25 years of years.
2024-05-19 16:54:11,915 - INFO - joeynmt.training - Epoch  10, Step:    36100, Batch Loss:     1.261848, Batch Acc: 0.632845, Tokens per Sec:    17007, Lr: 0.000300
2024-05-19 16:54:15,500 - INFO - joeynmt.training - Epoch  10, Step:    36200, Batch Loss:     1.302679, Batch Acc: 0.633180, Tokens per Sec:    20636, Lr: 0.000300
2024-05-19 16:54:18,945 - INFO - joeynmt.training - Epoch  10, Step:    36300, Batch Loss:     1.293013, Batch Acc: 0.629613, Tokens per Sec:    21263, Lr: 0.000300
2024-05-19 16:54:23,430 - INFO - joeynmt.training - Epoch  10, Step:    36400, Batch Loss:     1.305307, Batch Acc: 0.631394, Tokens per Sec:    17238, Lr: 0.000300
2024-05-19 16:54:26,835 - INFO - joeynmt.training - Epoch  10, Step:    36500, Batch Loss:     1.353446, Batch Acc: 0.627925, Tokens per Sec:    21436, Lr: 0.000300
2024-05-19 16:54:26,835 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:54:26,835 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:54:37,900 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:54:37,901 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.78, loss:   1.72, ppl:   5.61, acc:   0.51, generation: 10.8520[sec], evaluation: 0.1953[sec]
2024-05-19 16:54:37,905 - INFO - joeynmt.training - Example #0
2024-05-19 16:54:37,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:54:37,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:54:37,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'di@@', 'a@@', "'s", 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'cap@@', ',', 'who', 'had', 'the', 'P@@', 'o@@', 'ice', 'had', 'been', 'c@@', 'ro@@', 'w@@', 'ed', 'for', 'the', 'last', 'three', 'million', 'years', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:54:37,907 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:54:37,907 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:54:37,908 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two sdia's to show that the Poice cap, who had the Poice had been crowed for the last three million years of the United States, with 40 percent of the United States,
2024-05-19 16:54:37,908 - INFO - joeynmt.training - Example #1
2024-05-19 16:54:37,908 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:54:37,908 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:54:37,908 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'h', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'ice', 'as', 'it', "doesn't", 'show', 'the', 'di@@', 'v@@', 'il@@', '.', '</s>']
2024-05-19 16:54:37,909 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:54:37,909 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:54:37,909 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it doesn't show the dish of the ice of the ice of ice as it doesn't show the divil.
2024-05-19 16:54:37,909 - INFO - joeynmt.training - Example #2
2024-05-19 16:54:37,910 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:54:37,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:54:37,910 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'cap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le.', 'The', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le.', '</s>']
2024-05-19 16:54:37,910 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:54:37,911 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:54:37,911 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole. The North Pole.
2024-05-19 16:54:37,911 - INFO - joeynmt.training - Example #3
2024-05-19 16:54:37,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:54:37,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:54:37,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'su@@', 'mm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:54:37,912 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:54:37,912 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:54:37,912 - INFO - joeynmt.training - 	Hypothesis: It turns out in the summer and crimpt in the summer.
2024-05-19 16:54:37,912 - INFO - joeynmt.training - Example #4
2024-05-19 16:54:37,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:54:37,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:54:37,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'wing', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:54:37,914 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:54:37,914 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:54:37,914 - INFO - joeynmt.training - 	Hypothesis: The next slide I showing is a accelerated version of what happened the last 25 years.
2024-05-19 16:54:41,376 - INFO - joeynmt.training - Epoch  10, Step:    36600, Batch Loss:     1.449569, Batch Acc: 0.629664, Tokens per Sec:    21002, Lr: 0.000300
2024-05-19 16:54:44,769 - INFO - joeynmt.training - Epoch  10, Step:    36700, Batch Loss:     1.182895, Batch Acc: 0.632354, Tokens per Sec:    21692, Lr: 0.000300
2024-05-19 16:54:48,323 - INFO - joeynmt.training - Epoch  10, Step:    36800, Batch Loss:     1.440263, Batch Acc: 0.626039, Tokens per Sec:    20183, Lr: 0.000300
2024-05-19 16:54:52,637 - INFO - joeynmt.training - Epoch  10, Step:    36900, Batch Loss:     1.211630, Batch Acc: 0.630438, Tokens per Sec:    16823, Lr: 0.000300
2024-05-19 16:54:56,030 - INFO - joeynmt.training - Epoch  10, Step:    37000, Batch Loss:     1.195120, Batch Acc: 0.622105, Tokens per Sec:    22157, Lr: 0.000300
2024-05-19 16:54:56,031 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:54:56,031 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:55:07,735 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:55:07,736 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.04, loss:   1.73, ppl:   5.64, acc:   0.51, generation: 11.4922[sec], evaluation: 0.1963[sec]
2024-05-19 16:55:07,740 - INFO - joeynmt.training - Example #0
2024-05-19 16:55:07,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:55:07,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:55:07,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 'cap@@', ',', 'which', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'had', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'by', '4@@', '0', 'percent', 'percent', 'percent', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:55:07,742 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:55:07,742 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:55:07,742 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two sdias, to show that the polar cap, which was the past three million years of the size of the U.S. had 40 percent of the U.S. by 40 percent percent percent percent of the U.S.
2024-05-19 16:55:07,743 - INFO - joeynmt.training - Example #1
2024-05-19 16:55:07,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:55:07,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:55:07,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'next', 'thing', 'to', 'do', 'is', 'a', 'speci@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 'c', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:55:07,744 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:55:07,744 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:55:07,744 - INFO - joeynmt.training - 	Hypothesis: But this is actually the next thing to do is a specific problem because it doesn't show the dic of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice.
2024-05-19 16:55:07,744 - INFO - joeynmt.training - Example #2
2024-05-19 16:55:07,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:55:07,745 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:55:07,745 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'c@@', 'lim@@', 'ate', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:55:07,745 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:55:07,746 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:55:07,746 - INFO - joeynmt.training - 	Hypothesis: The ice climate on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 16:55:07,746 - INFO - joeynmt.training - Example #3
2024-05-19 16:55:07,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:55:07,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:55:07,746 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:55:07,747 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:55:07,747 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:55:07,747 - INFO - joeynmt.training - 	Hypothesis: It set out in the summer.
2024-05-19 16:55:07,747 - INFO - joeynmt.training - Example #4
2024-05-19 16:55:07,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:55:07,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:55:07,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:55:07,748 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:55:07,749 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:55:07,749 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a accelerated version of what happened the last 25 years.
2024-05-19 16:55:11,316 - INFO - joeynmt.training - Epoch  10, Step:    37100, Batch Loss:     1.306612, Batch Acc: 0.624722, Tokens per Sec:    20343, Lr: 0.000300
2024-05-19 16:55:14,701 - INFO - joeynmt.training - Epoch  10, Step:    37200, Batch Loss:     1.146385, Batch Acc: 0.623910, Tokens per Sec:    21344, Lr: 0.000300
2024-05-19 16:55:18,747 - INFO - joeynmt.training - Epoch  10, Step:    37300, Batch Loss:     1.305386, Batch Acc: 0.625739, Tokens per Sec:    18221, Lr: 0.000300
2024-05-19 16:55:22,584 - INFO - joeynmt.training - Epoch  10, Step:    37400, Batch Loss:     1.251216, Batch Acc: 0.623912, Tokens per Sec:    18815, Lr: 0.000300
2024-05-19 16:55:26,089 - INFO - joeynmt.training - Epoch  10, Step:    37500, Batch Loss:     1.320108, Batch Acc: 0.624056, Tokens per Sec:    21045, Lr: 0.000300
2024-05-19 16:55:26,090 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:55:26,090 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:55:36,961 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:55:36,962 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.26, loss:   1.72, ppl:   5.56, acc:   0.51, generation: 10.6638[sec], evaluation: 0.1923[sec]
2024-05-19 16:55:36,963 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:55:37,192 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/35500.ckpt
2024-05-19 16:55:37,207 - INFO - joeynmt.training - Example #0
2024-05-19 16:55:37,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:55:37,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:55:37,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'cap@@', 'ture@@', ',', 'which', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:55:37,209 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:55:37,209 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:55:37,210 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dias, to show that the Poice capture, which had about the past three million years of the size of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:55:37,210 - INFO - joeynmt.training - Example #1
2024-05-19 16:55:37,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:55:37,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:55:37,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'se@@', 'ver@@', 'al', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ir@@', 'd', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'di@@', 's@@', 'k.', '</s>']
2024-05-19 16:55:37,211 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:55:37,211 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:55:37,211 - INFO - joeynmt.training - 	Hypothesis: But this is actually the several problem because it doesn't show the third of this particular problem because it doesn't show the disk.
2024-05-19 16:55:37,211 - INFO - joeynmt.training - Example #2
2024-05-19 16:55:37,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:55:37,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:55:37,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'cap@@', 'ture', 'of', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'sen@@', 'se', 'is', 'in', 'a', 'sen@@', 'se', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:55:37,213 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:55:37,213 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:55:37,213 - INFO - joeynmt.training - 	Hypothesis: The ice capture of the North Pole is in a sense is in a sense of our global climate system.
2024-05-19 16:55:37,213 - INFO - joeynmt.training - Example #3
2024-05-19 16:55:37,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:55:37,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:55:37,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'it', 'into', 'the', 's@@', 'w@@', 'ing@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:55:37,214 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:55:37,214 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:55:37,214 - INFO - joeynmt.training - 	Hypothesis: It turns out it into the swinger and crimpt in the summer.
2024-05-19 16:55:37,215 - INFO - joeynmt.training - Example #4
2024-05-19 16:55:37,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:55:37,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:55:37,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'is', 'a', 'sp@@', 'ee@@', 'ch@@', 'ed', 'ver@@', 'sion', 'of', "what's", 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'years', 'happen@@', 'ed', 'in', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:55:37,216 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:55:37,216 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:55:37,216 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a speeched version of what's happened the last 25 years happened in the last 25 years.
2024-05-19 16:55:40,575 - INFO - joeynmt.training - Epoch  10, Step:    37600, Batch Loss:     1.366036, Batch Acc: 0.629802, Tokens per Sec:    20352, Lr: 0.000300
2024-05-19 16:55:43,986 - INFO - joeynmt.training - Epoch  10, Step:    37700, Batch Loss:     1.342607, Batch Acc: 0.623246, Tokens per Sec:    22091, Lr: 0.000300
2024-05-19 16:55:48,639 - INFO - joeynmt.training - Epoch  10, Step:    37800, Batch Loss:     1.386300, Batch Acc: 0.622125, Tokens per Sec:    15777, Lr: 0.000300
2024-05-19 16:55:52,082 - INFO - joeynmt.training - Epoch  10, Step:    37900, Batch Loss:     1.287686, Batch Acc: 0.624943, Tokens per Sec:    21792, Lr: 0.000300
2024-05-19 16:55:55,496 - INFO - joeynmt.training - Epoch  10, Step:    38000, Batch Loss:     1.213591, Batch Acc: 0.619187, Tokens per Sec:    21250, Lr: 0.000300
2024-05-19 16:55:55,496 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:55:55,496 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:56:07,049 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:56:07,049 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.06, loss:   1.72, ppl:   5.58, acc:   0.51, generation: 11.3304[sec], evaluation: 0.2061[sec]
2024-05-19 16:56:07,252 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/34000.ckpt
2024-05-19 16:56:07,282 - INFO - joeynmt.training - Example #0
2024-05-19 16:56:07,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:56:07,284 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:56:07,284 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 'y', 'cap@@', 'ac@@', 'ity,', 'which', 'was', 'the', 'p@@', 'ool@@', ',', 'which', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:56:07,285 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:56:07,285 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:56:07,285 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dias, to show that the pooly capacity, which was the pool, which had about the past three million years of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:56:07,285 - INFO - joeynmt.training - Example #1
2024-05-19 16:56:07,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:56:07,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:56:07,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'se@@', 'ver@@', 'al', 'proble@@', 'm', 'because', 'it', "didn't", 'show', 'the', 'di@@', 'c', 'proble@@', 'm', 'because', 'it', "didn't", 'show', 'the', 'di@@', 'c', 'proble@@', 'm', 'that', 'sho@@', 'ws', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:56:07,287 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:56:07,287 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:56:07,287 - INFO - joeynmt.training - 	Hypothesis: But this is actually the several problem because it didn't show the dic problem because it didn't show the dic problem that shows the ice.
2024-05-19 16:56:07,287 - INFO - joeynmt.training - Example #2
2024-05-19 16:56:07,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:56:07,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:56:07,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'the', 's@@', 'hel@@', 'l', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:56:07,288 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:56:07,288 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:56:07,289 - INFO - joeynmt.training - 	Hypothesis: The ice ap on the North Pole is in a certain sense, the shell of our global climate system.
2024-05-19 16:56:07,289 - INFO - joeynmt.training - Example #3
2024-05-19 16:56:07,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:56:07,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:56:07,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'to', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'into', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:56:07,290 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:56:07,290 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:56:07,291 - INFO - joeynmt.training - 	Hypothesis: It turns out to the winter and crimpt into the summer.
2024-05-19 16:56:07,291 - INFO - joeynmt.training - Example #4
2024-05-19 16:56:07,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:56:07,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:56:07,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de@@', 's', 'I', 'sho@@', 'ws', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'p@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:56:07,292 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:56:07,292 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:56:07,292 - INFO - joeynmt.training - 	Hypothesis: The next slides I shows is a accelerated version of what happened the past 25 years.
2024-05-19 16:56:10,803 - INFO - joeynmt.training - Epoch  10, Step:    38100, Batch Loss:     1.414861, Batch Acc: 0.620882, Tokens per Sec:    19299, Lr: 0.000300
2024-05-19 16:56:14,994 - INFO - joeynmt.training - Epoch  10, Step:    38200, Batch Loss:     1.248836, Batch Acc: 0.622534, Tokens per Sec:    17548, Lr: 0.000300
2024-05-19 16:56:18,955 - INFO - joeynmt.training - Epoch  10, Step:    38300, Batch Loss:     1.422346, Batch Acc: 0.623277, Tokens per Sec:    18836, Lr: 0.000300
2024-05-19 16:56:22,430 - INFO - joeynmt.training - Epoch  10, Step:    38400, Batch Loss:     1.178700, Batch Acc: 0.621836, Tokens per Sec:    21510, Lr: 0.000300
2024-05-19 16:56:25,835 - INFO - joeynmt.training - Epoch  10, Step:    38500, Batch Loss:     1.221028, Batch Acc: 0.621890, Tokens per Sec:    21583, Lr: 0.000300
2024-05-19 16:56:25,835 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:56:25,836 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:56:37,697 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:56:37,697 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.91, loss:   1.72, ppl:   5.59, acc:   0.51, generation: 11.6477[sec], evaluation: 0.1979[sec]
2024-05-19 16:56:37,910 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/31500.ckpt
2024-05-19 16:56:37,924 - INFO - joeynmt.training - Example #0
2024-05-19 16:56:37,924 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:56:37,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:56:37,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'P@@', 'o@@', 'ice', 'was', 'to', 'show', 'that', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', 'with', '4@@', '0', 'percent', 'of', 'the', 'V@@', 'S@@', 'S@@', ',', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'for@@', 't@@', 'un@@', 'e', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'from', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:56:37,926 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:56:37,926 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:56:37,926 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two dias, to show that the Poice was to show that the past three million years of the size of the United Statand of 40 percent of the United States, with 40 percent of the United States, with 40 percent of the VSS, with 40 percent of the United Statfortune of the United Statand from the United States,
2024-05-19 16:56:37,926 - INFO - joeynmt.training - Example #1
2024-05-19 16:56:37,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:56:37,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:56:37,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "didn't", 'show', 'the', 'de@@', 'ca@@', 'de@@', 's', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'th@@', 'es@@', 'e.', '</s>']
2024-05-19 16:56:37,928 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:56:37,928 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:56:37,928 - INFO - joeynmt.training - 	Hypothesis: But this is actually the serious problem because it didn't show the decades of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of these.
2024-05-19 16:56:37,928 - INFO - joeynmt.training - Example #2
2024-05-19 16:56:37,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:56:37,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:56:37,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'way,', 'the', 's@@', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'li@@', 'mat@@', 'e', 'syste@@', 'm', '</s>']
2024-05-19 16:56:37,929 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:56:37,930 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:56:37,930 - INFO - joeynmt.training - 	Hypothesis: The ice skp on the North Pole, in a way, the sheart of our global climate system
2024-05-19 16:56:37,930 - INFO - joeynmt.training - Example #3
2024-05-19 16:56:37,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:56:37,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:56:37,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'of', 'the', 'win@@', 'ter', 'and', 'c@@', 'ra@@', 'z@@', 'y.', '</s>']
2024-05-19 16:56:37,931 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:56:37,931 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:56:37,931 - INFO - joeynmt.training - 	Hypothesis: It turns out of the winter and crazy.
2024-05-19 16:56:37,932 - INFO - joeynmt.training - Example #4
2024-05-19 16:56:37,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:56:37,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:56:37,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:56:37,933 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:56:37,933 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:56:37,933 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a accelerated version of what happened the last 25 years.
2024-05-19 16:56:41,540 - INFO - joeynmt.training - Epoch  10, Step:    38600, Batch Loss:     1.450583, Batch Acc: 0.618619, Tokens per Sec:    19425, Lr: 0.000300
2024-05-19 16:56:46,081 - INFO - joeynmt.training - Epoch  10, Step:    38700, Batch Loss:     1.403055, Batch Acc: 0.620253, Tokens per Sec:    16805, Lr: 0.000300
2024-05-19 16:56:49,563 - INFO - joeynmt.training - Epoch  10, Step:    38800, Batch Loss:     1.322373, Batch Acc: 0.624206, Tokens per Sec:    21213, Lr: 0.000300
2024-05-19 16:56:53,036 - INFO - joeynmt.training - Epoch  10, Step:    38900, Batch Loss:     1.502688, Batch Acc: 0.617886, Tokens per Sec:    21365, Lr: 0.000300
2024-05-19 16:56:56,970 - INFO - joeynmt.training - Epoch  10, Step:    39000, Batch Loss:     1.187348, Batch Acc: 0.621415, Tokens per Sec:    18841, Lr: 0.000300
2024-05-19 16:56:56,970 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:56:56,970 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:57:07,303 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:57:07,303 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  16.51, loss:   1.72, ppl:   5.57, acc:   0.52, generation: 10.1268[sec], evaluation: 0.1899[sec]
2024-05-19 16:57:07,503 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/36000.ckpt
2024-05-19 16:57:07,520 - INFO - joeynmt.training - Example #0
2024-05-19 16:57:07,521 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:57:07,521 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:57:07,522 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's,', 'to', 'show', 'that', 'the', 'p@@', 'ool@@', 'er', 'cap@@', 'it@@', 'ac@@', 'y,', 'which', 'was', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'and', 'was', 'a', '4@@', '0', 'percent', 'of', 'the', 'U@@', 'nit@@', 'ed', 'St@@', 'at@@', 'es,', '</s>']
2024-05-19 16:57:07,522 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:57:07,522 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:57:07,523 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two dias, to show that the pooler capitacy, which was the past three million years of the size of the United Statand of the United Statand was a 40 percent of the United States,
2024-05-19 16:57:07,523 - INFO - joeynmt.training - Example #1
2024-05-19 16:57:07,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:57:07,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:57:07,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'is', 'the', 'ser@@', 'i@@', 'ous', 'proble@@', 'm', 'because', 'it', "didn't", 'show', 'the', 'di@@', 's@@', 'gu@@', 'st@@', 'ing', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:57:07,524 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:57:07,524 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:57:07,524 - INFO - joeynmt.training - 	Hypothesis: But this particular problem is the serious problem because it didn't show the disgusting of the ice of the ice of the ice of the ice.
2024-05-19 16:57:07,524 - INFO - joeynmt.training - Example #2
2024-05-19 16:57:07,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:57:07,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:57:07,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'he@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le,', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'ne@@', 'ar', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:57:07,526 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:57:07,526 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:57:07,526 - INFO - joeynmt.training - 	Hypothesis: The ice heap on the North Pole, in a sense of the near heart of our global climate system.
2024-05-19 16:57:07,526 - INFO - joeynmt.training - Example #3
2024-05-19 16:57:07,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:57:07,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:57:07,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'ned', 'out', 'to', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', ',', '</s>']
2024-05-19 16:57:07,527 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:57:07,527 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:57:07,527 - INFO - joeynmt.training - 	Hypothesis: It turned out to the winter and crimp,
2024-05-19 16:57:07,528 - INFO - joeynmt.training - Example #4
2024-05-19 16:57:07,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:57:07,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:57:07,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'ws', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:57:07,529 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:57:07,529 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:57:07,529 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a accelerated version of what happened the last 25 years.
2024-05-19 16:57:11,667 - INFO - joeynmt.training - Epoch  10, Step:    39100, Batch Loss:     1.182156, Batch Acc: 0.619449, Tokens per Sec:    16679, Lr: 0.000300
2024-05-19 16:57:16,401 - INFO - joeynmt.training - Epoch  10, Step:    39200, Batch Loss:     1.350809, Batch Acc: 0.618251, Tokens per Sec:    15945, Lr: 0.000300
2024-05-19 16:57:20,132 - INFO - joeynmt.training - Epoch  10, Step:    39300, Batch Loss:     1.314630, Batch Acc: 0.625333, Tokens per Sec:    19410, Lr: 0.000300
2024-05-19 16:57:23,812 - INFO - joeynmt.training - Epoch  10, Step:    39400, Batch Loss:     1.342571, Batch Acc: 0.618174, Tokens per Sec:    20042, Lr: 0.000300
2024-05-19 16:57:28,130 - INFO - joeynmt.training - Epoch  10, Step:    39500, Batch Loss:     1.249128, Batch Acc: 0.620451, Tokens per Sec:    16763, Lr: 0.000300
2024-05-19 16:57:28,131 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:57:28,131 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:57:40,627 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:57:40,628 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.09, loss:   1.71, ppl:   5.54, acc:   0.52, generation: 12.1348[sec], evaluation: 0.3325[sec]
2024-05-19 16:57:40,629 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:57:40,901 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/38500.ckpt
2024-05-19 16:57:40,931 - INFO - joeynmt.training - Example #0
2024-05-19 16:57:40,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'ig', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 'ton@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'va@@', 'stel@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2024-05-19 16:57:40,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'cap@@', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:57:40,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'pol@@', 'ar', 'ice', 'cap@@', 'ture@@', ',', 'which', 'had', 'about', 'the', 'p@@', 'ast', 'three', 'million', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:57:40,933 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:57:40,934 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:57:40,934 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the polar ice capture, which had about the past three million years of the U.S. with 40 percent of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:57:40,934 - INFO - joeynmt.training - Example #1
2024-05-19 16:57:40,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'speci@@', 'f@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2024-05-19 16:57:40,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'under@@', 'st@@', 'ates', 'the', 'ser@@', 'i@@', 'ou@@', 'sn@@', 'ess', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', "doesn't", 'show', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:57:40,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'n@@', 'st', 'of', 'this', 'partic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'was@@', "n't", 'sho@@', 'wing', 'the', 'di@@', 's@@', 'gu@@', 'i@@', 'de', 'of', 'the', 'ice', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:57:40,936 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:57:40,936 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:57:40,936 - INFO - joeynmt.training - 	Hypothesis: But this is actually the nst of this particular problem because it wasn't showing the disguide of the ice of the ice.
2024-05-19 16:57:40,936 - INFO - joeynmt.training - Example #2
2024-05-19 16:57:40,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'syste@@', 'em@@', '.']
2024-05-19 16:57:40,939 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se,', 'the', 'be@@', 'ating', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.']
2024-05-19 16:57:40,939 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ice', 'sk@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ole', 'is', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sen@@', 'se,', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lob@@', 'al', 'c@@', 'lim@@', 'ate', 'system@@', '.', '</s>']
2024-05-19 16:57:40,940 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:57:40,940 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:57:40,940 - INFO - joeynmt.training - 	Hypothesis: The ice skap on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 16:57:40,941 - INFO - joeynmt.training - Example #3
2024-05-19 16:57:40,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:57:40,941 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'win@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:57:40,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'win@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:57:40,942 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:57:40,942 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:57:40,942 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crimpt in the summer.
2024-05-19 16:57:40,943 - INFO - joeynmt.training - Example #4
2024-05-19 16:57:40,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgen@@', 'de', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2024-05-19 16:57:40,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'fa@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', "what's", 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'year@@', 's.']
2024-05-19 16:57:40,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'I', 'sho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'ated', 'ver@@', 'sion', 'of', 'what', 'happen@@', 'ed', 'the', 'last', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:57:40,944 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:57:40,944 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:57:40,944 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a accelerated version of what happened the last 25 years.
2024-05-19 16:57:44,338 - INFO - joeynmt.training - Epoch  10, Step:    39600, Batch Loss:     1.407151, Batch Acc: 0.614845, Tokens per Sec:    19938, Lr: 0.000300
2024-05-19 16:57:47,833 - INFO - joeynmt.training - Epoch  10, Step:    39700, Batch Loss:     1.391395, Batch Acc: 0.622523, Tokens per Sec:    21366, Lr: 0.000300
2024-05-19 16:57:49,800 - INFO - joeynmt.training - Epoch  10: total training loss 5109.17
2024-05-19 16:57:49,800 - INFO - joeynmt.training - Training ended after  10 epochs.
2024-05-19 16:57:49,801 - INFO - joeynmt.training - Best validation result (greedy) at step    39500:   5.54 ppl.
2024-05-19 16:57:49,823 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-19 16:57:49,921 - INFO - joeynmt.model - Enc-dec model built.
2024-05-19 16:57:50,105 - INFO - joeynmt.helpers - Load model from /content/drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/39500.ckpt.
2024-05-19 16:57:50,132 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2003),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2003),
	loss_function=None)
2024-05-19 16:57:50,133 - INFO - joeynmt.prediction - Decoding on dev set...
2024-05-19 16:57:50,133 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:57:50,133 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:58:07,996 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:58:07,997 - INFO - joeynmt.prediction - Evaluation result (beam search) bleu:  17.15, generation: 17.4977[sec], evaluation: 0.3359[sec]
2024-05-19 16:58:08,005 - INFO - joeynmt.prediction - Translations saved to: /content/mt-exercise-5/../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/00039500.hyps.dev.
2024-05-19 16:58:08,006 - INFO - joeynmt.prediction - Decoding on test set...
2024-05-19 16:58:08,006 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:58:08,006 - INFO - joeynmt.prediction - Predicting 1777 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:58:34,826 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:58:34,826 - INFO - joeynmt.prediction - Evaluation result (beam search) bleu:  24.30, generation: 26.2780[sec], evaluation: 0.5027[sec]
2024-05-19 16:58:34,834 - INFO - joeynmt.prediction - Translations saved to: /content/mt-exercise-5/../drive/MyDrive/mt-ex05/models/new/transformer_bpe2k/00039500.hyps.test.
