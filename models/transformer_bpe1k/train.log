2024-05-19 15:33:37,672 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2024-05-19 15:33:37,674 - INFO - joeynmt.helpers -                           cfg.name : transformer_bpe1k
2024-05-19 15:33:37,675 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2024-05-19 15:33:37,675 - INFO - joeynmt.helpers -                     cfg.data.train : data/subsampled/train
2024-05-19 15:33:37,676 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev.test/dev
2024-05-19 15:33:37,676 - INFO - joeynmt.helpers -                      cfg.data.test : data/dev.test/test
2024-05-19 15:33:37,676 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2024-05-19 15:33:37,676 - INFO - joeynmt.helpers -                  cfg.data.src.lang : nl
2024-05-19 15:33:37,676 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2024-05-19 15:33:37,677 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2024-05-19 15:33:37,677 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2024-05-19 15:33:37,677 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/joint_vocab1k_clean.txt
2024-05-19 15:33:37,677 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2024-05-19 15:33:37,677 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : none
2024-05-19 15:33:37,677 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 1000
2024-05-19 15:33:37,677 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/codes1000.bpe
2024-05-19 15:33:37,678 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en
2024-05-19 15:33:37,678 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2024-05-19 15:33:37,678 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2024-05-19 15:33:37,678 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2024-05-19 15:33:37,678 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/joint_vocab1k_clean.txt
2024-05-19 15:33:37,678 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2024-05-19 15:33:37,679 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : none
2024-05-19 15:33:37,679 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 1000
2024-05-19 15:33:37,679 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/codes1000.bpe
2024-05-19 15:33:37,679 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2024-05-19 15:33:37,679 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2024-05-19 15:33:37,679 - INFO - joeynmt.helpers -           cfg.testing.eval_metrics : ['bleu']
2024-05-19 15:33:37,680 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2024-05-19 15:33:37,680 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2024-05-19 15:33:37,680 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2024-05-19 15:33:37,680 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2024-05-19 15:33:37,680 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2024-05-19 15:33:37,680 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2024-05-19 15:33:37,680 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2024-05-19 15:33:37,681 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2024-05-19 15:33:37,681 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2024-05-19 15:33:37,681 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2024-05-19 15:33:37,681 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2024-05-19 15:33:37,681 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2024-05-19 15:33:37,681 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2024-05-19 15:33:37,681 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2024-05-19 15:33:37,682 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2024-05-19 15:33:37,682 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2024-05-19 15:33:37,682 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2024-05-19 15:33:37,682 - INFO - joeynmt.helpers -             cfg.training.model_dir : ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k
2024-05-19 15:33:37,682 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2024-05-19 15:33:37,682 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2024-05-19 15:33:37,682 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2024-05-19 15:33:37,683 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2024-05-19 15:33:37,683 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2024-05-19 15:33:37,683 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2024-05-19 15:33:37,683 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2024-05-19 15:33:37,683 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2024-05-19 15:33:37,683 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2024-05-19 15:33:37,683 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2024-05-19 15:33:37,684 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2024-05-19 15:33:37,684 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2024-05-19 15:33:37,684 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2024-05-19 15:33:37,684 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2024-05-19 15:33:37,684 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2024-05-19 15:33:37,684 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2024-05-19 15:33:37,685 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2024-05-19 15:33:37,685 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2024-05-19 15:33:37,685 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2024-05-19 15:33:37,685 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2024-05-19 15:33:37,685 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2024-05-19 15:33:37,685 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2024-05-19 15:33:37,685 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2024-05-19 15:33:37,686 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2024-05-19 15:33:37,686 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2024-05-19 15:33:37,686 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2024-05-19 15:33:37,686 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2024-05-19 15:33:37,686 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2024-05-19 15:33:37,686 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2024-05-19 15:33:37,686 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2024-05-19 15:33:37,687 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2024-05-19 15:33:37,758 - INFO - joeynmt.data - Building tokenizer...
2024-05-19 15:33:37,764 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-19 15:33:37,764 - INFO - joeynmt.tokenizers - en tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-19 15:33:37,765 - INFO - joeynmt.data - Loading train set...
2024-05-19 15:33:38,066 - INFO - joeynmt.data - Building vocabulary...
2024-05-19 15:33:38,095 - INFO - joeynmt.data - Loading dev set...
2024-05-19 15:33:38,102 - INFO - joeynmt.data - Loading test set...
2024-05-19 15:33:38,112 - INFO - joeynmt.data - Data loaded.
2024-05-19 15:33:38,113 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=nl, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-19 15:33:38,113 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1003, src_lang=nl, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-19 15:33:38,113 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1777, src_lang=nl, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-19 15:33:38,114 - INFO - joeynmt.data - First training example:
	[SRC] A@@ l G@@ or@@ e over het af@@ w@@ en@@ den van de k@@ li@@ maa@@ t@@ c@@ r@@ is@@ is
	[TRG] A@@ l G@@ or@@ e@@ : A@@ ver@@ ting the c@@ li@@ m@@ ate c@@ r@@ is@@ is
2024-05-19 15:33:38,114 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) en (6) k@@ (7) een (8) het (9) van
2024-05-19 15:33:38,114 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) en (6) k@@ (7) een (8) het (9) van
2024-05-19 15:33:38,114 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 1004
2024-05-19 15:33:38,114 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 1004
2024-05-19 15:33:38,127 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-19 15:33:38,200 - INFO - joeynmt.model - Enc-dec model built.
2024-05-19 15:33:42,604 - DEBUG - tensorflow - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2024-05-19 15:33:43,198 - DEBUG - h5py._conv - Creating converter from 7 to 5
2024-05-19 15:33:43,198 - DEBUG - h5py._conv - Creating converter from 5 to 7
2024-05-19 15:33:43,198 - DEBUG - h5py._conv - Creating converter from 7 to 5
2024-05-19 15:33:43,198 - DEBUG - h5py._conv - Creating converter from 5 to 7
2024-05-19 15:33:44,666 - DEBUG - jax._src.path - etils.epath found. Using etils.epath for file I/O.
2024-05-19 15:33:45,856 - INFO - joeynmt.model - Total params: 3156224
2024-05-19 15:33:45,857 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2024-05-19 15:33:45,858 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1004),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2024-05-19 15:33:46,960 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2024-05-19 15:33:46,961 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2024-05-19 15:33:46,961 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2024-05-19 15:33:46,961 - INFO - joeynmt.training - EPOCH 1
2024-05-19 15:33:53,021 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.729787, Batch Acc: 0.037216, Tokens per Sec:    12357, Lr: 0.000300
2024-05-19 15:33:57,035 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.512822, Batch Acc: 0.058645, Tokens per Sec:    18847, Lr: 0.000300
2024-05-19 15:34:00,941 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.316458, Batch Acc: 0.075435, Tokens per Sec:    19647, Lr: 0.000300
2024-05-19 15:34:04,198 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.326162, Batch Acc: 0.091187, Tokens per Sec:    23673, Lr: 0.000300
2024-05-19 15:34:07,617 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.223991, Batch Acc: 0.111453, Tokens per Sec:    22908, Lr: 0.000300
2024-05-19 15:34:07,618 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:34:07,618 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:34:25,670 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:34:25,670 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   0.24, loss:   3.18, ppl:  24.13, acc:   0.11, generation: 17.6537[sec], evaluation: 0.3441[sec]
2024-05-19 15:34:25,671 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:34:26,002 - INFO - joeynmt.training - Example #0
2024-05-19 15:34:26,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:34:26,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:34:26,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'have', 'the', 's@@', 'ame', 'of', 'the', 'f@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', '.', '</s>']
2024-05-19 15:34:26,004 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:34:26,004 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:34:26,004 - INFO - joeynmt.training - 	Hypothesis: And I have the same of the faaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaatttttttttttt.
2024-05-19 15:34:26,004 - INFO - joeynmt.training - Example #1
2024-05-19 15:34:26,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:34:26,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:34:26,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'the', 'f@@', 'a@@', 'm@@', 'e', 'of', 'the', 'f@@', 'a@@', 'b@@', 'a@@', 'b@@', 'a@@', 'b@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', '.', '</s>']
2024-05-19 15:34:26,006 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:34:26,007 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:34:26,007 - INFO - joeynmt.training - 	Hypothesis: But the fame of the fabababaaaaaaaaaaaaaaaaaaaaaa.
2024-05-19 15:34:26,008 - INFO - joeynmt.training - Example #2
2024-05-19 15:34:26,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:34:26,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:34:26,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 's@@', 'ame', 'the', 's@@', 'ame', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'of', 'the', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', '.', '</s>']
2024-05-19 15:34:26,010 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:34:26,010 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:34:26,010 - INFO - joeynmt.training - 	Hypothesis: And the same the same the same of the same of the same of the same of the ccccc.
2024-05-19 15:34:26,010 - INFO - joeynmt.training - Example #3
2024-05-19 15:34:26,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:34:26,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:34:26,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'b@@', '.', '</s>']
2024-05-19 15:34:26,011 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:34:26,012 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:34:26,012 - INFO - joeynmt.training - 	Hypothesis: And the b.
2024-05-19 15:34:26,012 - INFO - joeynmt.training - Example #4
2024-05-19 15:34:26,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:34:26,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:34:26,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'the', 'b@@', 'b@@', ',', 'I', 'think', 'the', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'e', 'of', 'the', 'the', 'b@@', '.', '</s>']
2024-05-19 15:34:26,013 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:34:26,014 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:34:26,014 - INFO - joeynmt.training - 	Hypothesis: And I think the bb, I think the bbbbbe of the the b.
2024-05-19 15:34:29,778 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.940449, Batch Acc: 0.133136, Tokens per Sec:    18459, Lr: 0.000300
2024-05-19 15:34:33,171 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.976938, Batch Acc: 0.152568, Tokens per Sec:    22634, Lr: 0.000300
2024-05-19 15:34:36,412 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     2.807338, Batch Acc: 0.174997, Tokens per Sec:    23518, Lr: 0.000300
2024-05-19 15:34:40,418 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     2.823080, Batch Acc: 0.189912, Tokens per Sec:    19105, Lr: 0.000300
2024-05-19 15:34:44,105 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.588526, Batch Acc: 0.202571, Tokens per Sec:    20448, Lr: 0.000300
2024-05-19 15:34:44,105 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:34:44,106 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:35:01,776 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:35:01,776 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   0.64, loss:   2.76, ppl:  15.87, acc:   0.19, generation: 17.4084[sec], evaluation: 0.2385[sec]
2024-05-19 15:35:01,777 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:35:01,994 - INFO - joeynmt.training - Example #0
2024-05-19 15:35:01,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:35:01,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:35:01,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'in', 'the', 're@@', 'd', 'to', 'the', 're@@', 'd', 'to', 'the', 'f@@', 'a@@', 'ga@@', 'in@@', ',', 'and', 'to', 'the', 'f@@', 'l@@', 'ast', 'the', 're@@', 'a@@', 'k@@', ',', 'the', 'b@@', 'er', 'of', 'the', 're@@', 'd', 'the', 'b@@', 'ra@@', 'in@@', ',', 'and', 'the', 're@@', 'd', 'the', 're@@', 's@@', 'si@@', 'on', 'the', 're@@', 'd', 'the', 're@@', 's@@', 'si@@', 'b@@', 'le', 'of', 'the', 're@@', 's@@', 'ame', 'of', 'the', 're@@', 's@@', 'ame', 'of', 'the', 're@@', 'd', 'to', 'the', 're@@', 'a@@', 'k@@', 'il@@', 'd', 'to', 'the', 're@@', 'd', 'to', 'the', 're@@', 'd', 'the', 're@@', 're@@', 're@@', 'd', 'to', 'the', 're@@', 'd', 'to', 'the', 're@@', 'd', 'to', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'si@@', 'b@@', 'er', 'of', 'the', 're@@', 's@@', 'ame', 'of', 'the', 're@@', 'd', 'the', 're@@', 'd', 'to', 'f@@', 'l@@', 'l@@', 'l@@', 'l@@', 'l@@', 'l@@', 'ast']
2024-05-19 15:35:01,996 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:35:01,996 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:35:01,997 - INFO - joeynmt.training - 	Hypothesis: And in the red to the red to the fagain, and to the flast the reak, the ber of the red the brain, and the red the ression the red the ressible of the resame of the resame of the red to the reakild to the red to the red the rerered to the red to the red to the same of the ssiber of the resame of the red the red to fllllllast
2024-05-19 15:35:01,997 - INFO - joeynmt.training - Example #1
2024-05-19 15:35:01,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:35:01,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:35:01,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 're@@', 's@@', 'ed', 'to', 'the', 're@@', 'a@@', 'ga@@', 'in@@', 'in@@', 'in@@', 'in@@', 'in@@', 'in@@', 'in@@', 'di@@', 'd', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'it', 'in', 'the', 're@@', '.', '</s>']
2024-05-19 15:35:01,998 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:35:01,998 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:35:01,998 - INFO - joeynmt.training - 	Hypothesis: But this is a resed to the reagaininininininindid it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it in the re.
2024-05-19 15:35:01,999 - INFO - joeynmt.training - Example #2
2024-05-19 15:35:01,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:35:01,999 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:35:01,999 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'as@@', 'e', 'in', 'the', 'N@@', 'e@@', 'a@@', 'k@@', 'es', 'in', 'the', 's@@', 'ame', 'is', 'the', 'f@@', 'a@@', 'k@@', 'e,', 'in', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'of', 'the', 'b@@', 'ra@@', 'in@@', '.', '</s>']
2024-05-19 15:35:02,000 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:35:02,000 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:35:02,000 - INFO - joeynmt.training - 	Hypothesis: The base in the Neakes in the same is the fake, in the same of the same of the same of the brain.
2024-05-19 15:35:02,000 - INFO - joeynmt.training - Example #3
2024-05-19 15:35:02,000 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:35:02,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:35:02,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["It's", 'in', 'the', 's@@', 'ame', 'of', 'the', 're@@', 's@@', 'ame', 'in', 'the', 're@@', 's@@', 'ame', 'in', 'the', 're@@', 's@@', 'ame', 'in', 'the', 're@@', 's@@', 'ame', 'in', 'the', 's@@', 'ame', 'of', 'the', 're@@', 's@@', 'ame', 'in', 'the', 're@@', 's@@', 'ame', 'in', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'in', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'in', 'the', 're@@', 're@@', 're@@', 're@@', 's@@', 'ame', 'of', 'the', 're@@', 're@@', 're@@', 're@@', 's@@', 'si@@', 'on', 'the', 're@@', 's@@', 'si@@', 'on', 'the', 're@@', '.', '</s>']
2024-05-19 15:35:02,001 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:35:02,001 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:35:02,001 - INFO - joeynmt.training - 	Hypothesis: It's in the same of the resame in the resame in the resame in the resame in the same of the resame in the resame in the same of the same of the same in the same of the same in the rerereresame of the rerereression the ression the re.
2024-05-19 15:35:02,002 - INFO - joeynmt.training - Example #4
2024-05-19 15:35:02,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:35:02,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:35:02,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'con@@', 'con@@', 'con@@', 'con@@', 'con@@', 'con@@', 'con@@', 't@@', 't@@', 'ly', 'is', 'the', 're@@', 'd', 'the', 're@@', 'd', 'the', 're@@', 'd', 'the', 're@@', 'd', 'the', 're@@', 'd', 'to', 'a', 'b@@', 'il@@', 'd', 'to', 'the', 're@@', 're@@', 're@@', 'd', 'to', 'the', 're@@', 'd', 'to', 'the', 're@@', 's@@', 'si@@', 'on', 'the', 're@@', '.', '</s>']
2024-05-19 15:35:02,003 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:35:02,003 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:35:02,003 - INFO - joeynmt.training - 	Hypothesis: The conconconconconconconttly is the red the red the red the red the red to a bild to the rerered to the red to the ression the re.
2024-05-19 15:35:05,523 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     2.720968, Batch Acc: 0.217198, Tokens per Sec:    20128, Lr: 0.000300
2024-05-19 15:35:10,941 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.602139, Batch Acc: 0.227852, Tokens per Sec:    13690, Lr: 0.000300
2024-05-19 15:35:15,054 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.448503, Batch Acc: 0.239997, Tokens per Sec:    18833, Lr: 0.000300
2024-05-19 15:35:18,270 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.605941, Batch Acc: 0.255019, Tokens per Sec:    23251, Lr: 0.000300
2024-05-19 15:35:21,583 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.263475, Batch Acc: 0.260774, Tokens per Sec:    22494, Lr: 0.000300
2024-05-19 15:35:21,584 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:35:21,584 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:35:37,615 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:35:37,615 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   1.55, loss:   2.56, ppl:  12.90, acc:   0.24, generation: 15.6306[sec], evaluation: 0.3650[sec]
2024-05-19 15:35:37,616 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:35:37,915 - INFO - joeynmt.training - Example #0
2024-05-19 15:35:37,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:35:37,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:35:37,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['A@@', 'n@@', 'a@@', 'y,', 'I', 'a@@', 've', 'two', 'di@@', 'd', 'two', 'di@@', 'd', 'to', 'the', 's@@', 'ame', 'to', 'the', 's@@', 'ame', 'years', 'a@@', 'k@@', 'l@@', 'ast', 'c@@', 'ou@@', 'p@@', 's', 'that', 'the', 'years', 'a@@', 'k@@', 'il@@', 'li@@', 'on', 'the', 'f@@', 'ri@@', 've', 'the', 'U@@', 'n@@', 'ed', 'to', 'the', 's@@', 'ame', 'of', 'the', 'U@@', '.@@', 'S@@', 'a@@', 'st@@', ',', 'and', 'the', 'U@@', '.@@', 'S@@', 'a@@', 'st@@', ',', 'and', 'the', 'U@@', 'n@@', 'a@@', 'st@@', ',', '</s>']
2024-05-19 15:35:37,918 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:35:37,918 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:35:37,918 - INFO - joeynmt.training - 	Hypothesis: Anay, I ave two did two did to the same to the same years aklast coups that the years akillion the frive the Uned to the same of the U.Sast, and the U.Sast, and the Unast,
2024-05-19 15:35:37,918 - INFO - joeynmt.training - Example #1
2024-05-19 15:35:37,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:35:37,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:35:37,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'of', 'the', 's@@', 'ame', 'of', 'the', 'f@@', 'a@@', 'm', 'of', 'the', 'f@@', 'a@@', 'm', 'of', 'the', 's@@', 'ho@@', 'to@@', 'ge@@', 's', 'of', 'the', 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:35:37,919 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:35:37,920 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:35:37,920 - INFO - joeynmt.training - 	Hypothesis: But this is the same of the same of the same of the fam of the fam of the shotoges of the show.
2024-05-19 15:35:37,920 - INFO - joeynmt.training - Example #2
2024-05-19 15:35:37,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:35:37,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:35:37,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 's@@', 'ho@@', 'w@@', 's', 'on', 'the', 'N@@', 'N@@', 'N@@', 'N@@', 'e@@', 'a@@', 'k@@', 'k@@', 'es', 'in', 'the', 's@@', 'ame', 'of', 'the', 'l@@', 'l@@', 'ast', 'of', 'the', 'p@@', 'ut', 'of', 'the', 'p@@', 'ut', 'of', 'the', 'p@@', 'ut', 'of', 'the', 'c@@', 'li@@', 'g@@', 'h@@', 't', 'of', 'the', 's@@', 'on@@', 'g@@', 'g@@', 'l@@', 'l@@', 'l@@', 'on@@', 'g@@', 'h@@', '.', '</s>']
2024-05-19 15:35:37,921 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:35:37,921 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:35:37,921 - INFO - joeynmt.training - 	Hypothesis: The shows on the NNNNeakkes in the same of the llast of the put of the put of the put of the clight of the songglllongh.
2024-05-19 15:35:37,921 - INFO - joeynmt.training - Example #3
2024-05-19 15:35:37,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:35:37,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:35:37,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 's@@', 'in@@', 'cre@@', 'at@@', 'ed', 'in', 'the', 's@@', 'in@@', 't', 'in', 'the', 's@@', 'ame', 'in', 'the', 'b@@', 'in@@', 'e.', '</s>']
2024-05-19 15:35:37,923 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:35:37,923 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:35:37,923 - INFO - joeynmt.training - 	Hypothesis: It was in the sincreated in the sint in the same in the bine.
2024-05-19 15:35:37,923 - INFO - joeynmt.training - Example #4
2024-05-19 15:35:37,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:35:37,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:35:37,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'the', 'di@@', 'a', 'lo@@', 't', 'of', 'the', 's@@', 's@@', 'ho@@', 'w@@', 's', 'of', 'the', 's@@', 'si@@', 'on', 'of', 'the', '2@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', ',', '</s>']
2024-05-19 15:35:37,924 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:35:37,924 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:35:37,924 - INFO - joeynmt.training - 	Hypothesis: The next the dia lot of the sshows of the ssion of the 20000000000000000000,
2024-05-19 15:35:42,194 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.256135, Batch Acc: 0.272399, Tokens per Sec:    16740, Lr: 0.000300
2024-05-19 15:35:45,487 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.252150, Batch Acc: 0.283906, Tokens per Sec:    23064, Lr: 0.000300
2024-05-19 15:35:48,915 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.441008, Batch Acc: 0.292803, Tokens per Sec:    22422, Lr: 0.000300
2024-05-19 15:35:52,432 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.417508, Batch Acc: 0.299171, Tokens per Sec:    21566, Lr: 0.000300
2024-05-19 15:35:56,747 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.452782, Batch Acc: 0.309700, Tokens per Sec:    18038, Lr: 0.000300
2024-05-19 15:35:56,747 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:35:56,748 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:36:13,900 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:36:13,901 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   2.12, loss:   2.41, ppl:  11.14, acc:   0.28, generation: 16.9306[sec], evaluation: 0.1996[sec]
2024-05-19 15:36:13,902 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:36:14,124 - INFO - joeynmt.training - Example #0
2024-05-19 15:36:14,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:36:14,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:36:14,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'der', 'I', 'years', 'I', 'have', 'two', 'di@@', 'd', 'to', 'see', 'this', 'di@@', 'd', 'to', 'see', 'the', 'p@@', 'ri@@', 'p@@', 'ut', 'the', 'p@@', 'ri@@', 'on', 'the', 'p@@', 'ri@@', 'on', 'the', 'b@@', 'er', 'of', 'the', 'b@@', 'li@@', 'on', 'mil@@', 'li@@', 'on', 'mil@@', 'li@@', 'on', 'mil@@', 'li@@', 'on', 'the', 'f@@', 'l@@', 'ast', 'of', 'the', 'S@@', 'a@@', 'st@@', 'and', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:36:14,126 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:36:14,126 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:36:14,126 - INFO - joeynmt.training - 	Hypothesis: Forder I years I have two did to see this did to see the priput the prion the prion the ber of the blion million million million the flast of the Sastand the U.S.
2024-05-19 15:36:14,126 - INFO - joeynmt.training - Example #1
2024-05-19 15:36:14,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:36:14,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:36:14,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'lo@@', 't', 'of', 'the', 'n@@', 'er@@', 'n@@', 'er@@', 's', 'of', 'the', 'f@@', 'i@@', 've', 'this', 'is', 'not', 'because', 'because', 'it', 'because', 'the', 'di@@', 'c@@', 'es', 'of', 'the', 'di@@', 'c@@', 'e.', '</s>']
2024-05-19 15:36:14,127 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:36:14,128 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:36:14,128 - INFO - joeynmt.training - 	Hypothesis: But this is a lot of the nerners of the five this is not because because it because the dices of the dice.
2024-05-19 15:36:14,128 - INFO - joeynmt.training - Example #2
2024-05-19 15:36:14,128 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:36:14,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:36:14,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'N@@', 'a@@', 'k@@', 'a@@', 'p', 'on', 'the', 'N@@', 'e@@', 'p', 'in', 'the', 'N@@', 'e@@', 'very', 's@@', 'he', 'was', 'in', 'the', 'p@@', 'op@@', 'ul@@', 'l', 'of', 'us', 'in', 'our', 'p@@', 'op@@', 'ul@@', 'l', 'us', 'us', 'us', 'of', 'us', 'of', 'us', 'of', 'us', 'the', 'sy@@', 'st@@', 'em@@', 'em@@', '.', '</s>']
2024-05-19 15:36:14,129 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:36:14,129 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:36:14,129 - INFO - joeynmt.training - 	Hypothesis: The Nakap on the Nep in the Nevery she was in the popull of us in our popull us us us of us of us of us the systemem.
2024-05-19 15:36:14,129 - INFO - joeynmt.training - Example #3
2024-05-19 15:36:14,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:36:14,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:36:14,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'cre@@', 'at@@', 'ed', 'in', 'the', 's@@', 'ame', 'in', 'the', 'b@@', 'om@@', 'e', 'in', 'the', 'b@@', 'om@@', '.', '</s>']
2024-05-19 15:36:14,130 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:36:14,130 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:36:14,131 - INFO - joeynmt.training - 	Hypothesis: It was in the wincreated in the same in the bome in the bom.
2024-05-19 15:36:14,131 - INFO - joeynmt.training - Example #4
2024-05-19 15:36:14,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:36:14,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:36:14,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'that', 'I', 'think', 'I', 'see', 'the', 'di@@', 'c@@', 'es', 'is', 'a', 's@@', 'ho@@', 'w@@', 'ing', 'of', 'what', 'was', 'a', '2@@', '5', 'years', 'of', '2@@', '5', 'years', 'of', '2@@', '5', 'years', 'of', '2@@', '5', 'years', 'of', '2@@', '5', 'years', 'a@@', 'go@@', '.', '</s>']
2024-05-19 15:36:14,132 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:36:14,132 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:36:14,132 - INFO - joeynmt.training - 	Hypothesis: The next that I think I see the dices is a showing of what was a 25 years of 25 years of 25 years of 25 years of 25 years ago.
2024-05-19 15:36:17,337 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.323954, Batch Acc: 0.318278, Tokens per Sec:    22466, Lr: 0.000300
2024-05-19 15:36:20,872 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.262581, Batch Acc: 0.324812, Tokens per Sec:    20808, Lr: 0.000300
2024-05-19 15:36:25,324 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.128690, Batch Acc: 0.329317, Tokens per Sec:    16853, Lr: 0.000300
2024-05-19 15:36:28,595 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.089852, Batch Acc: 0.339576, Tokens per Sec:    23106, Lr: 0.000300
2024-05-19 15:36:31,848 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.143760, Batch Acc: 0.344293, Tokens per Sec:    23312, Lr: 0.000300
2024-05-19 15:36:31,848 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:36:31,849 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:36:49,164 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:36:49,164 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   2.85, loss:   2.30, ppl:   9.94, acc:   0.31, generation: 16.9229[sec], evaluation: 0.3559[sec]
2024-05-19 15:36:49,165 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:36:49,393 - INFO - joeynmt.training - Example #0
2024-05-19 15:36:49,394 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:36:49,394 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:36:49,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'then', 'I', 'think', 'this', 'is', 'two', 'mil@@', 'li@@', 'on', 'these', 'two', 'mil@@', 'li@@', 'on', 'the', 'p@@', 'ut', 'that', 'the', 'p@@', 'oo@@', 'l@@', 's', 'that', 'the', 'p@@', 'op@@', 'ul@@', 'l', 'of', 'the', 'p@@', 'ri@@', 'v@@', 'es', 'that', 'the', 'c@@', 'ap@@', 'pro@@', 'vi@@', 'de@@', 's', 'of', 'the', 'U@@', 'n@@', 'it@@', 's', 'of', 'the', 'U@@', 'n@@', 'it@@', 's', 'of', 'the', 'U@@', '.@@', 'S@@', 'S@@', 't@@', 'at@@', 'ed', 'S@@', 't@@', 'at@@', 'ed', 'S@@', 't@@', 'ri@@', 'v@@', 'es', 'of', 'the', 'U@@', '.@@', 'S@@', 't@@', 'at@@', 'e@@', 'a@@', 'ge@@', 's', 'of', 'the', '1@@', '0@@', '0@@', '0@@', ',', '</s>']
2024-05-19 15:36:49,396 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:36:49,396 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:36:49,396 - INFO - joeynmt.training - 	Hypothesis: And then I think this is two million these two million the put that the pools that the popull of the prives that the capprovides of the Units of the Units of the U.SStated Stated Strives of the U.Stateages of the 1000,
2024-05-19 15:36:49,397 - INFO - joeynmt.training - Example #1
2024-05-19 15:36:49,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:36:49,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:36:49,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 's@@', 'our@@', 'c@@', 'es', 'of', 'this', 'is', 'not', 'the', 'spec@@', 'i@@', 'f@@', 'i@@', 've', 'the', 'di@@', 'd@@', "n't", 'the', 'di@@', 'se@@', ',', 'because', 'the', 'di@@', 'd@@', "n't", 'the', 'di@@', 'd@@', "n't", 're@@', 'al', 'proble@@', 'm@@', 's.', '</s>']
2024-05-19 15:36:49,398 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:36:49,398 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:36:49,398 - INFO - joeynmt.training - 	Hypothesis: But this is a sources of this is not the specifive the didn't the dise, because the didn't the didn't real problems.
2024-05-19 15:36:49,398 - INFO - joeynmt.training - Example #2
2024-05-19 15:36:49,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:36:49,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:36:49,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'N@@', 'or@@', 'der', 'on', 'the', 'N@@', 'or@@', 'or@@', 'th', 'is', 'in', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'the', 'c@@', 'l@@', 'as@@', 'k', 'of', 'our', 'c@@', 'op@@', 'y', 'of', 'our', 'b@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:36:49,399 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:36:49,400 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:36:49,400 - INFO - joeynmt.training - 	Hypothesis: The Norder on the Nororth is in the North is in the clask of our copy of our blobal system.
2024-05-19 15:36:49,400 - INFO - joeynmt.training - Example #3
2024-05-19 15:36:49,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:36:49,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:36:49,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'the', 'w@@', 'in@@', 'ter', 'and', 'the', 'c@@', 'oun@@', 'tr@@', 'y', 'in', 'the', 'on@@', 'om@@', 'e.', '</s>']
2024-05-19 15:36:49,401 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:36:49,401 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:36:49,401 - INFO - joeynmt.training - 	Hypothesis: It is in the winter and the winter and the country in the onome.
2024-05-19 15:36:49,401 - INFO - joeynmt.training - Example #4
2024-05-19 15:36:49,401 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:36:49,402 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:36:49,402 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'ne@@', 'x@@', 't', 'that', 'I', 'think', 'is', 'a', 's@@', 'ho@@', 'w@@', 's', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 's@@', 'si@@', 'm@@', 'ight', 'years', 'a@@', 'go@@', ',', '2@@', '5', 'years', 'a@@', 'go@@', '.', '</s>']
2024-05-19 15:36:49,402 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:36:49,403 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:36:49,403 - INFO - joeynmt.training - 	Hypothesis: And the next that I think is a shows of what happened the ssimight years ago, 25 years ago.
2024-05-19 15:36:53,885 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.033525, Batch Acc: 0.356696, Tokens per Sec:    16176, Lr: 0.000300
2024-05-19 15:36:57,412 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.142265, Batch Acc: 0.363829, Tokens per Sec:    21514, Lr: 0.000300
2024-05-19 15:37:00,668 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.059746, Batch Acc: 0.372242, Tokens per Sec:    23371, Lr: 0.000300
2024-05-19 15:37:04,281 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.004281, Batch Acc: 0.385265, Tokens per Sec:    21079, Lr: 0.000300
2024-05-19 15:37:08,210 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.105784, Batch Acc: 0.390254, Tokens per Sec:    19561, Lr: 0.000300
2024-05-19 15:37:08,211 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:37:08,211 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:37:22,710 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:37:22,710 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   3.95, loss:   2.19, ppl:   8.96, acc:   0.34, generation: 14.2966[sec], evaluation: 0.1848[sec]
2024-05-19 15:37:22,711 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:37:22,932 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/500.ckpt
2024-05-19 15:37:22,964 - INFO - joeynmt.training - Example #0
2024-05-19 15:37:22,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:37:22,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:37:22,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'on', 'years', 'of', 'these', 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 'the', 'two', 'di@@', 'a@@', "'s", 'the', 'p@@', 'ut', 'that', 'p@@', 'ut', 'the', 'p@@', 'op@@', 'ul@@', 'ar', 'of', 'the', 'p@@', 'op@@', 'ul@@', 'ar', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'gr@@', 'oun@@', 'd@@', 'ly', 'f@@', 'ound', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:37:22,966 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:37:22,966 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:37:22,966 - INFO - joeynmt.training - 	Hypothesis: Forion years of these two dia's two dia's the two dia's the put that put the popular of the popular million years of the groundly found the U.S.
2024-05-19 15:37:22,966 - INFO - joeynmt.training - Example #1
2024-05-19 15:37:22,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:37:22,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:37:22,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 're@@', 'al@@', 'iz@@', 'ed', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'i@@', 'f@@', 'i@@', 'f@@', 'i@@', 'f@@', 'i@@', 'f@@', 'i@@', 'f@@', 'i@@', 'f@@', 'a@@', 'il@@', 's', 'of', 'the', 'di@@', 'se@@', 'a@@', 'se@@', '.', '</s>']
2024-05-19 15:37:22,967 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:37:22,967 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:37:22,968 - INFO - joeynmt.training - 	Hypothesis: But this is the realized of this specifififififififails of the disease.
2024-05-19 15:37:22,968 - INFO - joeynmt.training - Example #2
2024-05-19 15:37:22,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:37:22,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:37:22,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'N@@', 'or@@', 'th', 'on', 'the', 'N@@', 'or@@', 'th', 'N@@', 'or@@', 'th', 'is', 'in', 'the', 'N@@', 'or@@', 'th', 'of', 'the', 'N@@', 'or@@', 'th', 'of', 'us', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'e', 'of', 'us', 'of', 'us', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:37:22,969 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:37:22,969 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:37:22,969 - INFO - joeynmt.training - 	Hypothesis: The North on the North North is in the North of the North of us in the cloppe of us of us system.
2024-05-19 15:37:22,969 - INFO - joeynmt.training - Example #3
2024-05-19 15:37:22,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:37:22,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:37:22,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'in', 'the', 's@@', 'ame', 'time@@', ',', '</s>']
2024-05-19 15:37:22,970 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:37:22,970 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:37:22,971 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and in the same time,
2024-05-19 15:37:22,971 - INFO - joeynmt.training - Example #4
2024-05-19 15:37:22,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:37:22,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:37:22,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'of', 'the', 'di@@', 'a', 'l@@', 'on@@', 'g', 'of', 'the', 'l@@', 'on@@', 'g', 'of', 'what', 'the', 'p@@', 'as@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'a@@', 'go@@', '.', '</s>']
2024-05-19 15:37:22,972 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:37:22,972 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:37:22,972 - INFO - joeynmt.training - 	Hypothesis: The next of the dia long of the long of what the passion of what happened 25 years ago.
2024-05-19 15:37:26,216 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     1.924662, Batch Acc: 0.391759, Tokens per Sec:    21457, Lr: 0.000300
2024-05-19 15:37:29,509 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.079857, Batch Acc: 0.391606, Tokens per Sec:    22703, Lr: 0.000300
2024-05-19 15:37:33,592 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     1.909124, Batch Acc: 0.403621, Tokens per Sec:    18251, Lr: 0.000300
2024-05-19 15:37:37,326 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.004761, Batch Acc: 0.404256, Tokens per Sec:    20213, Lr: 0.000300
2024-05-19 15:37:40,531 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.051286, Batch Acc: 0.416699, Tokens per Sec:    24083, Lr: 0.000300
2024-05-19 15:37:40,531 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:37:40,531 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:37:54,987 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:37:54,987 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   4.89, loss:   2.11, ppl:   8.26, acc:   0.37, generation: 14.2517[sec], evaluation: 0.1843[sec]
2024-05-19 15:37:54,988 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:37:55,231 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/1000.ckpt
2024-05-19 15:37:55,248 - INFO - joeynmt.training - Example #0
2024-05-19 15:37:55,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:37:55,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:37:55,250 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'i@@', 'or', 'years', 'I', 'c@@', 'ap@@', 'e', 'this', 'di@@', 'a@@', "'s", 'a', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 'ed', 'to', 's@@', 'k@@', 'ap@@', ',', 'who', 'was', 'the', 'p@@', 'op@@', 'ul@@', 'ar', 'the', 'l@@', 'ast', 'mil@@', 'li@@', 'on', 'years', 'and', 'years', 'ol@@', 'd', 'mil@@', 'li@@', 'on', 'years', 'years', 'ol@@', 'd', 'to', 'the', 'lar@@', 'ge@@', 'st', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:37:55,250 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:37:55,250 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:37:55,251 - INFO - joeynmt.training - 	Hypothesis: Fior years I cape this dia's a dia's showed to skap, who was the popular the last million years and years old million years years old to the largest of the U.S, with the U.S.
2024-05-19 15:37:55,251 - INFO - joeynmt.training - Example #1
2024-05-19 15:37:55,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:37:55,251 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:37:55,251 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 're@@', 'sc@@', 'ri@@', 'p@@', 'le', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'is', 'not', 'the', 'spec@@', 'i@@', 'f@@', 'ic', 'because', 'it', 'because', 'it', 'is', 'not', 'the', 'di@@', 'c@@', 'tion', 'of', 'the', 'di@@', 'c@@', 'tion@@', '.', '</s>']
2024-05-19 15:37:55,252 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:37:55,252 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:37:55,252 - INFO - joeynmt.training - 	Hypothesis: But this rescriple of this specific is not the specific because it because it is not the diction of the diction.
2024-05-19 15:37:55,253 - INFO - joeynmt.training - Example #2
2024-05-19 15:37:55,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:37:55,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:37:55,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'N@@', 'or@@', 'th', 'is', 'in', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'e', 'of', 'us', 'in', 'the', 'c@@', 'l@@', 'op@@', 'ul@@', 'ar', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:37:55,254 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:37:55,254 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:37:55,254 - INFO - joeynmt.training - 	Hypothesis: The cap on the North North is in the North is in the cloppe of us in the clopular system.
2024-05-19 15:37:55,254 - INFO - joeynmt.training - Example #3
2024-05-19 15:37:55,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:37:55,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:37:55,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'se@@', 'as@@', 'e', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'oo@@', 'm', 'in', 'the', 'se@@', 'as@@', 'e', 'and', 'c@@', 'r@@', 'ight', 'and', 'c@@', 'ri@@', 'p@@', 'le', 'in', 'the', 's@@', 'ou@@', 'p@@', 'le', 'in', 'the', 'w@@', 'in@@', 'ter@@', '.', '</s>']
2024-05-19 15:37:55,255 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:37:55,256 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:37:55,256 - INFO - joeynmt.training - 	Hypothesis: It sease in the winter and croom in the sease and cright and criple in the souple in the winter.
2024-05-19 15:37:55,256 - INFO - joeynmt.training - Example #4
2024-05-19 15:37:55,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:37:55,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:37:55,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'that', 'I', 'think', 'I', 's@@', 'een', 'a', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'de@@', 'p@@', 'en@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'a@@', 'go@@', '.', '</s>']
2024-05-19 15:37:55,257 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:37:55,257 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:37:55,257 - INFO - joeynmt.training - 	Hypothesis: The next that I think I seen a showed is a depension of what happened in the last 25 years ago.
2024-05-19 15:37:58,476 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     1.907396, Batch Acc: 0.424184, Tokens per Sec:    21965, Lr: 0.000300
2024-05-19 15:38:02,548 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     1.800080, Batch Acc: 0.419247, Tokens per Sec:    18708, Lr: 0.000300
2024-05-19 15:38:06,232 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     1.840943, Batch Acc: 0.426976, Tokens per Sec:    20816, Lr: 0.000300
2024-05-19 15:38:09,472 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     1.879373, Batch Acc: 0.433514, Tokens per Sec:    23517, Lr: 0.000300
2024-05-19 15:38:12,803 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     1.832474, Batch Acc: 0.432626, Tokens per Sec:    22863, Lr: 0.000300
2024-05-19 15:38:12,803 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:38:12,804 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:38:28,864 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:38:28,865 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   5.43, loss:   2.04, ppl:   7.71, acc:   0.39, generation: 15.6988[sec], evaluation: 0.3280[sec]
2024-05-19 15:38:28,866 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:38:29,113 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/1500.ckpt
2024-05-19 15:38:29,141 - INFO - joeynmt.training - Example #0
2024-05-19 15:38:29,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:38:29,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:38:29,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'year@@', ',', 'I', 'have', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 's', 'to', 's@@', 'k@@', 'ap@@', ',', 'that', 'the', 'p@@', 'oo@@', 'l@@', 's', 'of', 'the', 'de@@', 'de@@', 'd', 'mil@@', 'li@@', 'on', 'the', 'de@@', 'a@@', 'th@@', ',', 'who', 'was', 'a', 'b@@', 'li@@', 'on', 'the', 'si@@', 'de', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', ',', 'with', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', ',', 'with', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', ',', 'with', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', ',', '</s>']
2024-05-19 15:38:29,143 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:38:29,143 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:38:29,144 - INFO - joeynmt.training - 	Hypothesis: And I was a year, I have these two dia's shows to skap, that the pools of the deded million the death, who was a blion the side of the United S, with the United S, with the United S, with the United S,
2024-05-19 15:38:29,144 - INFO - joeynmt.training - Example #1
2024-05-19 15:38:29,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:38:29,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:38:29,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'sc@@', 're@@', 'e', 'of', 'this', 'is', 'n@@', 'as@@', 'e', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', "it's", 'not', 'the', 'di@@', 'c@@', 'tion', 'of', 'the', 'di@@', 'c@@', 'tion', 'of', 'the', 'di@@', 'c@@', 'le@@', '.', '</s>']
2024-05-19 15:38:29,145 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:38:29,145 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:38:29,146 - INFO - joeynmt.training - 	Hypothesis: But this is a scree of this is nase of this specific problem because it's not the diction of the diction of the dicle.
2024-05-19 15:38:29,146 - INFO - joeynmt.training - Example #2
2024-05-19 15:38:29,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:38:29,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:38:29,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'N@@', 'or@@', 'th', 'on', 'the', 'N@@', 'or@@', 'th', 'of', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ing', 'c@@', 'l@@', 'op@@', 'p@@', 'ed', 'of', 'us', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2024-05-19 15:38:29,147 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:38:29,147 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:38:29,148 - INFO - joeynmt.training - 	Hypothesis: The North on the North of the North is in the clopping clopped of us heart of our global systeem.
2024-05-19 15:38:29,148 - INFO - joeynmt.training - Example #3
2024-05-19 15:38:29,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:38:29,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:38:29,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'of', 'the', 'w@@', 'in@@', 'ter', 'and', 's@@', 'ho@@', 'w@@', 'ing', 'in', 'the', 's@@', 'om@@', 'e.', '</s>']
2024-05-19 15:38:29,149 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:38:29,149 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:38:29,149 - INFO - joeynmt.training - 	Hypothesis: It set of the winter and showing in the some.
2024-05-19 15:38:29,150 - INFO - joeynmt.training - Example #4
2024-05-19 15:38:29,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:38:29,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:38:29,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'of', 'the', 's@@', 'ame', 'is', 'a', 'stor@@', 'e', 'of', 'the', 's@@', 'ame', 'stor@@', 'e', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'a@@', 'go@@', '.', '</s>']
2024-05-19 15:38:29,151 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:38:29,151 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:38:29,152 - INFO - joeynmt.training - 	Hypothesis: The next of the same is a store of the same store of what the last 25 years ago.
2024-05-19 15:38:33,151 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     1.867906, Batch Acc: 0.435381, Tokens per Sec:    17950, Lr: 0.000300
2024-05-19 15:38:36,394 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     1.895286, Batch Acc: 0.438704, Tokens per Sec:    23477, Lr: 0.000300
2024-05-19 15:38:39,840 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     1.978727, Batch Acc: 0.436412, Tokens per Sec:    22056, Lr: 0.000300
2024-05-19 15:38:43,973 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     1.744533, Batch Acc: 0.443326, Tokens per Sec:    18581, Lr: 0.000300
2024-05-19 15:38:47,878 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     2.060211, Batch Acc: 0.446258, Tokens per Sec:    19691, Lr: 0.000300
2024-05-19 15:38:47,879 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:38:47,885 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:39:02,980 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:39:02,981 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   6.23, loss:   1.99, ppl:   7.31, acc:   0.40, generation: 14.8939[sec], evaluation: 0.1826[sec]
2024-05-19 15:39:02,982 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:39:03,210 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/2000.ckpt
2024-05-19 15:39:03,223 - INFO - joeynmt.training - Example #0
2024-05-19 15:39:03,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:39:03,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:39:03,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'year@@', ',', 'I', 'see', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 's', 'to', 't@@', 'on@@', 'es', 'that', 'the', 'l@@', 'is@@', 'h', 'of', 'the', 'l@@', 'ast', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'S@@', ',', 'which', 'was', 'the', 'f@@', 'a@@', 'st@@', 'er', 'of', 'the', 'S@@', ',', 'with', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'with', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'ur@@', 'e', 'of', 'the', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:39:03,225 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:39:03,226 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:39:03,226 - INFO - joeynmt.training - 	Hypothesis: And I was a year, I see these two dia's shows to tones that the lish of the last million years of the last million years of the S, which was the faster of the S, with the United with the United Stature of the States of the U.S.
2024-05-19 15:39:03,226 - INFO - joeynmt.training - Example #1
2024-05-19 15:39:03,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:39:03,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:39:03,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 're@@', 'pro@@', 'b@@', 'ab@@', 'ly', 'the', 'n@@', 'st', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'was', 'not', 'the', 'di@@', 'c@@', 'tion@@', ',', '</s>']
2024-05-19 15:39:03,228 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:39:03,228 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:39:03,228 - INFO - joeynmt.training - 	Hypothesis: But this reprobably the nst of this specific problem because it was not the diction,
2024-05-19 15:39:03,228 - INFO - joeynmt.training - Example #2
2024-05-19 15:39:03,228 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:39:03,229 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:39:03,229 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'r@@', 'ight', 'on', 'the', 'N@@', 'or@@', 'th', 'of', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ed', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ed', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:39:03,229 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:39:03,229 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:39:03,230 - INFO - joeynmt.training - 	Hypothesis: The right on the North of the North is in the clopped in the clopped of our global system.
2024-05-19 15:39:03,230 - INFO - joeynmt.training - Example #3
2024-05-19 15:39:03,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:39:03,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:39:03,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 's@@', 'he', 'c@@', 'ri@@', 'mp@@', 't', 'in', 'the', 's@@', 'om@@', 'e.', '</s>']
2024-05-19 15:39:03,231 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:39:03,231 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:39:03,231 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and she crimpt in the some.
2024-05-19 15:39:03,231 - INFO - joeynmt.training - Example #4
2024-05-19 15:39:03,232 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:39:03,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:39:03,232 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'that', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'a', 'stor@@', 'e', 'of', 'what', 'I', 'was', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'a@@', 'go@@', '.', '</s>']
2024-05-19 15:39:03,232 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:39:03,233 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:39:03,233 - INFO - joeynmt.training - 	Hypothesis: The next that I showed a store of what I was a version of what happened the last 25 years ago.
2024-05-19 15:39:04,290 - INFO - joeynmt.training - Epoch   1: total training loss 10719.41
2024-05-19 15:39:04,291 - INFO - joeynmt.training - EPOCH 2
2024-05-19 15:39:06,417 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.821702, Batch Acc: 0.465472, Tokens per Sec:    24558, Lr: 0.000300
2024-05-19 15:39:09,624 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.679876, Batch Acc: 0.462436, Tokens per Sec:    22907, Lr: 0.000300
2024-05-19 15:39:14,138 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.730813, Batch Acc: 0.465057, Tokens per Sec:    17060, Lr: 0.000300
2024-05-19 15:39:17,586 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.729011, Batch Acc: 0.463920, Tokens per Sec:    22710, Lr: 0.000300
2024-05-19 15:39:20,737 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.717842, Batch Acc: 0.472494, Tokens per Sec:    24145, Lr: 0.000300
2024-05-19 15:39:20,738 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:39:20,738 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:39:37,002 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:39:37,003 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   6.69, loss:   1.96, ppl:   7.11, acc:   0.41, generation: 16.0676[sec], evaluation: 0.1772[sec]
2024-05-19 15:39:37,004 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:39:37,218 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/2500.ckpt
2024-05-19 15:39:37,234 - INFO - joeynmt.training - Example #0
2024-05-19 15:39:37,234 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:39:37,235 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:39:37,235 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 's', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 's', 'that', 'the', 'p@@', 'oo@@', 'l@@', 's', 'the', 'p@@', 'oo@@', 'l@@', 's', 'of', 'the', 'l@@', 'is@@', 'h', 'years', 'a@@', 'go@@', ',', 'the', 'l@@', 'ast', 'mil@@', 'li@@', 'on', 'years', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'S@@', 'S@@', ',', 'with', '4@@', '0@@', '0@@', '0@@', '0@@', '-@@', 'c@@', 'ro@@', 'p@@', 's.', '</s>']
2024-05-19 15:39:37,235 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:39:37,236 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:39:37,236 - INFO - joeynmt.training - 	Hypothesis: And I was a year, I shows these two dia's shows that the pools the pools of the lish years ago, the last million years years of the United States of the SS, with 40000-crops.
2024-05-19 15:39:37,236 - INFO - joeynmt.training - Example #1
2024-05-19 15:39:37,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:39:37,236 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:39:37,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'very', 'sc@@', 're@@', 'e', 'the', 're@@', 's@@', 'our@@', 'ce', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'it', 'is', 'not', 'the', 'di@@', 'c@@', 't', 'of', 'the', 'un@@', 'der@@', 'st@@', 'and', 'se@@', 'e.', '</s>']
2024-05-19 15:39:37,237 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:39:37,237 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:39:37,238 - INFO - joeynmt.training - 	Hypothesis: But this is a very scree the resource of this specific problem because it it is not the dict of the understand see.
2024-05-19 15:39:37,238 - INFO - joeynmt.training - Example #2
2024-05-19 15:39:37,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:39:37,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:39:37,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 's@@', 'k@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'oo@@', 'l', 'is', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ing', 'hi@@', 'p@@', 't', 'of', 'us', 'he@@', 'ar@@', 't', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:39:37,239 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:39:37,239 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:39:37,239 - INFO - joeynmt.training - 	Hypothesis: The skap on the North pool is in the clopping hipt of us heart system.
2024-05-19 15:39:37,240 - INFO - joeynmt.training - Example #3
2024-05-19 15:39:37,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:39:37,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:39:37,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'p@@', 'le', 'in', 'the', 's@@', 'om@@', 'e.', '</s>']
2024-05-19 15:39:37,241 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:39:37,241 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:39:37,241 - INFO - joeynmt.training - 	Hypothesis: It set out in the winter and criple in the some.
2024-05-19 15:39:37,241 - INFO - joeynmt.training - Example #4
2024-05-19 15:39:37,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:39:37,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:39:37,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'een', 'a', 'stor@@', 'y', 'of', 'what', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '</s>']
2024-05-19 15:39:37,242 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:39:37,243 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:39:37,243 - INFO - joeynmt.training - 	Hypothesis: The next dia that I seen a story of what is a version of what happened the last 25 years is happened
2024-05-19 15:39:40,934 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.762035, Batch Acc: 0.472186, Tokens per Sec:    19087, Lr: 0.000300
2024-05-19 15:39:44,839 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.687985, Batch Acc: 0.472675, Tokens per Sec:    19905, Lr: 0.000300
2024-05-19 15:39:47,990 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.806174, Batch Acc: 0.475136, Tokens per Sec:    23685, Lr: 0.000300
2024-05-19 15:39:51,142 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.758184, Batch Acc: 0.475655, Tokens per Sec:    23549, Lr: 0.000300
2024-05-19 15:39:54,785 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     1.682883, Batch Acc: 0.478592, Tokens per Sec:    21104, Lr: 0.000300
2024-05-19 15:39:54,786 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:39:54,786 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:40:11,859 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:40:11,859 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   6.53, loss:   1.92, ppl:   6.83, acc:   0.42, generation: 16.6907[sec], evaluation: 0.3449[sec]
2024-05-19 15:40:11,860 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:40:12,158 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/3000.ckpt
2024-05-19 15:40:12,184 - INFO - joeynmt.training - Example #0
2024-05-19 15:40:12,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:40:12,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:40:12,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'ye@@', 'ar', 'I', 'was', 'a', 'two', 'di@@', 'a@@', "'s", 'to', 's@@', 'ho@@', 'w@@', 's', 'that', 'the', 'p@@', 'oo@@', 'l@@', 's', 'the', 'p@@', 'oo@@', 'l@@', 's', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'a@@', 'go@@', ',', 'the', 'f@@', 'a@@', 'st@@', 'er', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'S@@', '.', '</s>']
2024-05-19 15:40:12,186 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:40:12,186 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:40:12,186 - INFO - joeynmt.training - 	Hypothesis: And I was a year I was a two dia's to shows that the pools the pools the last three million years ago, the faster of the U.S. S.
2024-05-19 15:40:12,186 - INFO - joeynmt.training - Example #1
2024-05-19 15:40:12,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:40:12,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:40:12,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 're@@', 'pre@@', 's@@', 'si@@', 'on', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', "it's", 'not', 'the', 'di@@', 'c@@', 'tion@@', ',', 'because', 'it', "don't", 'the', 'di@@', 'c@@', 'tion@@', '.', '</s>']
2024-05-19 15:40:12,188 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:40:12,188 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:40:12,188 - INFO - joeynmt.training - 	Hypothesis: But this repression of this specific problem because it's not the diction, because it don't the diction.
2024-05-19 15:40:12,188 - INFO - joeynmt.training - Example #2
2024-05-19 15:40:12,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:40:12,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:40:12,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 's@@', 'k@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'oo@@', 'l', 'is', 'in', 'a', 'c@@', 'l@@', 'op@@', 'p@@', 'en@@', 'ter', 'of', 'us', 'har@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:40:12,189 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:40:12,190 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:40:12,190 - INFO - joeynmt.training - 	Hypothesis: The skap on the North pool is in a cloppenter of us hart of our global system.
2024-05-19 15:40:12,190 - INFO - joeynmt.training - Example #3
2024-05-19 15:40:12,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:40:12,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:40:12,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'm@@', 'b@@', 'er', 'and', 'c@@', 'ri@@', 'm@@', 'ber@@', '.', '</s>']
2024-05-19 15:40:12,191 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:40:12,192 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:40:12,192 - INFO - joeynmt.training - 	Hypothesis: It set out in the winter and crimber and crimber.
2024-05-19 15:40:12,192 - INFO - joeynmt.training - Example #4
2024-05-19 15:40:12,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:40:12,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:40:12,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'b@@', 'as@@', 'ic@@', 'ally', 'the', 'c@@', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'a', '2@@', '5', 'years', 'is', 'going', 'to', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:40:12,193 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:40:12,193 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:40:12,194 - INFO - joeynmt.training - 	Hypothesis: And the next dia that I showed is a basically the clast 25 years is a 25 years is going to happened.
2024-05-19 15:40:15,495 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     1.895113, Batch Acc: 0.479501, Tokens per Sec:    21058, Lr: 0.000300
2024-05-19 15:40:18,758 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     1.784912, Batch Acc: 0.481299, Tokens per Sec:    23792, Lr: 0.000300
2024-05-19 15:40:22,054 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     1.702448, Batch Acc: 0.484329, Tokens per Sec:    23093, Lr: 0.000300
2024-05-19 15:40:26,309 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     1.716442, Batch Acc: 0.486595, Tokens per Sec:    18076, Lr: 0.000300
2024-05-19 15:40:29,538 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.723363, Batch Acc: 0.490217, Tokens per Sec:    24131, Lr: 0.000300
2024-05-19 15:40:29,539 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:40:29,539 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:40:44,263 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:40:44,263 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   7.87, loss:   1.88, ppl:   6.58, acc:   0.43, generation: 14.5268[sec], evaluation: 0.1799[sec]
2024-05-19 15:40:44,264 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:40:44,472 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/3500.ckpt
2024-05-19 15:40:44,483 - INFO - joeynmt.training - Example #0
2024-05-19 15:40:44,484 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:40:44,484 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:40:44,485 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'ye@@', 'ar', 'I', 'was', 'this', 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 'p@@', 'oo@@', 'l@@', 's', 'that', 'the', 'p@@', 'oo@@', 'l@@', 's', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'f@@', 'a@@', 'ir@@', 'ly', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'f@@', 'a@@', 'st@@', 'er', 'of', 'the', 'v@@', 'a@@', 'st@@', 'er', 'of', 'the', 'S@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'p@@', 's', 'c@@', 'ro@@', 'p@@', 's', 'of', 'the', 'f@@', 'ig@@', 'u@@', 're@@', 's.', '</s>']
2024-05-19 15:40:44,485 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:40:44,485 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:40:44,486 - INFO - joeynmt.training - 	Hypothesis: And I was a year I was this two dia's two dia's pools that the pools of the last three million years of the fairly million years of the faster of the vaster of the S, with 40 percent crops crops of the figures.
2024-05-19 15:40:44,486 - INFO - joeynmt.training - Example #1
2024-05-19 15:40:44,486 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:40:44,486 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:40:44,486 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'pro@@', 'b@@', 'ab@@', 'ly', 'the', 're@@', 'al', 'proble@@', 'm', 'because', "it's", 'not', 'the', 'an@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', "it's", 'not', 'the', 'di@@', 'c@@', 'tion', 'of', 'the', 'an@@', 'i@@', 'ma@@', 'g@@', 'in@@', 'e.', '</s>']
2024-05-19 15:40:44,487 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:40:44,487 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:40:44,487 - INFO - joeynmt.training - 	Hypothesis: But this is a probably the real problem because it's not the anific problem because it's not the diction of the animagine.
2024-05-19 15:40:44,487 - INFO - joeynmt.training - Example #2
2024-05-19 15:40:44,488 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:40:44,488 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:40:44,488 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'se@@', 'c@@', 'ur@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'oo@@', 'l', 'is', 'in', 'the', 'c@@', 'l@@', 'ic@@', 'k', 'is', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ed', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:40:44,488 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:40:44,489 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:40:44,489 - INFO - joeynmt.training - 	Hypothesis: The secure on the North pool is in the click is in the clopped of our global system.
2024-05-19 15:40:44,489 - INFO - joeynmt.training - Example #3
2024-05-19 15:40:44,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:40:44,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:40:44,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'like', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'p@@', 't', 'in', 'the', 's@@', 'on@@', 'e.', '</s>']
2024-05-19 15:40:44,490 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:40:44,490 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:40:44,490 - INFO - joeynmt.training - 	Hypothesis: It looks like the winter and cript in the sone.
2024-05-19 15:40:44,490 - INFO - joeynmt.training - Example #4
2024-05-19 15:40:44,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:40:44,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:40:44,491 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 'la@@', 'w', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'a', 'very', 'b@@', 'ir@@', 'd', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'is', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'is', 'a', 'very', 'b@@', 're@@', 'a@@', 'd.', '</s>']
2024-05-19 15:40:44,491 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:40:44,491 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:40:44,492 - INFO - joeynmt.training - 	Hypothesis: The next dia that I law is a version of what the last 25 years is a very bird of what happened in 25 is happened in 25 is a very bread.
2024-05-19 15:40:47,669 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.752903, Batch Acc: 0.494151, Tokens per Sec:    22669, Lr: 0.000300
2024-05-19 15:40:50,928 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     1.700338, Batch Acc: 0.489810, Tokens per Sec:    23453, Lr: 0.000300
2024-05-19 15:40:55,330 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.667256, Batch Acc: 0.490924, Tokens per Sec:    17257, Lr: 0.000300
2024-05-19 15:40:58,606 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.533354, Batch Acc: 0.496512, Tokens per Sec:    23551, Lr: 0.000300
2024-05-19 15:41:01,735 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     1.587175, Batch Acc: 0.498852, Tokens per Sec:    24090, Lr: 0.000300
2024-05-19 15:41:01,735 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:41:01,736 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:41:17,085 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:41:17,085 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   7.92, loss:   1.87, ppl:   6.46, acc:   0.44, generation: 15.1389[sec], evaluation: 0.1911[sec]
2024-05-19 15:41:17,086 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:41:17,298 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/4000.ckpt
2024-05-19 15:41:17,309 - INFO - joeynmt.training - Example #0
2024-05-19 15:41:17,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:41:17,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:41:17,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'these', 'two', 'per@@', 'c@@', 'ent', 'to', 's@@', 'een', 'these', 'two', 'di@@', 'a@@', 's,', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'v@@', 'a@@', 'st@@', 'el@@', 'y', 'of', 'the', 'v@@', 'a@@', 'st@@', 'el@@', 'y', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:41:17,311 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:41:17,311 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:41:17,311 - INFO - joeynmt.training - 	Hypothesis: And I show these two percent to seen these two dias, that the police that the last three million years of the last three million years of the vastely of the vastely of the U.S.
2024-05-19 15:41:17,312 - INFO - joeynmt.training - Example #1
2024-05-19 15:41:17,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:41:17,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:41:17,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'pro@@', 'b@@', 'ab@@', 'ly', 'the', 'way', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'not', 'the', 'di@@', 'c@@', 't', 'of', 'this', 'is', 'not', 'the', 'di@@', 'c@@', 'tion@@', '.', '</s>']
2024-05-19 15:41:17,313 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:41:17,313 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:41:17,313 - INFO - joeynmt.training - 	Hypothesis: But this is probably the way of this specific problem because not the dict of this is not the diction.
2024-05-19 15:41:17,313 - INFO - joeynmt.training - Example #2
2024-05-19 15:41:17,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:41:17,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:41:17,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'qu@@', 'ic@@', 'k@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'a', 'se@@', 'c@@', 'er@@', 'ta@@', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:41:17,314 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:41:17,315 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:41:17,315 - INFO - joeynmt.training - 	Hypothesis: The quickap on the North is in a secertain the clopping heart of our global climate system.
2024-05-19 15:41:17,315 - INFO - joeynmt.training - Example #3
2024-05-19 15:41:17,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:41:17,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:41:17,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'oo@@', 'm', 'in', 'the', 's@@', 'o@@', '.', '</s>']
2024-05-19 15:41:17,316 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:41:17,316 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:41:17,316 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and croom in the so.
2024-05-19 15:41:17,316 - INFO - joeynmt.training - Example #4
2024-05-19 15:41:17,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:41:17,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:41:17,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'een', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'is', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:41:17,317 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:41:17,318 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:41:17,318 - INFO - joeynmt.training - 	Hypothesis: The next dia that I seen is a version of what the last 25 years of what happened the last 25 years of the last 25 years of the last 25 is happened.
2024-05-19 15:41:20,973 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     1.670647, Batch Acc: 0.492858, Tokens per Sec:    19631, Lr: 0.000300
2024-05-19 15:41:24,943 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     1.629260, Batch Acc: 0.496816, Tokens per Sec:    18520, Lr: 0.000300
2024-05-19 15:41:28,161 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.671727, Batch Acc: 0.503724, Tokens per Sec:    23454, Lr: 0.000300
2024-05-19 15:41:31,315 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     1.606237, Batch Acc: 0.500610, Tokens per Sec:    23910, Lr: 0.000300
2024-05-19 15:41:35,059 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     1.497680, Batch Acc: 0.511897, Tokens per Sec:    20143, Lr: 0.000300
2024-05-19 15:41:35,060 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:41:35,060 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:41:49,856 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:41:49,856 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   7.92, loss:   1.84, ppl:   6.28, acc:   0.45, generation: 14.4415[sec], evaluation: 0.3213[sec]
2024-05-19 15:41:49,858 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:41:50,124 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/4500.ckpt
2024-05-19 15:41:50,143 - INFO - joeynmt.training - Example #0
2024-05-19 15:41:50,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:41:50,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:41:50,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'this', 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 'to', 's@@', 'ho@@', 'w@@', 's', 'that', 'the', 'p@@', 'oo@@', 'l@@', 's', 'that', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 'the', 'b@@', 'ig@@', 'h', 'mil@@', 'li@@', 'on', 'years', 'to', 'the', 'b@@', 'ig@@', 'h', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'was', '4@@', '0@@', '-@@', 'f@@', 'a@@', 'st@@', 'er', 'to', 'a', 'f@@', 'a@@', 'st@@', 'er', 'the', 'c@@', 'u@@', 'p@@', '.', '</s>']
2024-05-19 15:41:50,146 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:41:50,146 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:41:50,146 - INFO - joeynmt.training - 	Hypothesis: And I show this two dia's two dia's to shows that the pools that the past three million years to the bigh million years to the bigh of the United States of the United States was 40-faster to a faster the cup.
2024-05-19 15:41:50,146 - INFO - joeynmt.training - Example #1
2024-05-19 15:41:50,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:41:50,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:41:50,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'por@@', 't', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'c@@', 'es@@', 's@@', 'ar@@', 'y', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'see', 'the', 'an@@', 'y', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'proble@@', 'm', 'is', 'not', 'the', 'di@@', 'c@@', 'es@@', 's.', '</s>']
2024-05-19 15:41:50,148 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:41:50,148 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:41:50,148 - INFO - joeynmt.training - 	Hypothesis: But this is actually the report of this specific problem because it doesn't the dicessary problem because it doesn't see the any the ice of the ice problem is not the dicess.
2024-05-19 15:41:50,148 - INFO - joeynmt.training - Example #2
2024-05-19 15:41:50,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:41:50,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:41:50,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'is', 'the', 'N@@', 'or@@', 'th', 'of', 'the', 'N@@', 'or@@', 'th', 'p@@', 'oo@@', 'l', 'is', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ed', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:41:50,149 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:41:50,150 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:41:50,150 - INFO - joeynmt.training - 	Hypothesis: The ice is the North of the North pool is in the clopped heart of our global climate system.
2024-05-19 15:41:50,150 - INFO - joeynmt.training - Example #3
2024-05-19 15:41:50,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:41:50,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:41:50,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'm@@', 'pl@@', 'y', 'in', 'the', 's@@', 'om@@', 'er.', '</s>']
2024-05-19 15:41:50,151 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:41:50,151 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:41:50,151 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crimply in the somer.
2024-05-19 15:41:50,152 - INFO - joeynmt.training - Example #4
2024-05-19 15:41:50,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:41:50,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:41:50,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'di@@', 'a', 'that', 'I', 's@@', 'how', 'is', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', '2@@', '5', 'years', 'is', '2@@', '5', 'years', 'is', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ing.', '</s>']
2024-05-19 15:41:50,153 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:41:50,153 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:41:50,153 - INFO - joeynmt.training - 	Hypothesis: The next dia that I showed dia that I show is the last 25 years is 25 years is 25 years is 25 years of what happened happened to happening.
2024-05-19 15:41:53,776 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     1.693361, Batch Acc: 0.503876, Tokens per Sec:    19847, Lr: 0.000300
2024-05-19 15:41:57,050 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     1.657139, Batch Acc: 0.504735, Tokens per Sec:    23262, Lr: 0.000300
2024-05-19 15:42:00,263 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     1.599292, Batch Acc: 0.500454, Tokens per Sec:    23641, Lr: 0.000300
2024-05-19 15:42:04,160 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     1.497768, Batch Acc: 0.509463, Tokens per Sec:    18967, Lr: 0.000300
2024-05-19 15:42:07,853 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     1.849285, Batch Acc: 0.509636, Tokens per Sec:    20701, Lr: 0.000300
2024-05-19 15:42:07,854 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:42:07,854 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:42:22,349 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:42:22,350 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   7.96, loss:   1.82, ppl:   6.15, acc:   0.45, generation: 14.2738[sec], evaluation: 0.2038[sec]
2024-05-19 15:42:22,351 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:42:22,572 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/5000.ckpt
2024-05-19 15:42:22,586 - INFO - joeynmt.training - Example #0
2024-05-19 15:42:22,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:42:22,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:42:22,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'g', 'year@@', ',', 'I', 's@@', 'een', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'een', 'that', 'the', 'l@@', 'ast', 'year@@', 's,', 'that', 'the', 'l@@', 'ast', 'de@@', 'p@@', 'ic@@', 't', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', '1@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'S@@', '.', 'with', '4@@', '0@@', '0@@', '-@@', 'S@@', ',', 'with', '4@@', '0@@', '-@@', 'c@@', 'ro@@', 'm@@', 'b@@', 'er', 'c@@', 'ro@@', 'm@@', 'es.', '</s>']
2024-05-19 15:42:22,589 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:42:22,589 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:42:22,589 - INFO - joeynmt.training - 	Hypothesis: Forig year, I seen this two dia's seen that the last years, that the last depict of the last three million years of the last 10 percent of the U.S. S. with 400-S, with 40-cromber cromes.
2024-05-19 15:42:22,589 - INFO - joeynmt.training - Example #1
2024-05-19 15:42:22,590 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:42:22,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:42:22,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 're@@', 'pre@@', 's@@', 'ent', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'the', 'an@@', 'i@@', 'ma@@', 'g@@', 'ine', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', "it's", 'not', 'the', 'di@@', 'c@@', 'at@@', 'e.', '</s>']
2024-05-19 15:42:22,591 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:42:22,591 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:42:22,591 - INFO - joeynmt.training - 	Hypothesis: But this represent of this specific problem because it didn't the animagine of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of the ice of this specific problem because it's not the dicate.
2024-05-19 15:42:22,591 - INFO - joeynmt.training - Example #2
2024-05-19 15:42:22,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:42:22,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:42:22,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'is', 'the', 'N@@', 'or@@', 'th', 'of', 'the', 'N@@', 'or@@', 'th', 'p@@', 'oo@@', 'l', 'is', 'in', 'the', 'c@@', 'ap@@', 'e', 'of', 'the', 'c@@', 'l@@', 'ic@@', 'k', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:42:22,592 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:42:22,592 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:42:22,593 - INFO - joeynmt.training - 	Hypothesis: The ice is the North of the North pool is in the cape of the click of our global system.
2024-05-19 15:42:22,593 - INFO - joeynmt.training - Example #3
2024-05-19 15:42:22,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:42:22,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:42:22,593 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'p@@', 's', 'in', 'the', 's@@', 'k@@', 'y.', '</s>']
2024-05-19 15:42:22,594 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:42:22,594 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:42:22,594 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crips in the sky.
2024-05-19 15:42:22,594 - INFO - joeynmt.training - Example #4
2024-05-19 15:42:22,595 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:42:22,595 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:42:22,595 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'ne@@', 'x@@', 't', 'an@@', 'i@@', 'ma@@', 'g@@', 'ine', 'I', 's@@', 'een', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'be', 'a', 'f@@', 'l@@', 'at@@', 'ing', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:42:22,595 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:42:22,596 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:42:22,596 - INFO - joeynmt.training - 	Hypothesis: And the next animagine I seen a version of what the last 25 years of what happened to 25 years of what happened to happened to 25 years of what happened to happened to 25 years of what happened to be a flating of what happened to show.
2024-05-19 15:42:25,841 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     1.522395, Batch Acc: 0.509187, Tokens per Sec:    22156, Lr: 0.000300
2024-05-19 15:42:29,262 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     1.786622, Batch Acc: 0.512412, Tokens per Sec:    21687, Lr: 0.000300
2024-05-19 15:42:33,664 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     1.639951, Batch Acc: 0.513492, Tokens per Sec:    17393, Lr: 0.000300
2024-05-19 15:42:36,955 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     1.640154, Batch Acc: 0.513313, Tokens per Sec:    23504, Lr: 0.000300
2024-05-19 15:42:40,072 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     1.596465, Batch Acc: 0.511976, Tokens per Sec:    24072, Lr: 0.000300
2024-05-19 15:42:40,073 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:42:40,073 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:42:52,652 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:42:52,653 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   9.04, loss:   1.80, ppl:   6.05, acc:   0.46, generation: 12.3841[sec], evaluation: 0.1772[sec]
2024-05-19 15:42:52,654 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:42:52,880 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/5500.ckpt
2024-05-19 15:42:52,892 - INFO - joeynmt.training - Example #0
2024-05-19 15:42:52,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:42:52,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:42:52,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'g', 'year@@', 's,', 'I', 'see', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 's', 'to', 's@@', 'k@@', 'ap@@', ',', 'which', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'f@@', 'a@@', 'st@@', 'er', 'was', 'about', 'the', 'f@@', 'a@@', 'st@@', 'er', 'of', 'the', 'f@@', 'a@@', 'st@@', 'er', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:42:52,894 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:42:52,894 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:42:52,894 - INFO - joeynmt.training - 	Hypothesis: Forig years, I see this two dia's shows to skap, which the police of the last three million years of the faster was about the faster of the faster of the U.S.
2024-05-19 15:42:52,894 - INFO - joeynmt.training - Example #1
2024-05-19 15:42:52,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:42:52,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:42:52,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'the', 'an@@', 'y', 'proble@@', 'm', 'because', 'it', 'di@@', 'c@@', 'tion@@', '.', '</s>']
2024-05-19 15:42:52,896 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:42:52,896 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:42:52,896 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem of this specific problem because it didn't the any problem because it diction.
2024-05-19 15:42:52,896 - INFO - joeynmt.training - Example #2
2024-05-19 15:42:52,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:42:52,897 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:42:52,897 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'oo@@', 'l@@', 'ing', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'oo@@', 'l', 'is', 'in', 'the', 'c@@', 'l@@', 'as@@', 'on', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:42:52,897 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:42:52,898 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:42:52,898 - INFO - joeynmt.training - 	Hypothesis: The ice cooling on the North pool is in the clason the climate system.
2024-05-19 15:42:52,898 - INFO - joeynmt.training - Example #3
2024-05-19 15:42:52,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:42:52,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:42:52,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'co@@', 'mp@@', 's', 'in', 'the', 'si@@', 'de', 'of', 'the', 'si@@', 'de', '</s>']
2024-05-19 15:42:52,899 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:42:52,899 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:42:52,899 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and comps in the side of the side
2024-05-19 15:42:52,899 - INFO - joeynmt.training - Example #4
2024-05-19 15:42:52,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:42:52,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:42:52,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'ho@@', 'w@@', 's', 'a', 'p@@', 'ut', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'a', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'is', 'a', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ing.', '</s>']
2024-05-19 15:42:52,900 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:42:52,901 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:42:52,901 - INFO - joeynmt.training - 	Hypothesis: The next dia that I shows a put of what the last 25 years is a 25 years of what happened in 25 years is a 25 years of what happening.
2024-05-19 15:42:56,131 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     1.538885, Batch Acc: 0.513737, Tokens per Sec:    21980, Lr: 0.000300
2024-05-19 15:42:59,969 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     1.565491, Batch Acc: 0.515746, Tokens per Sec:    20326, Lr: 0.000300
2024-05-19 15:43:03,854 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     1.477656, Batch Acc: 0.522980, Tokens per Sec:    19891, Lr: 0.000300
2024-05-19 15:43:06,957 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     1.638280, Batch Acc: 0.515833, Tokens per Sec:    24358, Lr: 0.000300
2024-05-19 15:43:10,167 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     1.716759, Batch Acc: 0.518914, Tokens per Sec:    23691, Lr: 0.000300
2024-05-19 15:43:10,167 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:43:10,168 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:43:25,048 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:43:25,048 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   8.65, loss:   1.78, ppl:   5.92, acc:   0.46, generation: 14.6657[sec], evaluation: 0.1965[sec]
2024-05-19 15:43:25,049 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:43:25,263 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/6000.ckpt
2024-05-19 15:43:25,287 - INFO - joeynmt.training - Example #0
2024-05-19 15:43:25,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:43:25,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:43:25,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'of', 'this', 'two', 'di@@', 'a@@', "'s", 'l@@', 'ast', 'year@@', ',', 'I', 'see', 'this', 'two', 'di@@', 'a@@', "'s", 'p@@', 'oo@@', 'l@@', 'ing', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'of', 'the', 'l@@', 'is@@', 't', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'f@@', 'a@@', 'st@@', 'er', 'of', 'the', 'v@@', 'a@@', 'st@@', 'er', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:43:25,289 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:43:25,289 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:43:25,289 - INFO - joeynmt.training - 	Hypothesis: And I think of this two dia's last year, I see this two dia's pooling the police of the list of the last three million years of the faster of the vaster of the U.S.
2024-05-19 15:43:25,289 - INFO - joeynmt.training - Example #1
2024-05-19 15:43:25,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:43:25,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:43:25,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 're@@', 'al', 'proble@@', 'm', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'the', 'di@@', 'c@@', 't', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'have', 'the', 'di@@', 'c@@', 'at@@', 'e.', '</s>']
2024-05-19 15:43:25,290 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:43:25,291 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:43:25,291 - INFO - joeynmt.training - 	Hypothesis: But this is the real problem of this particular problem because it didn't the dict of the ice of the ice of the ice of the ice of the ice of the ice of the ice problem because it didn't have the dicate.
2024-05-19 15:43:25,291 - INFO - joeynmt.training - Example #2
2024-05-19 15:43:25,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:43:25,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:43:25,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'is', 'the', 'N@@', 'or@@', 'th', 'p@@', 'oo@@', 'l', 'is', 'in', 'the', 'c@@', 'er@@', 'ta@@', 'in', 'the', 'c@@', 'ap@@', 'ac@@', 'h', 'he@@', 'ar@@', 't', 'of', 'us', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:43:25,292 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:43:25,292 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:43:25,292 - INFO - joeynmt.training - 	Hypothesis: The ice is the North pool is in the certain the capach heart of us heart of our global system.
2024-05-19 15:43:25,292 - INFO - joeynmt.training - Example #3
2024-05-19 15:43:25,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:43:25,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:43:25,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'at', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'it@@', 'e', 'in', 'the', 'si@@', 'de', 'and', 'c@@', 'r@@', 'it@@', 'y.', '</s>']
2024-05-19 15:43:25,293 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:43:25,294 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:43:25,294 - INFO - joeynmt.training - 	Hypothesis: It looks at the winter and crite in the side and crity.
2024-05-19 15:43:25,294 - INFO - joeynmt.training - Example #4
2024-05-19 15:43:25,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:43:25,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:43:25,295 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'of', 'the', 'ne@@', 'x@@', 't', 'I', 's@@', 'how', 'I', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's,', '</s>']
2024-05-19 15:43:25,295 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:43:25,295 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:43:25,295 - INFO - joeynmt.training - 	Hypothesis: The next of the next I show I is a version of what the last 25 years,
2024-05-19 15:43:29,249 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     1.599850, Batch Acc: 0.520187, Tokens per Sec:    17726, Lr: 0.000300
2024-05-19 15:43:32,959 - INFO - joeynmt.training - Epoch   2, Step:     8700, Batch Loss:     1.369639, Batch Acc: 0.523663, Tokens per Sec:    20229, Lr: 0.000300
2024-05-19 15:43:36,336 - INFO - joeynmt.training - Epoch   2, Step:     8800, Batch Loss:     1.542479, Batch Acc: 0.522770, Tokens per Sec:    21997, Lr: 0.000300
2024-05-19 15:43:39,621 - INFO - joeynmt.training - Epoch   2, Step:     8900, Batch Loss:     1.382931, Batch Acc: 0.530932, Tokens per Sec:    23657, Lr: 0.000300
2024-05-19 15:43:43,593 - INFO - joeynmt.training - Epoch   2, Step:     9000, Batch Loss:     1.544932, Batch Acc: 0.524002, Tokens per Sec:    18342, Lr: 0.000300
2024-05-19 15:43:43,593 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:43:43,594 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:43:59,979 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:43:59,980 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   9.03, loss:   1.76, ppl:   5.83, acc:   0.47, generation: 16.1827[sec], evaluation: 0.1848[sec]
2024-05-19 15:43:59,981 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:44:00,196 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/6500.ckpt
2024-05-19 15:44:00,224 - INFO - joeynmt.training - Example #0
2024-05-19 15:44:00,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:44:00,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:44:00,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'l@@', 'y,', 'l@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 's', 'to', 's@@', 'ho@@', 'w@@', 's', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'of', 's@@', 'k@@', 'ap@@', ',', 'that', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:44:00,226 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:44:00,226 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:44:00,226 - INFO - joeynmt.training - 	Hypothesis: And I ly, last year I shows to shows that the police of skap, that the past three million years of years of the United States of the United States of the U.S.
2024-05-19 15:44:00,227 - INFO - joeynmt.training - Example #1
2024-05-19 15:44:00,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:44:00,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:44:00,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'because', 'it', 'is', 'the', 're@@', 'qu@@', 'i@@', 'p@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'an@@', 'y', 'proble@@', 'm', 'because', 'it', 'di@@', 'd', 'not', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'di@@', 'se@@', 'c@@', 't@@', 's.', '</s>']
2024-05-19 15:44:00,228 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:44:00,228 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:44:00,228 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem because it is the requipic problem because it doesn't the any problem because it did not the ice of the ice of the ice of the ice of the ice of the ice of this specific problem because it disects.
2024-05-19 15:44:00,228 - INFO - joeynmt.training - Example #2
2024-05-19 15:44:00,229 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:44:00,229 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:44:00,229 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'is', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ol@@', 'ic@@', 'e', 'is', 'in', 'the', 'c@@', 'er@@', 'ta@@', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:44:00,229 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:44:00,229 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:44:00,230 - INFO - joeynmt.training - 	Hypothesis: The ice is the North police is in the certain the clopping heart of our global system.
2024-05-19 15:44:00,230 - INFO - joeynmt.training - Example #3
2024-05-19 15:44:00,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:44:00,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:44:00,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'm@@', 'm@@', 'pl@@', 'y', 'in', 'the', 'si@@', 'm@@', 'pl@@', 'y', 'in', 'the', 'si@@', 'm@@', 'pl@@', 'y', 'in', 'the', 's@@', 'om@@', 'er.', '</s>']
2024-05-19 15:44:00,231 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:44:00,231 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:44:00,231 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crimmply in the simply in the simply in the somer.
2024-05-19 15:44:00,231 - INFO - joeynmt.training - Example #4
2024-05-19 15:44:00,232 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:44:00,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:44:00,232 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'de@@', 'p@@', 'ic@@', 'k', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:44:00,233 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:44:00,233 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:44:00,233 - INFO - joeynmt.training - 	Hypothesis: The next dia that I shows is a version of what happened is a depick of what happened in 25 years of what happened.
2024-05-19 15:44:02,355 - INFO - joeynmt.training - Epoch   2: total training loss 7484.32
2024-05-19 15:44:02,355 - INFO - joeynmt.training - EPOCH 3
2024-05-19 15:44:03,497 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.412902, Batch Acc: 0.543327, Tokens per Sec:    23103, Lr: 0.000300
2024-05-19 15:44:06,760 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.482823, Batch Acc: 0.541292, Tokens per Sec:    23577, Lr: 0.000300
2024-05-19 15:44:10,740 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.427379, Batch Acc: 0.541773, Tokens per Sec:    19382, Lr: 0.000300
2024-05-19 15:44:14,597 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     1.374837, Batch Acc: 0.535097, Tokens per Sec:    20124, Lr: 0.000300
2024-05-19 15:44:17,819 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     1.698087, Batch Acc: 0.544124, Tokens per Sec:    23821, Lr: 0.000300
2024-05-19 15:44:17,820 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:44:17,820 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:44:34,654 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:44:34,654 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   9.08, loss:   1.75, ppl:   5.73, acc:   0.47, generation: 16.5847[sec], evaluation: 0.2255[sec]
2024-05-19 15:44:34,655 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:44:34,873 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/7000.ckpt
2024-05-19 15:44:34,886 - INFO - joeynmt.training - Example #0
2024-05-19 15:44:34,886 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:44:34,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:44:34,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'see', 'this', 'two', 'di@@', 'a@@', "'s", 'l@@', 'ast', 'ye@@', 'ar', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'v@@', 'a@@', 'st@@', 'er', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:44:34,888 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:44:34,888 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:44:34,888 - INFO - joeynmt.training - 	Hypothesis: And I see this two dia's last year to show that the police cap, that the police cap, that the last three million years of the vaster of the U.S.
2024-05-19 15:44:34,888 - INFO - joeynmt.training - Example #1
2024-05-19 15:44:34,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:44:34,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:44:34,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'c@@', 'at@@', 'ter@@', 's', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 's@@', 'ho@@', 'w@@', 's', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 's@@', 'ho@@', 'w@@', 's', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 's@@', 'ho@@', 'w@@', 's', 'the', 'way', 'because', 'it', 'is', 'the', 'ex@@', 'tra@@', 'or@@', 'd@@', 'in@@', 'ar@@', 'y', 'proble@@', 'm', 'because', 'it', 'is', 'that', 'it', 'is', 'a', 'di@@', 'c@@', 'at@@', 'e.', '</s>']
2024-05-19 15:44:34,890 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:44:34,890 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:44:34,890 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem of this specific problem because it doesn't the dicatters of the ice of the ice of the ice of the ice of the ice of the ice of this specific problem because it shows of this specific problem because it shows of this specific problem because it shows the way because it is the extraordinary problem because it is that it is a dicate.
2024-05-19 15:44:34,890 - INFO - joeynmt.training - Example #2
2024-05-19 15:44:34,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:44:34,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:44:34,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'able', 'is', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'the', 'c@@', 'er@@', 'ta@@', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:44:34,891 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:44:34,892 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:44:34,892 - INFO - joeynmt.training - 	Hypothesis: The ice capable is on the North Pole, in the certain the clopping heart of our global system.
2024-05-19 15:44:34,892 - INFO - joeynmt.training - Example #3
2024-05-19 15:44:34,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:44:34,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:44:34,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ing', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', '</s>']
2024-05-19 15:44:34,893 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:44:34,893 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:44:34,893 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and cring in the summer in the summer
2024-05-19 15:44:34,893 - INFO - joeynmt.training - Example #4
2024-05-19 15:44:34,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:44:34,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:44:34,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'f@@', 'a@@', 'st@@', '.', '</s>']
2024-05-19 15:44:34,894 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:44:34,895 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:44:34,895 - INFO - joeynmt.training - 	Hypothesis: The next dia I showed is a version of what the last 25 years of what happened in 25 years of what happened to happened to happened to the last 25 years of what happened to showed is a fast.
2024-05-19 15:44:38,498 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     1.435789, Batch Acc: 0.545170, Tokens per Sec:    19951, Lr: 0.000300
2024-05-19 15:44:42,338 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     1.399808, Batch Acc: 0.538510, Tokens per Sec:    19755, Lr: 0.000300
2024-05-19 15:44:45,716 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     1.312099, Batch Acc: 0.546080, Tokens per Sec:    22214, Lr: 0.000300
2024-05-19 15:44:48,974 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.365613, Batch Acc: 0.541359, Tokens per Sec:    23625, Lr: 0.000300
2024-05-19 15:44:52,665 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     1.744861, Batch Acc: 0.548382, Tokens per Sec:    21025, Lr: 0.000300
2024-05-19 15:44:52,666 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:44:52,666 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:45:09,662 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:45:09,663 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   9.10, loss:   1.73, ppl:   5.65, acc:   0.48, generation: 16.7806[sec], evaluation: 0.1965[sec]
2024-05-19 15:45:09,664 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:45:09,878 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/7500.ckpt
2024-05-19 15:45:09,892 - INFO - joeynmt.training - Example #0
2024-05-19 15:45:09,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:45:09,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:45:09,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'about', 'this', 'two', 'di@@', 'a@@', "'s", 'l@@', 'ast', 'ye@@', 'ar', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'l@@', 's', 'the', 'p@@', 'ol@@', 'l@@', 'is@@', 't', 'c@@', 'ap@@', ',', 'who', 'was', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'v@@', 'a@@', 'st@@', 'el@@', 's', 'of', 'the', 'v@@', 'a@@', 'st@@', 'el@@', 'd,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:45:09,894 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:45:09,894 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:45:09,895 - INFO - joeynmt.training - 	Hypothesis: And I think about this two dia's last year to show that the polls the pollist cap, who was the last three million years of the vastels of the vasteld, with 40 percent of the U.S.
2024-05-19 15:45:09,895 - INFO - joeynmt.training - Example #1
2024-05-19 15:45:09,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:45:09,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:45:09,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'because', 'it', 'di@@', 'c@@', "n't", 'the', 'di@@', 'c@@', "n't", 're@@', 'al', 'proble@@', 'm', 'because', 'it', 'di@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'di@@', 'c@@', 'es@@', 's@@', 'ar@@', 'y', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'the', 'di@@', 'c@@', 'at@@', 'e@@', 'd.', '</s>']
2024-05-19 15:45:09,896 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:45:09,896 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:45:09,896 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem because it dicn't the dicn't real problem because it diction of the ice of the ice of the ice of the ice of the ice of the ice of this particular problem because it dicessary of this particular problem because it is not the dicated.
2024-05-19 15:45:09,896 - INFO - joeynmt.training - Example #2
2024-05-19 15:45:09,897 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:45:09,897 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:45:09,897 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'able', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ol@@', 'ic@@', 'e', 'is', 'in', 'the', 'c@@', 'l@@', 'ine', 'of', 'us', 'in', 'the', 'c@@', 'l@@', 'ou@@', 's@@', 'ly', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:45:09,897 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:45:09,898 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:45:09,898 - INFO - joeynmt.training - 	Hypothesis: The ice capable on the North police is in the cline of us in the clously climate system.
2024-05-19 15:45:09,898 - INFO - joeynmt.training - Example #3
2024-05-19 15:45:09,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:45:09,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:45:09,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'it@@', 'e', 'in', 'the', 'c@@', 'om@@', 'er@@', 'er.', '</s>']
2024-05-19 15:45:09,899 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:45:09,899 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:45:09,899 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crite in the comerer.
2024-05-19 15:45:09,899 - INFO - joeynmt.training - Example #4
2024-05-19 15:45:09,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:45:09,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:45:09,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'I', 's@@', 'ho@@', 'w@@', 'ing', 'di@@', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:45:09,900 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:45:09,901 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:45:09,901 - INFO - joeynmt.training - 	Hypothesis: The next dia I showing dia version of what the last 25 years is happened the last 25 years is happened to happened.
2024-05-19 15:45:13,092 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     1.486030, Batch Acc: 0.542847, Tokens per Sec:    22544, Lr: 0.000300
2024-05-19 15:45:16,343 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     1.455269, Batch Acc: 0.535377, Tokens per Sec:    23012, Lr: 0.000300
2024-05-19 15:45:19,811 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.440706, Batch Acc: 0.541452, Tokens per Sec:    21638, Lr: 0.000300
2024-05-19 15:45:23,959 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     1.510306, Batch Acc: 0.544851, Tokens per Sec:    18709, Lr: 0.000300
2024-05-19 15:45:27,107 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.520763, Batch Acc: 0.547217, Tokens per Sec:    24286, Lr: 0.000300
2024-05-19 15:45:27,107 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:45:27,107 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:45:42,140 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:45:42,141 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:   9.58, loss:   1.72, ppl:   5.57, acc:   0.48, generation: 14.8217[sec], evaluation: 0.1838[sec]
2024-05-19 15:45:42,142 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:45:42,356 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/8000.ckpt
2024-05-19 15:45:42,371 - INFO - joeynmt.training - Example #0
2024-05-19 15:45:42,371 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:45:42,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:45:42,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'of', 'the', 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'of', 'the', 'l@@', 'ast', 'ye@@', 'ar', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'alle@@', 'd', 'the', 'l@@', 'ast', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:45:42,372 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:45:42,373 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:45:42,373 - INFO - joeynmt.training - 	Hypothesis: And I think of the two dia's two dia's to show that the police of the last year that the last three million years of years of the last three million of the U.S. with 40 percent of the U.S. with 40 percent called the last 40 percent cent of the U.S.
2024-05-19 15:45:42,373 - INFO - joeynmt.training - Example #1
2024-05-19 15:45:42,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:45:42,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:45:42,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'pre@@', 's@@', 'ent', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'se@@', 'as@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'the', 'di@@', 'se@@', 'as@@', 'e', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'the', 'di@@', 'se@@', 'e.', '</s>']
2024-05-19 15:45:42,374 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:45:42,374 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:45:42,374 - INFO - joeynmt.training - 	Hypothesis: But this is actually the represent of this specific problem because it doesn't the disease of the ice of the ice of the ice of the ice of the ice of the ice of this particular problem because it didn't the disease of this particular problem because it is not the disee.
2024-05-19 15:45:42,375 - INFO - joeynmt.training - Example #2
2024-05-19 15:45:42,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:45:42,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:45:42,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'is', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'the', 'c@@', 'er@@', 'ta@@', 'in', 'the', 'c@@', 'er@@', 'ta@@', 'in', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:45:42,376 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:45:42,376 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:45:42,376 - INFO - joeynmt.training - 	Hypothesis: The ice is on the North Pole, in the certain the certain the clopping heart of our global climate system.
2024-05-19 15:45:42,376 - INFO - joeynmt.training - Example #3
2024-05-19 15:45:42,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:45:42,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:45:42,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'm@@', 'pl@@', 'y', 'in', 'the', 'r@@', 'oo@@', 'm@@', 's.', '</s>']
2024-05-19 15:45:42,377 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:45:42,378 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:45:42,378 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crimply in the rooms.
2024-05-19 15:45:42,378 - INFO - joeynmt.training - Example #4
2024-05-19 15:45:42,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:45:42,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:45:42,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'how', 'I', 's@@', 'how', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', 'ast', '2@@', '5', 'years', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:45:42,379 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:45:42,379 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:45:42,379 - INFO - joeynmt.training - 	Hypothesis: The next dia that I show I show is a version of what the last ast 25 years of what the last 25 years of the last 25 years of what happened in the last 25 years of what happened to happened to happened to happened to happened to show.
2024-05-19 15:45:45,580 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.518768, Batch Acc: 0.551648, Tokens per Sec:    22021, Lr: 0.000300
2024-05-19 15:45:49,288 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     1.441536, Batch Acc: 0.552013, Tokens per Sec:    20176, Lr: 0.000300
2024-05-19 15:45:53,274 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     1.639571, Batch Acc: 0.549435, Tokens per Sec:    19179, Lr: 0.000300
2024-05-19 15:45:56,442 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     1.391264, Batch Acc: 0.546881, Tokens per Sec:    23481, Lr: 0.000300
2024-05-19 15:45:59,577 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     1.411115, Batch Acc: 0.554116, Tokens per Sec:    24208, Lr: 0.000300
2024-05-19 15:45:59,577 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:45:59,577 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:46:13,767 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:46:13,767 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.18, loss:   1.72, ppl:   5.56, acc:   0.48, generation: 13.9838[sec], evaluation: 0.1872[sec]
2024-05-19 15:46:13,768 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:46:13,983 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/8500.ckpt
2024-05-19 15:46:13,997 - INFO - joeynmt.training - Example #0
2024-05-19 15:46:13,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:46:13,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:46:13,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'g', 'year@@', 's,', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'f@@', 'l@@', 'ine', 'that', 'the', 'p@@', 'ol@@', 'l@@', 'y,', 'that', 'the', 'p@@', 'ol@@', 'l@@', 'y,', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:46:13,999 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:46:13,999 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:46:13,999 - INFO - joeynmt.training - 	Hypothesis: Forig years, I showed these two dia's fline that the polly, that the polly, that the last three million years, about the size of the U.S.
2024-05-19 15:46:13,999 - INFO - joeynmt.training - Example #1
2024-05-19 15:46:14,000 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:46:14,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:46:14,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'ex@@', 'c@@', 'ep@@', 't', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'c@@', 't', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:46:14,000 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:46:14,001 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:46:14,001 - INFO - joeynmt.training - 	Hypothesis: But this is actually the except of this particular problem because it doesn't the dict of the ice of the ice of the ice of the ice.
2024-05-19 15:46:14,001 - INFO - joeynmt.training - Example #2
2024-05-19 15:46:14,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:46:14,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:46:14,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'h', 'is', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ol@@', 'ic@@', 'e', 'is', 'in', 'a', 'c@@', 'li@@', 'm@@', 'ate', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:46:14,002 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:46:14,002 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:46:14,002 - INFO - joeynmt.training - 	Hypothesis: The ice capach is the North police is in a climate heart of our global climate system.
2024-05-19 15:46:14,002 - INFO - joeynmt.training - Example #3
2024-05-19 15:46:14,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:46:14,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:46:14,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'm@@', 'b@@', 'er', 'and', 'c@@', 'ri@@', 'm@@', 'pl@@', 'er', 'in', 'the', 'su@@', 'm@@', 'm@@', 'ther@@', 'e.', '</s>']
2024-05-19 15:46:14,003 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:46:14,004 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:46:14,004 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crimber and crimpler in the summthere.
2024-05-19 15:46:14,004 - INFO - joeynmt.training - Example #4
2024-05-19 15:46:14,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:46:14,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:46:14,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'f@@', 'a@@', 'st@@', 'ic@@', ',', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 'the', 'ne@@', 'x@@', 't', 'di@@', 'd', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 15:46:14,005 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:46:14,005 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:46:14,005 - INFO - joeynmt.training - 	Hypothesis: The next dia I showed is a fastic, a version of what the last 25 years of what happened the last 25 years of what happened to happened to the next did version of what the last 25 years.
2024-05-19 15:46:17,770 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     1.536911, Batch Acc: 0.550649, Tokens per Sec:    19491, Lr: 0.000300
2024-05-19 15:46:21,613 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.426053, Batch Acc: 0.550566, Tokens per Sec:    20035, Lr: 0.000300
2024-05-19 15:46:24,965 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     1.557481, Batch Acc: 0.548383, Tokens per Sec:    22484, Lr: 0.000300
2024-05-19 15:46:28,180 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     1.538807, Batch Acc: 0.551292, Tokens per Sec:    23807, Lr: 0.000300
2024-05-19 15:46:31,748 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     1.591126, Batch Acc: 0.550168, Tokens per Sec:    21059, Lr: 0.000300
2024-05-19 15:46:31,748 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:46:31,748 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:46:46,958 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:46:46,958 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.36, loss:   1.70, ppl:   5.49, acc:   0.49, generation: 14.8390[sec], evaluation: 0.3360[sec]
2024-05-19 15:46:46,959 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:46:47,263 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/9000.ckpt
2024-05-19 15:46:47,284 - INFO - joeynmt.training - Example #0
2024-05-19 15:46:47,285 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:46:47,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:46:47,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'think', 'that', 'the', 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'who', 'had', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'which', 'was', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'y', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:46:47,287 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:46:47,287 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:46:47,287 - INFO - joeynmt.training - 	Hypothesis: And I think that the two dia's two dia's shows to show that the police cap, who had the last three million years, which was about the size of the vastany of the U.S, with 40 percent of the United States of the U.S.
2024-05-19 15:46:47,287 - INFO - joeynmt.training - Example #1
2024-05-19 15:46:47,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:46:47,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:46:47,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 're@@', 'as@@', 'on', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'c@@', 'ul@@', 'at@@', 'ing', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e', 'is@@', 'su@@', 'e.', '</s>']
2024-05-19 15:46:47,290 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:46:47,290 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:46:47,290 - INFO - joeynmt.training - 	Hypothesis: But this is the reason of this particular problem because it doesn't the diculating of the ice of ice issue.
2024-05-19 15:46:47,291 - INFO - joeynmt.training - Example #2
2024-05-19 15:46:47,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:46:47,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:46:47,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'of', 'the', 'N@@', 'or@@', 'th', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'is', 'c@@', 'er@@', 'ta@@', 'in', 'the', 'c@@', 'ap@@', 'e', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:46:47,292 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:46:47,292 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:46:47,293 - INFO - joeynmt.training - 	Hypothesis: The ice of the North is in a certain is certain the cape of our global system.
2024-05-19 15:46:47,293 - INFO - joeynmt.training - Example #3
2024-05-19 15:46:47,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:46:47,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:46:47,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'y@@', 'm@@', 'es@@', 's@@', 'ar@@', 'i@@', 'er.', '</s>']
2024-05-19 15:46:47,294 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:46:47,294 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:46:47,298 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crymessarier.
2024-05-19 15:46:47,298 - INFO - joeynmt.training - Example #4
2024-05-19 15:46:47,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:46:47,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:46:47,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 15:46:47,299 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:46:47,299 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:46:47,300 - INFO - joeynmt.training - 	Hypothesis: The next dia that I shows is a version of what the last 25 years is happened in 25 years.
2024-05-19 15:46:50,754 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     1.466787, Batch Acc: 0.552182, Tokens per Sec:    19708, Lr: 0.000300
2024-05-19 15:46:54,120 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     1.363483, Batch Acc: 0.559007, Tokens per Sec:    22337, Lr: 0.000300
2024-05-19 15:46:57,293 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     1.464493, Batch Acc: 0.549852, Tokens per Sec:    23332, Lr: 0.000300
2024-05-19 15:47:01,171 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     1.506760, Batch Acc: 0.549178, Tokens per Sec:    19584, Lr: 0.000300
2024-05-19 15:47:04,798 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     1.615307, Batch Acc: 0.553013, Tokens per Sec:    21204, Lr: 0.000300
2024-05-19 15:47:04,798 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:47:04,798 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:47:19,276 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:47:19,277 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.00, loss:   1.69, ppl:   5.40, acc:   0.49, generation: 14.2759[sec], evaluation: 0.1818[sec]
2024-05-19 15:47:19,277 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:47:19,496 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/9500.ckpt
2024-05-19 15:47:19,511 - INFO - joeynmt.training - Example #0
2024-05-19 15:47:19,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:47:19,512 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:47:19,512 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'this', 'two', 'di@@', 'a@@', "'s", 'l@@', 'ast', 'ye@@', 'ar', 'I', 'see', 'this', 'two', 'di@@', 'a@@', "'s", 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'who', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:47:19,513 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:47:19,513 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:47:19,513 - INFO - joeynmt.training - 	Hypothesis: And I show this two dia's last year I see this two dia's police cap, who the last three million years of years of the U.S.
2024-05-19 15:47:19,514 - INFO - joeynmt.training - Example #1
2024-05-19 15:47:19,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:47:19,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:47:19,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'because', 'the', 're@@', 'qu@@', 'i@@', 'p@@', 'e', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'the', 'di@@', 'c@@', 't', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:47:19,515 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:47:19,515 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:47:19,515 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem because the requipe problem because it didn't the dict of the ice of the ice of the ice.
2024-05-19 15:47:19,515 - INFO - joeynmt.training - Example #2
2024-05-19 15:47:19,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:47:19,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:47:19,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'is', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'is', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'he@@', 'ar@@', 't', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:47:19,516 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:47:19,517 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:47:19,517 - INFO - joeynmt.training - 	Hypothesis: The ice is the North Pole, in a certain is a certain of our global heart system.
2024-05-19 15:47:19,517 - INFO - joeynmt.training - Example #3
2024-05-19 15:47:19,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:47:19,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:47:19,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'it@@', 'or@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'and', 'c@@', 'r@@', 'it@@', 'or@@', '.', '</s>']
2024-05-19 15:47:19,518 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:47:19,518 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:47:19,518 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and critors in the summer and critor.
2024-05-19 15:47:19,518 - INFO - joeynmt.training - Example #4
2024-05-19 15:47:19,519 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:47:19,519 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:47:19,519 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 15:47:19,519 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:47:19,520 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:47:19,520 - INFO - joeynmt.training - 	Hypothesis: The next dia that I showed is a version of what the last 25 is happened 25 is happened 25 is happened 25 is happened 25 years.
2024-05-19 15:47:22,715 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     1.441747, Batch Acc: 0.557281, Tokens per Sec:    22594, Lr: 0.000300
2024-05-19 15:47:25,902 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     1.458363, Batch Acc: 0.556308, Tokens per Sec:    23942, Lr: 0.000300
2024-05-19 15:47:30,182 - INFO - joeynmt.training - Epoch   3, Step:    12300, Batch Loss:     1.293515, Batch Acc: 0.553368, Tokens per Sec:    17531, Lr: 0.000300
2024-05-19 15:47:33,596 - INFO - joeynmt.training - Epoch   3, Step:    12400, Batch Loss:     1.708328, Batch Acc: 0.555187, Tokens per Sec:    23077, Lr: 0.000300
2024-05-19 15:47:36,784 - INFO - joeynmt.training - Epoch   3, Step:    12500, Batch Loss:     1.520530, Batch Acc: 0.555623, Tokens per Sec:    24188, Lr: 0.000300
2024-05-19 15:47:36,785 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:47:36,785 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:47:51,204 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:47:51,205 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.13, loss:   1.68, ppl:   5.36, acc:   0.49, generation: 14.2081[sec], evaluation: 0.1934[sec]
2024-05-19 15:47:51,206 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:47:51,417 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/10000.ckpt
2024-05-19 15:47:51,431 - INFO - joeynmt.training - Example #0
2024-05-19 15:47:51,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:47:51,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:47:51,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'you', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 'ed', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'a@@', 'st@@', 'ic', 'had', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 'es.', '</s>']
2024-05-19 15:47:51,433 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:47:51,433 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:47:51,434 - INFO - joeynmt.training - 	Hypothesis: And I show you this two dia's showed to show that the police cap, which the last three million years of years of the size of the vastic had about the size of the U.S, with 40 percent cromes.
2024-05-19 15:47:51,434 - INFO - joeynmt.training - Example #1
2024-05-19 15:47:51,434 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:47:51,434 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:47:51,434 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'actually', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'the', 'di@@', 'ff@@', 'ic@@', 'i@@', 'p@@', 'e', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'se@@', '.', '</s>']
2024-05-19 15:47:51,435 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:47:51,435 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:47:51,435 - INFO - joeynmt.training - 	Hypothesis: But this is actually actually actually the real problem because it is not the difficipe problem because it doesn't the dise.
2024-05-19 15:47:51,435 - INFO - joeynmt.training - Example #2
2024-05-19 15:47:51,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:47:51,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:47:51,436 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'of', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', 'd', 'is', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ing', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:47:51,436 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:47:51,437 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:47:51,437 - INFO - joeynmt.training - 	Hypothesis: The ice of the North Poled is in a sense of the clopping of our global climate system.
2024-05-19 15:47:51,437 - INFO - joeynmt.training - Example #3
2024-05-19 15:47:51,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:47:51,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:47:51,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'b@@', 'er', 'and', 'c@@', 'ri@@', 'mp@@', 's', 'in', 'the', 'c@@', 'r@@', 'y@@', 'm@@', 'es@@', 's.', '</s>']
2024-05-19 15:47:51,438 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:47:51,438 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:47:51,438 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crimps in the summer and crimps in the summer and crimps in the summber and crimps in the crymess.
2024-05-19 15:47:51,438 - INFO - joeynmt.training - Example #4
2024-05-19 15:47:51,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:47:51,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:47:51,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'how', 'I', 's@@', 'how', 'is', 'a', 'de@@', 'f@@', 'er@@', 't', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 'be', 'happ@@', 'en@@', 'ed', 'to', 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:47:51,440 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:47:51,440 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:47:51,440 - INFO - joeynmt.training - 	Hypothesis: The next dia that I show I show is a defert version of what the last 25 years of what the last 25 years of happened 25 years of happened in 25 years of what the last 25 years of what the last 25 years is happened to be happened to show.
2024-05-19 15:47:54,656 - INFO - joeynmt.training - Epoch   3, Step:    12600, Batch Loss:     1.656107, Batch Acc: 0.557358, Tokens per Sec:    21850, Lr: 0.000300
2024-05-19 15:47:59,055 - INFO - joeynmt.training - Epoch   3, Step:    12700, Batch Loss:     1.530589, Batch Acc: 0.552803, Tokens per Sec:    17484, Lr: 0.000300
2024-05-19 15:48:02,212 - INFO - joeynmt.training - Epoch   3, Step:    12800, Batch Loss:     1.385155, Batch Acc: 0.560377, Tokens per Sec:    23831, Lr: 0.000300
2024-05-19 15:48:05,411 - INFO - joeynmt.training - Epoch   3, Step:    12900, Batch Loss:     1.489506, Batch Acc: 0.565617, Tokens per Sec:    23697, Lr: 0.000300
2024-05-19 15:48:08,559 - INFO - joeynmt.training - Epoch   3, Step:    13000, Batch Loss:     1.397356, Batch Acc: 0.557939, Tokens per Sec:    23453, Lr: 0.000300
2024-05-19 15:48:08,559 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:48:08,560 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:48:22,780 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:48:22,780 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.95, loss:   1.67, ppl:   5.32, acc:   0.49, generation: 14.0216[sec], evaluation: 0.1817[sec]
2024-05-19 15:48:22,781 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:48:23,000 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/10500.ckpt
2024-05-19 15:48:23,015 - INFO - joeynmt.training - Example #0
2024-05-19 15:48:23,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:48:23,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:48:23,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'a', 'ye@@', 'ar', 'I', 's@@', 'how', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', ',', 'with', '4@@', '0@@', '-@@', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 'es.', '</s>']
2024-05-19 15:48:23,017 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:48:23,017 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:48:23,017 - INFO - joeynmt.training - 	Hypothesis: And a year I show these two dia's to show that the police cap, which the past three million years of the size of the size of the United States of the United S, with 40-40 percent cromes.
2024-05-19 15:48:23,018 - INFO - joeynmt.training - Example #1
2024-05-19 15:48:23,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:48:23,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:48:23,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'because', 'it', 'was', 'the', 'n@@', 'ic@@', 'e', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'se@@', 'c@@', 'ting', 'the', 'di@@', 'se@@', 'd.', '</s>']
2024-05-19 15:48:23,019 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:48:23,019 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:48:23,019 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem because it was the nice problem because it doesn't the disecting the dised.
2024-05-19 15:48:23,019 - INFO - joeynmt.training - Example #2
2024-05-19 15:48:23,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:48:23,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:48:23,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'a', 'b@@', 'it', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'the', 'c@@', 'ap@@', 'e', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:48:23,021 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:48:23,021 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:48:23,021 - INFO - joeynmt.training - 	Hypothesis: The ice capita bit on the North Pole, in a certain the cape of our global climate system.
2024-05-19 15:48:23,021 - INFO - joeynmt.training - Example #3
2024-05-19 15:48:23,021 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:48:23,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:48:23,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'and', 'c@@', 'r@@', 'ac@@', 'k@@', 's.', '</s>']
2024-05-19 15:48:23,022 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:48:23,022 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:48:23,022 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crack in the summer in the summer and cracks.
2024-05-19 15:48:23,023 - INFO - joeynmt.training - Example #4
2024-05-19 15:48:23,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:48:23,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:48:23,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'de@@', 'c@@', 'ide@@', 'd', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:48:23,024 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:48:23,024 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:48:23,024 - INFO - joeynmt.training - 	Hypothesis: The next dia I shows is a decided of what the last 25 years is happened the last 25 years is happened to 25 years of what happened the last 25 years is happened to show.
2024-05-19 15:48:27,345 - INFO - joeynmt.training - Epoch   3, Step:    13100, Batch Loss:     1.384035, Batch Acc: 0.565203, Tokens per Sec:    16883, Lr: 0.000300
2024-05-19 15:48:30,734 - INFO - joeynmt.training - Epoch   3, Step:    13200, Batch Loss:     1.515590, Batch Acc: 0.561848, Tokens per Sec:    22788, Lr: 0.000300
2024-05-19 15:48:33,941 - INFO - joeynmt.training - Epoch   3, Step:    13300, Batch Loss:     1.332643, Batch Acc: 0.557518, Tokens per Sec:    23646, Lr: 0.000300
2024-05-19 15:48:37,150 - INFO - joeynmt.training - Epoch   3, Step:    13400, Batch Loss:     1.402663, Batch Acc: 0.564159, Tokens per Sec:    23110, Lr: 0.000300
2024-05-19 15:48:41,519 - INFO - joeynmt.training - Epoch   3, Step:    13500, Batch Loss:     1.267389, Batch Acc: 0.565038, Tokens per Sec:    18153, Lr: 0.000300
2024-05-19 15:48:41,519 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:48:41,520 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:48:56,476 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:48:56,476 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.06, loss:   1.66, ppl:   5.25, acc:   0.50, generation: 14.7526[sec], evaluation: 0.1858[sec]
2024-05-19 15:48:56,477 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:48:56,691 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/11000.ckpt
2024-05-19 15:48:56,706 - INFO - joeynmt.training - Example #0
2024-05-19 15:48:56,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:48:56,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:48:56,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 'ing', 'the', 'p@@', 'ol@@', 'lo@@', 'w', 'of', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'c@@', 'ed', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 15:48:56,708 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:48:56,708 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:48:56,709 - INFO - joeynmt.training - 	Hypothesis: Fore year, I showed these two dia's showing the pollow of the police of the last three million years of the size of the size of the vastanced of the U.S. with 40 percent croms.
2024-05-19 15:48:56,709 - INFO - joeynmt.training - Example #1
2024-05-19 15:48:56,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:48:56,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:48:56,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'actually', 'the', 'ex@@', 'c@@', 'it@@', 'ed', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'c@@', 't@@', 'or@@', '.', '</s>']
2024-05-19 15:48:56,710 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:48:56,710 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:48:56,710 - INFO - joeynmt.training - 	Hypothesis: But this is actually actually the excited of this particular problem because it doesn't the dictor.
2024-05-19 15:48:56,710 - INFO - joeynmt.training - Example #2
2024-05-19 15:48:56,711 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:48:56,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:48:56,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:48:56,712 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:48:56,712 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:48:56,712 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 15:48:56,712 - INFO - joeynmt.training - Example #3
2024-05-19 15:48:56,712 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:48:56,712 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:48:56,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'it@@', 'e', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'al@@', '.', '</s>']
2024-05-19 15:48:56,713 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:48:56,713 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:48:56,713 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crite in the summmits in the summmal.
2024-05-19 15:48:56,714 - INFO - joeynmt.training - Example #4
2024-05-19 15:48:56,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:48:56,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:48:56,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 15:48:56,715 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:48:56,715 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:48:56,715 - INFO - joeynmt.training - 	Hypothesis: The next dia that I showed is a version of what happened is the last 25 years.
2024-05-19 15:48:59,598 - INFO - joeynmt.training - Epoch   3: total training loss 6637.79
2024-05-19 15:48:59,599 - INFO - joeynmt.training - EPOCH 4
2024-05-19 15:48:59,863 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     1.361384, Batch Acc: 0.577393, Tokens per Sec:    23023, Lr: 0.000300
2024-05-19 15:49:03,117 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     1.411936, Batch Acc: 0.580561, Tokens per Sec:    23222, Lr: 0.000300
2024-05-19 15:49:06,870 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     1.329537, Batch Acc: 0.584101, Tokens per Sec:    20725, Lr: 0.000300
2024-05-19 15:49:10,851 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.302602, Batch Acc: 0.575630, Tokens per Sec:    19222, Lr: 0.000300
2024-05-19 15:49:14,071 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.328630, Batch Acc: 0.578000, Tokens per Sec:    23903, Lr: 0.000300
2024-05-19 15:49:14,071 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:49:14,072 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:49:28,922 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:49:28,923 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.53, loss:   1.65, ppl:   5.18, acc:   0.50, generation: 14.6487[sec], evaluation: 0.1841[sec]
2024-05-19 15:49:28,924 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:49:29,166 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/11500.ckpt
2024-05-19 15:49:29,181 - INFO - joeynmt.training - Example #0
2024-05-19 15:49:29,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:49:29,183 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:49:29,183 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'you', 'just', 's@@', 'how', 'these', 'two', 'di@@', 'a@@', "'s", 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 's', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', '</s>']
2024-05-19 15:49:29,184 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:49:29,184 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:49:29,184 - INFO - joeynmt.training - 	Hypothesis: And I show you just show these two dia's to show that the past three million the past three million years of three million years of the size of the United States, with 40 percent of the United States, with 40 percent croms of the United States,
2024-05-19 15:49:29,185 - INFO - joeynmt.training - Example #1
2024-05-19 15:49:29,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:49:29,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:49:29,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'ex@@', 'per@@', 'ien@@', 'ce', 'is', 'the', 're@@', 'qu@@', 'i@@', 're@@', 'd', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'c@@', 't@@', 'or', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:49:29,186 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:49:29,186 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:49:29,187 - INFO - joeynmt.training - 	Hypothesis: But this experience is the required of this particular problem because it doesn't the dictor of the ice of the ice of the ice of the ice of the ice of the ice.
2024-05-19 15:49:29,187 - INFO - joeynmt.training - Example #2
2024-05-19 15:49:29,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:49:29,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:49:29,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'h', 'on', 'the', 'N@@', 'or@@', 'th', 'p@@', 'ol@@', 'ic@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'the', 'c@@', 'op@@', 'p@@', 'ing', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:49:29,188 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:49:29,188 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:49:29,188 - INFO - joeynmt.training - 	Hypothesis: The ice capach on the North police is in a certain the copping of our global climate system.
2024-05-19 15:49:29,189 - INFO - joeynmt.training - Example #3
2024-05-19 15:49:29,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:49:29,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:49:29,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ma@@', 'k@@', 'es', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'ri@@', 'mp@@', 's', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:49:29,190 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:49:29,190 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:49:29,190 - INFO - joeynmt.training - 	Hypothesis: It makes in the winter and crimps in the summer.
2024-05-19 15:49:29,191 - INFO - joeynmt.training - Example #4
2024-05-19 15:49:29,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:49:29,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:49:29,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'ho@@', 'w@@', 's', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'p@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:49:29,192 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:49:29,192 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:49:29,192 - INFO - joeynmt.training - 	Hypothesis: The next shows I shows is a version of what the past 25 years of what happened.
2024-05-19 15:49:32,390 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.223566, Batch Acc: 0.578588, Tokens per Sec:    21656, Lr: 0.000300
2024-05-19 15:49:36,271 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.496379, Batch Acc: 0.578827, Tokens per Sec:    19480, Lr: 0.000300
2024-05-19 15:49:40,123 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     1.338032, Batch Acc: 0.579099, Tokens per Sec:    19146, Lr: 0.000300
2024-05-19 15:49:43,334 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     1.479200, Batch Acc: 0.582031, Tokens per Sec:    23310, Lr: 0.000300
2024-05-19 15:49:46,551 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     1.201892, Batch Acc: 0.577124, Tokens per Sec:    23973, Lr: 0.000300
2024-05-19 15:49:46,551 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:49:46,551 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:50:03,134 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:50:03,135 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  10.78, loss:   1.64, ppl:   5.16, acc:   0.50, generation: 16.2049[sec], evaluation: 0.3418[sec]
2024-05-19 15:50:03,135 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:50:03,389 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/12000.ckpt
2024-05-19 15:50:03,418 - INFO - joeynmt.training - Example #0
2024-05-19 15:50:03,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:50:03,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:50:03,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'you', 'see', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 'ed', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'v@@', 'ast', '1@@', '0', 'per@@', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'f@@', 'i@@', 'x', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 's', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:50:03,421 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:50:03,421 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:50:03,421 - INFO - joeynmt.training - 	Hypothesis: And I show you see these two dia's showed to show that the police cap, that the last three million years of three million years of the vast 10 perpercent of the U.S. with 40 percent fix percent croms of the U.S.
2024-05-19 15:50:03,421 - INFO - joeynmt.training - Example #1
2024-05-19 15:50:03,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:50:03,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:50:03,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'c@@', 't@@', 'or', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:50:03,423 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:50:03,423 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:50:03,423 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem of this particular problem because it doesn't the dictor of the ice of the ice.
2024-05-19 15:50:03,423 - INFO - joeynmt.training - Example #2
2024-05-19 15:50:03,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:50:03,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:50:03,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'wa@@', 'y,', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:50:03,426 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:50:03,427 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:50:03,427 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole, in a sense, in a way, the climate system.
2024-05-19 15:50:03,427 - INFO - joeynmt.training - Example #3
2024-05-19 15:50:03,427 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:50:03,427 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:50:03,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'it@@', 'ic@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'and', 'c@@', 'r@@', 'it@@', 'ic@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'it@@', 'y.', '</s>']
2024-05-19 15:50:03,428 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:50:03,429 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:50:03,429 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and critics in the summer in the summer in the summer and critics in the summity.
2024-05-19 15:50:03,429 - INFO - joeynmt.training - Example #4
2024-05-19 15:50:03,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:50:03,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:50:03,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ed', 'to', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'the', 'l@@', 'ast', 'di@@', 'a', 'of', 'what', 'the', 'l@@', 'ast', 'is', 'a', 'di@@', 'b@@', 'le', 'di@@', 'se@@', 'd.', '</s>']
2024-05-19 15:50:03,430 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:50:03,431 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:50:03,431 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a version of what the last 25 years of what happened the last 25 years of what happened the last 25 years of what happened is happened to the last 25 years of what the last dia of what the last is a dible dised.
2024-05-19 15:50:07,482 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.456301, Batch Acc: 0.576568, Tokens per Sec:    17565, Lr: 0.000300
2024-05-19 15:50:10,804 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.300066, Batch Acc: 0.577343, Tokens per Sec:    22556, Lr: 0.000300
2024-05-19 15:50:14,018 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.478557, Batch Acc: 0.577392, Tokens per Sec:    24567, Lr: 0.000300
2024-05-19 15:50:17,577 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     1.448404, Batch Acc: 0.576279, Tokens per Sec:    20974, Lr: 0.000300
2024-05-19 15:50:21,612 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.342321, Batch Acc: 0.577665, Tokens per Sec:    18488, Lr: 0.000300
2024-05-19 15:50:21,613 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:50:21,613 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:50:37,249 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:50:37,250 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.50, loss:   1.64, ppl:   5.14, acc:   0.50, generation: 15.0091[sec], evaluation: 0.6072[sec]
2024-05-19 15:50:37,251 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:50:37,465 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/12500.ckpt
2024-05-19 15:50:37,495 - INFO - joeynmt.training - Example #0
2024-05-19 15:50:37,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:50:37,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:50:37,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 'ed', 'to', 's@@', 'how', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'f@@', 'a@@', 'st@@', ',', 'in', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 'es.', '</s>']
2024-05-19 15:50:37,497 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:50:37,498 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:50:37,498 - INFO - joeynmt.training - 	Hypothesis: And I showed this two dia's showed to show that the last three million years that the last three million years of the fast, in the size of the U.S, with 40 percent cromes.
2024-05-19 15:50:37,498 - INFO - joeynmt.training - Example #1
2024-05-19 15:50:37,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:50:37,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:50:37,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 's@@', 'our@@', 'c@@', 'es', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'the', 'di@@', 'c@@', 't', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 15:50:37,500 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:50:37,500 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:50:37,500 - INFO - joeynmt.training - 	Hypothesis: But this is actually the resources of this specific problem because it didn't the dict of the ice of the ice of the ice of the ice of the ice of ice.
2024-05-19 15:50:37,500 - INFO - joeynmt.training - Example #2
2024-05-19 15:50:37,501 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:50:37,501 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:50:37,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'the', 'c@@', 'ap@@', 'ac@@', 'h', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:50:37,501 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:50:37,502 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:50:37,502 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole, in a sense, in the capach of our global system.
2024-05-19 15:50:37,502 - INFO - joeynmt.training - Example #3
2024-05-19 15:50:37,502 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:50:37,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:50:37,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'it@@', 'e', 'in', 'the', 'su@@', 'm@@', 'm@@', 'es@@', 's.', '</s>']
2024-05-19 15:50:37,503 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:50:37,503 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:50:37,503 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crite in the summess.
2024-05-19 15:50:37,504 - INFO - joeynmt.training - Example #4
2024-05-19 15:50:37,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:50:37,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:50:37,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'that', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 15:50:37,505 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:50:37,505 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:50:37,505 - INFO - joeynmt.training - 	Hypothesis: The next slide that I shows is a version of what happened the last 25 years.
2024-05-19 15:50:40,680 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.628053, Batch Acc: 0.576327, Tokens per Sec:    22171, Lr: 0.000300
2024-05-19 15:50:43,899 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     1.372966, Batch Acc: 0.574580, Tokens per Sec:    23649, Lr: 0.000300
2024-05-19 15:50:47,898 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.441757, Batch Acc: 0.576685, Tokens per Sec:    19418, Lr: 0.000300
2024-05-19 15:50:51,355 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.258781, Batch Acc: 0.577463, Tokens per Sec:    22093, Lr: 0.000300
2024-05-19 15:50:54,557 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.185920, Batch Acc: 0.585009, Tokens per Sec:    23876, Lr: 0.000300
2024-05-19 15:50:54,557 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:50:54,558 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:51:10,130 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:51:10,131 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.52, loss:   1.63, ppl:   5.11, acc:   0.50, generation: 15.3590[sec], evaluation: 0.1962[sec]
2024-05-19 15:51:10,132 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:51:10,337 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/13000.ckpt
2024-05-19 15:51:10,352 - INFO - joeynmt.training - Example #0
2024-05-19 15:51:10,353 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:51:10,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:51:10,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'these', 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', 'ab@@', 'le@@', ',', 'who', 'was', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'f@@', 'l@@', 'ac@@', 'c@@', 'oun@@', 't@@', 's.', '</s>']
2024-05-19 15:51:10,354 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:51:10,354 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:51:10,354 - INFO - joeynmt.training - 	Hypothesis: And I show these two dia's two dia's to show that the police capable, who was three million years of years of the last three million years of the United S, with 40 percent of the United States flaccounts.
2024-05-19 15:51:10,354 - INFO - joeynmt.training - Example #1
2024-05-19 15:51:10,355 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:51:10,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:51:10,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'is', 'the', 'wor@@', 'st', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'se@@', 'c@@', 't@@', 'or@@', '.', '</s>']
2024-05-19 15:51:10,355 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:51:10,356 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:51:10,356 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem is the worst of this specific problem because it doesn't the disector.
2024-05-19 15:51:10,356 - INFO - joeynmt.training - Example #2
2024-05-19 15:51:10,356 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:51:10,356 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:51:10,357 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:51:10,357 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:51:10,357 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:51:10,357 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole, in a sense, in a sense, heart of our global system.
2024-05-19 15:51:10,357 - INFO - joeynmt.training - Example #3
2024-05-19 15:51:10,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:51:10,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:51:10,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'out', 'of', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:51:10,358 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:51:10,359 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:51:10,359 - INFO - joeynmt.training - 	Hypothesis: It is out of the winter and crack in the summer.
2024-05-19 15:51:10,359 - INFO - joeynmt.training - Example #4
2024-05-19 15:51:10,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:51:10,360 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:51:10,360 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'f@@', 'a@@', 'st@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'ne@@', 'x@@', 't', 'di@@', 'a', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'ne@@', 'x@@', 't', 'di@@', 'a', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'a', 'f@@', 'a@@', 'st@@', 'ed', 'di@@', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'f@@', 'a@@', 'st@@', 'ed', 'di@@', 'a', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'ne@@', 'x@@', 't', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'ne@@', 'x@@', 't', 'di@@', 'a', 'me@@', 'm@@', 'b@@', 'er', 'of', 'what']
2024-05-19 15:51:10,360 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:51:10,360 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:51:10,361 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a fasted version of what the last 25 years of what happened the last 25 years of what happened the last 25 years of what happened the next dia of what happened the next dia of what the last 25 years is a fasted diversion of what happened is a fasted dia of what happened the next of what happened the next dia member of what
2024-05-19 15:51:13,720 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.535579, Batch Acc: 0.582191, Tokens per Sec:    20852, Lr: 0.000300
2024-05-19 15:51:17,767 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     1.348524, Batch Acc: 0.577242, Tokens per Sec:    18692, Lr: 0.000300
2024-05-19 15:51:20,974 - INFO - joeynmt.training - Epoch   4, Step:    15800, Batch Loss:     1.234484, Batch Acc: 0.574998, Tokens per Sec:    23642, Lr: 0.000300
2024-05-19 15:51:24,214 - INFO - joeynmt.training - Epoch   4, Step:    15900, Batch Loss:     1.304140, Batch Acc: 0.574766, Tokens per Sec:    24379, Lr: 0.000300
2024-05-19 15:51:27,487 - INFO - joeynmt.training - Epoch   4, Step:    16000, Batch Loss:     1.305071, Batch Acc: 0.578689, Tokens per Sec:    23399, Lr: 0.000300
2024-05-19 15:51:27,487 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:51:27,487 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:51:40,401 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:51:40,401 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.29, loss:   1.63, ppl:   5.09, acc:   0.51, generation: 12.7238[sec], evaluation: 0.1729[sec]
2024-05-19 15:51:40,402 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:51:40,618 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/13500.ckpt
2024-05-19 15:51:40,645 - INFO - joeynmt.training - Example #0
2024-05-19 15:51:40,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:51:40,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:51:40,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'g', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'this', 'two', 'di@@', 'a@@', "'s", 'l@@', 'ast', 'ye@@', 'ar', 'to', 's@@', 'how', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 'b@@', 'er', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'oun@@', 't', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:51:40,647 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:51:40,647 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:51:40,647 - INFO - joeynmt.training - 	Hypothesis: Forig year, I showed this two dia's last year to show that the last three million years that the last three million years of the United States, with 40 percent cromber of the United States, with 40 percent count of the United States of the United States of the U.S.
2024-05-19 15:51:40,647 - INFO - joeynmt.training - Example #1
2024-05-19 15:51:40,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:51:40,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:51:40,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'pro@@', 'b@@', 'ab@@', 'ly', 'the', 'ex@@', 'c@@', 'ep@@', 't', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'c@@', 't@@', 'or@@', 'y', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:51:40,649 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:51:40,649 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:51:40,649 - INFO - joeynmt.training - 	Hypothesis: But this is a probably the except of this specific problem because it doesn't the dictory of the ice.
2024-05-19 15:51:40,650 - INFO - joeynmt.training - Example #2
2024-05-19 15:51:40,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:51:40,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:51:40,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', '</s>']
2024-05-19 15:51:40,651 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:51:40,651 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:51:40,651 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole, in a sense, in a certain sense,
2024-05-19 15:51:40,651 - INFO - joeynmt.training - Example #3
2024-05-19 15:51:40,651 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:51:40,652 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:51:40,652 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'from', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:51:40,652 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:51:40,653 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:51:40,653 - INFO - joeynmt.training - 	Hypothesis: It is from the winter and crace in the summer.
2024-05-19 15:51:40,653 - INFO - joeynmt.training - Example #4
2024-05-19 15:51:40,653 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:51:40,653 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:51:40,653 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'ho@@', 'w@@', 'ing', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'f@@', 'a@@', 'st@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', '</s>']
2024-05-19 15:51:40,654 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:51:40,654 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:51:40,654 - INFO - joeynmt.training - 	Hypothesis: The next showing I showed is a fasted version of what happened 25 years of what happened 25 years
2024-05-19 15:51:45,125 - INFO - joeynmt.training - Epoch   4, Step:    16100, Batch Loss:     1.442735, Batch Acc: 0.578104, Tokens per Sec:    15833, Lr: 0.000300
2024-05-19 15:51:48,301 - INFO - joeynmt.training - Epoch   4, Step:    16200, Batch Loss:     1.344250, Batch Acc: 0.579710, Tokens per Sec:    23820, Lr: 0.000300
2024-05-19 15:51:51,599 - INFO - joeynmt.training - Epoch   4, Step:    16300, Batch Loss:     1.352596, Batch Acc: 0.581856, Tokens per Sec:    23176, Lr: 0.000300
2024-05-19 15:51:54,733 - INFO - joeynmt.training - Epoch   4, Step:    16400, Batch Loss:     1.458907, Batch Acc: 0.581140, Tokens per Sec:    24134, Lr: 0.000300
2024-05-19 15:51:58,921 - INFO - joeynmt.training - Epoch   4, Step:    16500, Batch Loss:     1.217800, Batch Acc: 0.584156, Tokens per Sec:    18502, Lr: 0.000300
2024-05-19 15:51:58,921 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:51:58,922 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:52:13,887 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:52:13,887 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.81, loss:   1.62, ppl:   5.05, acc:   0.51, generation: 14.7625[sec], evaluation: 0.1848[sec]
2024-05-19 15:52:13,888 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:52:14,109 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/14000.ckpt
2024-05-19 15:52:14,122 - INFO - joeynmt.training - Example #0
2024-05-19 15:52:14,123 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:52:14,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:52:14,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'you', 'this', 'two', 'di@@', 'a@@', "'s", 'l@@', 'ast', 'ye@@', 'ar', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'who', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'which', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 's', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 15:52:14,125 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:52:14,125 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:52:14,125 - INFO - joeynmt.training - 	Hypothesis: And I show you this two dia's last year to show that the police cap, who the last three million years, which the last three million years of the U.S. with 40 percent croms of the U.S. with 40 percent croms.
2024-05-19 15:52:14,125 - INFO - joeynmt.training - Example #1
2024-05-19 15:52:14,126 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:52:14,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:52:14,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'because', 'it', 'is', 'the', 'wor@@', 'st', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e', 'ic@@', 'e.', '</s>']
2024-05-19 15:52:14,127 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:52:14,127 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:52:14,127 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem because it is the worst of this specific problem because it doesn't the ice of the ice of ice ice.
2024-05-19 15:52:14,127 - INFO - joeynmt.training - Example #2
2024-05-19 15:52:14,128 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:52:14,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:52:14,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:52:14,128 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:52:14,129 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:52:14,129 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole, in a certain sense, heart of our global climate system.
2024-05-19 15:52:14,129 - INFO - joeynmt.training - Example #3
2024-05-19 15:52:14,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:52:14,129 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:52:14,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'h', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:52:14,130 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:52:14,130 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:52:14,130 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crach in the summer.
2024-05-19 15:52:14,130 - INFO - joeynmt.training - Example #4
2024-05-19 15:52:14,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:52:14,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:52:14,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'I', 's@@', 'how', 'is', 'a', 'ver@@', 'si@@', 'on', 'is', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:52:14,132 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:52:14,132 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:52:14,132 - INFO - joeynmt.training - 	Hypothesis: The next dia I show is a version is a certain version of what happened the last 25 years is happened.
2024-05-19 15:52:17,376 - INFO - joeynmt.training - Epoch   4, Step:    16600, Batch Loss:     1.337622, Batch Acc: 0.583897, Tokens per Sec:    21744, Lr: 0.000300
2024-05-19 15:52:20,698 - INFO - joeynmt.training - Epoch   4, Step:    16700, Batch Loss:     1.191545, Batch Acc: 0.576236, Tokens per Sec:    22451, Lr: 0.000300
2024-05-19 15:52:24,467 - INFO - joeynmt.training - Epoch   4, Step:    16800, Batch Loss:     1.262513, Batch Acc: 0.579209, Tokens per Sec:    19998, Lr: 0.000300
2024-05-19 15:52:28,368 - INFO - joeynmt.training - Epoch   4, Step:    16900, Batch Loss:     1.295096, Batch Acc: 0.577612, Tokens per Sec:    19522, Lr: 0.000300
2024-05-19 15:52:31,498 - INFO - joeynmt.training - Epoch   4, Step:    17000, Batch Loss:     1.376149, Batch Acc: 0.583580, Tokens per Sec:    24419, Lr: 0.000300
2024-05-19 15:52:31,499 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:52:31,499 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:52:47,025 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:52:47,026 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  11.73, loss:   1.61, ppl:   5.02, acc:   0.51, generation: 15.3200[sec], evaluation: 0.1893[sec]
2024-05-19 15:52:47,027 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:52:47,236 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/14500.ckpt
2024-05-19 15:52:47,252 - INFO - joeynmt.training - Example #0
2024-05-19 15:52:47,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:52:47,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:52:47,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'you', 'two', 'di@@', 'a@@', 's', 'to', 's@@', 'how', 'the', 'p@@', 'ol@@', 'ic@@', 'y', 'to', 's@@', 'how', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'which', 'was', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'ce', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'p@@', 's', 'wa@@', 's.', '</s>']
2024-05-19 15:52:47,253 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:52:47,254 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:52:47,254 - INFO - joeynmt.training - 	Hypothesis: And I show you two dias to show the policy to show the police cap, which the last three million years, which was about the size of the vastance of the U.S. with 40 percent crops was.
2024-05-19 15:52:47,254 - INFO - joeynmt.training - Example #1
2024-05-19 15:52:47,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:52:47,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:52:47,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'all@@', 'y,', 'the', 're@@', 'all@@', 'y,', 'the', 're@@', 'qu@@', 'i@@', 're@@', 's', 'because', 'it', 'di@@', 'd', 'not', 'the', 'di@@', 'c@@', 'at@@', 't@@', 'ac@@', 'k', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e', 'is', 's@@', 'ho@@', 'w@@', 'ing', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:52:47,255 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:52:47,255 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:52:47,255 - INFO - joeynmt.training - 	Hypothesis: But this is actually the really, the really, the requires because it did not the dicattack of the ice of ice is showing the ice.
2024-05-19 15:52:47,256 - INFO - joeynmt.training - Example #2
2024-05-19 15:52:47,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:52:47,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:52:47,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'k@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:52:47,257 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:52:47,257 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:52:47,257 - INFO - joeynmt.training - 	Hypothesis: The ice capackap on the North Pole, in the climate of our global climate system.
2024-05-19 15:52:47,257 - INFO - joeynmt.training - Example #3
2024-05-19 15:52:47,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:52:47,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:52:47,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'y@@', 'm@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'er', 'and', 'c@@', 'r@@', 'y@@', 'm@@', 'al@@', '.', '</s>']
2024-05-19 15:52:47,258 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:52:47,258 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:52:47,259 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and cryms in the summer and crymal.
2024-05-19 15:52:47,259 - INFO - joeynmt.training - Example #4
2024-05-19 15:52:47,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:52:47,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:52:47,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'ho@@', 'w@@', 's', 'I', 's@@', 'how', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:52:47,260 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:52:47,260 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:52:47,260 - INFO - joeynmt.training - 	Hypothesis: The next shows I show is a version of what the last 25 years is happened to the last 25 years is happened to happened.
2024-05-19 15:52:50,549 - INFO - joeynmt.training - Epoch   4, Step:    17100, Batch Loss:     1.525998, Batch Acc: 0.581641, Tokens per Sec:    22043, Lr: 0.000300
2024-05-19 15:52:54,884 - INFO - joeynmt.training - Epoch   4, Step:    17200, Batch Loss:     1.285578, Batch Acc: 0.581373, Tokens per Sec:    17795, Lr: 0.000300
2024-05-19 15:52:58,340 - INFO - joeynmt.training - Epoch   4, Step:    17300, Batch Loss:     1.356164, Batch Acc: 0.586049, Tokens per Sec:    22573, Lr: 0.000300
2024-05-19 15:53:01,495 - INFO - joeynmt.training - Epoch   4, Step:    17400, Batch Loss:     1.262340, Batch Acc: 0.585013, Tokens per Sec:    24127, Lr: 0.000300
2024-05-19 15:53:04,719 - INFO - joeynmt.training - Epoch   4, Step:    17500, Batch Loss:     1.515941, Batch Acc: 0.581014, Tokens per Sec:    23636, Lr: 0.000300
2024-05-19 15:53:04,720 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:53:04,720 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:53:18,572 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:53:18,573 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.24, loss:   1.61, ppl:   5.00, acc:   0.51, generation: 13.6301[sec], evaluation: 0.1946[sec]
2024-05-19 15:53:18,574 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:53:18,802 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/15000.ckpt
2024-05-19 15:53:18,817 - INFO - joeynmt.training - Example #0
2024-05-19 15:53:18,818 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:53:18,818 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:53:18,818 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 'ing', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'was', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'or@@', 'y', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:53:18,819 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:53:18,819 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:53:18,819 - INFO - joeynmt.training - 	Hypothesis: For, I showed these two dia's showing to show that the police cap, which was three million years of the last three million years of the United States of the United States of the United States of the United States of the United States of the United Story of the U.S.
2024-05-19 15:53:18,819 - INFO - joeynmt.training - Example #1
2024-05-19 15:53:18,820 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:53:18,820 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:53:18,820 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'wor@@', 'st', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'the', 'di@@', 'ff@@', 'ic@@', 'ul@@', 't', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:53:18,821 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:53:18,821 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:53:18,821 - INFO - joeynmt.training - 	Hypothesis: But this is actually the worst of this particular problem because it didn't the difficult of the ice.
2024-05-19 15:53:18,821 - INFO - joeynmt.training - Example #2
2024-05-19 15:53:18,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:53:18,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:53:18,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:53:18,822 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:53:18,822 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:53:18,823 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole, in a sense, heart sense, heart of our global climate system.
2024-05-19 15:53:18,823 - INFO - joeynmt.training - Example #3
2024-05-19 15:53:18,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:53:18,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:53:18,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 's.', '</s>']
2024-05-19 15:53:18,824 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:53:18,824 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:53:18,824 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crace in the summms.
2024-05-19 15:53:18,824 - INFO - joeynmt.training - Example #4
2024-05-19 15:53:18,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:53:18,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:53:18,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'of', 'what', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'de@@', 'gre@@', 'e', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 'be', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'is', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'is', 'a', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ed', 'to', 'be', 'a', 'f@@', 'a@@', 'st@@', 'er', 'the', 'ne@@', 'x@@', 't', 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:53:18,826 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:53:18,826 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:53:18,826 - INFO - joeynmt.training - 	Hypothesis: The next slide of what I shows is a degree of what the last 25 years is happened 25 years is happened 25 years is happened to be 25 years is happened is 25 years is happened is a 25 years of what happened is a 25 years of what happened is a 25 years of what happened is a 25 years of what happened is happened is happened to be a faster the next show.
2024-05-19 15:53:22,666 - INFO - joeynmt.training - Epoch   4, Step:    17600, Batch Loss:     1.273453, Batch Acc: 0.582886, Tokens per Sec:    18179, Lr: 0.000300
2024-05-19 15:53:26,335 - INFO - joeynmt.training - Epoch   4, Step:    17700, Batch Loss:     1.132777, Batch Acc: 0.588705, Tokens per Sec:    21091, Lr: 0.000300
2024-05-19 15:53:29,723 - INFO - joeynmt.training - Epoch   4, Step:    17800, Batch Loss:     1.495136, Batch Acc: 0.582688, Tokens per Sec:    22061, Lr: 0.000300
2024-05-19 15:53:32,917 - INFO - joeynmt.training - Epoch   4, Step:    17900, Batch Loss:     1.325274, Batch Acc: 0.580883, Tokens per Sec:    24300, Lr: 0.000300
2024-05-19 15:53:36,809 - INFO - joeynmt.training - Epoch   4, Step:    18000, Batch Loss:     1.409567, Batch Acc: 0.581355, Tokens per Sec:    18759, Lr: 0.000300
2024-05-19 15:53:36,813 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:53:36,813 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:53:50,050 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:53:50,050 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.69, loss:   1.61, ppl:   4.98, acc:   0.51, generation: 12.8807[sec], evaluation: 0.3230[sec]
2024-05-19 15:53:50,051 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:53:50,306 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/15500.ckpt
2024-05-19 15:53:50,331 - INFO - joeynmt.training - Example #0
2024-05-19 15:53:50,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:53:50,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:53:50,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 'w@@', 'ing', 'these', 'two', 'di@@', 'a@@', "'s", 'p@@', 'ol@@', 'l@@', 'is@@', 't', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'is', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'ce', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'ce', 'of', 'the', 'U@@', 'S@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'ly', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:53:50,334 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:53:50,334 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:53:50,334 - INFO - joeynmt.training - 	Hypothesis: And I showed this two dia's showing these two dia's pollist the polar cap, which is three million years of the vastance of the vastance of the US, with 40 percent currently of the U.S.
2024-05-19 15:53:50,335 - INFO - joeynmt.training - Example #1
2024-05-19 15:53:50,335 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:53:50,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:53:50,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'qu@@', 'i@@', 're@@', 's', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:53:50,336 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:53:50,336 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:53:50,337 - INFO - joeynmt.training - 	Hypothesis: But this is actually the requires of this specific problem because it didn't show.
2024-05-19 15:53:50,337 - INFO - joeynmt.training - Example #2
2024-05-19 15:53:50,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:53:50,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:53:50,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'h', 'is', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'ten@@', 'c@@', 'e,', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:53:50,338 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:53:50,338 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:53:50,339 - INFO - joeynmt.training - 	Hypothesis: The ice capach is on the North Pole, in a sentence, heart of our global climate system.
2024-05-19 15:53:50,339 - INFO - joeynmt.training - Example #3
2024-05-19 15:53:50,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:53:50,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:53:50,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'loo@@', 'king', 'at', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:53:50,340 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:53:50,340 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:53:50,340 - INFO - joeynmt.training - 	Hypothesis: It is looking at the winter and crack in the summer.
2024-05-19 15:53:50,342 - INFO - joeynmt.training - Example #4
2024-05-19 15:53:50,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:53:50,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:53:50,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'that', 'I', 's@@', 'how', 'is', 'a', 'di@@', 'a', 'I', 's@@', 'how', 'is', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 'be', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 'be', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 'be', 'a', 'f@@', 'a@@', 'st@@', 'ic@@', 'tu@@', 're@@', '.', '</s>']
2024-05-19 15:53:50,344 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:53:50,344 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:53:50,344 - INFO - joeynmt.training - 	Hypothesis: The next dia that I show is a dia I show is happened in 25 years is happened to 25 years is happened to 25 years is happened to be 25 years is happened to be 25 years is happened to be a fasticture.
2024-05-19 15:53:53,964 - INFO - joeynmt.training - Epoch   4, Step:    18100, Batch Loss:     1.343193, Batch Acc: 0.581617, Tokens per Sec:    19909, Lr: 0.000300
2024-05-19 15:53:54,657 - INFO - joeynmt.training - Epoch   4: total training loss 6190.65
2024-05-19 15:53:54,658 - INFO - joeynmt.training - EPOCH 5
2024-05-19 15:53:57,341 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.342564, Batch Acc: 0.604849, Tokens per Sec:    22681, Lr: 0.000300
2024-05-19 15:54:00,522 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.348502, Batch Acc: 0.600178, Tokens per Sec:    24408, Lr: 0.000300
2024-05-19 15:54:04,290 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.381135, Batch Acc: 0.600888, Tokens per Sec:    20152, Lr: 0.000300
2024-05-19 15:54:07,934 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.193436, Batch Acc: 0.599303, Tokens per Sec:    20871, Lr: 0.000300
2024-05-19 15:54:07,935 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:54:07,935 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:54:21,615 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:54:21,616 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.05, loss:   1.60, ppl:   4.93, acc:   0.52, generation: 13.4671[sec], evaluation: 0.1928[sec]
2024-05-19 15:54:21,617 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:54:21,840 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/16000.ckpt
2024-05-19 15:54:21,854 - INFO - joeynmt.training - Example #0
2024-05-19 15:54:21,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:54:21,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:54:21,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'this', 'two', 'di@@', 'a@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'c@@', 'ap@@', ',', 'which', 'was', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'y', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'y', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'ce', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:54:21,855 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:54:21,856 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:54:21,856 - INFO - joeynmt.training - 	Hypothesis: And I showed this two dias to show that the police cape cap, which was three million years of the size of the vastany of the vastany of the vastance of the U.S.
2024-05-19 15:54:21,856 - INFO - joeynmt.training - Example #1
2024-05-19 15:54:21,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:54:21,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:54:21,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'the', 'di@@', 'c@@', 't', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e', 'is@@', 'he@@', 'd', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 15:54:21,857 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:54:21,857 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:54:21,857 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem of this particular problem because it didn't the dict of the ice of ice ished the ice of ice.
2024-05-19 15:54:21,858 - INFO - joeynmt.training - Example #2
2024-05-19 15:54:21,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:54:21,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:54:21,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'h', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:54:21,859 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:54:21,859 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:54:21,859 - INFO - joeynmt.training - 	Hypothesis: The ice capach is in a certain sense, in a sense of the climate heart of our global climate system.
2024-05-19 15:54:21,859 - INFO - joeynmt.training - Example #3
2024-05-19 15:54:21,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:54:21,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:54:21,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'from', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:54:21,860 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:54:21,861 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:54:21,861 - INFO - joeynmt.training - 	Hypothesis: It is from the winter and crace in the summer.
2024-05-19 15:54:21,861 - INFO - joeynmt.training - Example #4
2024-05-19 15:54:21,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:54:21,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:54:21,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'is', 'a', 'de@@', 'sig@@', 'n', 'I', 's@@', 'how', 'is', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:54:21,862 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:54:21,862 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:54:21,862 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a design I show is the last 25 years is 25 years of what happened the last 25 years is happened 25 years is happened to 25 years is happened.
2024-05-19 15:54:25,083 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.285875, Batch Acc: 0.601162, Tokens per Sec:    21642, Lr: 0.000300
2024-05-19 15:54:28,292 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.224732, Batch Acc: 0.599174, Tokens per Sec:    23084, Lr: 0.000300
2024-05-19 15:54:32,325 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.383100, Batch Acc: 0.596948, Tokens per Sec:    18758, Lr: 0.000300
2024-05-19 15:54:36,032 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.144179, Batch Acc: 0.598732, Tokens per Sec:    20124, Lr: 0.000300
2024-05-19 15:54:39,254 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.415871, Batch Acc: 0.600088, Tokens per Sec:    24077, Lr: 0.000300
2024-05-19 15:54:39,255 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:54:39,255 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:54:54,255 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:54:54,257 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.44, loss:   1.59, ppl:   4.92, acc:   0.52, generation: 14.6126[sec], evaluation: 0.3491[sec]
2024-05-19 15:54:54,258 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:54:54,548 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/16500.ckpt
2024-05-19 15:54:54,575 - INFO - joeynmt.training - Example #0
2024-05-19 15:54:54,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:54:54,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:54:54,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'g', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'who', 'had', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 'be', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:54:54,579 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:54:54,580 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:54:54,581 - INFO - joeynmt.training - 	Hypothesis: Forig year, I showed these two dias to show that the police cap, who had the last three million years to be about the size of the U.S.
2024-05-19 15:54:54,581 - INFO - joeynmt.training - Example #1
2024-05-19 15:54:54,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:54:54,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:54:54,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'all@@', 'y,', 'the', 're@@', 'qu@@', 'i@@', 're@@', 'd', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:54:54,582 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:54:54,582 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:54:54,582 - INFO - joeynmt.training - 	Hypothesis: But this is actually the really, the required of this particular problem because it doesn't show.
2024-05-19 15:54:54,583 - INFO - joeynmt.training - Example #2
2024-05-19 15:54:54,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:54:54,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:54:54,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:54:54,584 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:54:54,584 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:54:54,584 - INFO - joeynmt.training - 	Hypothesis: The ice cap on the North Pole, in a certain sense, the climate heart of our global climate system.
2024-05-19 15:54:54,584 - INFO - joeynmt.training - Example #3
2024-05-19 15:54:54,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:54:54,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:54:54,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'like', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:54:54,587 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:54:54,588 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:54:54,588 - INFO - joeynmt.training - 	Hypothesis: It looks like the winter and crack in the summmer.
2024-05-19 15:54:54,588 - INFO - joeynmt.training - Example #4
2024-05-19 15:54:54,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:54:54,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:54:54,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ed', 'to', 'the', 'p@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'to', 'be', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ed', 'to', 'be', 'happ@@', 'en@@', 'ed', 'to', 'the', 'ne@@', 'x@@', 't', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'is', 'happ@@', 'en@@', 'ed', 'to', 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:54:54,589 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:54:54,590 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:54:54,590 - INFO - joeynmt.training - 	Hypothesis: The next slide, I showed is a version of what happened is happened to the past 25 years is happened to 25 years is happened to be 25 years of what happened is happened to be happened to the next shows is a version of what happens is happened to show.
2024-05-19 15:54:59,136 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.439449, Batch Acc: 0.603059, Tokens per Sec:    15735, Lr: 0.000300
2024-05-19 15:55:03,248 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.385271, Batch Acc: 0.594048, Tokens per Sec:    18057, Lr: 0.000300
2024-05-19 15:55:06,557 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.159769, Batch Acc: 0.600066, Tokens per Sec:    22927, Lr: 0.000300
2024-05-19 15:55:09,692 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.297506, Batch Acc: 0.598910, Tokens per Sec:    24250, Lr: 0.000300
2024-05-19 15:55:13,352 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.296898, Batch Acc: 0.596850, Tokens per Sec:    20508, Lr: 0.000300
2024-05-19 15:55:13,353 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:55:13,353 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:55:29,648 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:55:29,648 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.23, loss:   1.59, ppl:   4.92, acc:   0.52, generation: 15.9034[sec], evaluation: 0.3586[sec]
2024-05-19 15:55:29,651 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:55:29,916 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/17000.ckpt
2024-05-19 15:55:29,952 - INFO - joeynmt.training - Example #0
2024-05-19 15:55:29,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:55:29,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:55:29,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 's@@', 'how', 'this', 'two', 'di@@', 'a@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'and', 'the', 'U@@', '.@@', 'S@@', '.', 'and', 'in', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:55:29,954 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:55:29,954 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:55:29,955 - INFO - joeynmt.training - 	Hypothesis: Last year, I show this two dias to show that the police cap, which the past three million years that the last three million years of the size of the U.S. and the U.S. and in the U.S.
2024-05-19 15:55:29,955 - INFO - joeynmt.training - Example #1
2024-05-19 15:55:29,955 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:55:29,955 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:55:29,955 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'qu@@', 'i@@', 're@@', 's', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'ho@@', 'w@@', 'ed', 'the', 'di@@', 'se@@', 'c@@', 't@@', 'or@@', '.', '</s>']
2024-05-19 15:55:29,956 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:55:29,956 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:55:29,956 - INFO - joeynmt.training - 	Hypothesis: But this is actually the requires of this specific problem because it doesn't showed the disector.
2024-05-19 15:55:29,956 - INFO - joeynmt.training - Example #2
2024-05-19 15:55:29,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:55:29,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:55:29,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'is', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', '</s>']
2024-05-19 15:55:29,958 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:55:29,958 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:55:29,958 - INFO - joeynmt.training - 	Hypothesis: The ice capacity is on the North Pole, in a certain sense,
2024-05-19 15:55:29,958 - INFO - joeynmt.training - Example #3
2024-05-19 15:55:29,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:55:29,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:55:29,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:55:29,960 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:55:29,960 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:55:29,960 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crack in the summer.
2024-05-19 15:55:29,960 - INFO - joeynmt.training - Example #4
2024-05-19 15:55:29,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:55:29,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:55:29,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', ',', 'I', 'le@@', 'a@@', 've', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'ne@@', 'x@@', 't', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'f@@', 'a@@', 'st@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'f@@', 'a@@', 'st@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:55:29,961 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:55:29,961 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:55:29,961 - INFO - joeynmt.training - 	Hypothesis: The next slide, I leave is a version of what happened is 25 years of what happened 25 years of what happened 25 years of what happened the next 25 years of what happened is a fasted version of what happened is a fasted version of what happened is happened.
2024-05-19 15:55:34,029 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.523355, Batch Acc: 0.594877, Tokens per Sec:    16949, Lr: 0.000300
2024-05-19 15:55:37,222 - INFO - joeynmt.training - Epoch   5, Step:    19700, Batch Loss:     1.272623, Batch Acc: 0.600086, Tokens per Sec:    24010, Lr: 0.000300
2024-05-19 15:55:40,557 - INFO - joeynmt.training - Epoch   5, Step:    19800, Batch Loss:     1.127868, Batch Acc: 0.600212, Tokens per Sec:    22623, Lr: 0.000300
2024-05-19 15:55:44,537 - INFO - joeynmt.training - Epoch   5, Step:    19900, Batch Loss:     1.319847, Batch Acc: 0.595237, Tokens per Sec:    19297, Lr: 0.000300
2024-05-19 15:55:48,269 - INFO - joeynmt.training - Epoch   5, Step:    20000, Batch Loss:     1.454182, Batch Acc: 0.597701, Tokens per Sec:    20378, Lr: 0.000300
2024-05-19 15:55:48,269 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:55:48,270 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:56:03,172 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:56:03,173 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.48, loss:   1.58, ppl:   4.87, acc:   0.52, generation: 14.6583[sec], evaluation: 0.2168[sec]
2024-05-19 15:56:03,174 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:56:03,390 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/17500.ckpt
2024-05-19 15:56:03,404 - INFO - joeynmt.training - Example #0
2024-05-19 15:56:03,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:56:03,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:56:03,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'you', 'that', 'the', 'two', 'di@@', 'a@@', "'s", 'two', 'di@@', 'a@@', "'s", 'l@@', 'ic@@', 'i@@', 'an', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'ce', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '.', 'S@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:56:03,406 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:56:03,406 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:56:03,406 - INFO - joeynmt.training - 	Hypothesis: And I show you that the two dia's two dia's lician to show that the police of the last three million years of the size of the vastance of the U.S. . S, with 40 percent of the U.S.
2024-05-19 15:56:03,407 - INFO - joeynmt.training - Example #1
2024-05-19 15:56:03,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:56:03,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:56:03,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'se@@', 'm@@', 'b@@', 'le', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 15:56:03,408 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:56:03,408 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:56:03,409 - INFO - joeynmt.training - 	Hypothesis: But this is actually the resemble of this specific problem because it didn't show.
2024-05-19 15:56:03,409 - INFO - joeynmt.training - Example #2
2024-05-19 15:56:03,409 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:56:03,409 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:56:03,409 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:56:03,410 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:56:03,410 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:56:03,410 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole is in a sense, in a sense, heart of our global heart of our global climate system.
2024-05-19 15:56:03,411 - INFO - joeynmt.training - Example #3
2024-05-19 15:56:03,411 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:56:03,411 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:56:03,411 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'y@@', 'm@@', 's', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:56:03,412 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:56:03,412 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:56:03,412 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and cryms in the summer.
2024-05-19 15:56:03,412 - INFO - joeynmt.training - Example #4
2024-05-19 15:56:03,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:56:03,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:56:03,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'of', 'what', 'is', 'a', 'di@@', 'c@@', 'at@@', 'te@@', 'mp@@', 't', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', '</s>']
2024-05-19 15:56:03,413 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:56:03,414 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:56:03,414 - INFO - joeynmt.training - 	Hypothesis: The next slide of what is a dicattempt of what happened the last 25 years is happened 25 years of what happened 25 years of what happened
2024-05-19 15:56:06,772 - INFO - joeynmt.training - Epoch   5, Step:    20100, Batch Loss:     1.452063, Batch Acc: 0.600695, Tokens per Sec:    21195, Lr: 0.000300
2024-05-19 15:56:10,212 - INFO - joeynmt.training - Epoch   5, Step:    20200, Batch Loss:     1.285566, Batch Acc: 0.596150, Tokens per Sec:    22165, Lr: 0.000300
2024-05-19 15:56:14,503 - INFO - joeynmt.training - Epoch   5, Step:    20300, Batch Loss:     1.392615, Batch Acc: 0.598289, Tokens per Sec:    18306, Lr: 0.000300
2024-05-19 15:56:17,870 - INFO - joeynmt.training - Epoch   5, Step:    20400, Batch Loss:     1.647473, Batch Acc: 0.601531, Tokens per Sec:    22624, Lr: 0.000300
2024-05-19 15:56:21,148 - INFO - joeynmt.training - Epoch   5, Step:    20500, Batch Loss:     1.343408, Batch Acc: 0.596523, Tokens per Sec:    23747, Lr: 0.000300
2024-05-19 15:56:21,148 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:56:21,148 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:56:35,012 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:56:35,012 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.79, loss:   1.59, ppl:   4.89, acc:   0.52, generation: 13.6178[sec], evaluation: 0.2253[sec]
2024-05-19 15:56:35,231 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/18000.ckpt
2024-05-19 15:56:35,247 - INFO - joeynmt.training - Example #0
2024-05-19 15:56:35,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:56:35,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:56:35,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', "'s", 'l@@', 'ast', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'that', 'the', 'l@@', 'ast', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'was', 'about', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 's.', '</s>']
2024-05-19 15:56:35,249 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:56:35,249 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:56:35,250 - INFO - joeynmt.training - 	Hypothesis: And I showed these two dia's last year, I showed that the last police cap, that the last three million years of the United States of the United States was about 40 percent currents.
2024-05-19 15:56:35,250 - INFO - joeynmt.training - Example #1
2024-05-19 15:56:35,250 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:56:35,250 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:56:35,250 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'qu@@', 'i@@', 're@@', 'd', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'di@@', 'd', 'not', 'the', 'di@@', 'se@@', 'c@@', 't@@', 'or@@', 'y', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e', 'is', 'not', 's@@', 'ho@@', 'w@@', 'ing', 'the', 'di@@', 'se@@', '.', '</s>']
2024-05-19 15:56:35,251 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:56:35,251 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:56:35,252 - INFO - joeynmt.training - 	Hypothesis: But this is actually the required of this particular problem because it did not the disectory of the ice of ice is not showing the dise.
2024-05-19 15:56:35,252 - INFO - joeynmt.training - Example #2
2024-05-19 15:56:35,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:56:35,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:56:35,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'h', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'c@@', 'l@@', 'as@@', 's@@', 'ul@@', 'ar@@', 'ly', 'c@@', 'li@@', 'm@@', 'ate', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:56:35,253 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:56:35,253 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:56:35,254 - INFO - joeynmt.training - 	Hypothesis: The ice capach is in a certain classularly climate heart of our global climate system.
2024-05-19 15:56:35,254 - INFO - joeynmt.training - Example #3
2024-05-19 15:56:35,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:56:35,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:56:35,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:56:35,255 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:56:35,255 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:56:35,255 - INFO - joeynmt.training - 	Hypothesis: It in the winter and crack in the summer.
2024-05-19 15:56:35,255 - INFO - joeynmt.training - Example #4
2024-05-19 15:56:35,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:56:35,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:56:35,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'sp@@', 'e@@', 'e@@', 'ding', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 15:56:35,257 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:56:35,257 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:56:35,257 - INFO - joeynmt.training - 	Hypothesis: The next slide, I showed is a speeding version of what the last 25 years is happened 25 years is happened in 25 years happened in the next slide.
2024-05-19 15:56:38,564 - INFO - joeynmt.training - Epoch   5, Step:    20600, Batch Loss:     1.235170, Batch Acc: 0.599190, Tokens per Sec:    22236, Lr: 0.000300
2024-05-19 15:56:42,709 - INFO - joeynmt.training - Epoch   5, Step:    20700, Batch Loss:     1.354865, Batch Acc: 0.599195, Tokens per Sec:    18397, Lr: 0.000300
2024-05-19 15:56:46,585 - INFO - joeynmt.training - Epoch   5, Step:    20800, Batch Loss:     1.324961, Batch Acc: 0.601491, Tokens per Sec:    19834, Lr: 0.000300
2024-05-19 15:56:49,878 - INFO - joeynmt.training - Epoch   5, Step:    20900, Batch Loss:     1.168275, Batch Acc: 0.598788, Tokens per Sec:    23219, Lr: 0.000300
2024-05-19 15:56:53,213 - INFO - joeynmt.training - Epoch   5, Step:    21000, Batch Loss:     1.291452, Batch Acc: 0.599354, Tokens per Sec:    22551, Lr: 0.000300
2024-05-19 15:56:53,214 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:56:53,214 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:57:07,628 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:57:07,628 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.74, loss:   1.58, ppl:   4.83, acc:   0.52, generation: 14.1998[sec], evaluation: 0.1954[sec]
2024-05-19 15:57:07,629 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:57:07,873 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/18500.ckpt
2024-05-19 15:57:07,888 - INFO - joeynmt.training - Example #0
2024-05-19 15:57:07,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:57:07,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:57:07,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'this', 'two', 'di@@', 'a@@', "'s", 's@@', 'ho@@', 't', 'to', 's@@', 'how', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'that', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', ',', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'ce', 'of', 'the', 'v@@', 'a@@', 'st@@', 'an@@', 'ce', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:57:07,890 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:57:07,890 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:57:07,891 - INFO - joeynmt.training - 	Hypothesis: For, I showed this two dia's shot to show the police cape that the past three million year, the size of the vastance of the vastance of the U.S.
2024-05-19 15:57:07,891 - INFO - joeynmt.training - Example #1
2024-05-19 15:57:07,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:57:07,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:57:07,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'is', 'the', 'wor@@', 'th', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'di@@', 'se@@', 'c@@', 't@@', 'or@@', 'y', 'is@@', "n't", 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:57:07,892 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:57:07,892 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:57:07,892 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem is the worth of this specific problem because it disectory isn't the ice of the ice.
2024-05-19 15:57:07,893 - INFO - joeynmt.training - Example #2
2024-05-19 15:57:07,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:57:07,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:57:07,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'li@@', 'p@@', ',', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:57:07,894 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:57:07,894 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:57:07,894 - INFO - joeynmt.training - 	Hypothesis: The ice clip, the North Pole is in a sense, in a sense, heart of our global climate system.
2024-05-19 15:57:07,894 - INFO - joeynmt.training - Example #3
2024-05-19 15:57:07,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:57:07,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:57:07,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'loo@@', 'ks', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'in@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:57:07,896 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:57:07,896 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:57:07,896 - INFO - joeynmt.training - 	Hypothesis: It looks in the winter and crinter and crink in the summer.
2024-05-19 15:57:07,897 - INFO - joeynmt.training - Example #4
2024-05-19 15:57:07,897 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:57:07,897 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:57:07,897 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'p@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'the', 'p@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 15:57:07,898 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:57:07,898 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:57:07,898 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a version of what the past 25 years of what the past 25 years happened.
2024-05-19 15:57:12,336 - INFO - joeynmt.training - Epoch   5, Step:    21100, Batch Loss:     1.419796, Batch Acc: 0.603151, Tokens per Sec:    16102, Lr: 0.000300
2024-05-19 15:57:15,900 - INFO - joeynmt.training - Epoch   5, Step:    21200, Batch Loss:     1.303030, Batch Acc: 0.593759, Tokens per Sec:    21059, Lr: 0.000300
2024-05-19 15:57:19,116 - INFO - joeynmt.training - Epoch   5, Step:    21300, Batch Loss:     1.183987, Batch Acc: 0.601110, Tokens per Sec:    24156, Lr: 0.000300
2024-05-19 15:57:22,278 - INFO - joeynmt.training - Epoch   5, Step:    21400, Batch Loss:     1.218107, Batch Acc: 0.601779, Tokens per Sec:    23436, Lr: 0.000300
2024-05-19 15:57:26,594 - INFO - joeynmt.training - Epoch   5, Step:    21500, Batch Loss:     1.184485, Batch Acc: 0.602847, Tokens per Sec:    17873, Lr: 0.000300
2024-05-19 15:57:26,594 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:57:26,595 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:57:40,884 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:57:40,885 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.15, loss:   1.57, ppl:   4.81, acc:   0.52, generation: 13.9248[sec], evaluation: 0.3329[sec]
2024-05-19 15:57:40,886 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:57:41,117 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/19000.ckpt
2024-05-19 15:57:41,133 - INFO - joeynmt.training - Example #0
2024-05-19 15:57:41,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:57:41,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:57:41,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'g', 'year@@', 's,', 'I', 's@@', 'how', 'the', 'l@@', 'ast', 'ye@@', 'ar', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'who', 'are', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'which', 'was', 'about', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:57:41,135 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:57:41,135 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:57:41,135 - INFO - joeynmt.training - 	Hypothesis: Forig years, I show the last year to show that the police cap, who are the last three million years, which was about the last three million years of the U.S. with 40 percent of the U.S.
2024-05-19 15:57:41,136 - INFO - joeynmt.training - Example #1
2024-05-19 15:57:41,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:57:41,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:57:41,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 're@@', 'all@@', 'y,', 'the', 're@@', 'all@@', 'y,', 'the', 'ne@@', 'x@@', 't', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'di@@', 'se@@', 'a@@', 'se@@', '.', '</s>']
2024-05-19 15:57:41,137 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:57:41,137 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:57:41,137 - INFO - joeynmt.training - 	Hypothesis: But this really, the really, the next of this specific problem because it doesn't show the disease.
2024-05-19 15:57:41,137 - INFO - joeynmt.training - Example #2
2024-05-19 15:57:41,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:57:41,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:57:41,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'h', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'wa@@', 'y,', 'in', 'the', 'c@@', 'l@@', 'as@@', 's@@', 'oc@@', 'i@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:57:41,138 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:57:41,139 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:57:41,139 - INFO - joeynmt.training - 	Hypothesis: The ice capach on the North Pole, in a way, in the classocial climate system.
2024-05-19 15:57:41,139 - INFO - joeynmt.training - Example #3
2024-05-19 15:57:41,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:57:41,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:57:41,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'in', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'it@@', 's', 'of', 'the', 'su@@', 'm@@', 'm@@', 'm@@', 'p', 'and', 'c@@', 'r@@', 'in@@', 'k@@', 'it@@', 'y@@', 's.', '</s>']
2024-05-19 15:57:41,140 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:57:41,141 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:57:41,141 - INFO - joeynmt.training - 	Hypothesis: It set in the winter and crack in the summmits in the summmits in the summmits in the summmits in the summmits in the summits in the summits in the summmits in the summmits in the summmits in the summmits of the summmp and crinkitys.
2024-05-19 15:57:41,141 - INFO - joeynmt.training - Example #4
2024-05-19 15:57:41,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:57:41,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:57:41,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'is', 'a', 'f@@', 'a@@', 'st@@', 'ly', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ing.', '</s>']
2024-05-19 15:57:41,142 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:57:41,142 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:57:41,142 - INFO - joeynmt.training - 	Hypothesis: The next slide I show you is a fastly version of what the last 25 years is happening.
2024-05-19 15:57:44,483 - INFO - joeynmt.training - Epoch   5, Step:    21600, Batch Loss:     1.285495, Batch Acc: 0.600965, Tokens per Sec:    21134, Lr: 0.000300
2024-05-19 15:57:47,925 - INFO - joeynmt.training - Epoch   5, Step:    21700, Batch Loss:     1.408371, Batch Acc: 0.605719, Tokens per Sec:    21891, Lr: 0.000300
2024-05-19 15:57:51,450 - INFO - joeynmt.training - Epoch   5, Step:    21800, Batch Loss:     1.304133, Batch Acc: 0.596236, Tokens per Sec:    21541, Lr: 0.000300
2024-05-19 15:57:55,671 - INFO - joeynmt.training - Epoch   5, Step:    21900, Batch Loss:     1.245414, Batch Acc: 0.598576, Tokens per Sec:    18172, Lr: 0.000300
2024-05-19 15:57:58,882 - INFO - joeynmt.training - Epoch   5, Step:    22000, Batch Loss:     1.362400, Batch Acc: 0.603819, Tokens per Sec:    23278, Lr: 0.000300
2024-05-19 15:57:58,883 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:57:58,883 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:58:14,864 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:58:14,865 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.18, loss:   1.56, ppl:   4.78, acc:   0.52, generation: 15.7614[sec], evaluation: 0.2014[sec]
2024-05-19 15:58:14,866 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:58:15,083 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/19500.ckpt
2024-05-19 15:58:15,099 - INFO - joeynmt.training - Example #0
2024-05-19 15:58:15,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:58:15,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:58:15,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'g', 'year@@', 's,', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', 'able', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 15:58:15,101 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:58:15,102 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:58:15,102 - INFO - joeynmt.training - 	Hypothesis: Forg years, I showed these two dias to show that the police capable that the last three million years of the United States, with 40 percent of the U.S.
2024-05-19 15:58:15,102 - INFO - joeynmt.training - Example #1
2024-05-19 15:58:15,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:58:15,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:58:15,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'se@@', 's', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:58:15,104 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:58:15,104 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:58:15,104 - INFO - joeynmt.training - 	Hypothesis: But this is actually the reses of this specific problem because it doesn't show the disection of the ice.
2024-05-19 15:58:15,104 - INFO - joeynmt.training - Example #2
2024-05-19 15:58:15,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:58:15,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:58:15,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'lo@@', 's@@', 'er', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:58:15,105 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:58:15,105 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:58:15,106 - INFO - joeynmt.training - 	Hypothesis: The ice closer on the North Pole, in a sense of the climate system.
2024-05-19 15:58:15,106 - INFO - joeynmt.training - Example #3
2024-05-19 15:58:15,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:58:15,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:58:15,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:58:15,107 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:58:15,107 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:58:15,107 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crack in the summer.
2024-05-19 15:58:15,108 - INFO - joeynmt.training - Example #4
2024-05-19 15:58:15,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:58:15,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:58:15,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 'di@@', 'a', 'I', 's@@', 'how', 'is', 'a', 'very', 'sp@@', 'e@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ing', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'very', 'sp@@', 'e@@', 'e@@', 'd.', '</s>']
2024-05-19 15:58:15,109 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:58:15,110 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:58:15,110 - INFO - joeynmt.training - 	Hypothesis: The next dia I show is a very speed version of what's happening the last 25 years is happened 25 years is happened in the last 25 years happened in the last 25 years of what happened is a very speed.
2024-05-19 15:58:18,482 - INFO - joeynmt.training - Epoch   5, Step:    22100, Batch Loss:     1.229833, Batch Acc: 0.599770, Tokens per Sec:    20880, Lr: 0.000300
2024-05-19 15:58:22,656 - INFO - joeynmt.training - Epoch   5, Step:    22200, Batch Loss:     1.146488, Batch Acc: 0.600682, Tokens per Sec:    18258, Lr: 0.000300
2024-05-19 15:58:26,388 - INFO - joeynmt.training - Epoch   5, Step:    22300, Batch Loss:     1.304757, Batch Acc: 0.602891, Tokens per Sec:    20339, Lr: 0.000300
2024-05-19 15:58:29,839 - INFO - joeynmt.training - Epoch   5, Step:    22400, Batch Loss:     1.316493, Batch Acc: 0.595985, Tokens per Sec:    22641, Lr: 0.000300
2024-05-19 15:58:33,003 - INFO - joeynmt.training - Epoch   5, Step:    22500, Batch Loss:     1.371039, Batch Acc: 0.603466, Tokens per Sec:    23552, Lr: 0.000300
2024-05-19 15:58:33,003 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:58:33,003 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:58:47,917 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:58:47,917 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.49, loss:   1.57, ppl:   4.80, acc:   0.52, generation: 14.6673[sec], evaluation: 0.2284[sec]
2024-05-19 15:58:48,186 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/20500.ckpt
2024-05-19 15:58:48,219 - INFO - joeynmt.training - Example #0
2024-05-19 15:58:48,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:58:48,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:58:48,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de', 'of', 's@@', 'li@@', 'de', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'f@@', 'ent', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'l@@', 'y.', '</s>']
2024-05-19 15:58:48,222 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:58:48,222 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:58:48,222 - INFO - joeynmt.training - 	Hypothesis: And I showed these two slide of slide that the police cap, that the last three million years of the last three million years of the United States of the U.S. with 40 percent fent currently.
2024-05-19 15:58:48,222 - INFO - joeynmt.training - Example #1
2024-05-19 15:58:48,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:58:48,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:58:48,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'all@@', 'y,', 'the', 're@@', 'se@@', 'ar@@', 'ch', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'se@@', 'c@@', 't', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:58:48,224 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:58:48,224 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:58:48,224 - INFO - joeynmt.training - 	Hypothesis: But this is actually the really, the research of this specific problem because it doesn't the disect of the ice of the ice.
2024-05-19 15:58:48,224 - INFO - joeynmt.training - Example #2
2024-05-19 15:58:48,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:58:48,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:58:48,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:58:48,226 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:58:48,226 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:58:48,226 - INFO - joeynmt.training - 	Hypothesis: The ice capacity on the North Pole, in a sense, in a climate system.
2024-05-19 15:58:48,226 - INFO - joeynmt.training - Example #3
2024-05-19 15:58:48,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:58:48,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:58:48,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'and', 'c@@', 'r@@', 'y@@', 'm@@', 'er', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:58:48,227 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:58:48,228 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:58:48,228 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crace and crymer in the summer.
2024-05-19 15:58:48,228 - INFO - joeynmt.training - Example #4
2024-05-19 15:58:48,228 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:58:48,228 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:58:48,228 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', ',', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'very', 's@@', 'ing@@', 'le', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'is', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 's.', '</s>']
2024-05-19 15:58:48,229 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:58:48,229 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:58:48,229 - INFO - joeynmt.training - 	Hypothesis: The next slide, I shows is a very single version of what happens is 25 years happened in 25 years of what happened is happened in 25 years of what happens.
2024-05-19 15:58:52,618 - INFO - joeynmt.training - Epoch   5, Step:    22600, Batch Loss:     1.381870, Batch Acc: 0.606209, Tokens per Sec:    16777, Lr: 0.000300
2024-05-19 15:58:54,326 - INFO - joeynmt.training - Epoch   5: total training loss 5887.93
2024-05-19 15:58:54,327 - INFO - joeynmt.training - EPOCH 6
2024-05-19 15:58:56,077 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.390713, Batch Acc: 0.623875, Tokens per Sec:    21914, Lr: 0.000300
2024-05-19 15:58:59,265 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.300581, Batch Acc: 0.622538, Tokens per Sec:    23444, Lr: 0.000300
2024-05-19 15:59:02,520 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.195636, Batch Acc: 0.620507, Tokens per Sec:    23714, Lr: 0.000300
2024-05-19 15:59:06,657 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.332058, Batch Acc: 0.612174, Tokens per Sec:    17941, Lr: 0.000300
2024-05-19 15:59:06,657 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:59:06,658 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:59:21,965 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:59:21,966 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.15, loss:   1.56, ppl:   4.78, acc:   0.53, generation: 15.0797[sec], evaluation: 0.2097[sec]
2024-05-19 15:59:21,967 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:59:22,203 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/20000.ckpt
2024-05-19 15:59:22,220 - INFO - joeynmt.training - Example #0
2024-05-19 15:59:22,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:59:22,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:59:22,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'you', 'two', 's@@', 'li@@', 'et', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'y', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'y', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'f@@', 'our', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 15:59:22,222 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:59:22,222 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:59:22,222 - INFO - joeynmt.training - 	Hypothesis: And I show you two sliet these two slight to show that the policy that the policy that the last three million years of about the size of the U.S. States, with 40 percent four percent croms.
2024-05-19 15:59:22,222 - INFO - joeynmt.training - Example #1
2024-05-19 15:59:22,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:59:22,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:59:22,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 're@@', 'as@@', 'on', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'se@@', 'c@@', 't', 'the', 'di@@', 'se@@', 'a@@', 'm', 'of', 'the', 'ic@@', 'e', 'l@@', 'ate', 'of', 'the', 'ic@@', 'e', 'l@@', 'ate', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:59:22,223 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:59:22,224 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:59:22,224 - INFO - joeynmt.training - 	Hypothesis: But this is the reason of this specific problem because it doesn't the disect the diseam of the ice late of the ice late of the ice.
2024-05-19 15:59:22,224 - INFO - joeynmt.training - Example #2
2024-05-19 15:59:22,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:59:22,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:59:22,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:59:22,225 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:59:22,225 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:59:22,226 - INFO - joeynmt.training - 	Hypothesis: The ice cape on the North Pole is in a certain sense, the climate heart of our global system.
2024-05-19 15:59:22,226 - INFO - joeynmt.training - Example #3
2024-05-19 15:59:22,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:59:22,226 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:59:22,226 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'in@@', 'es', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:59:22,227 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:59:22,227 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:59:22,227 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crinter and crines in the summer.
2024-05-19 15:59:22,227 - INFO - joeynmt.training - Example #4
2024-05-19 15:59:22,228 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:59:22,228 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:59:22,228 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'is', 'a', 'sp@@', 'e@@', 'e@@', 'de@@', 'd', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'is', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'the', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 15:59:22,229 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:59:22,229 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:59:22,229 - INFO - joeynmt.training - 	Hypothesis: The next slide I show you is a speeded version of what happens is happened in 25 years of what happened is the last 25 years of what happened to the next slide.
2024-05-19 15:59:25,540 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.264911, Batch Acc: 0.617037, Tokens per Sec:    21452, Lr: 0.000300
2024-05-19 15:59:28,715 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     1.284536, Batch Acc: 0.615236, Tokens per Sec:    23928, Lr: 0.000300
2024-05-19 15:59:32,520 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.289321, Batch Acc: 0.617599, Tokens per Sec:    19967, Lr: 0.000300
2024-05-19 15:59:36,396 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.357123, Batch Acc: 0.616515, Tokens per Sec:    19332, Lr: 0.000300
2024-05-19 15:59:39,939 - INFO - joeynmt.training - Epoch   6, Step:    23500, Batch Loss:     1.135395, Batch Acc: 0.614692, Tokens per Sec:    22469, Lr: 0.000300
2024-05-19 15:59:39,939 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 15:59:39,939 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 15:59:54,896 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 15:59:54,897 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.46, loss:   1.56, ppl:   4.77, acc:   0.53, generation: 14.7469[sec], evaluation: 0.1853[sec]
2024-05-19 15:59:54,897 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 15:59:55,130 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/21000.ckpt
2024-05-19 15:59:55,162 - INFO - joeynmt.training - Example #0
2024-05-19 15:59:55,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 15:59:55,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 15:59:55,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'is', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 15:59:55,164 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 15:59:55,164 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 15:59:55,165 - INFO - joeynmt.training - 	Hypothesis: And I showed these two slight to show that the police cap, which is the last three million years of the size three million years of the United States, with 40 percent croms.
2024-05-19 15:59:55,165 - INFO - joeynmt.training - Example #1
2024-05-19 15:59:55,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 15:59:55,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 15:59:55,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'qu@@', 'i@@', 're@@', 'd', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'se@@', 'c@@', 't@@', 'or@@', 'y', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 15:59:55,166 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 15:59:55,166 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 15:59:55,166 - INFO - joeynmt.training - 	Hypothesis: But this is actually the required of this specific problem because it doesn't the disectory of the ice.
2024-05-19 15:59:55,167 - INFO - joeynmt.training - Example #2
2024-05-19 15:59:55,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 15:59:55,167 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 15:59:55,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'k', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 15:59:55,168 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 15:59:55,168 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 15:59:55,168 - INFO - joeynmt.training - 	Hypothesis: The ice capack on the North Pole, in a sense, in a sense, heart of our global climate system.
2024-05-19 15:59:55,168 - INFO - joeynmt.training - Example #3
2024-05-19 15:59:55,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 15:59:55,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 15:59:55,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'from', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 15:59:55,169 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 15:59:55,170 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 15:59:55,170 - INFO - joeynmt.training - 	Hypothesis: It was from the winter and crace in the summer.
2024-05-19 15:59:55,170 - INFO - joeynmt.training - Example #4
2024-05-19 15:59:55,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 15:59:55,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 15:59:55,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 's.', '</s>']
2024-05-19 15:59:55,171 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 15:59:55,171 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 15:59:55,172 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what happens the last 25 years of what happened in 25 years of what happens.
2024-05-19 15:59:58,650 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.277898, Batch Acc: 0.615934, Tokens per Sec:    20068, Lr: 0.000300
2024-05-19 16:00:01,947 - INFO - joeynmt.training - Epoch   6, Step:    23700, Batch Loss:     1.211276, Batch Acc: 0.616356, Tokens per Sec:    23153, Lr: 0.000300
2024-05-19 16:00:06,901 - INFO - joeynmt.training - Epoch   6, Step:    23800, Batch Loss:     1.198193, Batch Acc: 0.614234, Tokens per Sec:    15555, Lr: 0.000300
2024-05-19 16:00:10,111 - INFO - joeynmt.training - Epoch   6, Step:    23900, Batch Loss:     1.179928, Batch Acc: 0.611907, Tokens per Sec:    23847, Lr: 0.000300
2024-05-19 16:00:13,342 - INFO - joeynmt.training - Epoch   6, Step:    24000, Batch Loss:     1.206897, Batch Acc: 0.612051, Tokens per Sec:    23116, Lr: 0.000300
2024-05-19 16:00:13,343 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:00:13,343 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:00:27,863 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:00:27,864 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  12.84, loss:   1.56, ppl:   4.74, acc:   0.53, generation: 14.3087[sec], evaluation: 0.1911[sec]
2024-05-19 16:00:27,865 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:00:28,088 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/21500.ckpt
2024-05-19 16:00:28,101 - INFO - joeynmt.training - Example #0
2024-05-19 16:00:28,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:00:28,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:00:28,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'this', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'that', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:00:28,103 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:00:28,104 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:00:28,104 - INFO - joeynmt.training - 	Hypothesis: And I showed this two slides to show that the police cap, that the past three million years of the last three million years of the U.S.
2024-05-19 16:00:28,104 - INFO - joeynmt.training - Example #1
2024-05-19 16:00:28,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:00:28,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:00:28,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'as@@', 'on', 'the', 'se@@', 'con@@', 'd', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'the', 'di@@', 'se@@', 'c@@', 'tion@@', '.', '</s>']
2024-05-19 16:00:28,106 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:00:28,106 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:00:28,107 - INFO - joeynmt.training - 	Hypothesis: But this is actually the reason the second of this specific problem because it is not the disection.
2024-05-19 16:00:28,107 - INFO - joeynmt.training - Example #2
2024-05-19 16:00:28,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:00:28,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:00:28,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'k', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:00:28,108 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:00:28,108 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:00:28,108 - INFO - joeynmt.training - 	Hypothesis: The ice capack on the North Pole, in a sense, in a sense, of our global climate system.
2024-05-19 16:00:28,109 - INFO - joeynmt.training - Example #3
2024-05-19 16:00:28,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:00:28,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:00:28,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'tur@@', 'n@@', 's', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k@@', 'a@@', 'ge@@', '.', '</s>']
2024-05-19 16:00:28,110 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:00:28,110 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:00:28,110 - INFO - joeynmt.training - 	Hypothesis: It turns out in the winter and crackage.
2024-05-19 16:00:28,110 - INFO - joeynmt.training - Example #4
2024-05-19 16:00:28,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:00:28,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:00:28,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ing', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ing', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:00:28,111 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:00:28,111 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:00:28,112 - INFO - joeynmt.training - 	Hypothesis: The next slide of what's happening is a version of what's happening is happened 25 years.
2024-05-19 16:00:31,619 - INFO - joeynmt.training - Epoch   6, Step:    24100, Batch Loss:     1.257019, Batch Acc: 0.613347, Tokens per Sec:    20502, Lr: 0.000300
2024-05-19 16:00:35,896 - INFO - joeynmt.training - Epoch   6, Step:    24200, Batch Loss:     1.251930, Batch Acc: 0.619077, Tokens per Sec:    17704, Lr: 0.000300
2024-05-19 16:00:39,375 - INFO - joeynmt.training - Epoch   6, Step:    24300, Batch Loss:     1.155087, Batch Acc: 0.613169, Tokens per Sec:    21994, Lr: 0.000300
2024-05-19 16:00:42,876 - INFO - joeynmt.training - Epoch   6, Step:    24400, Batch Loss:     1.298519, Batch Acc: 0.608741, Tokens per Sec:    21363, Lr: 0.000300
2024-05-19 16:00:46,460 - INFO - joeynmt.training - Epoch   6, Step:    24500, Batch Loss:     1.201137, Batch Acc: 0.610890, Tokens per Sec:    21581, Lr: 0.000300
2024-05-19 16:00:46,461 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:00:46,461 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:01:00,407 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:01:00,410 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.89, loss:   1.55, ppl:   4.72, acc:   0.53, generation: 13.5536[sec], evaluation: 0.3549[sec]
2024-05-19 16:01:00,411 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:01:00,699 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/22500.ckpt
2024-05-19 16:01:00,725 - INFO - joeynmt.training - Example #0
2024-05-19 16:01:00,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:01:00,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:01:00,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or', 'years', 'I', 's@@', 'how', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'is', 'the', 'p@@', 'ol@@', 'ar', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'about', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'de@@', 'gre@@', 'at@@', 'er', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'was', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 's.', '</s>']
2024-05-19 16:01:00,728 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:01:00,729 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:01:00,729 - INFO - joeynmt.training - 	Hypothesis: For years I show these two slides to show that the polar cap, which is the polar three million years about the last three million years of the degreater of the U.S. with 40 percent was currents.
2024-05-19 16:01:00,729 - INFO - joeynmt.training - Example #1
2024-05-19 16:01:00,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:01:00,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:01:00,730 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'al', 'proble@@', 'm', 'is', 'the', 're@@', 'qu@@', 'est@@', 'i@@', 'on', 'is', 'because', 'it', 's@@', 'ho@@', 'w@@', 'ed', 'not', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:01:00,731 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:01:00,738 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:01:00,739 - INFO - joeynmt.training - 	Hypothesis: But this is actually the real problem is the requestion is because it showed not the disection of the ice.
2024-05-19 16:01:00,739 - INFO - joeynmt.training - Example #2
2024-05-19 16:01:00,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:01:00,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:01:00,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:01:00,740 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:01:00,740 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:01:00,740 - INFO - joeynmt.training - 	Hypothesis: The ice capacity on the North Pole, in a sense of the global climate system.
2024-05-19 16:01:00,741 - INFO - joeynmt.training - Example #3
2024-05-19 16:01:00,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:01:00,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:01:00,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'is', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:01:00,742 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:01:00,742 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:01:00,742 - INFO - joeynmt.training - 	Hypothesis: It is in the winter and crace in the summer.
2024-05-19 16:01:00,742 - INFO - joeynmt.training - Example #4
2024-05-19 16:01:00,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:01:00,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:01:00,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', ',', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'going', 'on', 'on', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:01:00,744 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:01:00,744 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:01:00,744 - INFO - joeynmt.training - 	Hypothesis: The next slide, I shows is a version of what happened is going on on 25 years is happened in 25 years.
2024-05-19 16:01:05,120 - INFO - joeynmt.training - Epoch   6, Step:    24600, Batch Loss:     1.210528, Batch Acc: 0.609269, Tokens per Sec:    16417, Lr: 0.000300
2024-05-19 16:01:08,296 - INFO - joeynmt.training - Epoch   6, Step:    24700, Batch Loss:     1.326451, Batch Acc: 0.619009, Tokens per Sec:    23742, Lr: 0.000300
2024-05-19 16:01:11,789 - INFO - joeynmt.training - Epoch   6, Step:    24800, Batch Loss:     1.227861, Batch Acc: 0.611624, Tokens per Sec:    22028, Lr: 0.000300
2024-05-19 16:01:15,438 - INFO - joeynmt.training - Epoch   6, Step:    24900, Batch Loss:     1.393879, Batch Acc: 0.612649, Tokens per Sec:    21257, Lr: 0.000300
2024-05-19 16:01:19,726 - INFO - joeynmt.training - Epoch   6, Step:    25000, Batch Loss:     1.254872, Batch Acc: 0.611441, Tokens per Sec:    17586, Lr: 0.000300
2024-05-19 16:01:19,726 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:01:19,727 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:01:34,443 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:01:34,443 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.54, loss:   1.55, ppl:   4.70, acc:   0.53, generation: 14.5079[sec], evaluation: 0.1893[sec]
2024-05-19 16:01:34,444 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:01:34,655 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/22000.ckpt
2024-05-19 16:01:34,668 - INFO - joeynmt.training - Example #0
2024-05-19 16:01:34,668 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:01:34,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:01:34,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'this', 'two', 'di@@', 'a@@', 's', 'to', 's@@', 'how', 'this', 'two', 's@@', 'ho@@', 'w@@', 'ing', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'who', 'had', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'f@@', 'ron@@', 't', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'p@@', 's', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:01:34,670 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:01:34,670 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:01:34,670 - INFO - joeynmt.training - 	Hypothesis: And I show this two dias to show this two showing the polar cap, that the polar cap, who had the last three million years of the front of the U.S. with 40 percent crops of the U.S.
2024-05-19 16:01:34,671 - INFO - joeynmt.training - Example #1
2024-05-19 16:01:34,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:01:34,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:01:34,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'di@@', 'st@@', 'ri@@', 'bu@@', 'te', 'the', 'ne@@', 'x@@', 't', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:01:34,672 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:01:34,672 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:01:34,672 - INFO - joeynmt.training - 	Hypothesis: But this is the distribute the next of this particular problem because it didn't the disection of the ice.
2024-05-19 16:01:34,673 - INFO - joeynmt.training - Example #2
2024-05-19 16:01:34,673 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:01:34,673 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:01:34,673 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:01:34,674 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:01:34,674 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:01:34,674 - INFO - joeynmt.training - 	Hypothesis: The ice capacity on the North Pole, in a certain sense, climate system.
2024-05-19 16:01:34,674 - INFO - joeynmt.training - Example #3
2024-05-19 16:01:34,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:01:34,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:01:34,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:01:34,675 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:01:34,675 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:01:34,676 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crace in the summer.
2024-05-19 16:01:34,676 - INFO - joeynmt.training - Example #4
2024-05-19 16:01:34,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:01:34,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:01:34,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'is', 'happ@@', 'en@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:01:34,677 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:01:34,677 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:01:34,677 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is happened is a version of what happened is 25 years of what happened the last 25 years.
2024-05-19 16:01:38,051 - INFO - joeynmt.training - Epoch   6, Step:    25100, Batch Loss:     1.262362, Batch Acc: 0.611797, Tokens per Sec:    21224, Lr: 0.000300
2024-05-19 16:01:41,385 - INFO - joeynmt.training - Epoch   6, Step:    25200, Batch Loss:     1.396950, Batch Acc: 0.610175, Tokens per Sec:    22570, Lr: 0.000300
2024-05-19 16:01:45,333 - INFO - joeynmt.training - Epoch   6, Step:    25300, Batch Loss:     1.092511, Batch Acc: 0.613542, Tokens per Sec:    19549, Lr: 0.000300
2024-05-19 16:01:49,226 - INFO - joeynmt.training - Epoch   6, Step:    25400, Batch Loss:     1.238973, Batch Acc: 0.611146, Tokens per Sec:    20244, Lr: 0.000300
2024-05-19 16:01:52,553 - INFO - joeynmt.training - Epoch   6, Step:    25500, Batch Loss:     1.176674, Batch Acc: 0.619199, Tokens per Sec:    23057, Lr: 0.000300
2024-05-19 16:01:52,553 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:01:52,553 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:02:06,877 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:02:06,878 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.75, loss:   1.55, ppl:   4.70, acc:   0.53, generation: 14.0958[sec], evaluation: 0.2088[sec]
2024-05-19 16:02:06,879 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:02:07,110 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/23000.ckpt
2024-05-19 16:02:07,124 - INFO - joeynmt.training - Example #0
2024-05-19 16:02:07,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:02:07,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:02:07,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'year@@', 's,', 'I', 's@@', 'how', 'these', 'two', 'di@@', 'a@@', "'s", 'going', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'l@@', 'is@@', 't', 'c@@', 'ap@@', ',', 'that', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'it@@', 'y.', '</s>']
2024-05-19 16:02:07,126 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:02:07,126 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:02:07,126 - INFO - joeynmt.training - 	Hypothesis: Fore years, I show these two dia's going to show that the pollist cap, that the past three million years about the size of the United States, with 40 percent of the United States, with 40 percent curity.
2024-05-19 16:02:07,127 - INFO - joeynmt.training - Example #1
2024-05-19 16:02:07,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:02:07,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:02:07,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'un@@', 'der@@', 'st@@', 'and@@', 'ing', 'the', 'on@@', 'es', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'have', 'the', 'di@@', 'se@@', 'a@@', 'se@@', '.', '</s>']
2024-05-19 16:02:07,128 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:02:07,128 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:02:07,128 - INFO - joeynmt.training - 	Hypothesis: But this understanding the ones of this specific problem because it doesn't have the disease.
2024-05-19 16:02:07,128 - INFO - joeynmt.training - Example #2
2024-05-19 16:02:07,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:02:07,129 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:02:07,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'a', 'c@@', 'ap@@', 'it@@', 'a', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:02:07,130 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:02:07,130 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:02:07,130 - INFO - joeynmt.training - 	Hypothesis: The ice capita capita North Pole, in a sense, heart of our global climate system.
2024-05-19 16:02:07,130 - INFO - joeynmt.training - Example #3
2024-05-19 16:02:07,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:02:07,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:02:07,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'just', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:02:07,131 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:02:07,131 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:02:07,131 - INFO - joeynmt.training - 	Hypothesis: It just put out in the winter and crack in the summer.
2024-05-19 16:02:07,132 - INFO - joeynmt.training - Example #4
2024-05-19 16:02:07,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:02:07,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:02:07,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'of', 'what', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'is', 'happ@@', 'en@@', 'ed', 'to', 'the', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 16:02:07,133 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:02:07,133 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:02:07,133 - INFO - joeynmt.training - 	Hypothesis: The next slide of what is a version of what is a version of what is happened 25 years is happened 25 years is happened 25 years of the last 25 years of what happened is a version of what is happened to the next slide.
2024-05-19 16:02:10,391 - INFO - joeynmt.training - Epoch   6, Step:    25600, Batch Loss:     1.152712, Batch Acc: 0.613975, Tokens per Sec:    21726, Lr: 0.000300
2024-05-19 16:02:14,785 - INFO - joeynmt.training - Epoch   6, Step:    25700, Batch Loss:     1.253513, Batch Acc: 0.605737, Tokens per Sec:    17592, Lr: 0.000300
2024-05-19 16:02:18,615 - INFO - joeynmt.training - Epoch   6, Step:    25800, Batch Loss:     1.163565, Batch Acc: 0.616684, Tokens per Sec:    19832, Lr: 0.000300
2024-05-19 16:02:21,925 - INFO - joeynmt.training - Epoch   6, Step:    25900, Batch Loss:     1.268186, Batch Acc: 0.613547, Tokens per Sec:    23400, Lr: 0.000300
2024-05-19 16:02:25,610 - INFO - joeynmt.training - Epoch   6, Step:    26000, Batch Loss:     1.253476, Batch Acc: 0.616713, Tokens per Sec:    20462, Lr: 0.000300
2024-05-19 16:02:25,610 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:02:25,611 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:02:42,194 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:02:42,194 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.12, loss:   1.54, ppl:   4.66, acc:   0.53, generation: 16.1994[sec], evaluation: 0.3514[sec]
2024-05-19 16:02:42,195 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:02:42,493 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/23500.ckpt
2024-05-19 16:02:42,513 - INFO - joeynmt.training - Example #0
2024-05-19 16:02:42,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:02:42,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:02:42,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'e', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 's@@', 'ho@@', 'w@@', 'ing', 'that', 'the', 'p@@', 'ol@@', 'l@@', 'is@@', 'h', 'c@@', 'ap@@', ',', 'who', 'was', 'about', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'v@@', 'ed', 'was', 'about', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'v@@', 'ed', 'in', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:02:42,516 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:02:42,517 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:02:42,517 - INFO - joeynmt.training - 	Hypothesis: Fore year, I showed these two slight showing that the pollish cap, who was about three million years of the U.S. with 40 percent of the U.S. with 40 percent curved was about 40 percent curved in the U.S.
2024-05-19 16:02:42,517 - INFO - joeynmt.training - Example #1
2024-05-19 16:02:42,518 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:02:42,518 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:02:42,518 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 're@@', 'al', 're@@', 'al@@', 'i@@', 'ze', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 's@@', 'how', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:02:42,519 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:02:42,519 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:02:42,519 - INFO - joeynmt.training - 	Hypothesis: But this is the real realize of this specific problem because it didn't show the disection of the ice.
2024-05-19 16:02:42,519 - INFO - joeynmt.training - Example #2
2024-05-19 16:02:42,520 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:02:42,520 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:02:42,520 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'in', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:02:42,521 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:02:42,521 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:02:42,521 - INFO - joeynmt.training - 	Hypothesis: The ice capital in the North Pole, in a sense, in a sense, heart of our global climate system.
2024-05-19 16:02:42,521 - INFO - joeynmt.training - Example #3
2024-05-19 16:02:42,522 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:02:42,522 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:02:42,522 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:02:42,523 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:02:42,523 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:02:42,523 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crace in the summer.
2024-05-19 16:02:42,523 - INFO - joeynmt.training - Example #4
2024-05-19 16:02:42,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:02:42,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:02:42,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:02:42,525 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:02:42,525 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:02:42,525 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what the last 25 years of what the last 25 years.
2024-05-19 16:02:46,769 - INFO - joeynmt.training - Epoch   6, Step:    26100, Batch Loss:     1.147105, Batch Acc: 0.616000, Tokens per Sec:    16462, Lr: 0.000300
2024-05-19 16:02:50,146 - INFO - joeynmt.training - Epoch   6, Step:    26200, Batch Loss:     1.063136, Batch Acc: 0.608795, Tokens per Sec:    22687, Lr: 0.000300
2024-05-19 16:02:53,385 - INFO - joeynmt.training - Epoch   6, Step:    26300, Batch Loss:     1.304206, Batch Acc: 0.612250, Tokens per Sec:    23172, Lr: 0.000300
2024-05-19 16:02:56,892 - INFO - joeynmt.training - Epoch   6, Step:    26400, Batch Loss:     1.334403, Batch Acc: 0.619790, Tokens per Sec:    21167, Lr: 0.000300
2024-05-19 16:03:01,447 - INFO - joeynmt.training - Epoch   6, Step:    26500, Batch Loss:     1.225190, Batch Acc: 0.613038, Tokens per Sec:    16990, Lr: 0.000300
2024-05-19 16:03:01,447 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:03:01,447 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:03:15,354 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:03:15,355 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.23, loss:   1.54, ppl:   4.65, acc:   0.53, generation: 13.7006[sec], evaluation: 0.1890[sec]
2024-05-19 16:03:15,355 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:03:15,568 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/24000.ckpt
2024-05-19 16:03:15,581 - INFO - joeynmt.training - Example #0
2024-05-19 16:03:15,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:03:15,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:03:15,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'ho@@', 'w@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 's@@', 'how', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'v@@', 'a@@', 'st@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'ly', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 's.', '</s>']
2024-05-19 16:03:15,583 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:03:15,583 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:03:15,583 - INFO - joeynmt.training - 	Hypothesis: And I showed these two shows to show that the past three million years to show the last three million years, about the size of the vast, with 40 percent of the U.S. with 40 percent currently currents.
2024-05-19 16:03:15,583 - INFO - joeynmt.training - Example #1
2024-05-19 16:03:15,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:03:15,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:03:15,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'ri@@', 'bu@@', 'ted', 'the', 'ne@@', 'x@@', 't', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 16:03:15,585 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:03:15,585 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:03:15,585 - INFO - joeynmt.training - 	Hypothesis: But this distributed the next of this particular problem because it didn't show.
2024-05-19 16:03:15,585 - INFO - joeynmt.training - Example #2
2024-05-19 16:03:15,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:03:15,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:03:15,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'c@@', 'li@@', 'm@@', 'ate', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:03:15,586 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:03:15,586 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:03:15,586 - INFO - joeynmt.training - 	Hypothesis: The ice capita certain sense, in a certain sense, climate heart of our global climate system.
2024-05-19 16:03:15,587 - INFO - joeynmt.training - Example #3
2024-05-19 16:03:15,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:03:15,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:03:15,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 's@@', 'et', 'out', 'of', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:03:15,588 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:03:15,588 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:03:15,588 - INFO - joeynmt.training - 	Hypothesis: It set out of winter and crack in the summer.
2024-05-19 16:03:15,588 - INFO - joeynmt.training - Example #4
2024-05-19 16:03:15,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:03:15,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:03:15,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', ',', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'sp@@', 'e@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:03:15,589 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:03:15,590 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:03:15,590 - INFO - joeynmt.training - 	Hypothesis: The next slide, I shows is a speed version of what the last 25 years.
2024-05-19 16:03:18,775 - INFO - joeynmt.training - Epoch   6, Step:    26600, Batch Loss:     1.184300, Batch Acc: 0.615848, Tokens per Sec:    21644, Lr: 0.000300
2024-05-19 16:03:22,025 - INFO - joeynmt.training - Epoch   6, Step:    26700, Batch Loss:     1.370648, Batch Acc: 0.604129, Tokens per Sec:    23064, Lr: 0.000300
2024-05-19 16:03:25,581 - INFO - joeynmt.training - Epoch   6, Step:    26800, Batch Loss:     1.214910, Batch Acc: 0.615055, Tokens per Sec:    21460, Lr: 0.000300
2024-05-19 16:03:30,212 - INFO - joeynmt.training - Epoch   6, Step:    26900, Batch Loss:     1.312417, Batch Acc: 0.615925, Tokens per Sec:    16730, Lr: 0.000300
2024-05-19 16:03:33,663 - INFO - joeynmt.training - Epoch   6, Step:    27000, Batch Loss:     1.399269, Batch Acc: 0.607624, Tokens per Sec:    21716, Lr: 0.000300
2024-05-19 16:03:33,663 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:03:33,664 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:03:47,213 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:03:47,214 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.04, loss:   1.53, ppl:   4.63, acc:   0.53, generation: 13.3490[sec], evaluation: 0.1838[sec]
2024-05-19 16:03:47,214 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:03:47,423 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/24500.ckpt
2024-05-19 16:03:47,457 - INFO - joeynmt.training - Example #0
2024-05-19 16:03:47,458 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:03:47,458 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:03:47,458 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'this', 'two', 's@@', 'ho@@', 'w@@', 'ing', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'of', 'the', 'l@@', 'ast', 'ye@@', 'ar', 'to', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:03:47,459 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:03:47,459 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:03:47,459 - INFO - joeynmt.training - 	Hypothesis: And I showed this two showing these two slight of the last year to the last three million years of the size of the size of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:03:47,459 - INFO - joeynmt.training - Example #1
2024-05-19 16:03:47,459 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:03:47,460 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:03:47,460 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 's@@', 'ul@@', 'at@@', 'es', 'the', 'ne@@', 'x@@', 't', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 's@@', 'ho@@', 'w@@', 's', 'the', 'di@@', 'ver@@', 'se', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 16:03:47,460 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:03:47,460 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:03:47,461 - INFO - joeynmt.training - 	Hypothesis: But this is actually the resulates the next of this specific problem because it shows the diverse of the ice of ice.
2024-05-19 16:03:47,461 - INFO - joeynmt.training - Example #2
2024-05-19 16:03:47,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:03:47,461 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:03:47,461 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:03:47,462 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:03:47,462 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:03:47,462 - INFO - joeynmt.training - 	Hypothesis: The ice cap on the North Pole, in a sense, heart of our global climate system.
2024-05-19 16:03:47,462 - INFO - joeynmt.training - Example #3
2024-05-19 16:03:47,463 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:03:47,463 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:03:47,463 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'of', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:03:47,463 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:03:47,464 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:03:47,464 - INFO - joeynmt.training - 	Hypothesis: It put out of the winter and crace in the summer.
2024-05-19 16:03:47,464 - INFO - joeynmt.training - Example #4
2024-05-19 16:03:47,464 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:03:47,464 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:03:47,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', 'd', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 16:03:47,465 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:03:47,465 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:03:47,465 - INFO - joeynmt.training - 	Hypothesis: The next slided shows is a accelerated version of what the last 25 years is happened.
2024-05-19 16:03:50,933 - INFO - joeynmt.training - Epoch   6, Step:    27100, Batch Loss:     1.263548, Batch Acc: 0.615284, Tokens per Sec:    20631, Lr: 0.000300
2024-05-19 16:03:53,548 - INFO - joeynmt.training - Epoch   6: total training loss 5652.86
2024-05-19 16:03:53,548 - INFO - joeynmt.training - EPOCH 7
2024-05-19 16:03:54,674 - INFO - joeynmt.training - Epoch   7, Step:    27200, Batch Loss:     1.229255, Batch Acc: 0.620452, Tokens per Sec:    16899, Lr: 0.000300
2024-05-19 16:03:59,256 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     1.136598, Batch Acc: 0.632556, Tokens per Sec:    16319, Lr: 0.000300
2024-05-19 16:04:02,609 - INFO - joeynmt.training - Epoch   7, Step:    27400, Batch Loss:     1.181828, Batch Acc: 0.632700, Tokens per Sec:    23981, Lr: 0.000300
2024-05-19 16:04:05,963 - INFO - joeynmt.training - Epoch   7, Step:    27500, Batch Loss:     1.089407, Batch Acc: 0.628988, Tokens per Sec:    22513, Lr: 0.000300
2024-05-19 16:04:05,964 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:04:05,964 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:04:20,696 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:04:20,696 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.12, loss:   1.53, ppl:   4.62, acc:   0.53, generation: 14.1220[sec], evaluation: 0.5916[sec]
2024-05-19 16:04:20,697 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:04:20,913 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/25000.ckpt
2024-05-19 16:04:20,927 - INFO - joeynmt.training - Example #0
2024-05-19 16:04:20,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:04:20,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:04:20,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'l@@', 'ast', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'ho@@', 'w@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'e', 'c@@', 'ap@@', ',', 'which', 'is', 'the', 'p@@', 'ol@@', 'e', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', ',', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'm@@', 's', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'r@@', 'ent', 'c@@', 'ro@@', 'm@@', 's.', '</s>']
2024-05-19 16:04:20,929 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:04:20,929 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:04:20,929 - INFO - joeynmt.training - 	Hypothesis: And last year, I showed these two shows to show that the pole cap, which is the pole three million year, about the size of the United States, with 40 percent croms of the United St, with 40 percent current croms.
2024-05-19 16:04:20,930 - INFO - joeynmt.training - Example #1
2024-05-19 16:04:20,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:04:20,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:04:20,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'se@@', 'ar@@', 'ch@@', 'ing', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:04:20,931 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:04:20,931 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:04:20,931 - INFO - joeynmt.training - 	Hypothesis: But this is actually the researching of this particular problem because it is not the disection of the ice of the ice of the ice.
2024-05-19 16:04:20,931 - INFO - joeynmt.training - Example #2
2024-05-19 16:04:20,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:04:20,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:04:20,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:04:20,932 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:04:20,933 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:04:20,933 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole is in a sense, heart of our global climate system.
2024-05-19 16:04:20,933 - INFO - joeynmt.training - Example #3
2024-05-19 16:04:20,933 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:04:20,933 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:04:20,933 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:04:20,934 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:04:20,934 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:04:20,934 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crace in the summer.
2024-05-19 16:04:20,934 - INFO - joeynmt.training - Example #4
2024-05-19 16:04:20,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:04:20,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:04:20,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'is', 'a', 'sp@@', 'e@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ed', '</s>']
2024-05-19 16:04:20,935 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:04:20,936 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:04:20,936 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a speed version of what the last 25 years is happened in the last 25 years of what happened is happened
2024-05-19 16:04:24,291 - INFO - joeynmt.training - Epoch   7, Step:    27600, Batch Loss:     1.173317, Batch Acc: 0.632091, Tokens per Sec:    20878, Lr: 0.000300
2024-05-19 16:04:28,932 - INFO - joeynmt.training - Epoch   7, Step:    27700, Batch Loss:     1.148350, Batch Acc: 0.627597, Tokens per Sec:    16182, Lr: 0.000300
2024-05-19 16:04:32,305 - INFO - joeynmt.training - Epoch   7, Step:    27800, Batch Loss:     1.150541, Batch Acc: 0.628242, Tokens per Sec:    22400, Lr: 0.000300
2024-05-19 16:04:35,569 - INFO - joeynmt.training - Epoch   7, Step:    27900, Batch Loss:     1.096325, Batch Acc: 0.623291, Tokens per Sec:    23354, Lr: 0.000300
2024-05-19 16:04:39,063 - INFO - joeynmt.training - Epoch   7, Step:    28000, Batch Loss:     1.294757, Batch Acc: 0.624950, Tokens per Sec:    20638, Lr: 0.000300
2024-05-19 16:04:39,069 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:04:39,071 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:04:53,674 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:04:53,674 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.61, loss:   1.54, ppl:   4.67, acc:   0.53, generation: 14.3866[sec], evaluation: 0.1973[sec]
2024-05-19 16:04:53,871 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/25500.ckpt
2024-05-19 16:04:53,884 - INFO - joeynmt.training - Example #0
2024-05-19 16:04:53,885 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:04:53,886 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:04:53,886 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ro@@', 'p@@', 's.', '</s>']
2024-05-19 16:04:53,887 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:04:53,887 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:04:53,887 - INFO - joeynmt.training - 	Hypothesis: For year, I showed these two slides to show that the polar cape capacity that the last three million years of the size of the United States, with 40 percent of the United States, with 40 percent crops.
2024-05-19 16:04:53,887 - INFO - joeynmt.training - Example #1
2024-05-19 16:04:53,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:04:53,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:04:53,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'un@@', 'der@@', 'est@@', 'im@@', 'at@@', 'ed', 'the', 'wor@@', 'st', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'di@@', 'd', 'of', 'ic@@', 'e', 'ic@@', 'e', 'proble@@', 'm', 'because', 'it', 's@@', 'ho@@', 'w@@', 's', 'no@@', 'w@@', '.', '</s>']
2024-05-19 16:04:53,889 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:04:53,889 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:04:53,889 - INFO - joeynmt.training - 	Hypothesis: But this underestimated the worst of this specific problem because it doesn't show the did of ice ice problem because it shows now.
2024-05-19 16:04:53,889 - INFO - joeynmt.training - Example #2
2024-05-19 16:04:53,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:04:53,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:04:53,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:04:53,890 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:04:53,891 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:04:53,891 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a sense, heart of our global climate system.
2024-05-19 16:04:53,891 - INFO - joeynmt.training - Example #3
2024-05-19 16:04:53,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:04:53,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:04:53,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:04:53,892 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:04:53,892 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:04:53,892 - INFO - joeynmt.training - 	Hypothesis: It put out in the summer.
2024-05-19 16:04:53,892 - INFO - joeynmt.training - Example #4
2024-05-19 16:04:53,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:04:53,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:04:53,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', 'd', 's@@', 'li@@', 'de', 'of', 'what', 'happ@@', 'en@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'do', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'be', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 'be', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 'happ@@', 'en@@', 'ed', 'to', 'be', 'a', 'ver@@', 'si@@']
2024-05-19 16:04:53,893 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:04:53,894 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:04:53,894 - INFO - joeynmt.training - 	Hypothesis: The next slided slide of what happened version of what happened the last 25 years of what happened the last 25 years of what happened in the last 25 years of what happened is a version of what happened to do is a version of what happened the last 25 years of what happened to be a version of what happened to happened to be a version of what happened to happened to happened to be a versi
2024-05-19 16:04:57,514 - INFO - joeynmt.training - Epoch   7, Step:    28100, Batch Loss:     1.444491, Batch Acc: 0.623278, Tokens per Sec:    19381, Lr: 0.000300
2024-05-19 16:05:01,646 - INFO - joeynmt.training - Epoch   7, Step:    28200, Batch Loss:     1.290767, Batch Acc: 0.620013, Tokens per Sec:    17924, Lr: 0.000300
2024-05-19 16:05:04,854 - INFO - joeynmt.training - Epoch   7, Step:    28300, Batch Loss:     1.379232, Batch Acc: 0.624164, Tokens per Sec:    23366, Lr: 0.000300
2024-05-19 16:05:08,030 - INFO - joeynmt.training - Epoch   7, Step:    28400, Batch Loss:     1.088029, Batch Acc: 0.628077, Tokens per Sec:    24447, Lr: 0.000300
2024-05-19 16:05:11,570 - INFO - joeynmt.training - Epoch   7, Step:    28500, Batch Loss:     1.360061, Batch Acc: 0.628598, Tokens per Sec:    21700, Lr: 0.000300
2024-05-19 16:05:11,571 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:05:11,571 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:05:26,391 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:05:26,392 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.57, loss:   1.53, ppl:   4.60, acc:   0.54, generation: 14.4498[sec], evaluation: 0.3367[sec]
2024-05-19 16:05:26,393 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:05:26,648 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/28000.ckpt
2024-05-19 16:05:26,676 - INFO - joeynmt.training - Example #0
2024-05-19 16:05:26,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:05:26,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:05:26,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'these', 'two', 's@@', 'li@@', 'p@@', 's', 'I', 's@@', 'how', 'these', 'two', 's@@', 'li@@', 'de', 'of', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'is', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:05:26,678 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:05:26,678 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:05:26,678 - INFO - joeynmt.training - 	Hypothesis: And I show these two slips I show these two slide of the polar cap, which is the last three million years of the last three million years of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:05:26,679 - INFO - joeynmt.training - Example #1
2024-05-19 16:05:26,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:05:26,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:05:26,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 're@@', 'as@@', 'on', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'se@@', 'a@@', 'se@@', ',', 'because', 'it', 's@@', 'ho@@', 'w@@', 's', 'not', 'the', 'di@@', 'se@@', 'd.', '</s>']
2024-05-19 16:05:26,680 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:05:26,680 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:05:26,680 - INFO - joeynmt.training - 	Hypothesis: But this is the reason of this particular problem because it doesn't the disease, because it shows not the dised.
2024-05-19 16:05:26,680 - INFO - joeynmt.training - Example #2
2024-05-19 16:05:26,681 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:05:26,681 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:05:26,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'c@@', 'l@@', 'op@@', 'p@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:05:26,682 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:05:26,682 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:05:26,682 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a sense of the clopping heart of our global climate system.
2024-05-19 16:05:26,682 - INFO - joeynmt.training - Example #3
2024-05-19 16:05:26,682 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:05:26,682 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:05:26,682 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:05:26,683 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:05:26,683 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:05:26,683 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crack in the summer.
2024-05-19 16:05:26,684 - INFO - joeynmt.training - Example #4
2024-05-19 16:05:26,684 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:05:26,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:05:26,684 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'is', 'a', 'di@@', 'd', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 16:05:26,685 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:05:26,685 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:05:26,685 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a did version of what happens in the last 25 years happened 25 years happened.
2024-05-19 16:05:30,557 - INFO - joeynmt.training - Epoch   7, Step:    28600, Batch Loss:     1.186303, Batch Acc: 0.625125, Tokens per Sec:    18760, Lr: 0.000300
2024-05-19 16:05:33,788 - INFO - joeynmt.training - Epoch   7, Step:    28700, Batch Loss:     1.158344, Batch Acc: 0.623027, Tokens per Sec:    23907, Lr: 0.000300
2024-05-19 16:05:37,172 - INFO - joeynmt.training - Epoch   7, Step:    28800, Batch Loss:     1.178962, Batch Acc: 0.626352, Tokens per Sec:    22510, Lr: 0.000300
2024-05-19 16:05:40,946 - INFO - joeynmt.training - Epoch   7, Step:    28900, Batch Loss:     1.149045, Batch Acc: 0.623706, Tokens per Sec:    20234, Lr: 0.000300
2024-05-19 16:05:44,780 - INFO - joeynmt.training - Epoch   7, Step:    29000, Batch Loss:     1.241450, Batch Acc: 0.624689, Tokens per Sec:    19843, Lr: 0.000300
2024-05-19 16:05:44,780 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:05:44,781 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:05:59,051 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:05:59,051 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.68, loss:   1.53, ppl:   4.61, acc:   0.54, generation: 14.0475[sec], evaluation: 0.2044[sec]
2024-05-19 16:05:59,252 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/26000.ckpt
2024-05-19 16:05:59,270 - INFO - joeynmt.training - Example #0
2024-05-19 16:05:59,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:05:59,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:05:59,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'this', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'of', 'the', 'p@@', 'ol@@', 'ic@@', 'y', 'c@@', 'ap@@', ',', 'which', 'is', 'the', 'p@@', 'ol@@', 'lu@@', 't', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', ',', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'C@@', 'om@@', 'e', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:05:59,273 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:05:59,273 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:05:59,273 - INFO - joeynmt.training - 	Hypothesis: And I show this two slight these two slight of the policy cap, which is the pollut three million year, about the size of the U.S. Come of the U.S. with 40 percent of the U.S.
2024-05-19 16:05:59,274 - INFO - joeynmt.training - Example #1
2024-05-19 16:05:59,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:05:59,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:05:59,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 's@@', 'in@@', 'c@@', 'ul@@', 'at@@', 'ed', 'the', 'ne@@', 'x@@', 't', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 16:05:59,275 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:05:59,275 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:05:59,275 - INFO - joeynmt.training - 	Hypothesis: But this disinculated the next of this specific problem because it doesn't show the ice of ice.
2024-05-19 16:05:59,275 - INFO - joeynmt.training - Example #2
2024-05-19 16:05:59,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:05:59,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:05:59,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'ste@@', 'm', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:05:59,276 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:05:59,277 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:05:59,277 - INFO - joeynmt.training - 	Hypothesis: The ice capital climate system is in a certain sense, heart of our global climate system.
2024-05-19 16:05:59,277 - INFO - joeynmt.training - Example #3
2024-05-19 16:05:59,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:05:59,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:05:59,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'su@@', 'm@@', 'mer@@', ',', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:05:59,278 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:05:59,278 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:05:59,278 - INFO - joeynmt.training - 	Hypothesis: It put out in the summer, and crack in the summer.
2024-05-19 16:05:59,279 - INFO - joeynmt.training - Example #4
2024-05-19 16:05:59,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:05:59,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:05:59,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', ',', 'I', 's@@', 'ho@@', 'w@@', 's', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 16:05:59,280 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:05:59,280 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:05:59,280 - INFO - joeynmt.training - 	Hypothesis: The next slide, I shows a accelerated version of what happens 25 years happened 25 years happened.
2024-05-19 16:06:02,479 - INFO - joeynmt.training - Epoch   7, Step:    29100, Batch Loss:     1.168172, Batch Acc: 0.625877, Tokens per Sec:    22613, Lr: 0.000300
2024-05-19 16:06:05,881 - INFO - joeynmt.training - Epoch   7, Step:    29200, Batch Loss:     1.355934, Batch Acc: 0.621212, Tokens per Sec:    22264, Lr: 0.000300
2024-05-19 16:06:09,983 - INFO - joeynmt.training - Epoch   7, Step:    29300, Batch Loss:     1.051702, Batch Acc: 0.630885, Tokens per Sec:    18773, Lr: 0.000300
2024-05-19 16:06:13,409 - INFO - joeynmt.training - Epoch   7, Step:    29400, Batch Loss:     1.234365, Batch Acc: 0.625006, Tokens per Sec:    22505, Lr: 0.000300
2024-05-19 16:06:16,647 - INFO - joeynmt.training - Epoch   7, Step:    29500, Batch Loss:     1.224967, Batch Acc: 0.624249, Tokens per Sec:    23587, Lr: 0.000300
2024-05-19 16:06:16,647 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:06:16,647 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:06:31,493 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:06:31,494 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.96, loss:   1.52, ppl:   4.57, acc:   0.54, generation: 14.6339[sec], evaluation: 0.1932[sec]
2024-05-19 16:06:31,494 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:06:31,709 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/26500.ckpt
2024-05-19 16:06:31,727 - INFO - joeynmt.training - Example #0
2024-05-19 16:06:31,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:06:31,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:06:31,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'this', 'two', 's@@', 'li@@', 'de', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'was', 'about', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:06:31,729 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:06:31,729 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:06:31,729 - INFO - joeynmt.training - 	Hypothesis: And I showed this two slide of the U.S. to show that the polar cap, which was about the last three million years, about the size of the size of the U.S. with 40 percent of the U.S.
2024-05-19 16:06:31,730 - INFO - joeynmt.training - Example #1
2024-05-19 16:06:31,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:06:31,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:06:31,730 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 's@@', 'ab@@', 'il@@', 'ity', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'di@@', 'se@@', 'c@@', 't@@', 'or@@', 'y', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:06:31,731 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:06:31,731 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:06:31,731 - INFO - joeynmt.training - 	Hypothesis: But this disability of this particular problem because it doesn't show the disectory of the ice.
2024-05-19 16:06:31,732 - INFO - joeynmt.training - Example #2
2024-05-19 16:06:31,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:06:31,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:06:31,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:06:31,733 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:06:31,733 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:06:31,733 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a sense, in a sense, heart of our global climate system.
2024-05-19 16:06:31,734 - INFO - joeynmt.training - Example #3
2024-05-19 16:06:31,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:06:31,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:06:31,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:06:31,735 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:06:31,735 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:06:31,735 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crace in the summer.
2024-05-19 16:06:31,736 - INFO - joeynmt.training - Example #4
2024-05-19 16:06:31,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:06:31,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:06:31,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'e@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'happ@@', 'en@@', 'e@@', 'd.', '</s>']
2024-05-19 16:06:31,736 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:06:31,737 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:06:31,737 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a acceed version of what happens in the last 25 years of happened.
2024-05-19 16:06:34,896 - INFO - joeynmt.training - Epoch   7, Step:    29600, Batch Loss:     1.043839, Batch Acc: 0.626991, Tokens per Sec:    22219, Lr: 0.000300
2024-05-19 16:06:39,254 - INFO - joeynmt.training - Epoch   7, Step:    29700, Batch Loss:     1.219742, Batch Acc: 0.621636, Tokens per Sec:    17346, Lr: 0.000300
2024-05-19 16:06:42,630 - INFO - joeynmt.training - Epoch   7, Step:    29800, Batch Loss:     1.250492, Batch Acc: 0.626312, Tokens per Sec:    22051, Lr: 0.000300
2024-05-19 16:06:45,828 - INFO - joeynmt.training - Epoch   7, Step:    29900, Batch Loss:     1.243587, Batch Acc: 0.618080, Tokens per Sec:    24052, Lr: 0.000300
2024-05-19 16:06:49,131 - INFO - joeynmt.training - Epoch   7, Step:    30000, Batch Loss:     1.114140, Batch Acc: 0.622055, Tokens per Sec:    23410, Lr: 0.000300
2024-05-19 16:06:49,131 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:06:49,132 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:07:03,672 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:07:03,672 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.86, loss:   1.52, ppl:   4.59, acc:   0.54, generation: 14.1566[sec], evaluation: 0.3504[sec]
2024-05-19 16:07:03,904 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/27000.ckpt
2024-05-19 16:07:03,930 - INFO - joeynmt.training - Example #0
2024-05-19 16:07:03,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:07:03,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:07:03,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'was', 'the', 'p@@', 'ol@@', 'l@@', 'is@@', 'he@@', 'd', 'the', 'p@@', 'ol@@', 'l@@', 'is@@', 'he@@', 'd', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:07:03,932 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:07:03,932 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:07:03,933 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two dias to show that the polar cap, which was the pollished the pollished three million years of the U.S.
2024-05-19 16:07:03,933 - INFO - joeynmt.training - Example #1
2024-05-19 16:07:03,933 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:07:03,933 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:07:03,933 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 'ti@@', 've', 'proble@@', 'm', 'because', 'it', 's@@', 'ho@@', 'w@@', 's', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'di@@', 'd@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:07:03,934 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:07:03,934 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:07:03,934 - INFO - joeynmt.training - 	Hypothesis: But this distinctive problem because it shows of this specific problem because it didn't show the ice of the ice.
2024-05-19 16:07:03,934 - INFO - joeynmt.training - Example #2
2024-05-19 16:07:03,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:07:03,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:07:03,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'a', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se', 'of', 'c@@', 'li@@', 'm@@', 'ate', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:07:03,936 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:07:03,936 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:07:03,936 - INFO - joeynmt.training - 	Hypothesis: The ice capita on the North Pole, in a sense of climate heart of our global climate system.
2024-05-19 16:07:03,936 - INFO - joeynmt.training - Example #3
2024-05-19 16:07:03,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:07:03,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:07:03,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'in@@', 'c@@', 'lu@@', 'ding', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:07:03,937 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:07:03,937 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:07:03,937 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crinter and crincluding in the summer.
2024-05-19 16:07:03,937 - INFO - joeynmt.training - Example #4
2024-05-19 16:07:03,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:07:03,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:07:03,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ed', 'to', 's@@', 'li@@', 'de', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'do', 'is', 'happ@@', 'en@@', 'ing', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'to', 'be', 'the', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 16:07:03,939 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:07:03,939 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:07:03,939 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what happens is happened 25 years is happened 25 years of what happened 25 years of the last 25 years of what happened is happened to slide of what happened to do is happening is a version of what happened to be the next slide.
2024-05-19 16:07:08,016 - INFO - joeynmt.training - Epoch   7, Step:    30100, Batch Loss:     1.039320, Batch Acc: 0.627202, Tokens per Sec:    17148, Lr: 0.000300
2024-05-19 16:07:11,311 - INFO - joeynmt.training - Epoch   7, Step:    30200, Batch Loss:     1.156034, Batch Acc: 0.627100, Tokens per Sec:    22930, Lr: 0.000300
2024-05-19 16:07:14,581 - INFO - joeynmt.training - Epoch   7, Step:    30300, Batch Loss:     1.257196, Batch Acc: 0.622487, Tokens per Sec:    23419, Lr: 0.000300
2024-05-19 16:07:18,412 - INFO - joeynmt.training - Epoch   7, Step:    30400, Batch Loss:     1.180858, Batch Acc: 0.625685, Tokens per Sec:    20048, Lr: 0.000300
2024-05-19 16:07:22,451 - INFO - joeynmt.training - Epoch   7, Step:    30500, Batch Loss:     1.270752, Batch Acc: 0.624722, Tokens per Sec:    18511, Lr: 0.000300
2024-05-19 16:07:22,451 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:07:22,452 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:07:35,904 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:07:35,904 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.84, loss:   1.52, ppl:   4.59, acc:   0.54, generation: 13.2545[sec], evaluation: 0.1809[sec]
2024-05-19 16:07:36,103 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/27500.ckpt
2024-05-19 16:07:36,118 - INFO - joeynmt.training - Example #0
2024-05-19 16:07:36,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:07:36,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:07:36,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'al', 'year@@', 's,', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'that', 'the', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'a', 'c@@', 'u@@', 'm@@', 'ul@@', 'ti@@', 'pl@@', 'y', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:07:36,119 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:07:36,120 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:07:36,120 - INFO - joeynmt.training - 	Hypothesis: Forial years, I showed these two slight that the police capita cumultiply that the last three million years of the size of the U.S. with 40 percent the U.S.
2024-05-19 16:07:36,120 - INFO - joeynmt.training - Example #1
2024-05-19 16:07:36,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:07:36,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:07:36,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 't', 'is', 'the', 'ne@@', 'x@@', 't', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:07:36,121 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:07:36,121 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:07:36,121 - INFO - joeynmt.training - 	Hypothesis: But this distinct is the next of this particular problem because it doesn't show the ice of the ice.
2024-05-19 16:07:36,122 - INFO - joeynmt.training - Example #2
2024-05-19 16:07:36,122 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:07:36,122 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:07:36,122 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:07:36,123 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:07:36,123 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:07:36,123 - INFO - joeynmt.training - 	Hypothesis: The ice cap on the North Pole is in a certain sense of our global climate system.
2024-05-19 16:07:36,123 - INFO - joeynmt.training - Example #3
2024-05-19 16:07:36,123 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:07:36,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:07:36,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'oo@@', 'm@@', 's', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:07:36,124 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:07:36,124 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:07:36,124 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crooms in the summer.
2024-05-19 16:07:36,125 - INFO - joeynmt.training - Example #4
2024-05-19 16:07:36,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:07:36,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:07:36,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'ol@@', 'd.', '</s>']
2024-05-19 16:07:36,126 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:07:36,126 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:07:36,126 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a accelerated version of what happened 25 years happened 25 years happened 25 years old.
2024-05-19 16:07:39,339 - INFO - joeynmt.training - Epoch   7, Step:    30600, Batch Loss:     1.214696, Batch Acc: 0.624286, Tokens per Sec:    22383, Lr: 0.000300
2024-05-19 16:07:42,575 - INFO - joeynmt.training - Epoch   7, Step:    30700, Batch Loss:     1.214949, Batch Acc: 0.623175, Tokens per Sec:    23464, Lr: 0.000300
2024-05-19 16:07:46,143 - INFO - joeynmt.training - Epoch   7, Step:    30800, Batch Loss:     1.263771, Batch Acc: 0.625357, Tokens per Sec:    21775, Lr: 0.000300
2024-05-19 16:07:50,237 - INFO - joeynmt.training - Epoch   7, Step:    30900, Batch Loss:     1.408650, Batch Acc: 0.623234, Tokens per Sec:    18343, Lr: 0.000300
2024-05-19 16:07:53,454 - INFO - joeynmt.training - Epoch   7, Step:    31000, Batch Loss:     1.079061, Batch Acc: 0.623974, Tokens per Sec:    24507, Lr: 0.000300
2024-05-19 16:07:53,455 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:07:53,455 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:08:07,579 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:08:07,580 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.34, loss:   1.51, ppl:   4.55, acc:   0.54, generation: 13.8944[sec], evaluation: 0.2125[sec]
2024-05-19 16:08:07,581 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:08:07,813 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/29000.ckpt
2024-05-19 16:08:07,827 - INFO - joeynmt.training - Example #0
2024-05-19 16:08:07,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:08:07,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:08:07,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'ho@@', 'w@@', 'ed', 's@@', 'ho@@', 'w@@', 'ing', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'c@@', 'ur@@', 'r@@', 'ent', 'to', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'that', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:08:07,829 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:08:07,829 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:08:07,830 - INFO - joeynmt.training - 	Hypothesis: And I showed these two showed showing these two slight current to the past three million years, that the size of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:08:07,830 - INFO - joeynmt.training - Example #1
2024-05-19 16:08:07,830 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:08:07,830 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:08:07,830 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'un@@', 'der@@', 'est@@', 'im@@', 'ate', 'the', 'ne@@', 'x@@', 't', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:08:07,831 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:08:07,831 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:08:07,831 - INFO - joeynmt.training - 	Hypothesis: But this underestimate the next of this particular problem because it is not the disection of the ice.
2024-05-19 16:08:07,831 - INFO - joeynmt.training - Example #2
2024-05-19 16:08:07,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:08:07,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:08:07,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:08:07,832 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:08:07,833 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:08:07,833 - INFO - joeynmt.training - 	Hypothesis: The ice capital climate in a certain sense, the climate heart of our global climate system.
2024-05-19 16:08:07,833 - INFO - joeynmt.training - Example #3
2024-05-19 16:08:07,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:08:07,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:08:07,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'out', 'of', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:08:07,834 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:08:07,834 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:08:07,834 - INFO - joeynmt.training - 	Hypothesis: It was out of winter and crack in the summer.
2024-05-19 16:08:07,834 - INFO - joeynmt.training - Example #4
2024-05-19 16:08:07,835 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:08:07,835 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:08:07,835 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'is', 'a', 'ac@@', 'c@@', 'e@@', 'd,', 'ver@@', 'si@@', 'on', 'of', 'what', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'is', 'happ@@', 'en@@', 'ed', 'to', 'do', 'is', 'happ@@', 'en@@', 'ing', 'the', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 16:08:07,835 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:08:07,836 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:08:07,836 - INFO - joeynmt.training - 	Hypothesis: The next slide I show you is a acced, version of what is happened 25 years of the last 25 years of the last 25 years of the last 25 years of the last 25 years of the last 25 years of what is happened to do is happening the next slide.
2024-05-19 16:08:11,137 - INFO - joeynmt.training - Epoch   7, Step:    31100, Batch Loss:     1.425930, Batch Acc: 0.623306, Tokens per Sec:    21015, Lr: 0.000300
2024-05-19 16:08:14,834 - INFO - joeynmt.training - Epoch   7, Step:    31200, Batch Loss:     1.305752, Batch Acc: 0.623461, Tokens per Sec:    20308, Lr: 0.000300
2024-05-19 16:08:18,829 - INFO - joeynmt.training - Epoch   7, Step:    31300, Batch Loss:     1.302347, Batch Acc: 0.624197, Tokens per Sec:    18050, Lr: 0.000300
2024-05-19 16:08:22,028 - INFO - joeynmt.training - Epoch   7, Step:    31400, Batch Loss:     1.082996, Batch Acc: 0.624507, Tokens per Sec:    23309, Lr: 0.000300
2024-05-19 16:08:25,241 - INFO - joeynmt.training - Epoch   7, Step:    31500, Batch Loss:     1.351123, Batch Acc: 0.627559, Tokens per Sec:    23290, Lr: 0.000300
2024-05-19 16:08:25,242 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:08:25,242 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:08:39,349 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:08:39,350 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.38, loss:   1.52, ppl:   4.56, acc:   0.54, generation: 13.9052[sec], evaluation: 0.1853[sec]
2024-05-19 16:08:39,562 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/28500.ckpt
2024-05-19 16:08:39,576 - INFO - joeynmt.training - Example #0
2024-05-19 16:08:39,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:08:39,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:08:39,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'l@@', 'is@@', 'h', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', '--', '</s>']
2024-05-19 16:08:39,578 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:08:39,578 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:08:39,578 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slight to show that the pollish cap, that the last three million years of the size of the United States, with 40 percent of the United States, with 40 percent of the United States, with 40 percent of the United States --
2024-05-19 16:08:39,579 - INFO - joeynmt.training - Example #1
2024-05-19 16:08:39,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:08:39,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:08:39,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'ri@@', 'bu@@', 'ted', 'the', 'ar@@', 'n@@', 'st', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:08:39,580 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:08:39,580 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:08:39,580 - INFO - joeynmt.training - 	Hypothesis: But this distributed the arnst of this particular problem because it doesn't the ice of the ice.
2024-05-19 16:08:39,580 - INFO - joeynmt.training - Example #2
2024-05-19 16:08:39,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:08:39,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:08:39,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:08:39,581 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:08:39,582 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:08:39,582 - INFO - joeynmt.training - 	Hypothesis: The ice capacity on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 16:08:39,582 - INFO - joeynmt.training - Example #3
2024-05-19 16:08:39,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:08:39,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:08:39,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'ks', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:08:39,583 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:08:39,583 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:08:39,583 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and cracks in the summer.
2024-05-19 16:08:39,583 - INFO - joeynmt.training - Example #4
2024-05-19 16:08:39,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:08:39,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:08:39,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', 'di@@', 'd', 'di@@', 'd', 'di@@', 'd', 's@@', 'li@@', 'de', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', 'di@@', 'd', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 16:08:39,584 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:08:39,585 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:08:39,585 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a accelerated version of what happened in the last 25 years of the last 25 years of the last 25 years happened in the last 25 years of the last did did did slide of what happened in the last did slide.
2024-05-19 16:08:43,034 - INFO - joeynmt.training - Epoch   7, Step:    31600, Batch Loss:     1.243553, Batch Acc: 0.620878, Tokens per Sec:    20561, Lr: 0.000300
2024-05-19 16:08:46,977 - INFO - joeynmt.training - Epoch   7, Step:    31700, Batch Loss:     1.200940, Batch Acc: 0.618183, Tokens per Sec:    19190, Lr: 0.000300
2024-05-19 16:08:47,576 - INFO - joeynmt.training - Epoch   7: total training loss 5504.18
2024-05-19 16:08:47,577 - INFO - joeynmt.training - EPOCH 8
2024-05-19 16:08:50,321 - INFO - joeynmt.training - Epoch   8, Step:    31800, Batch Loss:     1.062471, Batch Acc: 0.642690, Tokens per Sec:    23324, Lr: 0.000300
2024-05-19 16:08:53,485 - INFO - joeynmt.training - Epoch   8, Step:    31900, Batch Loss:     1.073002, Batch Acc: 0.636872, Tokens per Sec:    24133, Lr: 0.000300
2024-05-19 16:08:57,029 - INFO - joeynmt.training - Epoch   8, Step:    32000, Batch Loss:     1.222828, Batch Acc: 0.639704, Tokens per Sec:    21427, Lr: 0.000300
2024-05-19 16:08:57,029 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:08:57,029 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:09:12,205 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:09:12,206 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.69, loss:   1.51, ppl:   4.53, acc:   0.54, generation: 14.8004[sec], evaluation: 0.3414[sec]
2024-05-19 16:09:12,206 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:09:12,436 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/30000.ckpt
2024-05-19 16:09:12,465 - INFO - joeynmt.training - Example #0
2024-05-19 16:09:12,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:09:12,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:09:12,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'that', 'the', 'p@@', 'ol@@', 'e', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'v@@', 'e.', '</s>']
2024-05-19 16:09:12,467 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:09:12,467 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:09:12,467 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slide of the United that the pole cap, that the last three million years of the size of the U.S. with 40 percent of the United States, with 40 percent curve.
2024-05-19 16:09:12,467 - INFO - joeynmt.training - Example #1
2024-05-19 16:09:12,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:09:12,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:09:12,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'ri@@', 'bu@@', 'ted', 'the', 'wor@@', 'st', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:09:12,469 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:09:12,469 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:09:12,469 - INFO - joeynmt.training - 	Hypothesis: But this distributed the worst of this particular problem because it doesn't show the disection of the ice.
2024-05-19 16:09:12,469 - INFO - joeynmt.training - Example #2
2024-05-19 16:09:12,470 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:09:12,470 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:09:12,470 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:09:12,471 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:09:12,471 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:09:12,471 - INFO - joeynmt.training - 	Hypothesis: The ice capacity is in a certain sense, in a sense, heart of our global climate system.
2024-05-19 16:09:12,471 - INFO - joeynmt.training - Example #3
2024-05-19 16:09:12,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:09:12,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:09:12,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'in@@', 'k', 'and', 'c@@', 'r@@', 'in@@', 'e.', '</s>']
2024-05-19 16:09:12,472 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:09:12,472 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:09:12,473 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crink and crine.
2024-05-19 16:09:12,473 - INFO - joeynmt.training - Example #4
2024-05-19 16:09:12,473 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:09:12,473 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:09:12,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'that', "I'm", 's@@', 'ho@@', 'w@@', 'ing', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:09:12,474 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:09:12,474 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:09:12,474 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'm showing is a version of what happened is a version of what happened the last 25 years.
2024-05-19 16:09:16,107 - INFO - joeynmt.training - Epoch   8, Step:    32100, Batch Loss:     1.132850, Batch Acc: 0.635709, Tokens per Sec:    19718, Lr: 0.000300
2024-05-19 16:09:19,293 - INFO - joeynmt.training - Epoch   8, Step:    32200, Batch Loss:     1.096334, Batch Acc: 0.642469, Tokens per Sec:    24044, Lr: 0.000300
2024-05-19 16:09:22,689 - INFO - joeynmt.training - Epoch   8, Step:    32300, Batch Loss:     1.236779, Batch Acc: 0.640203, Tokens per Sec:    22591, Lr: 0.000300
2024-05-19 16:09:26,555 - INFO - joeynmt.training - Epoch   8, Step:    32400, Batch Loss:     1.003292, Batch Acc: 0.642649, Tokens per Sec:    19492, Lr: 0.000300
2024-05-19 16:09:30,206 - INFO - joeynmt.training - Epoch   8, Step:    32500, Batch Loss:     1.167274, Batch Acc: 0.638031, Tokens per Sec:    20655, Lr: 0.000300
2024-05-19 16:09:30,207 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:09:30,207 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:09:46,403 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:09:46,403 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  13.97, loss:   1.52, ppl:   4.58, acc:   0.54, generation: 15.9854[sec], evaluation: 0.1930[sec]
2024-05-19 16:09:46,614 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/30500.ckpt
2024-05-19 16:09:46,626 - INFO - joeynmt.training - Example #0
2024-05-19 16:09:46,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:09:46,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:09:46,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 's@@', 'ho@@', 'w@@', 'ed', 'this', 'two', 's@@', 'ho@@', 'w@@', 'ing', 'these', 'two', 's@@', 'li@@', 'de', 'of', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', 'e', 'c@@', 'ap@@', ',', 'which', 'is', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'that', 'was', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 's.', '</s>']
2024-05-19 16:09:46,628 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:09:46,629 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:09:46,629 - INFO - joeynmt.training - 	Hypothesis: And showed this two showing these two slide of the polar cape cap, which is the last three million years that was about the size of the U.S. with 40 percent of the U.S. with 40 percent currents.
2024-05-19 16:09:46,629 - INFO - joeynmt.training - Example #1
2024-05-19 16:09:46,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:09:46,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:09:46,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'ri@@', 'bu@@', 'te@@', 's', 'the', 'wor@@', 'st', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 's@@', 'ho@@', 'w@@', 's', 'not', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:09:46,630 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:09:46,630 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:09:46,631 - INFO - joeynmt.training - 	Hypothesis: But this distributes the worst of this specific problem because it shows not the disection of the ice.
2024-05-19 16:09:46,631 - INFO - joeynmt.training - Example #2
2024-05-19 16:09:46,631 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:09:46,631 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:09:46,631 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'is', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'wa@@', 'y,', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'he@@', 'ar@@', 't', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:09:46,632 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:09:46,632 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:09:46,632 - INFO - joeynmt.training - 	Hypothesis: The ice capacity is on the North Pole, in a way, heart of our global heart system.
2024-05-19 16:09:46,632 - INFO - joeynmt.training - Example #3
2024-05-19 16:09:46,633 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:09:46,633 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:09:46,633 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:09:46,633 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:09:46,633 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:09:46,634 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crack in the summer.
2024-05-19 16:09:46,634 - INFO - joeynmt.training - Example #4
2024-05-19 16:09:46,634 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:09:46,634 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:09:46,634 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'ol@@', 'd.', '</s>']
2024-05-19 16:09:46,635 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:09:46,635 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:09:46,635 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what the last 25 years old.
2024-05-19 16:09:49,929 - INFO - joeynmt.training - Epoch   8, Step:    32600, Batch Loss:     1.173239, Batch Acc: 0.640683, Tokens per Sec:    21472, Lr: 0.000300
2024-05-19 16:09:53,510 - INFO - joeynmt.training - Epoch   8, Step:    32700, Batch Loss:     1.107138, Batch Acc: 0.634471, Tokens per Sec:    20838, Lr: 0.000300
2024-05-19 16:09:57,725 - INFO - joeynmt.training - Epoch   8, Step:    32800, Batch Loss:     1.117903, Batch Acc: 0.631351, Tokens per Sec:    18007, Lr: 0.000300
2024-05-19 16:10:00,947 - INFO - joeynmt.training - Epoch   8, Step:    32900, Batch Loss:     1.029197, Batch Acc: 0.633340, Tokens per Sec:    24135, Lr: 0.000300
2024-05-19 16:10:04,241 - INFO - joeynmt.training - Epoch   8, Step:    33000, Batch Loss:     1.211065, Batch Acc: 0.635605, Tokens per Sec:    23895, Lr: 0.000300
2024-05-19 16:10:04,242 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:10:04,242 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:10:19,315 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:10:19,316 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.02, loss:   1.51, ppl:   4.52, acc:   0.54, generation: 14.8546[sec], evaluation: 0.2009[sec]
2024-05-19 16:10:19,316 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:10:19,544 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/32500.ckpt
2024-05-19 16:10:19,559 - INFO - joeynmt.training - Example #0
2024-05-19 16:10:19,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:10:19,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:10:19,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'of', 'the', 'p@@', 'ol@@', 'ar', 's@@', 'ho@@', 'w@@', 's', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'which', 'was', 'about', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'about', '4@@', '0', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'about', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'at@@', 'or@@', '.', '</s>']
2024-05-19 16:10:19,561 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:10:19,561 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:10:19,561 - INFO - joeynmt.training - 	Hypothesis: And I show these two slight of the polar shows that the last three million years, which was about three million years, about 40 million years, about 40 percent of the U.S. with 40 percent of the U.S. with 40 percent curator.
2024-05-19 16:10:19,561 - INFO - joeynmt.training - Example #1
2024-05-19 16:10:19,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:10:19,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:10:19,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 're@@', 'as@@', 'on', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:10:19,563 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:10:19,563 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:10:19,563 - INFO - joeynmt.training - 	Hypothesis: But this is the reason of this particular problem because it doesn't show the ice of the ice.
2024-05-19 16:10:19,563 - INFO - joeynmt.training - Example #2
2024-05-19 16:10:19,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:10:19,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:10:19,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'wa@@', 'y,', 'the', 'c@@', 'l@@', 'as@@', 's@@', 'r@@', 'oo@@', 'm', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:10:19,564 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:10:19,565 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:10:19,565 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a way, the classroom of our global climate system.
2024-05-19 16:10:19,565 - INFO - joeynmt.training - Example #3
2024-05-19 16:10:19,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:10:19,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:10:19,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'in', 'the', 'su@@', 'm@@', 'm@@', 's', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:10:19,566 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:10:19,566 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:10:19,566 - INFO - joeynmt.training - 	Hypothesis: It put in the summs and crace in the summer.
2024-05-19 16:10:19,566 - INFO - joeynmt.training - Example #4
2024-05-19 16:10:19,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:10:19,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:10:19,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:10:19,568 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:10:19,568 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:10:19,568 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a accelerated version of what happens in the last 25 years.
2024-05-19 16:10:23,763 - INFO - joeynmt.training - Epoch   8, Step:    33100, Batch Loss:     1.199779, Batch Acc: 0.638802, Tokens per Sec:    16937, Lr: 0.000300
2024-05-19 16:10:27,439 - INFO - joeynmt.training - Epoch   8, Step:    33200, Batch Loss:     1.226325, Batch Acc: 0.638255, Tokens per Sec:    20694, Lr: 0.000300
2024-05-19 16:10:30,849 - INFO - joeynmt.training - Epoch   8, Step:    33300, Batch Loss:     1.200398, Batch Acc: 0.630193, Tokens per Sec:    22584, Lr: 0.000300
2024-05-19 16:10:34,189 - INFO - joeynmt.training - Epoch   8, Step:    33400, Batch Loss:     1.236491, Batch Acc: 0.634050, Tokens per Sec:    23025, Lr: 0.000300
2024-05-19 16:10:38,576 - INFO - joeynmt.training - Epoch   8, Step:    33500, Batch Loss:     1.261570, Batch Acc: 0.633745, Tokens per Sec:    17553, Lr: 0.000300
2024-05-19 16:10:38,577 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:10:38,577 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:10:53,037 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:10:53,038 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.51, loss:   1.51, ppl:   4.53, acc:   0.54, generation: 14.2349[sec], evaluation: 0.2080[sec]
2024-05-19 16:10:53,248 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/29500.ckpt
2024-05-19 16:10:53,264 - INFO - joeynmt.training - Example #0
2024-05-19 16:10:53,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:10:53,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:10:53,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de', 'of', 's@@', 'li@@', 'g@@', 'h@@', 't', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', 'tur@@', 'e', 'that', 'the', 'p@@', 'ol@@', 'ar', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 'the', 'si@@', 'ze', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'was', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'ly', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'ly', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'ly', 'to', 's@@', 'how', 'these', 'two', 's@@', 'li@@', 'p@@', 's.', '</s>']
2024-05-19 16:10:53,265 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:10:53,266 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:10:53,266 - INFO - joeynmt.training - 	Hypothesis: And I showed these two slide of slight that the polar capture that the polar three million years to the size three million years of the U.S. with 40 percent years of the U.S. with 40 percent was currently currently currently to show these two slips.
2024-05-19 16:10:53,266 - INFO - joeynmt.training - Example #1
2024-05-19 16:10:53,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:10:53,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:10:53,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'ri@@', 'bu@@', 't,', 'the', 'rec@@', 'or@@', 'd', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:10:53,267 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:10:53,267 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:10:53,267 - INFO - joeynmt.training - 	Hypothesis: But this distribut, the record of this specific problem because it doesn't show the ice of the ice of the ice.
2024-05-19 16:10:53,268 - INFO - joeynmt.training - Example #2
2024-05-19 16:10:53,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:10:53,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:10:53,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', 'The', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:10:53,269 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:10:53,269 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:10:53,269 - INFO - joeynmt.training - 	Hypothesis: The ice climate system. The North Pole is climate system.
2024-05-19 16:10:53,270 - INFO - joeynmt.training - Example #3
2024-05-19 16:10:53,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:10:53,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:10:53,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'su@@', 'm@@', 'mer@@', ',', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:10:53,271 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:10:53,271 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:10:53,271 - INFO - joeynmt.training - 	Hypothesis: It put out in the summer, and crack in summer.
2024-05-19 16:10:53,271 - INFO - joeynmt.training - Example #4
2024-05-19 16:10:53,271 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:10:53,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:10:53,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'was', 'a', 'very', 'sp@@', 'e@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'a', 'very', 'sp@@', 'e@@', 'ed', 'about', '2@@', '5', 'years', 'is', 'a', 'very', 'sp@@', 'e@@', 'ed', 'about', 'a', 'b@@', 'it', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:10:53,272 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:10:53,272 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:10:53,273 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a accelerated version of what happened the last 25 years happened in the last 25 years happened in the last 25 years happened in the last 25 years was a very speed version of what the last 25 years happened in the last 25 years is a very speed about 25 years is a very speed about a bit of what happened the last 25 years.
2024-05-19 16:10:56,592 - INFO - joeynmt.training - Epoch   8, Step:    33600, Batch Loss:     1.215144, Batch Acc: 0.637641, Tokens per Sec:    21194, Lr: 0.000300
2024-05-19 16:11:00,125 - INFO - joeynmt.training - Epoch   8, Step:    33700, Batch Loss:     1.310586, Batch Acc: 0.634061, Tokens per Sec:    21993, Lr: 0.000300
2024-05-19 16:11:03,790 - INFO - joeynmt.training - Epoch   8, Step:    33800, Batch Loss:     1.223433, Batch Acc: 0.634309, Tokens per Sec:    20779, Lr: 0.000300
2024-05-19 16:11:07,892 - INFO - joeynmt.training - Epoch   8, Step:    33900, Batch Loss:     1.297285, Batch Acc: 0.635885, Tokens per Sec:    18518, Lr: 0.000300
2024-05-19 16:11:11,199 - INFO - joeynmt.training - Epoch   8, Step:    34000, Batch Loss:     1.081569, Batch Acc: 0.636665, Tokens per Sec:    23377, Lr: 0.000300
2024-05-19 16:11:11,199 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:11:11,200 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:11:24,744 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:11:24,745 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.47, loss:   1.50, ppl:   4.49, acc:   0.54, generation: 13.3322[sec], evaluation: 0.1926[sec]
2024-05-19 16:11:24,746 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:11:24,958 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/31500.ckpt
2024-05-19 16:11:24,973 - INFO - joeynmt.training - Example #0
2024-05-19 16:11:24,974 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:11:24,974 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:11:24,974 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'l@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 'di@@', 'a@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'e', 'c@@', 'ap@@', 'tur@@', 'e', 'c@@', 'ap@@', 'tur@@', 'e', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', '</s>']
2024-05-19 16:11:24,975 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:11:24,975 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:11:24,975 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these two dias to show that the pole capture capture that the last three million years of about the size of the United States, with 40 percent of the United States, with 40 percent percent of the United States, with 40 percent percent of the United States,
2024-05-19 16:11:24,975 - INFO - joeynmt.training - Example #1
2024-05-19 16:11:24,975 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:11:24,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:11:24,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 't', 'is', 'the', 'wor@@', 'st', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 'the', 'di@@', 'c@@', 't', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:11:24,976 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:11:24,976 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:11:24,977 - INFO - joeynmt.training - 	Hypothesis: But this distinct is the worst of this specific problem because it doesn't the dict of the ice.
2024-05-19 16:11:24,977 - INFO - joeynmt.training - Example #2
2024-05-19 16:11:24,977 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:11:24,977 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:11:24,977 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'li@@', 'm@@', 'ate', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:11:24,978 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:11:24,978 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:11:24,978 - INFO - joeynmt.training - 	Hypothesis: The ice climate on the North Pole is in a certain sense, climate system.
2024-05-19 16:11:24,978 - INFO - joeynmt.training - Example #3
2024-05-19 16:11:24,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:11:24,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:11:24,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'es', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:11:24,979 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:11:24,979 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:11:24,980 - INFO - joeynmt.training - 	Hypothesis: It put in the winter and craces in the summer.
2024-05-19 16:11:24,980 - INFO - joeynmt.training - Example #4
2024-05-19 16:11:24,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:11:24,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:11:24,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ing', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', 'di@@', 'a', 'I', 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 16:11:24,981 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:11:24,981 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:11:24,981 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a accelerated version of what happened in the last 25 years of the last 25 years of the last 25 years of happened in the last 25 years of the last 25 years of the last 25 years of what happened is happening in the last 25 years of the last dia I show.
2024-05-19 16:11:28,246 - INFO - joeynmt.training - Epoch   8, Step:    34100, Batch Loss:     1.054186, Batch Acc: 0.637228, Tokens per Sec:    21545, Lr: 0.000300
2024-05-19 16:11:31,797 - INFO - joeynmt.training - Epoch   8, Step:    34200, Batch Loss:     1.190868, Batch Acc: 0.626986, Tokens per Sec:    21543, Lr: 0.000300
2024-05-19 16:11:36,122 - INFO - joeynmt.training - Epoch   8, Step:    34300, Batch Loss:     1.293931, Batch Acc: 0.630336, Tokens per Sec:    17423, Lr: 0.000300
2024-05-19 16:11:39,381 - INFO - joeynmt.training - Epoch   8, Step:    34400, Batch Loss:     1.159798, Batch Acc: 0.630101, Tokens per Sec:    23323, Lr: 0.000300
2024-05-19 16:11:42,572 - INFO - joeynmt.training - Epoch   8, Step:    34500, Batch Loss:     1.191228, Batch Acc: 0.628843, Tokens per Sec:    24033, Lr: 0.000300
2024-05-19 16:11:42,573 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:11:42,573 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:11:56,581 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:11:56,581 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.79, loss:   1.51, ppl:   4.52, acc:   0.54, generation: 13.7849[sec], evaluation: 0.2046[sec]
2024-05-19 16:11:56,784 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/31000.ckpt
2024-05-19 16:11:56,799 - INFO - joeynmt.training - Example #0
2024-05-19 16:11:56,800 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:11:56,800 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:11:56,800 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'l@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', 'e', 'c@@', 'ap@@', 'e', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@']
2024-05-19 16:11:56,801 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:11:56,801 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:11:56,801 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these two slides to show that the polar cape cape that the last three million years about the size of the United States, with 40 percent of the United States, with 40 percent of the United States, with 40 percent of the United S, with 40 percent of the United States, with 40 percent of the United S
2024-05-19 16:11:56,801 - INFO - joeynmt.training - Example #1
2024-05-19 16:11:56,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:11:56,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:11:56,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 'tion', 'is', 'the', 'wor@@', 'st', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'the', 'di@@', 'se@@', 'c@@', 't', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:11:56,803 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:11:56,803 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:11:56,803 - INFO - joeynmt.training - 	Hypothesis: But this distinction is the worst of this particular problem because it is not the disect of the ice.
2024-05-19 16:11:56,803 - INFO - joeynmt.training - Example #2
2024-05-19 16:11:56,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:11:56,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:11:56,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:11:56,804 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:11:56,805 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:11:56,805 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a sense, heart of our global climate system.
2024-05-19 16:11:56,805 - INFO - joeynmt.training - Example #3
2024-05-19 16:11:56,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:11:56,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:11:56,806 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'in@@', 'k@@', 's,', '</s>']
2024-05-19 16:11:56,806 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:11:56,806 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:11:56,806 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crinks,
2024-05-19 16:11:56,807 - INFO - joeynmt.training - Example #4
2024-05-19 16:11:56,807 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:11:56,807 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:11:56,807 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'a', 'very', 'sp@@', 'e@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:11:56,808 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:11:56,808 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:11:56,808 - INFO - joeynmt.training - 	Hypothesis: And the next slide I shows a very speed version of what happened the last 25 years.
2024-05-19 16:12:00,479 - INFO - joeynmt.training - Epoch   8, Step:    34600, Batch Loss:     1.156431, Batch Acc: 0.628065, Tokens per Sec:    19025, Lr: 0.000300
2024-05-19 16:12:04,499 - INFO - joeynmt.training - Epoch   8, Step:    34700, Batch Loss:     1.081951, Batch Acc: 0.633702, Tokens per Sec:    18610, Lr: 0.000300
2024-05-19 16:12:07,954 - INFO - joeynmt.training - Epoch   8, Step:    34800, Batch Loss:     1.279848, Batch Acc: 0.631519, Tokens per Sec:    22453, Lr: 0.000300
2024-05-19 16:12:11,158 - INFO - joeynmt.training - Epoch   8, Step:    34900, Batch Loss:     1.156724, Batch Acc: 0.632294, Tokens per Sec:    24018, Lr: 0.000300
2024-05-19 16:12:14,843 - INFO - joeynmt.training - Epoch   8, Step:    35000, Batch Loss:     1.227512, Batch Acc: 0.633858, Tokens per Sec:    20455, Lr: 0.000300
2024-05-19 16:12:14,843 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:12:14,844 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:12:28,826 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:12:28,831 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.08, loss:   1.50, ppl:   4.50, acc:   0.54, generation: 13.5969[sec], evaluation: 0.3572[sec]
2024-05-19 16:12:29,067 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/33500.ckpt
2024-05-19 16:12:29,116 - INFO - joeynmt.training - Example #0
2024-05-19 16:12:29,117 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:12:29,117 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:12:29,117 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'is', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:12:29,118 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:12:29,118 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:12:29,118 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the polar cap, which is the past three million years about the size of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:12:29,118 - INFO - joeynmt.training - Example #1
2024-05-19 16:12:29,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:12:29,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:12:29,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'un@@', 'der@@', 'est@@', 'im@@', 'ate', 'actually', 'the', 'wor@@', 'st', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:12:29,120 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:12:29,120 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:12:29,120 - INFO - joeynmt.training - 	Hypothesis: But this underestimate actually the worst of this particular problem because it doesn't show the ice.
2024-05-19 16:12:29,120 - INFO - joeynmt.training - Example #2
2024-05-19 16:12:29,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:12:29,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:12:29,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'in', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'wa@@', 'y,', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:12:29,122 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:12:29,122 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:12:29,122 - INFO - joeynmt.training - 	Hypothesis: The ice capital in the North Pole is in a way, the climate heart of our global climate system.
2024-05-19 16:12:29,122 - INFO - joeynmt.training - Example #3
2024-05-19 16:12:29,122 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:12:29,122 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:12:29,122 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'it@@', 'ic@@', 'al', 'c@@', 'r@@', 'it@@', 'ic@@', 'al', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:12:29,123 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:12:29,123 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:12:29,123 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and critical critical in summer.
2024-05-19 16:12:29,123 - INFO - joeynmt.training - Example #4
2024-05-19 16:12:29,124 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:12:29,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:12:29,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'is', 'a', 'sp@@', 'e@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'of', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'was', 'happ@@', 'en@@', 'ing', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', 's@@', 'li@@', 'de', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'the', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 16:12:29,125 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:12:29,125 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:12:29,125 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a speed version of what happens in the last 25 years of the last 25 years of happened in 25 years of happened in the last 25 years was happening in the last 25 years of the last slide of what happened is the next slide.
2024-05-19 16:12:33,147 - INFO - joeynmt.training - Epoch   8, Step:    35100, Batch Loss:     1.136824, Batch Acc: 0.631075, Tokens per Sec:    17433, Lr: 0.000300
2024-05-19 16:12:36,459 - INFO - joeynmt.training - Epoch   8, Step:    35200, Batch Loss:     1.129219, Batch Acc: 0.637199, Tokens per Sec:    23228, Lr: 0.000300
2024-05-19 16:12:39,680 - INFO - joeynmt.training - Epoch   8, Step:    35300, Batch Loss:     1.210594, Batch Acc: 0.631764, Tokens per Sec:    23725, Lr: 0.000300
2024-05-19 16:12:43,285 - INFO - joeynmt.training - Epoch   8, Step:    35400, Batch Loss:     1.180071, Batch Acc: 0.628465, Tokens per Sec:    21086, Lr: 0.000300
2024-05-19 16:12:47,095 - INFO - joeynmt.training - Epoch   8, Step:    35500, Batch Loss:     1.190517, Batch Acc: 0.630644, Tokens per Sec:    20125, Lr: 0.000300
2024-05-19 16:12:47,095 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:12:47,096 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:13:00,922 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:13:00,922 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.76, loss:   1.50, ppl:   4.47, acc:   0.54, generation: 13.6231[sec], evaluation: 0.1856[sec]
2024-05-19 16:13:00,923 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:13:01,142 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/32000.ckpt
2024-05-19 16:13:01,157 - INFO - joeynmt.training - Example #0
2024-05-19 16:13:01,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:13:01,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:13:01,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'of', 'the', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:13:01,159 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:13:01,159 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:13:01,159 - INFO - joeynmt.training - 	Hypothesis: And I showed these two slight of the two slight that the last three million years to the last three million years to the size of the U.S.
2024-05-19 16:13:01,159 - INFO - joeynmt.training - Example #1
2024-05-19 16:13:01,160 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:13:01,160 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:13:01,160 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 'most', 'di@@', 'st@@', 'ri@@', 'bu@@', 'te', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:13:01,161 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:13:01,161 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:13:01,161 - INFO - joeynmt.training - 	Hypothesis: But this is the most distribute of this particular problem because it doesn't show the disection of the ice.
2024-05-19 16:13:01,161 - INFO - joeynmt.training - Example #2
2024-05-19 16:13:01,161 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:13:01,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:13:01,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'he@@', 'ar@@', 't', 'of', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:13:01,162 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:13:01,162 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:13:01,162 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a sense, in a sense, heart of our global heart of climate system.
2024-05-19 16:13:01,163 - INFO - joeynmt.training - Example #3
2024-05-19 16:13:01,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:13:01,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:13:01,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:13:01,164 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:13:01,164 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:13:01,164 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crace in the summer.
2024-05-19 16:13:01,164 - INFO - joeynmt.training - Example #4
2024-05-19 16:13:01,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:13:01,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:13:01,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'is', 'a', 'very', 's@@', 'ing@@', 'le', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'very', 's@@', 'ing@@', 'le', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 16:13:01,165 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:13:01,165 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:13:01,165 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a very single version of what happened the last 25 years of the last 25 years of the last 25 years of the last 25 years of what happened the last 25 years of what happened is a very single version of what the last slide.
2024-05-19 16:13:04,408 - INFO - joeynmt.training - Epoch   8, Step:    35600, Batch Loss:     1.220291, Batch Acc: 0.628867, Tokens per Sec:    21713, Lr: 0.000300
2024-05-19 16:13:07,641 - INFO - joeynmt.training - Epoch   8, Step:    35700, Batch Loss:     1.174861, Batch Acc: 0.635155, Tokens per Sec:    23768, Lr: 0.000300
2024-05-19 16:13:11,379 - INFO - joeynmt.training - Epoch   8, Step:    35800, Batch Loss:     1.048581, Batch Acc: 0.628407, Tokens per Sec:    20177, Lr: 0.000300
2024-05-19 16:13:15,359 - INFO - joeynmt.training - Epoch   8, Step:    35900, Batch Loss:     1.077810, Batch Acc: 0.630622, Tokens per Sec:    19119, Lr: 0.000300
2024-05-19 16:13:18,648 - INFO - joeynmt.training - Epoch   8, Step:    36000, Batch Loss:     1.173953, Batch Acc: 0.629260, Tokens per Sec:    23271, Lr: 0.000300
2024-05-19 16:13:18,649 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:13:18,649 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:13:32,499 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:13:32,499 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.63, loss:   1.50, ppl:   4.47, acc:   0.54, generation: 13.6235[sec], evaluation: 0.2093[sec]
2024-05-19 16:13:32,708 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/34500.ckpt
2024-05-19 16:13:32,723 - INFO - joeynmt.training - Example #0
2024-05-19 16:13:32,724 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:13:32,724 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:13:32,725 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'is', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 'be', 'about', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'S@@', 'S@@', 't@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:13:32,725 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:13:32,725 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:13:32,726 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the polar cap, which is three million years to be about the last three million years, about the size of the USSt, with 40 percent of the U.S.
2024-05-19 16:13:32,726 - INFO - joeynmt.training - Example #1
2024-05-19 16:13:32,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:13:32,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:13:32,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'most', 'se@@', 'con@@', 'd', 'the', 'most', 'most', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'ho@@', 'w@@', 'ed', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 16:13:32,727 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:13:32,727 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:13:32,727 - INFO - joeynmt.training - 	Hypothesis: But this is actually the most second the most most of this specific problem because it doesn't showed the disection of the ice of ice.
2024-05-19 16:13:32,727 - INFO - joeynmt.training - Example #2
2024-05-19 16:13:32,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:13:32,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:13:32,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'c@@', 'li@@', 'm@@', 'ate', 'sen@@', 'se', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:13:32,729 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:13:32,729 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:13:32,729 - INFO - joeynmt.training - 	Hypothesis: The ice cap on the North Pole, in a climate sense of our global climate system.
2024-05-19 16:13:32,729 - INFO - joeynmt.training - Example #3
2024-05-19 16:13:32,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:13:32,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:13:32,730 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'oo@@', 'm@@', 's', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:13:32,730 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:13:32,730 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:13:32,731 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crooms in the summer.
2024-05-19 16:13:32,731 - INFO - joeynmt.training - Example #4
2024-05-19 16:13:32,731 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:13:32,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:13:32,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:13:32,732 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:13:32,732 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:13:32,732 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a accelerated version of what happened the last 25 years.
2024-05-19 16:13:35,968 - INFO - joeynmt.training - Epoch   8, Step:    36100, Batch Loss:     0.940551, Batch Acc: 0.638240, Tokens per Sec:    21722, Lr: 0.000300
2024-05-19 16:13:39,510 - INFO - joeynmt.training - Epoch   8, Step:    36200, Batch Loss:     0.926169, Batch Acc: 0.636760, Tokens per Sec:    21267, Lr: 0.000300
2024-05-19 16:13:41,308 - INFO - joeynmt.training - Epoch   8: total training loss 5337.20
2024-05-19 16:13:41,319 - INFO - joeynmt.training - EPOCH 9
2024-05-19 16:13:43,475 - INFO - joeynmt.training - Epoch   9, Step:    36300, Batch Loss:     1.069767, Batch Acc: 0.650818, Tokens per Sec:    21687, Lr: 0.000300
2024-05-19 16:13:46,715 - INFO - joeynmt.training - Epoch   9, Step:    36400, Batch Loss:     1.092794, Batch Acc: 0.652233, Tokens per Sec:    24260, Lr: 0.000300
2024-05-19 16:13:50,117 - INFO - joeynmt.training - Epoch   9, Step:    36500, Batch Loss:     1.000747, Batch Acc: 0.649225, Tokens per Sec:    22141, Lr: 0.000300
2024-05-19 16:13:50,118 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:13:50,118 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:14:04,408 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:14:04,409 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.81, loss:   1.50, ppl:   4.47, acc:   0.54, generation: 14.0745[sec], evaluation: 0.1973[sec]
2024-05-19 16:14:04,621 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/33000.ckpt
2024-05-19 16:14:04,636 - INFO - joeynmt.training - Example #0
2024-05-19 16:14:04,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:14:04,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:14:04,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'l@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 's@@', 'ho@@', 'w@@', 'ing', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 's@@', 'how', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'was', 'c@@', 'ur@@', 'r@@', 'ic@@', 'at@@', 'e.', '</s>']
2024-05-19 16:14:04,638 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:14:04,638 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:14:04,638 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these two slight showing that the last three million years to show that the last three million years of the size of the United States, with 40 percent of the United States was curricate.
2024-05-19 16:14:04,638 - INFO - joeynmt.training - Example #1
2024-05-19 16:14:04,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:14:04,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:14:04,639 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 'ti@@', 've', 'the', 'rec@@', 'or@@', 'de@@', 'd', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'di@@', 'se@@', 'as@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 16:14:04,640 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:14:04,640 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:14:04,640 - INFO - joeynmt.training - 	Hypothesis: But this distinctive the recorded of this specific problem because it doesn't show the disease of the ice of ice.
2024-05-19 16:14:04,640 - INFO - joeynmt.training - Example #2
2024-05-19 16:14:04,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:14:04,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:14:04,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'in', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:14:04,641 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:14:04,641 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:14:04,641 - INFO - joeynmt.training - 	Hypothesis: The ice capital in the North Pole, in a certain sense, heart of our global climate system.
2024-05-19 16:14:04,642 - INFO - joeynmt.training - Example #3
2024-05-19 16:14:04,642 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:14:04,642 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:14:04,642 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:14:04,643 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:14:04,643 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:14:04,643 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crace in the summer.
2024-05-19 16:14:04,643 - INFO - joeynmt.training - Example #4
2024-05-19 16:14:04,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:14:04,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:14:04,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de@@', ',', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'ol@@', 'd.', '</s>']
2024-05-19 16:14:04,644 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:14:04,645 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:14:04,645 - INFO - joeynmt.training - 	Hypothesis: The next slide slide, I shows is a version of what the last 25 years of what happened 25 years old.
2024-05-19 16:14:08,483 - INFO - joeynmt.training - Epoch   9, Step:    36600, Batch Loss:     1.119222, Batch Acc: 0.647582, Tokens per Sec:    19112, Lr: 0.000300
2024-05-19 16:14:12,336 - INFO - joeynmt.training - Epoch   9, Step:    36700, Batch Loss:     1.081841, Batch Acc: 0.652843, Tokens per Sec:    19810, Lr: 0.000300
2024-05-19 16:14:15,607 - INFO - joeynmt.training - Epoch   9, Step:    36800, Batch Loss:     1.296894, Batch Acc: 0.643181, Tokens per Sec:    22745, Lr: 0.000300
2024-05-19 16:14:18,815 - INFO - joeynmt.training - Epoch   9, Step:    36900, Batch Loss:     1.070713, Batch Acc: 0.643796, Tokens per Sec:    23210, Lr: 0.000300
2024-05-19 16:14:22,674 - INFO - joeynmt.training - Epoch   9, Step:    37000, Batch Loss:     1.190335, Batch Acc: 0.648279, Tokens per Sec:    19422, Lr: 0.000300
2024-05-19 16:14:22,675 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:14:22,675 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:14:38,961 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:14:38,961 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.09, loss:   1.51, ppl:   4.52, acc:   0.54, generation: 16.0625[sec], evaluation: 0.2055[sec]
2024-05-19 16:14:38,966 - INFO - joeynmt.training - Example #0
2024-05-19 16:14:38,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:14:38,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:14:38,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'l@@', 'is@@', 'h', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'was', 'about', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'was', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 's.', '</s>']
2024-05-19 16:14:38,969 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:14:38,969 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:14:38,969 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slides to show that the pollish cap, that the last three million years, about the size of the polar cap, which was about 40 percent of the United States with 40 percent of the United States was currents.
2024-05-19 16:14:38,969 - INFO - joeynmt.training - Example #1
2024-05-19 16:14:38,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:14:38,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:14:38,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 'tion', 'actually', 'the', 'most', 'se@@', 'ver@@', 'al', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'the', 'di@@', 'c@@', 'at@@', 'h', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:14:38,970 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:14:38,971 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:14:38,971 - INFO - joeynmt.training - 	Hypothesis: But this distinction actually the most several problem because it is not the dicath of the ice.
2024-05-19 16:14:38,971 - INFO - joeynmt.training - Example #2
2024-05-19 16:14:38,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:14:38,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:14:38,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'tu@@', 're@@', 'd', 'in', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:14:38,972 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:14:38,972 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:14:38,973 - INFO - joeynmt.training - 	Hypothesis: The ice captured in the North Pole, in a sense, heart of our global climate system.
2024-05-19 16:14:38,973 - INFO - joeynmt.training - Example #3
2024-05-19 16:14:38,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:14:38,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:14:38,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:14:38,974 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:14:38,974 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:14:38,974 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crace in summer.
2024-05-19 16:14:38,975 - INFO - joeynmt.training - Example #4
2024-05-19 16:14:38,975 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:14:38,975 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:14:38,975 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', ',', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:14:38,976 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:14:38,976 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:14:38,976 - INFO - joeynmt.training - 	Hypothesis: The next slide, I shows is a accelerated version of what happened the last 25 years.
2024-05-19 16:14:42,221 - INFO - joeynmt.training - Epoch   9, Step:    37100, Batch Loss:     1.225084, Batch Acc: 0.645521, Tokens per Sec:    23394, Lr: 0.000300
2024-05-19 16:14:45,373 - INFO - joeynmt.training - Epoch   9, Step:    37200, Batch Loss:     1.102592, Batch Acc: 0.645892, Tokens per Sec:    24328, Lr: 0.000300
2024-05-19 16:14:48,565 - INFO - joeynmt.training - Epoch   9, Step:    37300, Batch Loss:     1.172090, Batch Acc: 0.646462, Tokens per Sec:    23422, Lr: 0.000300
2024-05-19 16:14:52,801 - INFO - joeynmt.training - Epoch   9, Step:    37400, Batch Loss:     1.282722, Batch Acc: 0.642377, Tokens per Sec:    17565, Lr: 0.000300
2024-05-19 16:14:55,963 - INFO - joeynmt.training - Epoch   9, Step:    37500, Batch Loss:     1.176316, Batch Acc: 0.642541, Tokens per Sec:    24331, Lr: 0.000300
2024-05-19 16:14:55,963 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:14:55,964 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:15:10,224 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:15:10,225 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.67, loss:   1.50, ppl:   4.47, acc:   0.55, generation: 14.0478[sec], evaluation: 0.1943[sec]
2024-05-19 16:15:10,430 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/35000.ckpt
2024-05-19 16:15:10,442 - INFO - joeynmt.training - Example #0
2024-05-19 16:15:10,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:15:10,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:15:10,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'l@@', 'ast', 'year@@', ',', 'I', 's@@', 'how', 'these', 'two', 'di@@', 'a@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'u@@', 't@@', 'ting', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', ',', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'ly', 'had', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'ly', 'c@@', 'ur@@', 'r@@', 'en@@', 'c@@', 'e@@', 'd.', '</s>']
2024-05-19 16:15:10,444 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:15:10,444 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:15:10,444 - INFO - joeynmt.training - 	Hypothesis: And last year, I show these two dias to show that the polar cutting the polar cap, that the last three million year, about the size of the U.S. currently had currently currenced.
2024-05-19 16:15:10,444 - INFO - joeynmt.training - Example #1
2024-05-19 16:15:10,445 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:15:10,445 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:15:10,445 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 'ti@@', 've', 'the', 'ser@@', 'v@@', 'ation', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'di@@', 'se@@', 'c@@', 't@@', 'or@@', '.', '</s>']
2024-05-19 16:15:10,446 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:15:10,446 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:15:10,446 - INFO - joeynmt.training - 	Hypothesis: But this distinctive the servation of this specific problem because it doesn't show the disector.
2024-05-19 16:15:10,447 - INFO - joeynmt.training - Example #2
2024-05-19 16:15:10,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:15:10,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:15:10,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:15:10,448 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:15:10,448 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:15:10,448 - INFO - joeynmt.training - 	Hypothesis: The ice capacity on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 16:15:10,449 - INFO - joeynmt.training - Example #3
2024-05-19 16:15:10,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:15:10,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:15:10,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:15:10,450 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:15:10,450 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:15:10,450 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crack in the summer.
2024-05-19 16:15:10,450 - INFO - joeynmt.training - Example #4
2024-05-19 16:15:10,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:15:10,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:15:10,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', 's', 'I', 's@@', 'how', 'is', 'happ@@', 'en@@', 'ing', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:15:10,452 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:15:10,452 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:15:10,452 - INFO - joeynmt.training - 	Hypothesis: The next slides I show is happening is a accelerated version of what happened the last 25 years.
2024-05-19 16:15:13,681 - INFO - joeynmt.training - Epoch   9, Step:    37600, Batch Loss:     1.112844, Batch Acc: 0.636773, Tokens per Sec:    22626, Lr: 0.000300
2024-05-19 16:15:17,633 - INFO - joeynmt.training - Epoch   9, Step:    37700, Batch Loss:     1.248955, Batch Acc: 0.645574, Tokens per Sec:    19436, Lr: 0.000300
2024-05-19 16:15:21,725 - INFO - joeynmt.training - Epoch   9, Step:    37800, Batch Loss:     1.263361, Batch Acc: 0.638774, Tokens per Sec:    18395, Lr: 0.000300
2024-05-19 16:15:24,871 - INFO - joeynmt.training - Epoch   9, Step:    37900, Batch Loss:     1.193921, Batch Acc: 0.642232, Tokens per Sec:    23927, Lr: 0.000300
2024-05-19 16:15:28,084 - INFO - joeynmt.training - Epoch   9, Step:    38000, Batch Loss:     1.204529, Batch Acc: 0.640814, Tokens per Sec:    23159, Lr: 0.000300
2024-05-19 16:15:28,085 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:15:28,085 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:15:42,056 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:15:42,056 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.33, loss:   1.50, ppl:   4.47, acc:   0.55, generation: 13.7391[sec], evaluation: 0.2123[sec]
2024-05-19 16:15:42,057 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:15:42,272 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/34000.ckpt
2024-05-19 16:15:42,287 - INFO - joeynmt.training - Example #0
2024-05-19 16:15:42,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:15:42,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:15:42,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'al', 'year@@', 's,', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'of', 'the', 'l@@', 'ast', 'year@@', 's,', 'and', 'that', 'the', 'p@@', 'ol@@', 'l@@', 'is@@', 'h', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', ',', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'v@@', 'ed', '</s>']
2024-05-19 16:15:42,289 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:15:42,289 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:15:42,289 - INFO - joeynmt.training - 	Hypothesis: Forial years, I showed these two slight of the last years, and that the pollish three million year, about the size of the United States, with 40 percent of the United States with 40 percent curved
2024-05-19 16:15:42,290 - INFO - joeynmt.training - Example #1
2024-05-19 16:15:42,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:15:42,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:15:42,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'as@@', 'on', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:15:42,291 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:15:42,291 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:15:42,291 - INFO - joeynmt.training - 	Hypothesis: But this is actually the reason of this specific problem because it doesn't show the ice problem because it doesn't show the ice.
2024-05-19 16:15:42,291 - INFO - joeynmt.training - Example #2
2024-05-19 16:15:42,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:15:42,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:15:42,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:15:42,292 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:15:42,293 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:15:42,293 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a certain sense, heart of our global climate system.
2024-05-19 16:15:42,293 - INFO - joeynmt.training - Example #3
2024-05-19 16:15:42,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:15:42,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:15:42,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'h', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:15:42,294 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:15:42,294 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:15:42,294 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crach in the summer.
2024-05-19 16:15:42,294 - INFO - joeynmt.training - Example #4
2024-05-19 16:15:42,295 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:15:42,295 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:15:42,295 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'is', 'a', 'de@@', 'c@@', 'e@@', 'e@@', 'd,', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:15:42,296 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:15:42,296 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:15:42,296 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a deceed, version of what happens in the last 25 years.
2024-05-19 16:15:45,660 - INFO - joeynmt.training - Epoch   9, Step:    38100, Batch Loss:     1.300083, Batch Acc: 0.637639, Tokens per Sec:    21400, Lr: 0.000300
2024-05-19 16:15:49,818 - INFO - joeynmt.training - Epoch   9, Step:    38200, Batch Loss:     1.247060, Batch Acc: 0.645916, Tokens per Sec:    18259, Lr: 0.000300
2024-05-19 16:15:53,073 - INFO - joeynmt.training - Epoch   9, Step:    38300, Batch Loss:     1.284687, Batch Acc: 0.641611, Tokens per Sec:    23467, Lr: 0.000300
2024-05-19 16:15:56,233 - INFO - joeynmt.training - Epoch   9, Step:    38400, Batch Loss:     1.157918, Batch Acc: 0.639949, Tokens per Sec:    24213, Lr: 0.000300
2024-05-19 16:15:59,557 - INFO - joeynmt.training - Epoch   9, Step:    38500, Batch Loss:     1.034427, Batch Acc: 0.639843, Tokens per Sec:    23370, Lr: 0.000300
2024-05-19 16:15:59,557 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:15:59,558 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:16:12,958 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:16:12,959 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.08, loss:   1.49, ppl:   4.44, acc:   0.55, generation: 13.1941[sec], evaluation: 0.1895[sec]
2024-05-19 16:16:12,960 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:16:13,191 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/37500.ckpt
2024-05-19 16:16:13,202 - INFO - joeynmt.training - Example #0
2024-05-19 16:16:13,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:16:13,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:16:13,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de', 'of', 'the', 'l@@', 'ast', 'year@@', 's,', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'about', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'v@@', 'ed', '</s>']
2024-05-19 16:16:13,204 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:16:13,204 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:16:13,204 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slide of the last years, that the last three million years about three million years, about the size of the U.S. with 40 percent of the U.S., with 40 percent curved
2024-05-19 16:16:13,204 - INFO - joeynmt.training - Example #1
2024-05-19 16:16:13,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:16:13,205 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:16:13,205 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 're@@', 'se@@', 'ar@@', 'ch', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'ho@@', 'w@@', 'ed', 'the', 'ar@@', 'e@@', 'a', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:16:13,205 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:16:13,205 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:16:13,206 - INFO - joeynmt.training - 	Hypothesis: But this is actually the research of this particular problem because it doesn't showed the area of the ice of the ice of the ice of the ice of the ice.
2024-05-19 16:16:13,206 - INFO - joeynmt.training - Example #2
2024-05-19 16:16:13,206 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:16:13,206 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:16:13,206 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'wa@@', 'y,', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:16:13,207 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:16:13,207 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:16:13,207 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a way, heart of our global climate system.
2024-05-19 16:16:13,207 - INFO - joeynmt.training - Example #3
2024-05-19 16:16:13,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:16:13,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:16:13,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'up', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:16:13,208 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:16:13,209 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:16:13,209 - INFO - joeynmt.training - 	Hypothesis: It put up in the winter and crack in the summer.
2024-05-19 16:16:13,209 - INFO - joeynmt.training - Example #4
2024-05-19 16:16:13,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:16:13,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:16:13,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:16:13,210 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:16:13,210 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:16:13,210 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what happened the last 25 years.
2024-05-19 16:16:17,484 - INFO - joeynmt.training - Epoch   9, Step:    38600, Batch Loss:     1.130813, Batch Acc: 0.644721, Tokens per Sec:    16971, Lr: 0.000300
2024-05-19 16:16:20,781 - INFO - joeynmt.training - Epoch   9, Step:    38700, Batch Loss:     1.076125, Batch Acc: 0.641162, Tokens per Sec:    23373, Lr: 0.000300
2024-05-19 16:16:23,993 - INFO - joeynmt.training - Epoch   9, Step:    38800, Batch Loss:     1.235257, Batch Acc: 0.640265, Tokens per Sec:    23660, Lr: 0.000300
2024-05-19 16:16:27,280 - INFO - joeynmt.training - Epoch   9, Step:    38900, Batch Loss:     1.127747, Batch Acc: 0.637996, Tokens per Sec:    23490, Lr: 0.000300
2024-05-19 16:16:31,580 - INFO - joeynmt.training - Epoch   9, Step:    39000, Batch Loss:     1.137252, Batch Acc: 0.642142, Tokens per Sec:    18145, Lr: 0.000300
2024-05-19 16:16:31,581 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:16:31,581 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:16:46,752 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:16:46,753 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.31, loss:   1.49, ppl:   4.44, acc:   0.55, generation: 14.9609[sec], evaluation: 0.1931[sec]
2024-05-19 16:16:46,956 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/36500.ckpt
2024-05-19 16:16:46,966 - INFO - joeynmt.training - Example #0
2024-05-19 16:16:46,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:16:46,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:16:46,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'al', 'year@@', 's,', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'to', 's@@', 'how', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'about', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', ',', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'that', 'was', 's@@', 'ho@@', 'w@@', 'ed', 'to', 'the', 'si@@', 'ze', 'of', 'the', 'l@@', 'ast', 'year@@', ',', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 's@@', 'how', 'that', 'the', 'l@@', 'ast']
2024-05-19 16:16:46,968 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:16:46,969 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:16:46,969 - INFO - joeynmt.training - 	Hypothesis: Forial years, I showed these two slight to show that the last three million years about three million years about the size of the United States, with 40 percent of the United S, with 40 percent of the United States, with 40 percent of the United States that was showed to the size of the last year, three million years to show that the last
2024-05-19 16:16:46,969 - INFO - joeynmt.training - Example #1
2024-05-19 16:16:46,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:16:46,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:16:46,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 're@@', 'as@@', 'on', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 16:16:46,971 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:16:46,971 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:16:46,971 - INFO - joeynmt.training - 	Hypothesis: But this is the reason of this particular problem because it doesn't show the ice of the ice of the ice of ice.
2024-05-19 16:16:46,971 - INFO - joeynmt.training - Example #2
2024-05-19 16:16:46,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:16:46,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:16:46,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'lo@@', 'se', 'c@@', 'ap@@', 'tu@@', 're@@', ',', 'in', 'a', 'sen@@', 'se', 'of', 'the', 'c@@', 'li@@', 'm@@', 'ate', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:16:46,973 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:16:46,973 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:16:46,973 - INFO - joeynmt.training - 	Hypothesis: The ice close capture, in a sense of the climate of our global climate system.
2024-05-19 16:16:46,973 - INFO - joeynmt.training - Example #3
2024-05-19 16:16:46,974 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:16:46,974 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:16:46,974 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'h', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:16:46,974 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:16:46,974 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:16:46,975 - INFO - joeynmt.training - 	Hypothesis: It put in the winter and crach in summer.
2024-05-19 16:16:46,975 - INFO - joeynmt.training - Example #4
2024-05-19 16:16:46,975 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:16:46,975 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:16:46,975 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'is', 'a', 'sp@@', 'e@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'is', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:16:46,976 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:16:46,976 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:16:46,976 - INFO - joeynmt.training - 	Hypothesis: The next slide I show is a speed version of what happens is happened in the last 25 years.
2024-05-19 16:16:50,254 - INFO - joeynmt.training - Epoch   9, Step:    39100, Batch Loss:     1.160188, Batch Acc: 0.638950, Tokens per Sec:    21939, Lr: 0.000300
2024-05-19 16:16:53,548 - INFO - joeynmt.training - Epoch   9, Step:    39200, Batch Loss:     1.117412, Batch Acc: 0.638542, Tokens per Sec:    23212, Lr: 0.000300
2024-05-19 16:16:57,211 - INFO - joeynmt.training - Epoch   9, Step:    39300, Batch Loss:     1.206155, Batch Acc: 0.641246, Tokens per Sec:    20375, Lr: 0.000300
2024-05-19 16:17:01,106 - INFO - joeynmt.training - Epoch   9, Step:    39400, Batch Loss:     1.139876, Batch Acc: 0.644415, Tokens per Sec:    19223, Lr: 0.000300
2024-05-19 16:17:04,323 - INFO - joeynmt.training - Epoch   9, Step:    39500, Batch Loss:     1.139159, Batch Acc: 0.643394, Tokens per Sec:    23805, Lr: 0.000300
2024-05-19 16:17:04,323 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:17:04,324 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:17:18,515 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:17:18,516 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.47, loss:   1.50, ppl:   4.46, acc:   0.55, generation: 13.9797[sec], evaluation: 0.1943[sec]
2024-05-19 16:17:18,718 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/36000.ckpt
2024-05-19 16:17:18,728 - INFO - joeynmt.training - Example #0
2024-05-19 16:17:18,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:17:18,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:17:18,730 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'th@@', 'en,', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de', 'of', 's@@', 'li@@', 'de', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', 'tur@@', 'e', 'that', 'the', 'p@@', 'ol@@', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'year@@', 's,', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'v@@', 'ed', '</s>']
2024-05-19 16:17:18,731 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:17:18,731 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:17:18,731 - INFO - joeynmt.training - 	Hypothesis: And then, I showed these two slide of slide that the polar capture that the pollast three million years, about the size of the size of the United States of the United States with 40 percent curved
2024-05-19 16:17:18,731 - INFO - joeynmt.training - Example #1
2024-05-19 16:17:18,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:17:18,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:17:18,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'the', 're@@', 'se@@', 'ar@@', 'ch@@', 'ing', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'di@@', 'd', 'not', 'the', 'di@@', 'se@@', 'c@@', 'tion', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:17:18,733 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:17:18,733 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:17:18,733 - INFO - joeynmt.training - 	Hypothesis: But this is the researching of this particular problem because it did not the disection of the ice.
2024-05-19 16:17:18,733 - INFO - joeynmt.training - Example #2
2024-05-19 16:17:18,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:17:18,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:17:18,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:17:18,735 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:17:18,735 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:17:18,735 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a sense, heart of our global climate global climate system.
2024-05-19 16:17:18,735 - INFO - joeynmt.training - Example #3
2024-05-19 16:17:18,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:17:18,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:17:18,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'h', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:17:18,736 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:17:18,736 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:17:18,737 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crach in the summer.
2024-05-19 16:17:18,737 - INFO - joeynmt.training - Example #4
2024-05-19 16:17:18,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:17:18,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:17:18,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:17:18,738 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:17:18,738 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:17:18,738 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a accelerated version of what happened in the last 25 years.
2024-05-19 16:17:23,116 - INFO - joeynmt.training - Epoch   9, Step:    39600, Batch Loss:     1.073965, Batch Acc: 0.638111, Tokens per Sec:    17047, Lr: 0.000300
2024-05-19 16:17:27,536 - INFO - joeynmt.training - Epoch   9, Step:    39700, Batch Loss:     1.110828, Batch Acc: 0.640828, Tokens per Sec:    16598, Lr: 0.000300
2024-05-19 16:17:30,916 - INFO - joeynmt.training - Epoch   9, Step:    39800, Batch Loss:     1.134850, Batch Acc: 0.635056, Tokens per Sec:    22336, Lr: 0.000300
2024-05-19 16:17:34,074 - INFO - joeynmt.training - Epoch   9, Step:    39900, Batch Loss:     1.043417, Batch Acc: 0.635327, Tokens per Sec:    24019, Lr: 0.000300
2024-05-19 16:17:37,283 - INFO - joeynmt.training - Epoch   9, Step:    40000, Batch Loss:     1.068686, Batch Acc: 0.637288, Tokens per Sec:    23924, Lr: 0.000300
2024-05-19 16:17:37,283 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:17:37,283 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:17:51,951 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:17:51,952 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.36, loss:   1.49, ppl:   4.42, acc:   0.55, generation: 14.4496[sec], evaluation: 0.2003[sec]
2024-05-19 16:17:51,953 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:17:52,194 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/35500.ckpt
2024-05-19 16:17:52,213 - INFO - joeynmt.training - Example #0
2024-05-19 16:17:52,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:17:52,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:17:52,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'lu@@', 't', 'of', 'the', 'p@@', 'ol@@', 'lu@@', 't', 'c@@', 'ap@@', 'tur@@', 'e', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:17:52,215 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:17:52,216 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:17:52,217 - INFO - joeynmt.training - 	Hypothesis: And I showed these two slides to show that the pollut of the pollut capture that the last three million years of the U.S. with 40 percent of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:17:52,217 - INFO - joeynmt.training - Example #1
2024-05-19 16:17:52,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:17:52,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:17:52,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'b@@', 'it', 'of', 'the', 'most', 'pro@@', 'duc@@', 'tion', 'of', 'this', 'spec@@', 'i@@', 'f@@', 'ic', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 16:17:52,218 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:17:52,219 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:17:52,219 - INFO - joeynmt.training - 	Hypothesis: But this is a bit of the most production of this specific problem because it doesn't show.
2024-05-19 16:17:52,219 - INFO - joeynmt.training - Example #2
2024-05-19 16:17:52,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:17:52,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:17:52,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'lo@@', 'se', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', 'And', 'in', 'a', 'wa@@', 'y,', 'in', 'a', 'sen@@', 'se', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:17:52,220 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:17:52,221 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:17:52,221 - INFO - joeynmt.training - 	Hypothesis: The ice close climate system. And in a way, in a sense of our global climate system.
2024-05-19 16:17:52,222 - INFO - joeynmt.training - Example #3
2024-05-19 16:17:52,222 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:17:52,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:17:52,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'k', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:17:52,224 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:17:52,224 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:17:52,224 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crack in the summer.
2024-05-19 16:17:52,224 - INFO - joeynmt.training - Example #4
2024-05-19 16:17:52,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:17:52,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:17:52,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'that', "I'@@", 'll', 's@@', 'how', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'was', 'happ@@', 'en@@', 'ing', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', '2@@', '5', 'years', 'of', 'what', 'was', 'happ@@', 'en@@', 'ing', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'was', 'happ@@', 'en@@', 'ed', 'in', 'the', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'of', 'what', 'was', 'happ@@', 'en@@', 'ing', 'is', 'a', 'very', 'mu@@', 'ch', 'more', 'ac@@', 'c@@', 'el@@', 'er@@', 'ate', 'ver@@', 'si@@', 'on', 'of', 'what', 'was', 'happ@@', 'en@@', 'ing', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'was', 'happ@@', 'en@@', 'ing', 'is', 'happ@@', 'en@@', 'ing', 'is', 'a', 'very', 'mu@@', 'ch', 'more', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'in', 'the', 'ne@@', 'x@@']
2024-05-19 16:17:52,226 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:17:52,226 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:17:52,226 - INFO - joeynmt.training - 	Hypothesis: The next slide that I'll show is a version of what was happening the last 25 years happened in 25 years of what was happening in the last 25 years happened in the last 25 years of what was happened in the next slide of what was happening is a very much more accelerate version of what was happening is a version of what was happening is happening is a very much more accelerated in the nex
2024-05-19 16:17:56,564 - INFO - joeynmt.training - Epoch   9, Step:    40100, Batch Loss:     1.139163, Batch Acc: 0.638874, Tokens per Sec:    16878, Lr: 0.000300
2024-05-19 16:17:59,802 - INFO - joeynmt.training - Epoch   9, Step:    40200, Batch Loss:     1.066961, Batch Acc: 0.638389, Tokens per Sec:    23351, Lr: 0.000300
2024-05-19 16:18:03,252 - INFO - joeynmt.training - Epoch   9, Step:    40300, Batch Loss:     1.143653, Batch Acc: 0.640916, Tokens per Sec:    22175, Lr: 0.000300
2024-05-19 16:18:06,760 - INFO - joeynmt.training - Epoch   9, Step:    40400, Batch Loss:     1.228913, Batch Acc: 0.633646, Tokens per Sec:    21121, Lr: 0.000300
2024-05-19 16:18:11,029 - INFO - joeynmt.training - Epoch   9, Step:    40500, Batch Loss:     1.230192, Batch Acc: 0.638951, Tokens per Sec:    18208, Lr: 0.000300
2024-05-19 16:18:11,029 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:18:11,030 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:18:26,073 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:18:26,073 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.71, loss:   1.48, ppl:   4.40, acc:   0.55, generation: 14.3958[sec], evaluation: 0.6251[sec]
2024-05-19 16:18:26,074 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:18:26,284 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/38000.ckpt
2024-05-19 16:18:26,299 - INFO - joeynmt.training - Example #0
2024-05-19 16:18:26,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:18:26,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:18:26,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'how', 'these', 'two', 's@@', 'li@@', 'de', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'was', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'that', 'was', 'a', 'f@@', 'our', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'that', 'the', 'p@@', 'ol@@', 'ar', 'was', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:18:26,301 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:18:26,302 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:18:26,302 - INFO - joeynmt.training - 	Hypothesis: And I show these two slide of the United to show that the polar cap, which was the last three million years of the last three million years of the United States with 40 percent of the United States with 40 percent of the United States that was a four percent of the United States that the polar was three million years of the U.S.
2024-05-19 16:18:26,302 - INFO - joeynmt.training - Example #1
2024-05-19 16:18:26,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:18:26,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:18:26,303 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 't', 'the', 'most', 'se@@', 'ver@@', 'al', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:18:26,303 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:18:26,304 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:18:26,304 - INFO - joeynmt.training - 	Hypothesis: But this distinct the most several problem because it doesn't show the ice of the ice.
2024-05-19 16:18:26,304 - INFO - joeynmt.training - Example #2
2024-05-19 16:18:26,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:18:26,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:18:26,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'lo@@', 'se', 'of', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'sen@@', 'se@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:18:26,305 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:18:26,305 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:18:26,306 - INFO - joeynmt.training - 	Hypothesis: The ice close of the North Pole is in a sense, in a sense, heart of our global climate system.
2024-05-19 16:18:26,306 - INFO - joeynmt.training - Example #3
2024-05-19 16:18:26,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:18:26,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:18:26,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'it', 'into', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'h', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:18:26,307 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:18:26,307 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:18:26,307 - INFO - joeynmt.training - 	Hypothesis: It put it into the winter and crach in the summer.
2024-05-19 16:18:26,307 - INFO - joeynmt.training - Example #4
2024-05-19 16:18:26,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:18:26,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:18:26,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'happ@@', 'en@@', 's.', '</s>']
2024-05-19 16:18:26,308 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:18:26,309 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:18:26,309 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what happens in the last 25 years happened 25 years happened 25 years happened 25 years happened in the last 25 years happens.
2024-05-19 16:18:29,587 - INFO - joeynmt.training - Epoch   9, Step:    40600, Batch Loss:     1.152363, Batch Acc: 0.634052, Tokens per Sec:    21672, Lr: 0.000300
2024-05-19 16:18:32,892 - INFO - joeynmt.training - Epoch   9, Step:    40700, Batch Loss:     1.189721, Batch Acc: 0.640412, Tokens per Sec:    23355, Lr: 0.000300
2024-05-19 16:18:35,081 - INFO - joeynmt.training - Epoch   9: total training loss 5220.02
2024-05-19 16:18:35,081 - INFO - joeynmt.training - EPOCH 10
2024-05-19 16:18:36,816 - INFO - joeynmt.training - Epoch  10, Step:    40800, Batch Loss:     1.183113, Batch Acc: 0.652644, Tokens per Sec:    15851, Lr: 0.000300
2024-05-19 16:18:40,816 - INFO - joeynmt.training - Epoch  10, Step:    40900, Batch Loss:     1.141752, Batch Acc: 0.656171, Tokens per Sec:    19185, Lr: 0.000300
2024-05-19 16:18:44,185 - INFO - joeynmt.training - Epoch  10, Step:    41000, Batch Loss:     1.156531, Batch Acc: 0.658725, Tokens per Sec:    22493, Lr: 0.000300
2024-05-19 16:18:44,186 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:18:44,186 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:18:58,700 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:18:58,701 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.94, loss:   1.49, ppl:   4.42, acc:   0.55, generation: 14.2955[sec], evaluation: 0.1998[sec]
2024-05-19 16:18:58,904 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/39500.ckpt
2024-05-19 16:18:58,918 - INFO - joeynmt.training - Example #0
2024-05-19 16:18:58,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:18:58,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:18:58,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'ho@@', 'w@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'was', 'about', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'c@@', 'ur@@', 'v@@', 'ed', '</s>']
2024-05-19 16:18:58,920 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:18:58,921 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:18:58,921 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two shows to show that the polar cap, which was about three million years of the last three million years of the U.S. with 40 percent of the United States, with 40 percent curved
2024-05-19 16:18:58,921 - INFO - joeynmt.training - Example #1
2024-05-19 16:18:58,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:18:58,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:18:58,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'ri@@', 'bu@@', 'te', 'the', 'rec@@', 'or@@', 'ds', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:18:58,922 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:18:58,922 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:18:58,923 - INFO - joeynmt.training - 	Hypothesis: But this distribute the records of this particular problem because it doesn't show the ice of the ice.
2024-05-19 16:18:58,923 - INFO - joeynmt.training - Example #2
2024-05-19 16:18:58,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:18:58,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:18:58,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'able', 'to', 'c@@', 'li@@', 'm@@', 'ate', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:18:58,924 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:18:58,924 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:18:58,924 - INFO - joeynmt.training - 	Hypothesis: The ice capable to climate the North Pole is in a sense, heart of our global climate system.
2024-05-19 16:18:58,924 - INFO - joeynmt.training - Example #3
2024-05-19 16:18:58,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:18:58,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:18:58,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'of', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:18:58,925 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:18:58,926 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:18:58,926 - INFO - joeynmt.training - 	Hypothesis: It put out of the winter and crace in the summer.
2024-05-19 16:18:58,926 - INFO - joeynmt.training - Example #4
2024-05-19 16:18:58,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:18:58,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:18:58,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 'ing', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ing', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'has', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'has', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'has', 'happ@@', 'en@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ing', 'of', 'what', 'has', 'happ@@', 'en@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ing', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 16:18:58,927 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:18:58,927 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:18:58,928 - INFO - joeynmt.training - 	Hypothesis: The next slide I showing is a accelerated version of what's happening the last 25 years of what has happened in the last 25 years of what has happened in the last 25 years of what has happened is a accelerating of what has happened is a accelerating slide.
2024-05-19 16:19:02,150 - INFO - joeynmt.training - Epoch  10, Step:    41100, Batch Loss:     1.044342, Batch Acc: 0.654246, Tokens per Sec:    21926, Lr: 0.000300
2024-05-19 16:19:06,312 - INFO - joeynmt.training - Epoch  10, Step:    41200, Batch Loss:     1.146638, Batch Acc: 0.653413, Tokens per Sec:    18274, Lr: 0.000300
2024-05-19 16:19:09,879 - INFO - joeynmt.training - Epoch  10, Step:    41300, Batch Loss:     1.017280, Batch Acc: 0.653706, Tokens per Sec:    21283, Lr: 0.000300
2024-05-19 16:19:13,023 - INFO - joeynmt.training - Epoch  10, Step:    41400, Batch Loss:     1.111521, Batch Acc: 0.660989, Tokens per Sec:    23534, Lr: 0.000300
2024-05-19 16:19:16,210 - INFO - joeynmt.training - Epoch  10, Step:    41500, Batch Loss:     1.255332, Batch Acc: 0.652933, Tokens per Sec:    24175, Lr: 0.000300
2024-05-19 16:19:16,210 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:19:16,211 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:19:33,001 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:19:33,002 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.71, loss:   1.49, ppl:   4.43, acc:   0.55, generation: 16.5716[sec], evaluation: 0.2011[sec]
2024-05-19 16:19:33,202 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/39000.ckpt
2024-05-19 16:19:33,218 - INFO - joeynmt.training - Example #0
2024-05-19 16:19:33,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:19:33,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:19:33,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year@@', ',', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'was', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 'be', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 's@@', 'how', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'in', '4@@', '0', 'per@@', 'c@@', 'ent', 'was', 'c@@', 'ur@@', 'r@@', 'ent', 'in', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'that', 'was', 's@@', 'ho@@', 'w@@', 'ed', 'to', 's@@', 'how', 'the', 'p@@', 'ol@@', 'ar', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'to', 's@@', 'how', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es']
2024-05-19 16:19:33,220 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:19:33,220 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:19:33,220 - INFO - joeynmt.training - 	Hypothesis: Last year, I showed these two slight to show that the polar cap, which was three million years to be three million years to show the size of the United States with 40 percent of the United States in 40 percent was current in the United States that was showed to show the polar three million years to show the United States
2024-05-19 16:19:33,221 - INFO - joeynmt.training - Example #1
2024-05-19 16:19:33,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:19:33,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:19:33,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'ing@@', 'u@@', 'is@@', 'h@@', 'ing', 'the', 'se@@', 'con@@', 'd', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'ho@@', 'w@@', 'ing', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 16:19:33,222 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:19:33,222 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:19:33,222 - INFO - joeynmt.training - 	Hypothesis: But this distinguishing the second of this particular problem because it doesn't showing the ice of ice.
2024-05-19 16:19:33,223 - INFO - joeynmt.training - Example #2
2024-05-19 16:19:33,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:19:33,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:19:33,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'o@@', 'le@@', ',', 'in', 'a', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:19:33,224 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:19:33,224 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:19:33,224 - INFO - joeynmt.training - 	Hypothesis: The ice capital on the North Pole, in a sense, heart of our global climate system.
2024-05-19 16:19:33,224 - INFO - joeynmt.training - Example #3
2024-05-19 16:19:33,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:19:33,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:19:33,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'ked', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:19:33,226 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:19:33,226 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:19:33,226 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and cracked in the summer.
2024-05-19 16:19:33,226 - INFO - joeynmt.training - Example #4
2024-05-19 16:19:33,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:19:33,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:19:33,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'of', 'what', 'is', 'happ@@', 'en@@', 'ing', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:19:33,228 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:19:33,228 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:19:33,228 - INFO - joeynmt.training - 	Hypothesis: The next slide of what is happening is a accelerated version of what happens in the last 25 years.
2024-05-19 16:19:37,279 - INFO - joeynmt.training - Epoch  10, Step:    41600, Batch Loss:     1.070603, Batch Acc: 0.650236, Tokens per Sec:    17946, Lr: 0.000300
2024-05-19 16:19:40,817 - INFO - joeynmt.training - Epoch  10, Step:    41700, Batch Loss:     1.195105, Batch Acc: 0.654866, Tokens per Sec:    21342, Lr: 0.000300
2024-05-19 16:19:44,153 - INFO - joeynmt.training - Epoch  10, Step:    41800, Batch Loss:     0.947628, Batch Acc: 0.652091, Tokens per Sec:    22885, Lr: 0.000300
2024-05-19 16:19:47,350 - INFO - joeynmt.training - Epoch  10, Step:    41900, Batch Loss:     1.127141, Batch Acc: 0.649228, Tokens per Sec:    23558, Lr: 0.000300
2024-05-19 16:19:51,416 - INFO - joeynmt.training - Epoch  10, Step:    42000, Batch Loss:     1.160758, Batch Acc: 0.648935, Tokens per Sec:    18451, Lr: 0.000300
2024-05-19 16:19:51,417 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:19:51,417 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:20:05,688 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:20:05,688 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.84, loss:   1.49, ppl:   4.42, acc:   0.55, generation: 13.8861[sec], evaluation: 0.3511[sec]
2024-05-19 16:20:05,916 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/38500.ckpt
2024-05-19 16:20:05,934 - INFO - joeynmt.training - Example #0
2024-05-19 16:20:05,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:20:05,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:20:05,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'that', 'the', 'p@@', 'ol@@', 'l@@', 'is@@', 'he@@', 'd', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'with', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'was', 'a', 'p@@', 'ol@@', 'ic@@', 'e', 'c@@', 'ro@@', 'w@@', 's.', '</s>']
2024-05-19 16:20:05,936 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:20:05,937 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:20:05,937 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the polar cap, that the pollished the last three million years of the last three million years of the United States with the United States with 40 percent of the United States was a police crows.
2024-05-19 16:20:05,938 - INFO - joeynmt.training - Example #1
2024-05-19 16:20:05,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:20:05,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:20:05,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'ri@@', 'bu@@', 'ted', 'the', 'most', 'se@@', 'qu@@', 'en@@', 'ce', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'ho@@', 'w@@', 'ing', 'the', 'di@@', 'se@@', 'as@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:20:05,939 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:20:05,940 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:20:05,940 - INFO - joeynmt.training - 	Hypothesis: But this distributed the most sequence of this particular problem because it doesn't showing the disease of the ice.
2024-05-19 16:20:05,940 - INFO - joeynmt.training - Example #2
2024-05-19 16:20:05,940 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:20:05,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:20:05,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'it@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'in', 'a', 'c@@', 'li@@', 'm@@', 'ate', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:20:05,941 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:20:05,942 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:20:05,942 - INFO - joeynmt.training - 	Hypothesis: The ice capital climate in a climate climate system.
2024-05-19 16:20:05,942 - INFO - joeynmt.training - Example #3
2024-05-19 16:20:05,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:20:05,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:20:05,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'ked', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:20:05,943 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:20:05,944 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:20:05,944 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and cracked in the summer.
2024-05-19 16:20:05,944 - INFO - joeynmt.training - Example #4
2024-05-19 16:20:05,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:20:05,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:20:05,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'the', 'l@@', 'ast', 'di@@', 'a', 'I', 's@@', 'ho@@', 'w@@', 'ing', 's@@', 'ho@@', 'w@@', 'ing', 'is', 'a', 'very', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'happ@@', 'en@@', 'ing', 'is', 'happ@@', 'en@@', 'ing', 'is', 'happ@@', 'en@@', 'ed', 'to', 'be', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@']
2024-05-19 16:20:05,945 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:20:05,945 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:20:05,945 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a accelerated version of what the last 25 years of what happened is the last 25 years of what happened is happened in the last 25 years of what happened is a accelerated version of what the last dia I showing showing is a very accelerated version of what happened is happening is happening is happened to be a version of what happen
2024-05-19 16:20:09,390 - INFO - joeynmt.training - Epoch  10, Step:    42100, Batch Loss:     1.219172, Batch Acc: 0.649358, Tokens per Sec:    20106, Lr: 0.000300
2024-05-19 16:20:12,649 - INFO - joeynmt.training - Epoch  10, Step:    42200, Batch Loss:     1.169597, Batch Acc: 0.650014, Tokens per Sec:    23759, Lr: 0.000300
2024-05-19 16:20:15,906 - INFO - joeynmt.training - Epoch  10, Step:    42300, Batch Loss:     1.012097, Batch Acc: 0.649161, Tokens per Sec:    23315, Lr: 0.000300
2024-05-19 16:20:20,333 - INFO - joeynmt.training - Epoch  10, Step:    42400, Batch Loss:     1.157633, Batch Acc: 0.647438, Tokens per Sec:    17135, Lr: 0.000300
2024-05-19 16:20:23,534 - INFO - joeynmt.training - Epoch  10, Step:    42500, Batch Loss:     1.104714, Batch Acc: 0.652215, Tokens per Sec:    23401, Lr: 0.000300
2024-05-19 16:20:23,535 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:20:23,535 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:20:37,610 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:20:37,610 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.00, loss:   1.49, ppl:   4.43, acc:   0.55, generation: 13.8565[sec], evaluation: 0.2000[sec]
2024-05-19 16:20:37,833 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/41500.ckpt
2024-05-19 16:20:37,850 - INFO - joeynmt.training - Example #0
2024-05-19 16:20:37,851 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:20:37,852 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:20:37,852 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['F@@', 'or@@', 'i@@', 'al', 'year@@', 's,', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'was', 'c@@', 'ur@@', 'r@@', 'ing', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'was', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'ly', 'to', 's@@', 'how', 'that', 'the', 'l@@', 'ast', 'was', 'c@@', 'ur@@', 'r@@', 'ent', 'of', 'the', 'l@@', 'ast', 'year@@', 's.', '</s>']
2024-05-19 16:20:37,853 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:20:37,853 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:20:37,853 - INFO - joeynmt.training - 	Hypothesis: Forial years, I showed these two slides to show that the past three million years of the last three million years of the size of the United States of the United States was curring of the United States was currently to show that the last was current of the last years.
2024-05-19 16:20:37,853 - INFO - joeynmt.training - Example #1
2024-05-19 16:20:37,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:20:37,854 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:20:37,854 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'un@@', 'der@@', 'est@@', 'im@@', 'ate', 'the', 'most', 'se@@', 'ver@@', 'al', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 16:20:37,855 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:20:37,855 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:20:37,856 - INFO - joeynmt.training - 	Hypothesis: But this underestimate the most several problem because it doesn't show.
2024-05-19 16:20:37,856 - INFO - joeynmt.training - Example #2
2024-05-19 16:20:37,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:20:37,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:20:37,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'ap@@', 'ac@@', 'ity', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:20:37,857 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:20:37,857 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:20:37,857 - INFO - joeynmt.training - 	Hypothesis: The ice capacity on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 16:20:37,858 - INFO - joeynmt.training - Example #3
2024-05-19 16:20:37,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:20:37,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:20:37,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'of', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:20:37,859 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:20:37,859 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:20:37,859 - INFO - joeynmt.training - 	Hypothesis: It put out of the winter and crace in summer.
2024-05-19 16:20:37,859 - INFO - joeynmt.training - Example #4
2024-05-19 16:20:37,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:20:37,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:20:37,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', ',', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'of', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'what', 'happ@@', 'en@@', 'ed', 'is', 'a', 'sp@@', 'e@@', 'ed', 'ver@@', 'si@@', 'on', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ing', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ing', 'is', 'a', 'sp@@', 'e@@', 'ed', 'in', 'the', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de@@', '.', '</s>']
2024-05-19 16:20:37,861 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:20:37,861 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:20:37,861 - INFO - joeynmt.training - 	Hypothesis: The next slide, I shows is a accelerated version of what happened 25 years of what happened 25 years of the last 25 years of what happened in the last 25 years of what happened is a speed version of what's happening in the last 25 years of what's happening is a speed in the next slide.
2024-05-19 16:20:41,136 - INFO - joeynmt.training - Epoch  10, Step:    42600, Batch Loss:     1.006794, Batch Acc: 0.647665, Tokens per Sec:    21550, Lr: 0.000300
2024-05-19 16:20:44,363 - INFO - joeynmt.training - Epoch  10, Step:    42700, Batch Loss:     0.942885, Batch Acc: 0.646829, Tokens per Sec:    23723, Lr: 0.000300
2024-05-19 16:20:48,866 - INFO - joeynmt.training - Epoch  10, Step:    42800, Batch Loss:     1.023489, Batch Acc: 0.651371, Tokens per Sec:    17136, Lr: 0.000300
2024-05-19 16:20:52,070 - INFO - joeynmt.training - Epoch  10, Step:    42900, Batch Loss:     1.061185, Batch Acc: 0.651371, Tokens per Sec:    24040, Lr: 0.000300
2024-05-19 16:20:55,216 - INFO - joeynmt.training - Epoch  10, Step:    43000, Batch Loss:     1.247377, Batch Acc: 0.649776, Tokens per Sec:    24672, Lr: 0.000300
2024-05-19 16:20:55,216 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:20:55,216 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:21:09,366 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:21:09,366 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.99, loss:   1.48, ppl:   4.41, acc:   0.55, generation: 13.9345[sec], evaluation: 0.1981[sec]
2024-05-19 16:21:09,563 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/42500.ckpt
2024-05-19 16:21:09,573 - INFO - joeynmt.helpers - delete /content/drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/42500.ckpt
2024-05-19 16:21:09,573 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/42500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/42500.ckpt')
2024-05-19 16:21:09,579 - INFO - joeynmt.training - Example #0
2024-05-19 16:21:09,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:21:09,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:21:09,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'ho@@', 'w@@', 'ing', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'which', 'was', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'cen@@', 't.', '</s>']
2024-05-19 16:21:09,581 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:21:09,581 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:21:09,581 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two showing these two slides that the polar cap, which was the last three million years of the last three million years of the United States, with 40 percent.
2024-05-19 16:21:09,582 - INFO - joeynmt.training - Example #1
2024-05-19 16:21:09,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:21:09,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:21:09,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'un@@', 'der@@', 'est@@', 'im@@', 'at@@', 'ing', 'the', 'most', 'se@@', 'con@@', 'd', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'ho@@', 'w@@', 'ing', 'the', 'di@@', 's@@', "n't", 's@@', 'ho@@', 'w@@', '.', '</s>']
2024-05-19 16:21:09,583 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:21:09,583 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:21:09,583 - INFO - joeynmt.training - 	Hypothesis: But this underestimating the most second of this particular problem because it doesn't showing the disn't show.
2024-05-19 16:21:09,584 - INFO - joeynmt.training - Example #2
2024-05-19 16:21:09,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:21:09,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:21:09,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'as@@', 'e', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:21:09,585 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:21:09,585 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:21:09,585 - INFO - joeynmt.training - 	Hypothesis: The ice case on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 16:21:09,585 - INFO - joeynmt.training - Example #3
2024-05-19 16:21:09,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:21:09,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:21:09,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'was', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'in@@', 'c@@', 'lu@@', 'de@@', 'd', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:21:09,586 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:21:09,586 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:21:09,587 - INFO - joeynmt.training - 	Hypothesis: It was in the winter and crincluded in summer.
2024-05-19 16:21:09,587 - INFO - joeynmt.training - Example #4
2024-05-19 16:21:09,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:21:09,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:21:09,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'of', 'what', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ac@@', 'c@@', 'el@@', 'er@@', 'at@@', 'ing', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 's', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ed', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ing', '2@@', '5', 'years', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ing', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'is', 'happ@@', 'en@@', 'ing', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:21:09,588 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:21:09,588 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:21:09,588 - INFO - joeynmt.training - 	Hypothesis: The next slide of what I shows is a accelerating version of what happens 25 years is happened 25 years is happening 25 years happened in the last 25 years is happening in the last 25 years is happening in the last 25 years.
2024-05-19 16:21:12,737 - INFO - joeynmt.training - Epoch  10, Step:    43100, Batch Loss:     1.214638, Batch Acc: 0.648195, Tokens per Sec:    22624, Lr: 0.000300
2024-05-19 16:21:17,143 - INFO - joeynmt.training - Epoch  10, Step:    43200, Batch Loss:     0.968869, Batch Acc: 0.646999, Tokens per Sec:    16961, Lr: 0.000300
2024-05-19 16:21:20,461 - INFO - joeynmt.training - Epoch  10, Step:    43300, Batch Loss:     1.125157, Batch Acc: 0.646827, Tokens per Sec:    22816, Lr: 0.000300
2024-05-19 16:21:23,740 - INFO - joeynmt.training - Epoch  10, Step:    43400, Batch Loss:     1.194052, Batch Acc: 0.645321, Tokens per Sec:    23566, Lr: 0.000300
2024-05-19 16:21:26,986 - INFO - joeynmt.training - Epoch  10, Step:    43500, Batch Loss:     1.146781, Batch Acc: 0.647027, Tokens per Sec:    23263, Lr: 0.000300
2024-05-19 16:21:26,986 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:21:26,986 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:21:40,798 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:21:40,799 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  15.53, loss:   1.48, ppl:   4.40, acc:   0.55, generation: 13.5922[sec], evaluation: 0.2022[sec]
2024-05-19 16:21:40,800 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:21:41,039 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/41000.ckpt
2024-05-19 16:21:41,055 - INFO - joeynmt.training - Example #0
2024-05-19 16:21:41,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:21:41,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:21:41,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de', 'of', 's@@', 'ho@@', 'w@@', 'ing', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'was', 'f@@', 'our', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es', 'was', 'about', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'and', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'g@@', 'h@@', 't', 's@@', 'k@@', 'y,', 'that', 'the', 'l@@', 'ast', 'year@@', ',', '</s>']
2024-05-19 16:21:41,057 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:21:41,057 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:21:41,057 - INFO - joeynmt.training - 	Hypothesis: And I showed these two slide of showing these two slight polar cap, that the last three million years of the last three million years of the United States of the United States was four percent of the United States was about 40 percent of the U.S. and I showed these two slight sky, that the last year,
2024-05-19 16:21:41,058 - INFO - joeynmt.training - Example #1
2024-05-19 16:21:41,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:21:41,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:21:41,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'un@@', 'der@@', 'est@@', 'im@@', 'at@@', 'e,', 'the', 'most', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:21:41,059 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:21:41,059 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:21:41,059 - INFO - joeynmt.training - 	Hypothesis: But this underestimate, the most of this particular problem because it doesn't show the ice of the ice.
2024-05-19 16:21:41,059 - INFO - joeynmt.training - Example #2
2024-05-19 16:21:41,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:21:41,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:21:41,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:21:41,061 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:21:41,061 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:21:41,061 - INFO - joeynmt.training - 	Hypothesis: The ice cap on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 16:21:41,061 - INFO - joeynmt.training - Example #3
2024-05-19 16:21:41,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:21:41,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:21:41,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'e', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:21:41,062 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:21:41,062 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:21:41,063 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crace in the summer.
2024-05-19 16:21:41,063 - INFO - joeynmt.training - Example #4
2024-05-19 16:21:41,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:21:41,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:21:41,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'of', 'what', 'happ@@', 'en@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'years', 'has', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:21:41,064 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:21:41,064 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:21:41,064 - INFO - joeynmt.training - 	Hypothesis: The next slide of what happens is a version of what happened in the last 25 years has happened in the last 25 years.
2024-05-19 16:21:45,235 - INFO - joeynmt.training - Epoch  10, Step:    43600, Batch Loss:     1.016801, Batch Acc: 0.650077, Tokens per Sec:    17308, Lr: 0.000300
2024-05-19 16:21:48,623 - INFO - joeynmt.training - Epoch  10, Step:    43700, Batch Loss:     1.153102, Batch Acc: 0.642370, Tokens per Sec:    22336, Lr: 0.000300
2024-05-19 16:21:51,942 - INFO - joeynmt.training - Epoch  10, Step:    43800, Batch Loss:     1.086644, Batch Acc: 0.642123, Tokens per Sec:    22892, Lr: 0.000300
2024-05-19 16:21:55,145 - INFO - joeynmt.training - Epoch  10, Step:    43900, Batch Loss:     1.116476, Batch Acc: 0.650943, Tokens per Sec:    23501, Lr: 0.000300
2024-05-19 16:21:59,223 - INFO - joeynmt.training - Epoch  10, Step:    44000, Batch Loss:     1.123843, Batch Acc: 0.640509, Tokens per Sec:    18999, Lr: 0.000300
2024-05-19 16:21:59,224 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:21:59,224 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:22:14,664 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:22:14,664 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.54, loss:   1.48, ppl:   4.37, acc:   0.55, generation: 15.2261[sec], evaluation: 0.1935[sec]
2024-05-19 16:22:14,665 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:22:14,880 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/40000.ckpt
2024-05-19 16:22:14,893 - INFO - joeynmt.training - Example #0
2024-05-19 16:22:14,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:22:14,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:22:14,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'e', 'c@@', 'ap@@', ',', 'who', 'was', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', 'n@@', 'it@@', 'ed', 'S@@', 't@@', 'at@@', 'es,', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:22:14,895 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:22:14,895 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:22:14,895 - INFO - joeynmt.training - 	Hypothesis: And I showed these two slides to show these two slides to show that the pole cap, who was the last three million years of the United States, with 40 percent of the United States, with 40 percent of the U.S.
2024-05-19 16:22:14,895 - INFO - joeynmt.training - Example #1
2024-05-19 16:22:14,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:22:14,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:22:14,896 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'di@@', 'st@@', 'in@@', 'c@@', 't', 'is', 'the', 'ser@@', 'ies', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 16:22:14,897 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:22:14,897 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:22:14,897 - INFO - joeynmt.training - 	Hypothesis: But this distinct is the series of this particular problem because it doesn't show the ice of the ice of ice.
2024-05-19 16:22:14,897 - INFO - joeynmt.training - Example #2
2024-05-19 16:22:14,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:22:14,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:22:14,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:22:14,898 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:22:14,899 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:22:14,899 - INFO - joeynmt.training - 	Hypothesis: The ice cap on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 16:22:14,899 - INFO - joeynmt.training - Example #3
2024-05-19 16:22:14,899 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:22:14,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:22:14,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'h', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:22:14,900 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:22:14,900 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:22:14,900 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and crach in summer.
2024-05-19 16:22:14,900 - INFO - joeynmt.training - Example #4
2024-05-19 16:22:14,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:22:14,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:22:14,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ing', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:22:14,902 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:22:14,902 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:22:14,902 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what's happening in the last 25 years.
2024-05-19 16:22:18,233 - INFO - joeynmt.training - Epoch  10, Step:    44100, Batch Loss:     1.032467, Batch Acc: 0.644219, Tokens per Sec:    22096, Lr: 0.000300
2024-05-19 16:22:21,628 - INFO - joeynmt.training - Epoch  10, Step:    44200, Batch Loss:     1.153541, Batch Acc: 0.646651, Tokens per Sec:    22408, Lr: 0.000300
2024-05-19 16:22:25,036 - INFO - joeynmt.training - Epoch  10, Step:    44300, Batch Loss:     1.150824, Batch Acc: 0.642655, Tokens per Sec:    22092, Lr: 0.000300
2024-05-19 16:22:29,121 - INFO - joeynmt.training - Epoch  10, Step:    44400, Batch Loss:     0.970567, Batch Acc: 0.645992, Tokens per Sec:    18668, Lr: 0.000300
2024-05-19 16:22:32,366 - INFO - joeynmt.training - Epoch  10, Step:    44500, Batch Loss:     0.998785, Batch Acc: 0.641045, Tokens per Sec:    23104, Lr: 0.000300
2024-05-19 16:22:32,366 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:22:32,367 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:22:46,865 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:22:46,865 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.98, loss:   1.47, ppl:   4.36, acc:   0.55, generation: 14.2829[sec], evaluation: 0.1968[sec]
2024-05-19 16:22:46,866 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 16:22:47,118 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/42000.ckpt
2024-05-19 16:22:47,133 - INFO - joeynmt.training - Example #0
2024-05-19 16:22:47,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:22:47,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:22:47,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'and', 'had', 'about', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:22:47,135 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:22:47,135 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:22:47,136 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these two slides to show that the polar cap, that the last three million years of the last three million years of the U.S. and had about the size of the U.S.
2024-05-19 16:22:47,136 - INFO - joeynmt.training - Example #1
2024-05-19 16:22:47,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:22:47,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:22:47,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'un@@', 'der@@', 'est@@', 'im@@', 'ate', 'the', 'most', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'di@@', 'se@@', 'as@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'proble@@', 'm', 'because', 'it', 'is', 'not', 'the', 'di@@', 'se@@', 'c@@', 'ur@@', 'r@@', 'en@@', 't@@', 'ly', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'hi@@', 'p', 'the', 'di@@', 'se@@', 'as@@', 'e', 'of', 'the', 'ic@@', 'e.', '</s>']
2024-05-19 16:22:47,137 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:22:47,137 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:22:47,137 - INFO - joeynmt.training - 	Hypothesis: But this underestimate the most of this particular problem because it doesn't show the disease of the ice of the ice of the ice of the ice of the ice of the ice problem because it is not the disecurrently of this particular problem because it doesn't ship the disease of the ice.
2024-05-19 16:22:47,137 - INFO - joeynmt.training - Example #2
2024-05-19 16:22:47,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:22:47,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:22:47,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'c@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'th', 'P@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:22:47,138 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:22:47,139 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:22:47,139 - INFO - joeynmt.training - 	Hypothesis: The ice cap on the North Pole is in a certain sense, heart of our global climate system.
2024-05-19 16:22:47,139 - INFO - joeynmt.training - Example #3
2024-05-19 16:22:47,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:22:47,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:22:47,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'of', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'ing', 'in', 'the', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:22:47,140 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:22:47,140 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:22:47,140 - INFO - joeynmt.training - 	Hypothesis: It put out of the winter and cracing in the summer.
2024-05-19 16:22:47,141 - INFO - joeynmt.training - Example #4
2024-05-19 16:22:47,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:22:47,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:22:47,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 's', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:22:47,142 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:22:47,142 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:22:47,142 - INFO - joeynmt.training - 	Hypothesis: The next slide I shows is a version of what happened in the last 25 years.
2024-05-19 16:22:50,376 - INFO - joeynmt.training - Epoch  10, Step:    44600, Batch Loss:     0.912942, Batch Acc: 0.646055, Tokens per Sec:    21812, Lr: 0.000300
2024-05-19 16:22:53,927 - INFO - joeynmt.training - Epoch  10, Step:    44700, Batch Loss:     1.046971, Batch Acc: 0.642127, Tokens per Sec:    21621, Lr: 0.000300
2024-05-19 16:22:58,099 - INFO - joeynmt.training - Epoch  10, Step:    44800, Batch Loss:     1.050805, Batch Acc: 0.646786, Tokens per Sec:    18247, Lr: 0.000300
2024-05-19 16:23:01,360 - INFO - joeynmt.training - Epoch  10, Step:    44900, Batch Loss:     1.196642, Batch Acc: 0.643317, Tokens per Sec:    23011, Lr: 0.000300
2024-05-19 16:23:04,602 - INFO - joeynmt.training - Epoch  10, Step:    45000, Batch Loss:     1.091198, Batch Acc: 0.645757, Tokens per Sec:    23189, Lr: 0.000300
2024-05-19 16:23:04,603 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:23:04,603 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:23:19,996 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:23:19,997 - INFO - joeynmt.prediction - Evaluation result (greedy) bleu:  14.89, loss:   1.48, ppl:   4.39, acc:   0.55, generation: 15.1696[sec], evaluation: 0.2060[sec]
2024-05-19 16:23:20,199 - INFO - joeynmt.helpers - delete ../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/43000.ckpt
2024-05-19 16:23:20,216 - INFO - joeynmt.training - Example #0
2024-05-19 16:23:20,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['V@@', 'or@@', 'i@@', 'g', 'jaar', 'li@@', 'et', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'd@@', 'ri@@', 'e', 'mil@@', 'jo@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gr@@', 'oo@@', 't@@', 'te', 'had', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2024-05-19 16:23:20,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'c@@', 'ap@@', ',', 'which', 'for', 'most', 'of', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'w@@', 'er', '4@@', '8', 'st@@', 'at@@', 'es,', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'per@@', 'cen@@', 't.']
2024-05-19 16:23:20,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'l@@', 'ast', 'ye@@', 'ar', 'I', 's@@', 'how', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'to', 's@@', 'how', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'that', 'the', 'p@@', 'ol@@', 'ar', 'c@@', 'ap@@', ',', 'that', 'the', 'l@@', 'ast', 'th@@', 're@@', 'e', 'mil@@', 'li@@', 'on', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'with', '4@@', '0', 'per@@', 'c@@', 'ent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-19 16:23:20,217 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-19 16:23:20,217 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 16:23:20,218 - INFO - joeynmt.training - 	Hypothesis: And last year I show these two slides to show that the polar cap, that the polar cap, that the last three million years of the U.S. with 40 percent of the U.S. with 40 percent of the U.S. with 40 percent of the U.S.
2024-05-19 16:23:20,218 - INFO - joeynmt.training - Example #1
2024-05-19 16:23:20,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eig@@', 'en@@', 'lijk', 'de', 'er@@', 'n@@', 'st', 'van', 'dit', 'spec@@', 'i@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'te', 'van', 'het', 'ij@@', 's', 'la@@', 'at', 'zi@@', 'en.']
2024-05-19 16:23:20,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'un@@', 'der@@', 'st@@', 'at@@', 'es', 'the', 'ser@@', 'i@@', 'ou@@', 's@@', 'n@@', 'ess', 'of', 'this', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 'do@@', 'es@@', "n't", 's@@', 'how', 'the', 'th@@', 'ic@@', 'k@@', 'n@@', 'ess', 'of', 'the', 'ic@@', 'e.']
2024-05-19 16:23:20,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', 'wor@@', 'se', 'of', 'the', 'most', 'par@@', 'tic@@', 'ul@@', 'ar', 'proble@@', 'm', 'because', 'it', 's@@', 'ho@@', 'w@@', 's', 'not', 'the', 'di@@', 'c@@', 'at@@', 'ch', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e', 'p@@', 'ut', 'the', 'ic@@', 'e', 'of', 'the', 'ic@@', 'e', 'of', 'ic@@', 'e.', '</s>']
2024-05-19 16:23:20,219 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-19 16:23:20,219 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 16:23:20,220 - INFO - joeynmt.training - 	Hypothesis: But this is actually the worse of the most particular problem because it shows not the dicatch of the ice of ice put the ice of the ice of ice.
2024-05-19 16:23:20,220 - INFO - joeynmt.training - Example #2
2024-05-19 16:23:20,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'k@@', 'ere', 'z@@', 'in', 'het', 'k@@', 'l@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'k@@', 'li@@', 'maa@@', 't@@', 'sy@@', 'ste@@', 'em@@', '.']
2024-05-19 16:23:20,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ic@@', 'e', 'ca@@', 'p', 'is,', 'in', 'a', 'sen@@', 'se@@', ',', 'the', 'be@@', 'at@@', 'ing', 'he@@', 'ar@@', 't', 'of', 'the', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.']
2024-05-19 16:23:20,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ic@@', 'e', 'k@@', 'a@@', 'p', 'on', 'the', 'N@@', 'or@@', 'se', 'p@@', 'ol@@', 'e', 'is', 'in', 'a', 'c@@', 'er@@', 'ta@@', 'in', 'sen@@', 'se@@', ',', 'he@@', 'ar@@', 't', 'of', 'our', 'g@@', 'lo@@', 'b@@', 'al', 'c@@', 'li@@', 'm@@', 'ate', 'sy@@', 'st@@', 'em@@', '.', '</s>']
2024-05-19 16:23:20,221 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-19 16:23:20,221 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 16:23:20,221 - INFO - joeynmt.training - 	Hypothesis: The ice kap on the Norse pole is in a certain sense, heart of our global climate system.
2024-05-19 16:23:20,222 - INFO - joeynmt.training - Example #3
2024-05-19 16:23:20,222 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ri@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2024-05-19 16:23:20,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'and@@', 's', 'in', 'w@@', 'in@@', 'ter', 'and', 'con@@', 'tr@@', 'ac@@', 'ts', 'in', 'su@@', 'm@@', 'mer@@', '.']
2024-05-19 16:23:20,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'p@@', 'ut', 'out', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'c@@', 'r@@', 'ac@@', 'es', 'in', 'su@@', 'm@@', 'mer@@', '.', '</s>']
2024-05-19 16:23:20,223 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-19 16:23:20,223 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-19 16:23:20,223 - INFO - joeynmt.training - 	Hypothesis: It put out in the winter and craces in summer.
2024-05-19 16:23:20,223 - INFO - joeynmt.training - Example #4
2024-05-19 16:23:20,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'la@@', 'at', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'si@@', 'e', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'beur@@', 'd.']
2024-05-19 16:23:20,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'how', 'you', 'will', 'be', 'a', 'ra@@', 'p@@', 'id', 'f@@', 'a@@', 'st@@', '-@@', 'for@@', 'war@@', 'd', 'of', 'wh@@', "at's", 'happ@@', 'en@@', 'ed', 'over', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.']
2024-05-19 16:23:20,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ne@@', 'x@@', 't', 's@@', 'li@@', 'de', 'I', 's@@', 'ho@@', 'w@@', 'ed', 'is', 'a', 'ver@@', 'si@@', 'on', 'of', 'what', 'happ@@', 'en@@', 'ed', 'in', 'the', 'l@@', 'ast', '2@@', '5', 'year@@', 's.', '</s>']
2024-05-19 16:23:20,224 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-19 16:23:20,225 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 16:23:20,225 - INFO - joeynmt.training - 	Hypothesis: The next slide I showed is a version of what happened in the last 25 years.
2024-05-19 16:23:24,342 - INFO - joeynmt.training - Epoch  10, Step:    45100, Batch Loss:     1.143421, Batch Acc: 0.645052, Tokens per Sec:    17313, Lr: 0.000300
2024-05-19 16:23:28,045 - INFO - joeynmt.training - Epoch  10, Step:    45200, Batch Loss:     1.183702, Batch Acc: 0.644071, Tokens per Sec:    20564, Lr: 0.000300
2024-05-19 16:23:31,245 - INFO - joeynmt.training - Epoch  10, Step:    45300, Batch Loss:     1.098764, Batch Acc: 0.644438, Tokens per Sec:    23017, Lr: 0.000300
2024-05-19 16:23:31,279 - INFO - joeynmt.training - Epoch  10: total training loss 5137.57
2024-05-19 16:23:31,279 - INFO - joeynmt.training - Training ended after  10 epochs.
2024-05-19 16:23:31,279 - INFO - joeynmt.training - Best validation result (greedy) at step    44500:   4.36 ppl.
2024-05-19 16:23:31,301 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-19 16:23:31,365 - INFO - joeynmt.model - Enc-dec model built.
2024-05-19 16:23:31,513 - INFO - joeynmt.helpers - Load model from /content/drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/44500.ckpt.
2024-05-19 16:23:31,534 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1004),
	loss_function=None)
2024-05-19 16:23:31,535 - INFO - joeynmt.prediction - Decoding on dev set...
2024-05-19 16:23:31,535 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:23:31,536 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:23:54,563 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:23:54,564 - INFO - joeynmt.prediction - Evaluation result (beam search) bleu:  16.92, generation: 22.8372[sec], evaluation: 0.1752[sec]
2024-05-19 16:23:54,570 - INFO - joeynmt.prediction - Translations saved to: /content/mt-exercise-5/../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/00044500.hyps.dev.
2024-05-19 16:23:54,571 - INFO - joeynmt.prediction - Decoding on test set...
2024-05-19 16:23:54,571 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 16:23:54,571 - INFO - joeynmt.prediction - Predicting 1777 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 16:24:28,887 - INFO - joeynmt.metrics - nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.2
2024-05-19 16:24:28,888 - INFO - joeynmt.prediction - Evaluation result (beam search) bleu:  23.88, generation: 33.9816[sec], evaluation: 0.3104[sec]
2024-05-19 16:24:28,896 - INFO - joeynmt.prediction - Translations saved to: /content/mt-exercise-5/../drive/MyDrive/mt-ex05/models/new/transformer_bpe1k/00044500.hyps.test.
