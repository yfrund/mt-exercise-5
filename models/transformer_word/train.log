2024-05-14 07:51:56,469 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                           cfg.name : transformer_word
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                     cfg.data.train : data/subsampled/train
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev.test/dev
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                      cfg.data.test : data/dev.test/test
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                  cfg.data.src.lang : nl
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                 cfg.data.src.level : word
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -             cfg.data.src.voc_limit : 2000
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : moses
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                 cfg.data.trg.level : word
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : 2000
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : moses
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2024-05-14 07:51:56,470 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_word
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2024-05-14 07:51:56,471 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2024-05-14 07:51:56,472 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2024-05-14 07:51:56,542 - INFO - joeynmt.data - Building tokenizer...
2024-05-14 07:51:56,542 - INFO - joeynmt.tokenizers - nl tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none)
2024-05-14 07:51:56,542 - INFO - joeynmt.tokenizers - en tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none)
2024-05-14 07:51:56,542 - INFO - joeynmt.data - Loading train set...
2024-05-14 07:51:56,918 - INFO - joeynmt.data - Building vocabulary...
2024-05-14 07:51:59,357 - INFO - joeynmt.data - Loading dev set...
2024-05-14 07:51:59,362 - INFO - joeynmt.data - Loading test set...
2024-05-14 07:51:59,372 - INFO - joeynmt.data - Data loaded.
2024-05-14 07:51:59,372 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=nl, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-14 07:51:59,372 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1003, src_lang=nl, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-14 07:51:59,372 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1777, src_lang=nl, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-14 07:51:59,372 - INFO - joeynmt.data - First training example:
	[SRC] Al Gore over het afwenden van de klimaatcrisis
	[TRG] Al Gore: Averting the climate crisis
2024-05-14 07:51:59,372 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) een (6) het (7) van (8) en (9) dat
2024-05-14 07:51:59,372 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) to (6) of (7) a (8) and (9) that
2024-05-14 07:51:59,372 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2004
2024-05-14 07:51:59,372 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2004
2024-05-14 07:51:59,374 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-14 07:51:59,440 - INFO - joeynmt.model - Enc-dec model built.
2024-05-14 07:52:03,453 - DEBUG - tensorflow - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2024-05-14 07:52:03,958 - DEBUG - h5py._conv - Creating converter from 7 to 5
2024-05-14 07:52:03,958 - DEBUG - h5py._conv - Creating converter from 5 to 7
2024-05-14 07:52:03,958 - DEBUG - h5py._conv - Creating converter from 7 to 5
2024-05-14 07:52:03,958 - DEBUG - h5py._conv - Creating converter from 5 to 7
2024-05-14 07:52:04,918 - DEBUG - jax._src.path - etils.epath found. Using etils.epath for file I/O.
2024-05-14 07:52:05,920 - INFO - joeynmt.model - Total params: 3925248
2024-05-14 07:52:05,921 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2024-05-14 07:52:05,922 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2024-05-14 07:52:06,949 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2024-05-14 07:52:06,949 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2024-05-14 07:52:06,950 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2024-05-14 07:52:06,950 - INFO - joeynmt.training - EPOCH 1
2024-05-14 07:52:13,419 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.223729, Batch Acc: 0.207312, Tokens per Sec:    10293, Lr: 0.000300
2024-05-14 07:52:16,457 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.910071, Batch Acc: 0.245067, Tokens per Sec:    22788, Lr: 0.000300
2024-05-14 07:52:19,456 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.582177, Batch Acc: 0.274839, Tokens per Sec:    23329, Lr: 0.000300
2024-05-14 07:52:22,531 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.545960, Batch Acc: 0.305873, Tokens per Sec:    22285, Lr: 0.000300
2024-05-14 07:52:26,415 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.453277, Batch Acc: 0.326168, Tokens per Sec:    17620, Lr: 0.000300
2024-05-14 07:52:26,416 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:52:26,416 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:52:30,917 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.58, ppl:  13.17, acc:   0.31, generation: 4.4924[sec], evaluation: 0.0000[sec]
2024-05-14 07:52:30,917 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:52:31,025 - INFO - joeynmt.training - Example #0
2024-05-14 07:52:31,025 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:52:31,025 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:52:31,025 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', '<unk>', 'I', '<unk>', '<unk>', 'to', '<unk>', 'and', '<unk>', 'to', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'of', 'the', '<unk>', '<unk>', '</s>']
2024-05-14 07:52:31,026 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:52:31,026 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:52:31,026 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> <unk> I <unk> <unk> to <unk> and <unk> to <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> of the <unk> <unk>
2024-05-14 07:52:31,026 - INFO - joeynmt.training - Example #1
2024-05-14 07:52:31,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:52:31,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:52:31,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', '<unk>', '<unk>', 'of', 'the', '<unk>', '<unk>', 'is', 'not', '<unk>', 'is', 'not', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:52:31,026 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:52:31,026 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:52:31,026 - INFO - joeynmt.training - 	Hypothesis: But this <unk> <unk> <unk> of the <unk> <unk> is not <unk> is not the <unk> of the <unk>
2024-05-14 07:52:31,026 - INFO - joeynmt.training - Example #2
2024-05-14 07:52:31,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:52:31,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:52:31,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', '<unk>', '<unk>', 'is', 'the', '<unk>', '<unk>', 'is', '<unk>', '<unk>', 'of', 'our', '<unk>', '</s>']
2024-05-14 07:52:31,027 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:52:31,027 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:52:31,027 - INFO - joeynmt.training - 	Hypothesis: The <unk> <unk> <unk> is the <unk> <unk> is <unk> <unk> of our <unk>
2024-05-14 07:52:31,027 - INFO - joeynmt.training - Example #3
2024-05-14 07:52:31,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:52:31,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:52:31,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'in', 'the', '<unk>', '<unk>', 'and', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:52:31,027 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:52:31,027 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:52:31,027 - INFO - joeynmt.training - 	Hypothesis: It in the <unk> <unk> and <unk> <unk> <unk> <unk>
2024-05-14 07:52:31,028 - INFO - joeynmt.training - Example #4
2024-05-14 07:52:31,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:52:31,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:52:31,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'that', 'I', '<unk>', 'I', '<unk>', 'is', 'a', '<unk>', 'of', '<unk>', 'is', 'a', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:52:31,028 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:52:31,028 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:52:31,028 - INFO - joeynmt.training - 	Hypothesis: The <unk> that I <unk> I <unk> is a <unk> of <unk> is a <unk> of the <unk>
2024-05-14 07:52:34,049 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.367448, Batch Acc: 0.337790, Tokens per Sec:    21403, Lr: 0.000300
2024-05-14 07:52:37,903 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.417805, Batch Acc: 0.351360, Tokens per Sec:    18141, Lr: 0.000300
2024-05-14 07:52:41,244 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     2.300259, Batch Acc: 0.365301, Tokens per Sec:    19934, Lr: 0.000300
2024-05-14 07:52:44,306 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     2.289074, Batch Acc: 0.374923, Tokens per Sec:    22270, Lr: 0.000300
2024-05-14 07:52:48,308 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.117135, Batch Acc: 0.385025, Tokens per Sec:    16988, Lr: 0.000300
2024-05-14 07:52:48,308 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:52:48,308 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:52:53,373 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.35, ppl:  10.51, acc:   0.35, generation: 5.0566[sec], evaluation: 0.0000[sec]
2024-05-14 07:52:53,373 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:52:53,481 - INFO - joeynmt.training - Example #0
2024-05-14 07:52:53,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:52:53,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:52:53,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', '<unk>', 'I', '<unk>', 'these', '<unk>', '<unk>', 'to', '<unk>', '<unk>', 'and', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'and', 'three', 'three', 'three', 'years', 'years', 'years', 'years', 'about', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:52:53,481 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:52:53,481 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:52:53,481 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> <unk> I <unk> these <unk> <unk> to <unk> <unk> and <unk> the <unk> <unk> <unk> <unk> <unk> <unk> and three three three years years years years about the <unk> <unk> <unk>
2024-05-14 07:52:53,481 - INFO - joeynmt.training - Example #1
2024-05-14 07:52:53,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:52:53,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:52:53,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', '<unk>', 'the', '<unk>', 'of', 'this', 'is', 'because', 'the', '<unk>', 'because', 'the', '<unk>', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:52:53,482 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:52:53,482 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:52:53,482 - INFO - joeynmt.training - 	Hypothesis: But this <unk> <unk> the <unk> of this is because the <unk> because the <unk> of the <unk> of the <unk>
2024-05-14 07:52:53,482 - INFO - joeynmt.training - Example #2
2024-05-14 07:52:53,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:52:53,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:52:53,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', '<unk>', '<unk>', '<unk>', 'of', 'our', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:52:53,482 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:52:53,482 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:52:53,482 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a <unk> <unk> <unk> of our <unk> <unk> <unk>
2024-05-14 07:52:53,482 - INFO - joeynmt.training - Example #3
2024-05-14 07:52:53,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:52:53,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:52:53,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:52:53,483 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:52:53,483 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:52:53,483 - INFO - joeynmt.training - 	Hypothesis: It <unk> <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:52:53,483 - INFO - joeynmt.training - Example #4
2024-05-14 07:52:53,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:52:53,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:52:53,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'next', '<unk>', 'I', '<unk>', 'is', 'a', '<unk>', 'of', '<unk>', '<unk>', '<unk>', '<unk>', 'of', 'what', 'there', 'is', '<unk>', '</s>']
2024-05-14 07:52:53,483 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:52:53,483 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:52:53,483 - INFO - joeynmt.training - 	Hypothesis: And the next <unk> I <unk> is a <unk> of <unk> <unk> <unk> <unk> of what there is <unk>
2024-05-14 07:52:56,551 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     2.122619, Batch Acc: 0.394595, Tokens per Sec:    21483, Lr: 0.000300
2024-05-14 07:52:59,674 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.042114, Batch Acc: 0.405372, Tokens per Sec:    21751, Lr: 0.000300
2024-05-14 07:53:02,991 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     1.941406, Batch Acc: 0.413501, Tokens per Sec:    20484, Lr: 0.000300
2024-05-14 07:53:06,661 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     1.984285, Batch Acc: 0.411516, Tokens per Sec:    18151, Lr: 0.000300
2024-05-14 07:53:09,665 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.010294, Batch Acc: 0.423971, Tokens per Sec:    22226, Lr: 0.000300
2024-05-14 07:53:09,666 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:53:09,666 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:53:13,998 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.46, acc:   0.37, generation: 4.3248[sec], evaluation: 0.0000[sec]
2024-05-14 07:53:13,999 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:53:14,104 - INFO - joeynmt.training - Example #0
2024-05-14 07:53:14,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:53:14,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:53:14,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'was', 'this', 'two', '<unk>', 'to', 'see', 'this', 'two', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:53:14,104 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:53:14,105 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:53:14,105 - INFO - joeynmt.training - 	Hypothesis: <unk> years I was this two <unk> to see this two <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2024-05-14 07:53:14,105 - INFO - joeynmt.training - Example #1
2024-05-14 07:53:14,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:53:14,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:53:14,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', '<unk>', 'the', '<unk>', 'of', 'this', 'problem', 'because', "it's", 'not', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:53:14,105 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:53:14,105 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:53:14,105 - INFO - joeynmt.training - 	Hypothesis: But this <unk> <unk> the <unk> of this problem because it's not the <unk> of the <unk>
2024-05-14 07:53:14,105 - INFO - joeynmt.training - Example #2
2024-05-14 07:53:14,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:53:14,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:53:14,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'in', 'a', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:53:14,106 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:53:14,106 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:53:14,106 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> in a <unk> <unk> <unk> <unk> <unk>
2024-05-14 07:53:14,106 - INFO - joeynmt.training - Example #3
2024-05-14 07:53:14,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:53:14,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:53:14,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:53:14,106 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:53:14,106 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:53:14,106 - INFO - joeynmt.training - 	Hypothesis: It <unk> <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:53:14,106 - INFO - joeynmt.training - Example #4
2024-05-14 07:53:14,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:53:14,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:53:14,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', 'I', 'see', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:53:14,107 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:53:14,107 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:53:14,107 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I see <unk> <unk> <unk> <unk>
2024-05-14 07:53:18,082 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.063708, Batch Acc: 0.431187, Tokens per Sec:    16665, Lr: 0.000300
2024-05-14 07:53:21,231 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     1.980469, Batch Acc: 0.436659, Tokens per Sec:    21546, Lr: 0.000300
2024-05-14 07:53:24,246 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.064649, Batch Acc: 0.439625, Tokens per Sec:    22315, Lr: 0.000300
2024-05-14 07:53:27,301 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     1.996993, Batch Acc: 0.447120, Tokens per Sec:    22479, Lr: 0.000300
2024-05-14 07:53:31,132 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     1.938209, Batch Acc: 0.451521, Tokens per Sec:    18158, Lr: 0.000300
2024-05-14 07:53:31,132 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:53:31,133 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:53:34,964 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.16, ppl:   8.70, acc:   0.39, generation: 3.8236[sec], evaluation: 0.0000[sec]
2024-05-14 07:53:34,965 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:53:35,070 - INFO - joeynmt.training - Example #0
2024-05-14 07:53:35,070 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:53:35,070 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:53:35,070 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', '<unk>', 'this', 'two', '<unk>', 'to', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:53:35,071 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:53:35,071 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:53:35,071 - INFO - joeynmt.training - 	Hypothesis: <unk> years I <unk> this two <unk> to <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2024-05-14 07:53:35,071 - INFO - joeynmt.training - Example #1
2024-05-14 07:53:35,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:53:35,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:53:35,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', '<unk>', 'the', '<unk>', 'of', 'this', '<unk>', '<unk>', 'because', "it's", 'not', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:53:35,071 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:53:35,071 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:53:35,071 - INFO - joeynmt.training - 	Hypothesis: But this <unk> <unk> the <unk> of this <unk> <unk> because it's not the <unk> of the <unk>
2024-05-14 07:53:35,071 - INFO - joeynmt.training - Example #2
2024-05-14 07:53:35,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:53:35,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:53:35,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:53:35,072 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:53:35,072 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:53:35,072 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a <unk> <unk> <unk> <unk>
2024-05-14 07:53:35,072 - INFO - joeynmt.training - Example #3
2024-05-14 07:53:35,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:53:35,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:53:35,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', '<unk>', 'and', '<unk>', '<unk>', '</s>']
2024-05-14 07:53:35,072 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:53:35,072 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:53:35,072 - INFO - joeynmt.training - 	Hypothesis: It <unk> <unk> and <unk> <unk>
2024-05-14 07:53:35,072 - INFO - joeynmt.training - Example #4
2024-05-14 07:53:35,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:53:35,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:53:35,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'see', '<unk>', '', 'is', 'a', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:53:35,073 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:53:35,073 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:53:35,073 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I see <unk>  is a <unk> <unk> <unk> <unk>
2024-05-14 07:53:38,153 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     1.900782, Batch Acc: 0.451350, Tokens per Sec:    21624, Lr: 0.000300
2024-05-14 07:53:41,239 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     1.975619, Batch Acc: 0.458365, Tokens per Sec:    22381, Lr: 0.000300
2024-05-14 07:53:45,308 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.082877, Batch Acc: 0.460310, Tokens per Sec:    17003, Lr: 0.000300
2024-05-14 07:53:48,380 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     1.881147, Batch Acc: 0.458754, Tokens per Sec:    22066, Lr: 0.000300
2024-05-14 07:53:51,438 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     1.846632, Batch Acc: 0.471772, Tokens per Sec:    22661, Lr: 0.000300
2024-05-14 07:53:51,438 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:53:51,439 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:53:55,038 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.11, ppl:   8.28, acc:   0.40, generation: 3.5844[sec], evaluation: 0.0000[sec]
2024-05-14 07:53:55,038 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:53:55,210 - INFO - joeynmt.training - Example #0
2024-05-14 07:53:55,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:53:55,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:53:55,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'of', 'the', '<unk>', 'I', 'see', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'the', 'last', 'three', 'million', 'years', '', 'and', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:53:55,212 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:53:55,212 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:53:55,212 - INFO - joeynmt.training - 	Hypothesis: <unk> years of the <unk> I see two <unk> to show that the <unk>  that the <unk> <unk> <unk> the last three million years  and <unk> <unk> <unk> <unk>
2024-05-14 07:53:55,212 - INFO - joeynmt.training - Example #1
2024-05-14 07:53:55,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:53:55,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:53:55,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', '<unk>', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', "it's", 'not', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:53:55,213 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:53:55,213 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:53:55,213 - INFO - joeynmt.training - 	Hypothesis: But this <unk> <unk> the <unk> of this particular problem because it's not the <unk> of the <unk>
2024-05-14 07:53:55,213 - INFO - joeynmt.training - Example #2
2024-05-14 07:53:55,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:53:55,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:53:55,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', '<unk>', '', 'the', '<unk>', 'of', 'our', '<unk>', '</s>']
2024-05-14 07:53:55,213 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:53:55,214 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:53:55,214 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a <unk>  the <unk> of our <unk>
2024-05-14 07:53:55,214 - INFO - joeynmt.training - Example #3
2024-05-14 07:53:55,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:53:55,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:53:55,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'from', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:53:55,214 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:53:55,214 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:53:55,214 - INFO - joeynmt.training - 	Hypothesis: It <unk> from the <unk> and <unk> in the <unk>
2024-05-14 07:53:55,215 - INFO - joeynmt.training - Example #4
2024-05-14 07:53:55,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:53:55,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:53:55,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'show', 'me', '', 'a', '<unk>', '<unk>', 'of', 'what', 'was', 'the', 'last', '25', 'years', 'of', 'what', 'was', '<unk>', '</s>']
2024-05-14 07:53:55,215 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:53:55,215 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:53:55,215 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show show me  a <unk> <unk> of what was the last 25 years of what was <unk>
2024-05-14 07:53:55,273 - INFO - joeynmt.training - Epoch   1: total training loss 5565.01
2024-05-14 07:53:55,274 - INFO - joeynmt.training - EPOCH 2
2024-05-14 07:53:59,130 - INFO - joeynmt.training - Epoch   2, Step:     2600, Batch Loss:     1.771603, Batch Acc: 0.476466, Tokens per Sec:    17412, Lr: 0.000300
2024-05-14 07:54:02,130 - INFO - joeynmt.training - Epoch   2, Step:     2700, Batch Loss:     1.854235, Batch Acc: 0.480629, Tokens per Sec:    22470, Lr: 0.000300
2024-05-14 07:54:05,174 - INFO - joeynmt.training - Epoch   2, Step:     2800, Batch Loss:     1.883024, Batch Acc: 0.486428, Tokens per Sec:    22816, Lr: 0.000300
2024-05-14 07:54:08,272 - INFO - joeynmt.training - Epoch   2, Step:     2900, Batch Loss:     1.827500, Batch Acc: 0.480941, Tokens per Sec:    21627, Lr: 0.000300
2024-05-14 07:54:12,138 - INFO - joeynmt.training - Epoch   2, Step:     3000, Batch Loss:     1.810245, Batch Acc: 0.485883, Tokens per Sec:    17582, Lr: 0.000300
2024-05-14 07:54:12,138 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:54:12,139 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:54:15,719 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.05, ppl:   7.73, acc:   0.41, generation: 3.5716[sec], evaluation: 0.0000[sec]
2024-05-14 07:54:15,720 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:54:15,823 - INFO - joeynmt.helpers - delete models/transformer_word/500.ckpt
2024-05-14 07:54:15,833 - INFO - joeynmt.training - Example #0
2024-05-14 07:54:15,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:54:15,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:54:15,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'was', '<unk>', 'this', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '<unk>', '<unk>', '', 'that', 'the', 'last', 'three', 'million', 'years', '', 'about', 'the', '<unk>', '<unk>', 'of', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:54:15,834 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:54:15,834 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:54:15,834 - INFO - joeynmt.training - 	Hypothesis: <unk> years I was <unk> this two <unk> to show that the <unk> <unk> <unk>  that the last three million years  about the <unk> <unk> of the <unk> <unk> <unk> <unk>
2024-05-14 07:54:15,834 - INFO - joeynmt.training - Example #1
2024-05-14 07:54:15,834 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:54:15,834 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:54:15,834 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'see', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:54:15,834 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:54:15,834 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:54:15,834 - INFO - joeynmt.training - 	Hypothesis: But this <unk> is actually the <unk> of this particular problem because it doesn't see the <unk> of the <unk>
2024-05-14 07:54:15,835 - INFO - joeynmt.training - Example #2
2024-05-14 07:54:15,835 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:54:15,835 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:54:15,835 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', '<unk>', '<unk>', '<unk>', 'of', 'us', '<unk>', '</s>']
2024-05-14 07:54:15,835 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:54:15,835 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:54:15,835 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a <unk> <unk> <unk> of us <unk>
2024-05-14 07:54:15,835 - INFO - joeynmt.training - Example #3
2024-05-14 07:54:15,835 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:54:15,835 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:54:15,835 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'out', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:54:15,835 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:54:15,835 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:54:15,836 - INFO - joeynmt.training - 	Hypothesis: It <unk> out in the <unk> and <unk> in the <unk>
2024-05-14 07:54:15,836 - INFO - joeynmt.training - Example #4
2024-05-14 07:54:15,836 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:54:15,836 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:54:15,836 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', 'I', 'show', 'show', 'you', '', 'a', '<unk>', 'version', 'of', 'what', 'there', 'is', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:54:15,836 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:54:15,836 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:54:15,836 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I show show you  a <unk> version of what there is the last 25 years is <unk>
2024-05-14 07:54:18,887 - INFO - joeynmt.training - Epoch   2, Step:     3100, Batch Loss:     1.811883, Batch Acc: 0.482678, Tokens per Sec:    21464, Lr: 0.000300
2024-05-14 07:54:22,288 - INFO - joeynmt.training - Epoch   2, Step:     3200, Batch Loss:     1.821034, Batch Acc: 0.491739, Tokens per Sec:    20415, Lr: 0.000300
2024-05-14 07:54:25,869 - INFO - joeynmt.training - Epoch   2, Step:     3300, Batch Loss:     1.821539, Batch Acc: 0.491325, Tokens per Sec:    19311, Lr: 0.000300
2024-05-14 07:54:28,937 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:     1.826030, Batch Acc: 0.497629, Tokens per Sec:    22693, Lr: 0.000300
2024-05-14 07:54:31,960 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:     1.605818, Batch Acc: 0.495207, Tokens per Sec:    22297, Lr: 0.000300
2024-05-14 07:54:31,960 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:54:31,960 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:54:36,189 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.07, ppl:   7.89, acc:   0.41, generation: 4.2143[sec], evaluation: 0.0000[sec]
2024-05-14 07:54:36,359 - INFO - joeynmt.helpers - delete models/transformer_word/1000.ckpt
2024-05-14 07:54:36,374 - INFO - joeynmt.training - Example #0
2024-05-14 07:54:36,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:54:36,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:54:36,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'was', '<unk>', 'these', 'two', '<unk>', 'to', 'show', 'this', 'is', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', 'last', 'three', 'million', 'years', '', 'about', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:54:36,375 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:54:36,376 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:54:36,376 - INFO - joeynmt.training - 	Hypothesis: <unk> years I was <unk> these two <unk> to show this is that the <unk>  that the <unk>  that the last three million years  about the size of the <unk> <unk> <unk> <unk>
2024-05-14 07:54:36,376 - INFO - joeynmt.training - Example #1
2024-05-14 07:54:36,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:54:36,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:54:36,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'is', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:54:36,376 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:54:36,377 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:54:36,377 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem is because it doesn't <unk> the <unk> of the <unk>
2024-05-14 07:54:36,377 - INFO - joeynmt.training - Example #2
2024-05-14 07:54:36,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:54:36,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:54:36,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense', 'of', 'our', '<unk>', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '</s>']
2024-05-14 07:54:36,377 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:54:36,377 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:54:36,378 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense of our <unk>  the <unk> heart of our <unk>
2024-05-14 07:54:36,378 - INFO - joeynmt.training - Example #3
2024-05-14 07:54:36,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:54:36,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:54:36,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:54:36,378 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:54:36,378 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:54:36,378 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:54:36,378 - INFO - joeynmt.training - Example #4
2024-05-14 07:54:36,379 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:54:36,379 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:54:36,379 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', 'I', 'show', 'show', 'show', '', 'a', '<unk>', 'version', 'of', 'what', 'was', 'happened', 'happened', 'happened', 'happened', 'to', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:54:36,379 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:54:36,379 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:54:36,379 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I show show show  a <unk> version of what was happened happened happened happened to 25 years is <unk>
2024-05-14 07:54:39,674 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     1.651578, Batch Acc: 0.503429, Tokens per Sec:    19754, Lr: 0.000300
2024-05-14 07:54:42,783 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     1.711434, Batch Acc: 0.495483, Tokens per Sec:    21614, Lr: 0.000300
2024-05-14 07:54:45,904 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     1.621217, Batch Acc: 0.498980, Tokens per Sec:    22150, Lr: 0.000300
2024-05-14 07:54:49,705 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     1.519709, Batch Acc: 0.507030, Tokens per Sec:    18062, Lr: 0.000300
2024-05-14 07:54:52,973 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     1.644849, Batch Acc: 0.500567, Tokens per Sec:    21328, Lr: 0.000300
2024-05-14 07:54:52,974 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:54:52,974 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:54:57,037 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.16, acc:   0.43, generation: 4.0553[sec], evaluation: 0.0000[sec]
2024-05-14 07:54:57,038 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:54:57,143 - INFO - joeynmt.helpers - delete models/transformer_word/1500.ckpt
2024-05-14 07:54:57,152 - INFO - joeynmt.training - Example #0
2024-05-14 07:54:57,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:54:57,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:54:57,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'this', 'two', '<unk>', 'to', 'show', 'this', 'this', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:54:57,153 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:54:57,153 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:54:57,153 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed this two <unk> to show this this two <unk> to show that the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2024-05-14 07:54:57,153 - INFO - joeynmt.training - Example #1
2024-05-14 07:54:57,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:54:57,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:54:57,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'is', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:54:57,153 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:54:57,153 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:54:57,153 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem is the <unk> of the <unk>
2024-05-14 07:54:57,153 - INFO - joeynmt.training - Example #2
2024-05-14 07:54:57,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:54:57,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:54:57,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense', 'of', '<unk>', 'our', '<unk>', '</s>']
2024-05-14 07:54:57,154 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:54:57,154 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:54:57,154 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense of <unk> our <unk>
2024-05-14 07:54:57,154 - INFO - joeynmt.training - Example #3
2024-05-14 07:54:57,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:54:57,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:54:57,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'out', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:54:57,154 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:54:57,154 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:54:57,154 - INFO - joeynmt.training - 	Hypothesis: It <unk> out in the <unk> and <unk> in the <unk>
2024-05-14 07:54:57,154 - INFO - joeynmt.training - Example #4
2024-05-14 07:54:57,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:54:57,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:54:57,155 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', 'I', 'show', 'show', 'you', '', 'a', '<unk>', 'version', 'of', 'what', 'was', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:54:57,155 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:54:57,155 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:54:57,155 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I show show you  a <unk> version of what was the last 25 years is <unk>
2024-05-14 07:55:00,291 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     1.668353, Batch Acc: 0.501535, Tokens per Sec:    20326, Lr: 0.000300
2024-05-14 07:55:04,317 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     1.779386, Batch Acc: 0.503665, Tokens per Sec:    17181, Lr: 0.000300
2024-05-14 07:55:07,381 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     1.632443, Batch Acc: 0.506714, Tokens per Sec:    21491, Lr: 0.000300
2024-05-14 07:55:10,461 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     1.662688, Batch Acc: 0.500555, Tokens per Sec:    22523, Lr: 0.000300
2024-05-14 07:55:13,595 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.515149, Batch Acc: 0.505543, Tokens per Sec:    21878, Lr: 0.000300
2024-05-14 07:55:13,595 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:55:13,596 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:55:18,442 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.27, acc:   0.42, generation: 4.8369[sec], evaluation: 0.0000[sec]
2024-05-14 07:55:18,551 - INFO - joeynmt.helpers - delete models/transformer_word/2000.ckpt
2024-05-14 07:55:18,561 - INFO - joeynmt.training - Example #0
2024-05-14 07:55:18,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:55:18,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:55:18,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'this', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', 'last', 'three', 'million', 'years', '', 'about', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:55:18,561 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:55:18,562 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:55:18,562 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show this two <unk> to show that the <unk>  that the last three million years  about the size of the <unk> <unk> <unk> <unk>
2024-05-14 07:55:18,562 - INFO - joeynmt.training - Example #1
2024-05-14 07:55:18,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:55:18,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:55:18,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'problem', '--', 'because', 'it', "doesn't", 'see', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:55:18,562 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:55:18,562 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:55:18,562 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this problem -- because it doesn't see the <unk> of the ice <unk>
2024-05-14 07:55:18,562 - INFO - joeynmt.training - Example #2
2024-05-14 07:55:18,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:55:18,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:55:18,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'certain', 'sense', 'of', 'our', '<unk>', '', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:55:18,563 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:55:18,563 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:55:18,563 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a certain sense of our <unk>  the <unk> <unk> <unk>
2024-05-14 07:55:18,563 - INFO - joeynmt.training - Example #3
2024-05-14 07:55:18,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:55:18,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:55:18,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:55:18,563 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:55:18,563 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:55:18,563 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:55:18,563 - INFO - joeynmt.training - Example #4
2024-05-14 07:55:18,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:55:18,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:55:18,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'I', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:55:18,564 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:55:18,564 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:55:18,564 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show I show you  is a <unk> version of what happened the last 25 years is <unk>
2024-05-14 07:55:21,598 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.714432, Batch Acc: 0.512567, Tokens per Sec:    21773, Lr: 0.000300
2024-05-14 07:55:24,625 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.747467, Batch Acc: 0.510493, Tokens per Sec:    22154, Lr: 0.000300
2024-05-14 07:55:28,018 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.683193, Batch Acc: 0.508052, Tokens per Sec:    19677, Lr: 0.000300
2024-05-14 07:55:31,680 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.628975, Batch Acc: 0.515555, Tokens per Sec:    18725, Lr: 0.000300
2024-05-14 07:55:34,718 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.702726, Batch Acc: 0.516948, Tokens per Sec:    22008, Lr: 0.000300
2024-05-14 07:55:34,719 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:55:34,719 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:55:39,422 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.30, acc:   0.42, generation: 4.6943[sec], evaluation: 0.0000[sec]
2024-05-14 07:55:39,525 - INFO - joeynmt.helpers - delete models/transformer_word/2500.ckpt
2024-05-14 07:55:39,534 - INFO - joeynmt.training - Example #0
2024-05-14 07:55:39,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:55:39,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:55:39,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', '<unk>', 'these', 'two', '<unk>', 'to', 'show', 'this', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:55:39,535 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:55:39,535 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:55:39,535 - INFO - joeynmt.training - 	Hypothesis: <unk> years I <unk> these two <unk> to show this two <unk> to show that the <unk>  that the <unk> <unk> <unk> <unk> <unk> <unk>
2024-05-14 07:55:39,535 - INFO - joeynmt.training - Example #1
2024-05-14 07:55:39,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:55:39,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:55:39,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'is', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:55:39,535 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:55:39,535 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:55:39,535 - INFO - joeynmt.training - 	Hypothesis: But this <unk> is the <unk> of this particular problem because it doesn't <unk> the <unk> of the ice <unk>
2024-05-14 07:55:39,536 - INFO - joeynmt.training - Example #2
2024-05-14 07:55:39,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:55:39,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:55:39,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense', 'of', '<unk>', '', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:55:39,536 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:55:39,536 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:55:39,536 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense of <unk>  the <unk> <unk> <unk>
2024-05-14 07:55:39,536 - INFO - joeynmt.training - Example #3
2024-05-14 07:55:39,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:55:39,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:55:39,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:55:39,536 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:55:39,537 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:55:39,537 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:55:39,537 - INFO - joeynmt.training - Example #4
2024-05-14 07:55:39,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:55:39,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:55:39,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'was', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 07:55:39,537 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:55:39,537 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:55:39,537 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show show  is a <unk> version of what was the last 25 years.
2024-05-14 07:55:39,668 - INFO - joeynmt.training - Epoch   2: total training loss 4288.18
2024-05-14 07:55:39,668 - INFO - joeynmt.training - EPOCH 3
2024-05-14 07:55:43,585 - INFO - joeynmt.training - Epoch   3, Step:     5100, Batch Loss:     1.593286, Batch Acc: 0.531427, Tokens per Sec:    16450, Lr: 0.000300
2024-05-14 07:55:46,650 - INFO - joeynmt.training - Epoch   3, Step:     5200, Batch Loss:     1.509036, Batch Acc: 0.527243, Tokens per Sec:    22574, Lr: 0.000300
2024-05-14 07:55:49,706 - INFO - joeynmt.training - Epoch   3, Step:     5300, Batch Loss:     1.524899, Batch Acc: 0.529673, Tokens per Sec:    22094, Lr: 0.000300
2024-05-14 07:55:52,739 - INFO - joeynmt.training - Epoch   3, Step:     5400, Batch Loss:     1.797702, Batch Acc: 0.525205, Tokens per Sec:    21966, Lr: 0.000300
2024-05-14 07:55:56,723 - INFO - joeynmt.training - Epoch   3, Step:     5500, Batch Loss:     1.644242, Batch Acc: 0.526197, Tokens per Sec:    17308, Lr: 0.000300
2024-05-14 07:55:56,723 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:55:56,723 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:56:01,528 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.24, acc:   0.42, generation: 4.7953[sec], evaluation: 0.0000[sec]
2024-05-14 07:56:01,633 - INFO - joeynmt.helpers - delete models/transformer_word/3500.ckpt
2024-05-14 07:56:01,643 - INFO - joeynmt.training - Example #0
2024-05-14 07:56:01,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:56:01,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:56:01,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'this', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:56:01,644 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:56:01,644 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:56:01,644 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show this <unk> <unk> <unk> <unk> <unk> <unk> <unk>  that the <unk> <unk> <unk> <unk> <unk>
2024-05-14 07:56:01,644 - INFO - joeynmt.training - Example #1
2024-05-14 07:56:01,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:56:01,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:56:01,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:56:01,644 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:56:01,644 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:56:01,645 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 07:56:01,645 - INFO - joeynmt.training - Example #2
2024-05-14 07:56:01,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:56:01,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:56:01,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense', 'of', '<unk>', '', 'the', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 07:56:01,645 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:56:01,645 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:56:01,645 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense of <unk>  the heart of our <unk> <unk>
2024-05-14 07:56:01,645 - INFO - joeynmt.training - Example #3
2024-05-14 07:56:01,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:56:01,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:56:01,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:56:01,646 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:56:01,646 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:56:01,646 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:56:01,646 - INFO - joeynmt.training - Example #4
2024-05-14 07:56:01,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:56:01,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:56:01,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'I', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:56:01,646 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:56:01,646 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:56:01,646 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show I show you  is a <unk> version of what the last 25 years is <unk>
2024-05-14 07:56:04,707 - INFO - joeynmt.training - Epoch   3, Step:     5600, Batch Loss:     1.664754, Batch Acc: 0.524613, Tokens per Sec:    21605, Lr: 0.000300
2024-05-14 07:56:08,391 - INFO - joeynmt.training - Epoch   3, Step:     5700, Batch Loss:     1.551588, Batch Acc: 0.525883, Tokens per Sec:    18081, Lr: 0.000300
2024-05-14 07:56:11,682 - INFO - joeynmt.training - Epoch   3, Step:     5800, Batch Loss:     1.580371, Batch Acc: 0.525697, Tokens per Sec:    20777, Lr: 0.000300
2024-05-14 07:56:14,769 - INFO - joeynmt.training - Epoch   3, Step:     5900, Batch Loss:     1.552419, Batch Acc: 0.526432, Tokens per Sec:    21922, Lr: 0.000300
2024-05-14 07:56:17,798 - INFO - joeynmt.training - Epoch   3, Step:     6000, Batch Loss:     1.539249, Batch Acc: 0.528512, Tokens per Sec:    22460, Lr: 0.000300
2024-05-14 07:56:17,799 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:56:17,799 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:56:22,817 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.18, acc:   0.43, generation: 5.0097[sec], evaluation: 0.0000[sec]
2024-05-14 07:56:22,929 - INFO - joeynmt.helpers - delete models/transformer_word/3000.ckpt
2024-05-14 07:56:22,938 - INFO - joeynmt.training - Example #0
2024-05-14 07:56:22,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:56:22,939 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:56:22,939 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'see', 'this', 'two', '<unk>', 'to', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:56:22,939 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:56:22,939 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:56:22,939 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to see this two <unk> to <unk>  that the <unk>  that the <unk> <unk> <unk>
2024-05-14 07:56:22,939 - INFO - joeynmt.training - Example #1
2024-05-14 07:56:22,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:56:22,939 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:56:22,939 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:56:22,940 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:56:22,940 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:56:22,940 - INFO - joeynmt.training - 	Hypothesis: But this <unk> the <unk> of this particular problem because it doesn't <unk> the <unk> of the ice <unk>
2024-05-14 07:56:22,940 - INFO - joeynmt.training - Example #2
2024-05-14 07:56:22,940 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:56:22,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:56:22,940 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense', 'of', '<unk>', '', 'the', 'heart', 'of', 'our', '<unk>', '</s>']
2024-05-14 07:56:22,940 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:56:22,940 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:56:22,940 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense of <unk>  the heart of our <unk>
2024-05-14 07:56:22,940 - INFO - joeynmt.training - Example #3
2024-05-14 07:56:22,940 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:56:22,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:56:22,940 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:56:22,941 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:56:22,941 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:56:22,941 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:56:22,941 - INFO - joeynmt.training - Example #4
2024-05-14 07:56:22,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:56:22,941 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:56:22,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:56:22,941 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:56:22,941 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:56:22,941 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show show  is a <unk> version of what happened in the last 25 years is <unk>
2024-05-14 07:56:26,034 - INFO - joeynmt.training - Epoch   3, Step:     6100, Batch Loss:     1.637329, Batch Acc: 0.526006, Tokens per Sec:    20961, Lr: 0.000300
2024-05-14 07:56:29,077 - INFO - joeynmt.training - Epoch   3, Step:     6200, Batch Loss:     1.404941, Batch Acc: 0.526517, Tokens per Sec:    23143, Lr: 0.000300
2024-05-14 07:56:32,121 - INFO - joeynmt.training - Epoch   3, Step:     6300, Batch Loss:     1.702216, Batch Acc: 0.527965, Tokens per Sec:    22009, Lr: 0.000300
2024-05-14 07:56:36,001 - INFO - joeynmt.training - Epoch   3, Step:     6400, Batch Loss:     1.451556, Batch Acc: 0.528819, Tokens per Sec:    17490, Lr: 0.000300
2024-05-14 07:56:39,049 - INFO - joeynmt.training - Epoch   3, Step:     6500, Batch Loss:     1.623160, Batch Acc: 0.530376, Tokens per Sec:    21902, Lr: 0.000300
2024-05-14 07:56:39,049 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:56:39,049 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:56:43,564 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.07, acc:   0.43, generation: 4.5042[sec], evaluation: 0.0000[sec]
2024-05-14 07:56:43,564 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:56:43,669 - INFO - joeynmt.helpers - delete models/transformer_word/5000.ckpt
2024-05-14 07:56:43,679 - INFO - joeynmt.training - Example #0
2024-05-14 07:56:43,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:56:43,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:56:43,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'this', 'two', '<unk>', 'to', 'see', 'this', 'two', '<unk>', 'to', '<unk>', '', 'that', 'the', '<unk>', '', 'the', 'last', 'three', 'million', 'years', '--', 'about', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:56:43,679 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:56:43,680 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:56:43,680 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed this two <unk> to see this two <unk> to <unk>  that the <unk>  the last three million years -- about the <unk> <unk> <unk> <unk>
2024-05-14 07:56:43,680 - INFO - joeynmt.training - Example #1
2024-05-14 07:56:43,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:56:43,680 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:56:43,680 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:56:43,680 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:56:43,680 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:56:43,680 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't <unk> the <unk> of the ice <unk>
2024-05-14 07:56:43,680 - INFO - joeynmt.training - Example #2
2024-05-14 07:56:43,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:56:43,680 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:56:43,680 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'certain', 'sense', 'of', 'our', '<unk>', '', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 07:56:43,681 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:56:43,681 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:56:43,681 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a certain sense of our <unk>   the <unk> heart of our <unk> <unk>
2024-05-14 07:56:43,681 - INFO - joeynmt.training - Example #3
2024-05-14 07:56:43,681 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:56:43,681 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:56:43,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:56:43,681 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:56:43,681 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:56:43,681 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:56:43,681 - INFO - joeynmt.training - Example #4
2024-05-14 07:56:43,681 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:56:43,681 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:56:43,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'there', 'is', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:56:43,682 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:56:43,682 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:56:43,682 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I show  is a <unk> version of what there is the last 25 years is <unk>
2024-05-14 07:56:47,179 - INFO - joeynmt.training - Epoch   3, Step:     6600, Batch Loss:     1.711430, Batch Acc: 0.528336, Tokens per Sec:    18703, Lr: 0.000300
2024-05-14 07:56:50,736 - INFO - joeynmt.training - Epoch   3, Step:     6700, Batch Loss:     1.496673, Batch Acc: 0.529337, Tokens per Sec:    19403, Lr: 0.000300
2024-05-14 07:56:53,809 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:     1.611123, Batch Acc: 0.528915, Tokens per Sec:    21862, Lr: 0.000300
2024-05-14 07:56:56,871 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:     1.485237, Batch Acc: 0.527080, Tokens per Sec:    22240, Lr: 0.000300
2024-05-14 07:57:00,358 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     1.610885, Batch Acc: 0.531295, Tokens per Sec:    19704, Lr: 0.000300
2024-05-14 07:57:00,358 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:57:00,358 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:57:04,231 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.72, acc:   0.44, generation: 3.8644[sec], evaluation: 0.0000[sec]
2024-05-14 07:57:04,231 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:57:04,333 - INFO - joeynmt.helpers - delete models/transformer_word/4500.ckpt
2024-05-14 07:57:04,342 - INFO - joeynmt.training - Example #0
2024-05-14 07:57:04,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:57:04,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:57:04,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'this', '', 'to', 'show', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:57:04,343 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:57:04,343 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:57:04,343 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show this  to show that the <unk> <unk> <unk> <unk> <unk>
2024-05-14 07:57:04,343 - INFO - joeynmt.training - Example #1
2024-05-14 07:57:04,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:57:04,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:57:04,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:57:04,343 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:57:04,343 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:57:04,344 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 07:57:04,344 - INFO - joeynmt.training - Example #2
2024-05-14 07:57:04,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:57:04,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:57:04,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', '<unk>', 'heart', 'of', 'our', '<unk>', '</s>']
2024-05-14 07:57:04,344 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:57:04,344 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:57:04,344 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense,  the <unk> <unk> heart of our <unk>
2024-05-14 07:57:04,344 - INFO - joeynmt.training - Example #3
2024-05-14 07:57:04,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:57:04,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:57:04,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:57:04,344 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:57:04,344 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:57:04,344 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:57:04,345 - INFO - joeynmt.training - Example #4
2024-05-14 07:57:04,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:57:04,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:57:04,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'was', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 07:57:04,345 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:57:04,345 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:57:04,345 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show show you  is a <unk> version of what was the last 25 years.
2024-05-14 07:57:07,448 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     1.531559, Batch Acc: 0.530497, Tokens per Sec:    21325, Lr: 0.000300
2024-05-14 07:57:10,606 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     1.509036, Batch Acc: 0.537304, Tokens per Sec:    21279, Lr: 0.000300
2024-05-14 07:57:14,325 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     1.606387, Batch Acc: 0.531876, Tokens per Sec:    18219, Lr: 0.000300
2024-05-14 07:57:17,856 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     1.559710, Batch Acc: 0.527723, Tokens per Sec:    19183, Lr: 0.000300
2024-05-14 07:57:21,000 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     1.513133, Batch Acc: 0.533319, Tokens per Sec:    21878, Lr: 0.000300
2024-05-14 07:57:21,000 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:57:21,000 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:57:25,501 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.79, acc:   0.44, generation: 4.4853[sec], evaluation: 0.0000[sec]
2024-05-14 07:57:25,657 - INFO - joeynmt.helpers - delete models/transformer_word/5500.ckpt
2024-05-14 07:57:25,672 - INFO - joeynmt.training - Example #0
2024-05-14 07:57:25,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:57:25,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:57:25,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:57:25,673 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:57:25,673 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:57:25,673 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show these two <unk> to show that the <unk>  that the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2024-05-14 07:57:25,673 - INFO - joeynmt.training - Example #1
2024-05-14 07:57:25,673 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:57:25,673 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:57:25,673 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:57:25,674 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:57:25,674 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:57:25,674 - INFO - joeynmt.training - 	Hypothesis: But this <unk> the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 07:57:25,674 - INFO - joeynmt.training - Example #2
2024-05-14 07:57:25,674 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:57:25,674 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:57:25,674 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 07:57:25,675 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:57:25,675 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:57:25,675 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 07:57:25,675 - INFO - joeynmt.training - Example #3
2024-05-14 07:57:25,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:57:25,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:57:25,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:57:25,676 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:57:25,676 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:57:25,676 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:57:25,676 - INFO - joeynmt.training - Example #4
2024-05-14 07:57:25,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:57:25,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:57:25,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:57:25,677 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:57:25,677 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:57:25,677 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show you  is a <unk> version of what happened in the last 25 years is <unk>
2024-05-14 07:57:26,310 - INFO - joeynmt.training - Epoch   3: total training loss 3970.31
2024-05-14 07:57:26,311 - INFO - joeynmt.training - EPOCH 4
2024-05-14 07:57:29,625 - INFO - joeynmt.training - Epoch   4, Step:     7600, Batch Loss:     1.417308, Batch Acc: 0.553972, Tokens per Sec:    17024, Lr: 0.000300
2024-05-14 07:57:32,751 - INFO - joeynmt.training - Epoch   4, Step:     7700, Batch Loss:     1.493059, Batch Acc: 0.553151, Tokens per Sec:    22625, Lr: 0.000300
2024-05-14 07:57:35,941 - INFO - joeynmt.training - Epoch   4, Step:     7800, Batch Loss:     1.460748, Batch Acc: 0.553181, Tokens per Sec:    21391, Lr: 0.000300
2024-05-14 07:57:39,318 - INFO - joeynmt.training - Epoch   4, Step:     7900, Batch Loss:     1.384960, Batch Acc: 0.548583, Tokens per Sec:    20171, Lr: 0.000300
2024-05-14 07:57:43,160 - INFO - joeynmt.training - Epoch   4, Step:     8000, Batch Loss:     1.531763, Batch Acc: 0.547871, Tokens per Sec:    17529, Lr: 0.000300
2024-05-14 07:57:43,160 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:57:43,161 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:57:46,442 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.84, acc:   0.43, generation: 3.2698[sec], evaluation: 0.0000[sec]
2024-05-14 07:57:46,553 - INFO - joeynmt.helpers - delete models/transformer_word/6000.ckpt
2024-05-14 07:57:46,563 - INFO - joeynmt.training - Example #0
2024-05-14 07:57:46,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:57:46,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:57:46,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'year', 'I', '<unk>', 'these', 'two', '<unk>', 'to', 'show', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '<unk>', '', 'about', 'the', 'last', 'three', 'million', 'years', '--', '</s>']
2024-05-14 07:57:46,564 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:57:46,564 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:57:46,564 - INFO - joeynmt.training - 	Hypothesis: <unk> year I <unk> these two <unk> to show these two <unk> to show that the <unk> <unk>  about the last three million years --
2024-05-14 07:57:46,564 - INFO - joeynmt.training - Example #1
2024-05-14 07:57:46,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:57:46,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:57:46,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:57:46,564 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:57:46,565 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:57:46,565 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 07:57:46,565 - INFO - joeynmt.training - Example #2
2024-05-14 07:57:46,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:57:46,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:57:46,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 07:57:46,565 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:57:46,565 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:57:46,565 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense,  the <unk> heart of our <unk> <unk>
2024-05-14 07:57:46,565 - INFO - joeynmt.training - Example #3
2024-05-14 07:57:46,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:57:46,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:57:46,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:57:46,566 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:57:46,566 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:57:46,566 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:57:46,566 - INFO - joeynmt.training - Example #4
2024-05-14 07:57:46,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:57:46,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:57:46,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'is', 'the', 'last', '25', 'years', '<unk>', '</s>']
2024-05-14 07:57:46,566 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:57:46,566 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:57:46,566 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show show you  is a <unk> version of what happened is the last 25 years <unk>
2024-05-14 07:57:49,710 - INFO - joeynmt.training - Epoch   4, Step:     8100, Batch Loss:     1.545218, Batch Acc: 0.546617, Tokens per Sec:    20658, Lr: 0.000300
2024-05-14 07:57:53,203 - INFO - joeynmt.training - Epoch   4, Step:     8200, Batch Loss:     1.471802, Batch Acc: 0.544745, Tokens per Sec:    19853, Lr: 0.000300
2024-05-14 07:57:56,741 - INFO - joeynmt.training - Epoch   4, Step:     8300, Batch Loss:     1.480895, Batch Acc: 0.545811, Tokens per Sec:    19020, Lr: 0.000300
2024-05-14 07:57:59,753 - INFO - joeynmt.training - Epoch   4, Step:     8400, Batch Loss:     1.464625, Batch Acc: 0.546066, Tokens per Sec:    22429, Lr: 0.000300
2024-05-14 07:58:02,781 - INFO - joeynmt.training - Epoch   4, Step:     8500, Batch Loss:     1.465006, Batch Acc: 0.543639, Tokens per Sec:    22558, Lr: 0.000300
2024-05-14 07:58:02,781 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:58:02,781 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:58:07,206 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.99, acc:   0.43, generation: 4.4102[sec], evaluation: 0.0000[sec]
2024-05-14 07:58:07,363 - INFO - joeynmt.helpers - delete models/transformer_word/4000.ckpt
2024-05-14 07:58:07,378 - INFO - joeynmt.training - Example #0
2024-05-14 07:58:07,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:58:07,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:58:07,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'this', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'had', 'about', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '</s>']
2024-05-14 07:58:07,379 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:58:07,379 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:58:07,380 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show this <unk>  that the <unk>  that the <unk>  that had about the size of the <unk> <unk>
2024-05-14 07:58:07,380 - INFO - joeynmt.training - Example #1
2024-05-14 07:58:07,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:58:07,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:58:07,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'is', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:58:07,380 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:58:07,380 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:58:07,381 - INFO - joeynmt.training - 	Hypothesis: But this <unk> the <unk> of this particular problem is because it doesn't <unk> the <unk> of the ice <unk>
2024-05-14 07:58:07,381 - INFO - joeynmt.training - Example #2
2024-05-14 07:58:07,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:58:07,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:58:07,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 07:58:07,382 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:58:07,382 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:58:07,382 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 07:58:07,382 - INFO - joeynmt.training - Example #3
2024-05-14 07:58:07,382 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:58:07,382 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:58:07,382 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:58:07,383 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:58:07,383 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:58:07,383 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:58:07,383 - INFO - joeynmt.training - Example #4
2024-05-14 07:58:07,383 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:58:07,383 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:58:07,383 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'was', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:58:07,384 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:58:07,384 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:58:07,384 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show show you  is a <unk> version of what was the last 25 years is <unk>
2024-05-14 07:58:11,579 - INFO - joeynmt.training - Epoch   4, Step:     8600, Batch Loss:     1.534446, Batch Acc: 0.548021, Tokens per Sec:    15669, Lr: 0.000300
2024-05-14 07:58:14,662 - INFO - joeynmt.training - Epoch   4, Step:     8700, Batch Loss:     1.408740, Batch Acc: 0.545366, Tokens per Sec:    21947, Lr: 0.000300
2024-05-14 07:58:17,749 - INFO - joeynmt.training - Epoch   4, Step:     8800, Batch Loss:     1.481775, Batch Acc: 0.542907, Tokens per Sec:    22019, Lr: 0.000300
2024-05-14 07:58:21,434 - INFO - joeynmt.training - Epoch   4, Step:     8900, Batch Loss:     1.510426, Batch Acc: 0.545611, Tokens per Sec:    18734, Lr: 0.000300
2024-05-14 07:58:24,724 - INFO - joeynmt.training - Epoch   4, Step:     9000, Batch Loss:     1.405122, Batch Acc: 0.544078, Tokens per Sec:    20437, Lr: 0.000300
2024-05-14 07:58:24,725 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:58:24,725 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:58:28,196 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.62, acc:   0.44, generation: 3.4635[sec], evaluation: 0.0000[sec]
2024-05-14 07:58:28,197 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:58:28,303 - INFO - joeynmt.helpers - delete models/transformer_word/6500.ckpt
2024-05-14 07:58:28,314 - INFO - joeynmt.training - Example #0
2024-05-14 07:58:28,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:58:28,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:58:28,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'this', '--', 'the', '<unk>', '<unk>', '<unk>', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'had', 'about', 'the', '<unk>', '<unk>', '</s>']
2024-05-14 07:58:28,314 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:58:28,314 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:58:28,314 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show this -- the <unk> <unk> <unk> that the <unk>  that the <unk> <unk> <unk> had about the <unk> <unk>
2024-05-14 07:58:28,314 - INFO - joeynmt.training - Example #1
2024-05-14 07:58:28,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:58:28,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:58:28,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:58:28,315 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:58:28,315 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:58:28,315 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 07:58:28,315 - INFO - joeynmt.training - Example #2
2024-05-14 07:58:28,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:58:28,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:58:28,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:58:28,315 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:58:28,315 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:58:28,315 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> <unk> <unk> <unk>
2024-05-14 07:58:28,315 - INFO - joeynmt.training - Example #3
2024-05-14 07:58:28,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:58:28,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:58:28,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:58:28,316 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:58:28,316 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:58:28,316 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:58:28,316 - INFO - joeynmt.training - Example #4
2024-05-14 07:58:28,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:58:28,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:58:28,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years', 'of', '<unk>', '</s>']
2024-05-14 07:58:28,316 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:58:28,316 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:58:28,316 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show  is a <unk> version of what happened in the last 25 years of <unk>
2024-05-14 07:58:31,377 - INFO - joeynmt.training - Epoch   4, Step:     9100, Batch Loss:     1.555607, Batch Acc: 0.546678, Tokens per Sec:    21660, Lr: 0.000300
2024-05-14 07:58:35,302 - INFO - joeynmt.training - Epoch   4, Step:     9200, Batch Loss:     1.489653, Batch Acc: 0.544509, Tokens per Sec:    16786, Lr: 0.000300
2024-05-14 07:58:38,477 - INFO - joeynmt.training - Epoch   4, Step:     9300, Batch Loss:     1.494729, Batch Acc: 0.540109, Tokens per Sec:    20711, Lr: 0.000300
2024-05-14 07:58:41,578 - INFO - joeynmt.training - Epoch   4, Step:     9400, Batch Loss:     1.538212, Batch Acc: 0.549006, Tokens per Sec:    22330, Lr: 0.000300
2024-05-14 07:58:44,681 - INFO - joeynmt.training - Epoch   4, Step:     9500, Batch Loss:     1.501735, Batch Acc: 0.541841, Tokens per Sec:    21629, Lr: 0.000300
2024-05-14 07:58:44,681 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:58:44,681 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:58:49,488 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.59, acc:   0.45, generation: 4.7981[sec], evaluation: 0.0000[sec]
2024-05-14 07:58:49,489 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:58:49,594 - INFO - joeynmt.helpers - delete models/transformer_word/8500.ckpt
2024-05-14 07:58:49,605 - INFO - joeynmt.training - Example #0
2024-05-14 07:58:49,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:58:49,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:58:49,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'this', 'two', '<unk>', 'to', 'show', 'this', 'is', 'that', 'the', '<unk>', '', 'that', '<unk>', 'the', 'last', 'three', 'million', 'years', '--', 'about', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:58:49,606 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:58:49,606 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:58:49,606 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed this two <unk> to show this is that the <unk>  that <unk> the last three million years -- about the size of the <unk> <unk> <unk>
2024-05-14 07:58:49,606 - INFO - joeynmt.training - Example #1
2024-05-14 07:58:49,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:58:49,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:58:49,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:58:49,606 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:58:49,606 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:58:49,606 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 07:58:49,607 - INFO - joeynmt.training - Example #2
2024-05-14 07:58:49,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:58:49,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:58:49,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 07:58:49,607 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:58:49,607 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:58:49,607 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense,  the <unk> heart of our <unk> <unk>
2024-05-14 07:58:49,607 - INFO - joeynmt.training - Example #3
2024-05-14 07:58:49,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:58:49,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:58:49,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:58:49,607 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:58:49,607 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:58:49,608 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:58:49,608 - INFO - joeynmt.training - Example #4
2024-05-14 07:58:49,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:58:49,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:58:49,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', "I'm", 'going', 'to', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'the', 'last', '25', 'years', 'of', 'what', 'happened', 'in', '25', 'years', 'of', 'what', 'happened', 'to', '25', 'years', 'of', '<unk>', '</s>']
2024-05-14 07:58:49,608 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:58:49,608 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:58:49,608 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I'm going to show you  is a <unk> version of what happened the last 25 years of what happened in 25 years of what happened to 25 years of <unk>
2024-05-14 07:58:52,687 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:     1.544370, Batch Acc: 0.541751, Tokens per Sec:    21376, Lr: 0.000300
2024-05-14 07:58:55,713 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:     1.583475, Batch Acc: 0.542850, Tokens per Sec:    22602, Lr: 0.000300
2024-05-14 07:58:58,834 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:     1.409804, Batch Acc: 0.547394, Tokens per Sec:    21626, Lr: 0.000300
2024-05-14 07:59:02,882 - INFO - joeynmt.training - Epoch   4, Step:     9900, Batch Loss:     1.539450, Batch Acc: 0.539824, Tokens per Sec:    16641, Lr: 0.000300
2024-05-14 07:59:05,978 - INFO - joeynmt.training - Epoch   4, Step:    10000, Batch Loss:     1.494817, Batch Acc: 0.541989, Tokens per Sec:    22136, Lr: 0.000300
2024-05-14 07:59:05,978 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:59:05,978 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:59:09,930 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.76, acc:   0.44, generation: 3.9420[sec], evaluation: 0.0000[sec]
2024-05-14 07:59:10,038 - INFO - joeynmt.helpers - delete models/transformer_word/8000.ckpt
2024-05-14 07:59:10,047 - INFO - joeynmt.training - Example #0
2024-05-14 07:59:10,047 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:59:10,047 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:59:10,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:59:10,048 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:59:10,048 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:59:10,048 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to <unk>  that the <unk> <unk>  that the <unk>  that the <unk> <unk> <unk> <unk> <unk>
2024-05-14 07:59:10,048 - INFO - joeynmt.training - Example #1
2024-05-14 07:59:10,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:59:10,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:59:10,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:59:10,048 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:59:10,048 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:59:10,048 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 07:59:10,048 - INFO - joeynmt.training - Example #2
2024-05-14 07:59:10,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:59:10,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:59:10,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', '<unk>', 'in', 'a', 'sense,', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 07:59:10,049 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:59:10,049 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:59:10,049 - INFO - joeynmt.training - 	Hypothesis: The <unk> <unk> in a sense, is in a sense,  the <unk> heart of our <unk> <unk>
2024-05-14 07:59:10,049 - INFO - joeynmt.training - Example #3
2024-05-14 07:59:10,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:59:10,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:59:10,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:59:10,049 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:59:10,049 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:59:10,049 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:59:10,049 - INFO - joeynmt.training - Example #4
2024-05-14 07:59:10,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:59:10,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:59:10,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 07:59:10,050 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:59:10,050 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:59:10,050 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show show  is a <unk> version of what happened in the last 25 years is <unk>
2024-05-14 07:59:10,865 - INFO - joeynmt.training - Epoch   4: total training loss 3789.29
2024-05-14 07:59:10,865 - INFO - joeynmt.training - EPOCH 5
2024-05-14 07:59:13,459 - INFO - joeynmt.training - Epoch   5, Step:    10100, Batch Loss:     1.556049, Batch Acc: 0.562122, Tokens per Sec:    19551, Lr: 0.000300
2024-05-14 07:59:17,195 - INFO - joeynmt.training - Epoch   5, Step:    10200, Batch Loss:     1.300184, Batch Acc: 0.565497, Tokens per Sec:    17624, Lr: 0.000300
2024-05-14 07:59:20,261 - INFO - joeynmt.training - Epoch   5, Step:    10300, Batch Loss:     1.343616, Batch Acc: 0.562721, Tokens per Sec:    22084, Lr: 0.000300
2024-05-14 07:59:23,349 - INFO - joeynmt.training - Epoch   5, Step:    10400, Batch Loss:     1.271271, Batch Acc: 0.561985, Tokens per Sec:    21955, Lr: 0.000300
2024-05-14 07:59:26,757 - INFO - joeynmt.training - Epoch   5, Step:    10500, Batch Loss:     1.423304, Batch Acc: 0.560877, Tokens per Sec:    20006, Lr: 0.000300
2024-05-14 07:59:26,757 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:59:26,757 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:59:31,167 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.62, acc:   0.44, generation: 4.4003[sec], evaluation: 0.0000[sec]
2024-05-14 07:59:31,267 - INFO - joeynmt.helpers - delete models/transformer_word/7500.ckpt
2024-05-14 07:59:31,277 - INFO - joeynmt.training - Example #0
2024-05-14 07:59:31,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:59:31,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:59:31,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 07:59:31,277 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:59:31,277 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:59:31,277 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show that the <unk>  that the <unk>  that the <unk> <unk>  that the <unk> <unk> <unk>
2024-05-14 07:59:31,277 - INFO - joeynmt.training - Example #1
2024-05-14 07:59:31,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:59:31,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:59:31,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 07:59:31,278 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:59:31,278 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:59:31,278 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't show the <unk> of the <unk>
2024-05-14 07:59:31,278 - INFO - joeynmt.training - Example #2
2024-05-14 07:59:31,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:59:31,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:59:31,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 07:59:31,278 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:59:31,278 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:59:31,278 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense,  the <unk> heart of our <unk> <unk>
2024-05-14 07:59:31,278 - INFO - joeynmt.training - Example #3
2024-05-14 07:59:31,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:59:31,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:59:31,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:59:31,279 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:59:31,279 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:59:31,279 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:59:31,279 - INFO - joeynmt.training - Example #4
2024-05-14 07:59:31,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:59:31,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:59:31,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years', 'of', 'what', 'happened', 'is', 'in', 'the', 'last', '25', 'years', 'of', '<unk>', '</s>']
2024-05-14 07:59:31,279 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:59:31,279 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:59:31,279 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show  is a <unk> version of what happened in the last 25 years of what happened is in the last 25 years of <unk>
2024-05-14 07:59:34,395 - INFO - joeynmt.training - Epoch   5, Step:    10600, Batch Loss:     1.468738, Batch Acc: 0.557385, Tokens per Sec:    21060, Lr: 0.000300
2024-05-14 07:59:37,452 - INFO - joeynmt.training - Epoch   5, Step:    10700, Batch Loss:     1.420609, Batch Acc: 0.561141, Tokens per Sec:    22080, Lr: 0.000300
2024-05-14 07:59:41,173 - INFO - joeynmt.training - Epoch   5, Step:    10800, Batch Loss:     1.483959, Batch Acc: 0.561665, Tokens per Sec:    18444, Lr: 0.000300
2024-05-14 07:59:44,573 - INFO - joeynmt.training - Epoch   5, Step:    10900, Batch Loss:     1.378706, Batch Acc: 0.557703, Tokens per Sec:    19870, Lr: 0.000300
2024-05-14 07:59:47,627 - INFO - joeynmt.training - Epoch   5, Step:    11000, Batch Loss:     1.530455, Batch Acc: 0.557872, Tokens per Sec:    22409, Lr: 0.000300
2024-05-14 07:59:47,628 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 07:59:47,628 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 07:59:51,797 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.53, acc:   0.45, generation: 4.1614[sec], evaluation: 0.0000[sec]
2024-05-14 07:59:51,798 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 07:59:51,905 - INFO - joeynmt.helpers - delete models/transformer_word/10000.ckpt
2024-05-14 07:59:51,915 - INFO - joeynmt.training - Example #0
2024-05-14 07:59:51,915 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 07:59:51,915 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 07:59:51,915 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'these', 'two', '<unk>', 'to', '<unk>', '</s>']
2024-05-14 07:59:51,916 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 07:59:51,916 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 07:59:51,916 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show these two <unk> to <unk>
2024-05-14 07:59:51,916 - INFO - joeynmt.training - Example #1
2024-05-14 07:59:51,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 07:59:51,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 07:59:51,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 07:59:51,916 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 07:59:51,916 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 07:59:51,916 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 07:59:51,916 - INFO - joeynmt.training - Example #2
2024-05-14 07:59:51,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 07:59:51,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 07:59:51,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 07:59:51,917 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 07:59:51,917 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 07:59:51,917 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense,  the <unk> heart of our <unk> <unk>
2024-05-14 07:59:51,917 - INFO - joeynmt.training - Example #3
2024-05-14 07:59:51,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 07:59:51,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 07:59:51,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 07:59:51,917 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 07:59:51,918 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 07:59:51,918 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 07:59:51,918 - INFO - joeynmt.training - Example #4
2024-05-14 07:59:51,918 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 07:59:51,918 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 07:59:51,918 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', "I'm", 'going', 'to', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', '</s>']
2024-05-14 07:59:51,918 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 07:59:51,918 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 07:59:51,918 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I'm going to show you  is a <unk> version of what has been <unk>
2024-05-14 07:59:55,977 - INFO - joeynmt.training - Epoch   5, Step:    11100, Batch Loss:     1.220157, Batch Acc: 0.556750, Tokens per Sec:    16116, Lr: 0.000300
2024-05-14 07:59:59,035 - INFO - joeynmt.training - Epoch   5, Step:    11200, Batch Loss:     1.450169, Batch Acc: 0.554757, Tokens per Sec:    22242, Lr: 0.000300
2024-05-14 08:00:02,072 - INFO - joeynmt.training - Epoch   5, Step:    11300, Batch Loss:     1.489675, Batch Acc: 0.559990, Tokens per Sec:    23088, Lr: 0.000300
2024-05-14 08:00:05,164 - INFO - joeynmt.training - Epoch   5, Step:    11400, Batch Loss:     1.501707, Batch Acc: 0.554451, Tokens per Sec:    22720, Lr: 0.000300
2024-05-14 08:00:09,143 - INFO - joeynmt.training - Epoch   5, Step:    11500, Batch Loss:     1.530875, Batch Acc: 0.558247, Tokens per Sec:    17163, Lr: 0.000300
2024-05-14 08:00:09,143 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:00:09,143 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:00:13,116 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.71, acc:   0.44, generation: 3.9645[sec], evaluation: 0.0000[sec]
2024-05-14 08:00:13,219 - INFO - joeynmt.helpers - delete models/transformer_word/7000.ckpt
2024-05-14 08:00:13,229 - INFO - joeynmt.training - Example #0
2024-05-14 08:00:13,229 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:00:13,229 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:00:13,229 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'year', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:00:13,229 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:00:13,229 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:00:13,230 - INFO - joeynmt.training - 	Hypothesis: <unk> year I showed these two <unk> to show you that the <unk>  that the <unk>  that the <unk> <unk> <unk> <unk> <unk> <unk>
2024-05-14 08:00:13,230 - INFO - joeynmt.training - Example #1
2024-05-14 08:00:13,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:00:13,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:00:13,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', '--', '', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:00:13,230 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:00:13,230 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:00:13,230 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem --  because it doesn't show the <unk> of the ice <unk>
2024-05-14 08:00:13,230 - INFO - joeynmt.training - Example #2
2024-05-14 08:00:13,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:00:13,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:00:13,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:00:13,230 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:00:13,231 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:00:13,231 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:00:13,231 - INFO - joeynmt.training - Example #3
2024-05-14 08:00:13,231 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:00:13,231 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:00:13,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:00:13,231 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:00:13,231 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:00:13,231 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:00:13,231 - INFO - joeynmt.training - Example #4
2024-05-14 08:00:13,231 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:00:13,231 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:00:13,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'is', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 08:00:13,231 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:00:13,231 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:00:13,232 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show show you  is a <unk> version of what is the last 25 years is <unk>
2024-05-14 08:00:16,339 - INFO - joeynmt.training - Epoch   5, Step:    11600, Batch Loss:     1.472479, Batch Acc: 0.558161, Tokens per Sec:    20736, Lr: 0.000300
2024-05-14 08:00:19,910 - INFO - joeynmt.training - Epoch   5, Step:    11700, Batch Loss:     1.461368, Batch Acc: 0.560463, Tokens per Sec:    19377, Lr: 0.000300
2024-05-14 08:00:23,645 - INFO - joeynmt.training - Epoch   5, Step:    11800, Batch Loss:     1.603539, Batch Acc: 0.554127, Tokens per Sec:    18278, Lr: 0.000300
2024-05-14 08:00:26,783 - INFO - joeynmt.training - Epoch   5, Step:    11900, Batch Loss:     1.435631, Batch Acc: 0.561170, Tokens per Sec:    21722, Lr: 0.000300
2024-05-14 08:00:29,887 - INFO - joeynmt.training - Epoch   5, Step:    12000, Batch Loss:     1.368987, Batch Acc: 0.559631, Tokens per Sec:    21709, Lr: 0.000300
2024-05-14 08:00:29,888 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:00:29,888 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:00:34,224 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.54, acc:   0.44, generation: 4.3201[sec], evaluation: 0.0000[sec]
2024-05-14 08:00:34,378 - INFO - joeynmt.helpers - delete models/transformer_word/11500.ckpt
2024-05-14 08:00:34,393 - INFO - joeynmt.helpers - delete /content/mt-exercise-5/models/transformer_word/11500.ckpt
2024-05-14 08:00:34,394 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/mt-exercise-5/models/transformer_word/11500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/mt-exercise-5/models/transformer_word/11500.ckpt')
2024-05-14 08:00:34,394 - INFO - joeynmt.training - Example #0
2024-05-14 08:00:34,394 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:00:34,394 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:00:34,394 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'to', 'show', 'these', 'two', '<unk>', 'to', 'show', 'the', '<unk>', '<unk>', '<unk>', 'that', 'the', '<unk>', '<unk>', '', 'which', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:00:34,395 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:00:34,395 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:00:34,395 - INFO - joeynmt.training - 	Hypothesis: <unk> years to show these two <unk> to show the <unk> <unk> <unk> that the <unk> <unk>  which <unk> the <unk> <unk> <unk> <unk> <unk>
2024-05-14 08:00:34,395 - INFO - joeynmt.training - Example #1
2024-05-14 08:00:34,395 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:00:34,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:00:34,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'is', 'actually', '<unk>', '</s>']
2024-05-14 08:00:34,396 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:00:34,396 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:00:34,396 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem is actually <unk>
2024-05-14 08:00:34,396 - INFO - joeynmt.training - Example #2
2024-05-14 08:00:34,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:00:34,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:00:34,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', '<unk>', 'in', 'a', 'sense', 'of', '<unk>', '</s>']
2024-05-14 08:00:34,397 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:00:34,397 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:00:34,397 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> <unk> in a sense of <unk>
2024-05-14 08:00:34,397 - INFO - joeynmt.training - Example #3
2024-05-14 08:00:34,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:00:34,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:00:34,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:00:34,398 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:00:34,398 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:00:34,398 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:00:34,398 - INFO - joeynmt.training - Example #4
2024-05-14 08:00:34,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:00:34,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:00:34,398 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'the', 'last', '25', 'years', '<unk>', '</s>']
2024-05-14 08:00:34,399 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:00:34,399 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:00:34,399 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show you  is a <unk> version of what has been <unk> the last 25 years <unk>
2024-05-14 08:00:37,730 - INFO - joeynmt.training - Epoch   5, Step:    12100, Batch Loss:     1.440707, Batch Acc: 0.551260, Tokens per Sec:    19294, Lr: 0.000300
2024-05-14 08:00:40,841 - INFO - joeynmt.training - Epoch   5, Step:    12200, Batch Loss:     1.588024, Batch Acc: 0.552371, Tokens per Sec:    21817, Lr: 0.000300
2024-05-14 08:00:43,971 - INFO - joeynmt.training - Epoch   5, Step:    12300, Batch Loss:     1.423435, Batch Acc: 0.558229, Tokens per Sec:    21765, Lr: 0.000300
2024-05-14 08:00:47,965 - INFO - joeynmt.training - Epoch   5, Step:    12400, Batch Loss:     1.420336, Batch Acc: 0.554926, Tokens per Sec:    17061, Lr: 0.000300
2024-05-14 08:00:51,246 - INFO - joeynmt.training - Epoch   5, Step:    12500, Batch Loss:     1.379668, Batch Acc: 0.560055, Tokens per Sec:    20784, Lr: 0.000300
2024-05-14 08:00:51,247 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:00:51,247 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:00:54,824 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.62, acc:   0.45, generation: 3.5696[sec], evaluation: 0.0000[sec]
2024-05-14 08:00:54,927 - INFO - joeynmt.helpers - delete models/transformer_word/9000.ckpt
2024-05-14 08:00:54,936 - INFO - joeynmt.training - Example #0
2024-05-14 08:00:54,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:00:54,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:00:54,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', 'that', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '', 'that', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:00:54,937 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:00:54,937 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:00:54,937 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show you that <unk>  that the <unk> <unk>  that <unk> the <unk> <unk> <unk>
2024-05-14 08:00:54,937 - INFO - joeynmt.training - Example #1
2024-05-14 08:00:54,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:00:54,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:00:54,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', '', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:00:54,937 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:00:54,937 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:00:54,937 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem  because it doesn't show the <unk> of the ice <unk>
2024-05-14 08:00:54,937 - INFO - joeynmt.training - Example #2
2024-05-14 08:00:54,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:00:54,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:00:54,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:00:54,937 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:00:54,938 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:00:54,938 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense,  the <unk> heart of our <unk> <unk>
2024-05-14 08:00:54,938 - INFO - joeynmt.training - Example #3
2024-05-14 08:00:54,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:00:54,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:00:54,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:00:54,938 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:00:54,938 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:00:54,938 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:00:54,938 - INFO - joeynmt.training - Example #4
2024-05-14 08:00:54,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:00:54,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:00:54,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'happened', 'over', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:00:54,939 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:00:54,939 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:00:54,939 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show show  is a <unk> version of what has happened over the last 25 years.
2024-05-14 08:00:55,911 - INFO - joeynmt.training - Epoch   5: total training loss 3649.15
2024-05-14 08:00:55,911 - INFO - joeynmt.training - EPOCH 6
2024-05-14 08:00:58,017 - INFO - joeynmt.training - Epoch   6, Step:    12600, Batch Loss:     1.298790, Batch Acc: 0.581722, Tokens per Sec:    21988, Lr: 0.000300
2024-05-14 08:01:02,084 - INFO - joeynmt.training - Epoch   6, Step:    12700, Batch Loss:     1.394079, Batch Acc: 0.571625, Tokens per Sec:    16420, Lr: 0.000300
2024-05-14 08:01:05,151 - INFO - joeynmt.training - Epoch   6, Step:    12800, Batch Loss:     1.373011, Batch Acc: 0.574601, Tokens per Sec:    22089, Lr: 0.000300
2024-05-14 08:01:08,182 - INFO - joeynmt.training - Epoch   6, Step:    12900, Batch Loss:     1.382578, Batch Acc: 0.578958, Tokens per Sec:    22290, Lr: 0.000300
2024-05-14 08:01:11,273 - INFO - joeynmt.training - Epoch   6, Step:    13000, Batch Loss:     1.431185, Batch Acc: 0.573622, Tokens per Sec:    22440, Lr: 0.000300
2024-05-14 08:01:11,273 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:01:11,273 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:01:15,833 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.59, acc:   0.45, generation: 4.5497[sec], evaluation: 0.0000[sec]
2024-05-14 08:01:15,940 - INFO - joeynmt.helpers - delete models/transformer_word/12500.ckpt
2024-05-14 08:01:15,954 - INFO - joeynmt.helpers - delete /content/mt-exercise-5/models/transformer_word/12500.ckpt
2024-05-14 08:01:15,954 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/mt-exercise-5/models/transformer_word/12500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/mt-exercise-5/models/transformer_word/12500.ckpt')
2024-05-14 08:01:15,955 - INFO - joeynmt.training - Example #0
2024-05-14 08:01:15,955 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:01:15,955 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:01:15,955 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:01:15,956 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:01:15,956 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:01:15,956 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to <unk>  that the <unk> <unk> <unk> the <unk>  that the <unk> <unk> <unk> <unk>
2024-05-14 08:01:15,956 - INFO - joeynmt.training - Example #1
2024-05-14 08:01:15,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:01:15,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:01:15,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:01:15,957 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:01:15,957 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:01:15,957 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 08:01:15,957 - INFO - joeynmt.training - Example #2
2024-05-14 08:01:15,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:01:15,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:01:15,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:01:15,958 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:01:15,958 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:01:15,958 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense,  the <unk> heart of our <unk> <unk>
2024-05-14 08:01:15,958 - INFO - joeynmt.training - Example #3
2024-05-14 08:01:15,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:01:15,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:01:15,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:01:15,958 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:01:15,958 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:01:15,958 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:01:15,958 - INFO - joeynmt.training - Example #4
2024-05-14 08:01:15,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:01:15,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:01:15,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', "I'm", 'going', 'to', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '25', 'years', 'from', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:01:15,959 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:01:15,959 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:01:15,959 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I'm going to show you  is a <unk> version of what has been 25 years from what happened in the last 25 years.
2024-05-14 08:01:19,014 - INFO - joeynmt.training - Epoch   6, Step:    13100, Batch Loss:     1.376795, Batch Acc: 0.572139, Tokens per Sec:    21067, Lr: 0.000300
2024-05-14 08:01:22,175 - INFO - joeynmt.training - Epoch   6, Step:    13200, Batch Loss:     1.379448, Batch Acc: 0.569914, Tokens per Sec:    21757, Lr: 0.000300
2024-05-14 08:01:25,427 - INFO - joeynmt.training - Epoch   6, Step:    13300, Batch Loss:     1.443994, Batch Acc: 0.568017, Tokens per Sec:    21103, Lr: 0.000300
2024-05-14 08:01:29,375 - INFO - joeynmt.training - Epoch   6, Step:    13400, Batch Loss:     1.354224, Batch Acc: 0.573013, Tokens per Sec:    17564, Lr: 0.000300
2024-05-14 08:01:32,455 - INFO - joeynmt.training - Epoch   6, Step:    13500, Batch Loss:     1.419948, Batch Acc: 0.570668, Tokens per Sec:    22510, Lr: 0.000300
2024-05-14 08:01:32,455 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:01:32,455 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:01:36,644 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.93, acc:   0.44, generation: 4.1800[sec], evaluation: 0.0000[sec]
2024-05-14 08:01:36,645 - INFO - joeynmt.training - Example #0
2024-05-14 08:01:36,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:01:36,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:01:36,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', '<unk>', '', '<unk>', 'to', '<unk>', '<unk>', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:01:36,645 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:01:36,645 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:01:36,645 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to <unk>  <unk> to <unk> <unk> that the <unk>  that the <unk> <unk> <unk> the size of the <unk> <unk> <unk>
2024-05-14 08:01:36,645 - INFO - joeynmt.training - Example #1
2024-05-14 08:01:36,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:01:36,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:01:36,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'is', 'the', '<unk>', 'of', 'this', 'particular', 'problem', '', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:01:36,646 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:01:36,646 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:01:36,646 - INFO - joeynmt.training - 	Hypothesis: But this <unk> is the <unk> of this particular problem  because it doesn't show the <unk> of the <unk>
2024-05-14 08:01:36,646 - INFO - joeynmt.training - Example #2
2024-05-14 08:01:36,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:01:36,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:01:36,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'way,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:01:36,646 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:01:36,647 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:01:36,647 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a way,  the <unk> heart of our <unk> <unk>
2024-05-14 08:01:36,647 - INFO - joeynmt.training - Example #3
2024-05-14 08:01:36,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:01:36,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:01:36,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:01:36,647 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:01:36,647 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:01:36,647 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:01:36,647 - INFO - joeynmt.training - Example #4
2024-05-14 08:01:36,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:01:36,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:01:36,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'in', 'the', 'last', '25', 'years', 'is', '<unk>', '</s>']
2024-05-14 08:01:36,648 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:01:36,648 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:01:36,648 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show  is a <unk> version of what has been <unk> in the last 25 years is <unk>
2024-05-14 08:01:40,246 - INFO - joeynmt.training - Epoch   6, Step:    13600, Batch Loss:     1.360581, Batch Acc: 0.567400, Tokens per Sec:    19284, Lr: 0.000300
2024-05-14 08:01:43,708 - INFO - joeynmt.training - Epoch   6, Step:    13700, Batch Loss:     1.396245, Batch Acc: 0.568229, Tokens per Sec:    19558, Lr: 0.000300
2024-05-14 08:01:46,823 - INFO - joeynmt.training - Epoch   6, Step:    13800, Batch Loss:     1.501628, Batch Acc: 0.568435, Tokens per Sec:    21515, Lr: 0.000300
2024-05-14 08:01:49,909 - INFO - joeynmt.training - Epoch   6, Step:    13900, Batch Loss:     1.221366, Batch Acc: 0.567245, Tokens per Sec:    22461, Lr: 0.000300
2024-05-14 08:01:53,644 - INFO - joeynmt.training - Epoch   6, Step:    14000, Batch Loss:     1.436244, Batch Acc: 0.567641, Tokens per Sec:    17959, Lr: 0.000300
2024-05-14 08:01:53,644 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:01:53,645 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:01:57,459 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.61, acc:   0.45, generation: 3.8060[sec], evaluation: 0.0000[sec]
2024-05-14 08:01:57,559 - INFO - joeynmt.helpers - delete models/transformer_word/10500.ckpt
2024-05-14 08:01:57,569 - INFO - joeynmt.training - Example #0
2024-05-14 08:01:57,569 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:01:57,569 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:01:57,569 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:01:57,569 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:01:57,569 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:01:57,569 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show you  that the <unk>  that the <unk> <unk> <unk> <unk> <unk>
2024-05-14 08:01:57,569 - INFO - joeynmt.training - Example #1
2024-05-14 08:01:57,569 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:01:57,569 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:01:57,569 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', "it's", 'not', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:01:57,570 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:01:57,570 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:01:57,570 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it's not the <unk> of the ice <unk>
2024-05-14 08:01:57,570 - INFO - joeynmt.training - Example #2
2024-05-14 08:01:57,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:01:57,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:01:57,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'way,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:01:57,570 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:01:57,570 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:01:57,570 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a way,  the <unk> heart of our <unk> <unk>
2024-05-14 08:01:57,570 - INFO - joeynmt.training - Example #3
2024-05-14 08:01:57,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:01:57,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:01:57,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:01:57,571 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:01:57,571 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:01:57,571 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:01:57,571 - INFO - joeynmt.training - Example #4
2024-05-14 08:01:57,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:01:57,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:01:57,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'is', 'a', '<unk>', '<unk>', 'of', 'what', 'has', 'been', '25', 'years', 'of', "what's", 'happening', 'over', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:01:57,571 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:01:57,571 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:01:57,571 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show is a <unk> <unk> of what has been 25 years of what's happening over the last 25 years.
2024-05-14 08:02:00,640 - INFO - joeynmt.training - Epoch   6, Step:    14100, Batch Loss:     1.341445, Batch Acc: 0.572761, Tokens per Sec:    21718, Lr: 0.000300
2024-05-14 08:02:03,706 - INFO - joeynmt.training - Epoch   6, Step:    14200, Batch Loss:     1.404888, Batch Acc: 0.563048, Tokens per Sec:    22291, Lr: 0.000300
2024-05-14 08:02:07,536 - INFO - joeynmt.training - Epoch   6, Step:    14300, Batch Loss:     1.308096, Batch Acc: 0.571578, Tokens per Sec:    17448, Lr: 0.000300
2024-05-14 08:02:10,787 - INFO - joeynmt.training - Epoch   6, Step:    14400, Batch Loss:     1.301987, Batch Acc: 0.567352, Tokens per Sec:    21103, Lr: 0.000300
2024-05-14 08:02:13,810 - INFO - joeynmt.training - Epoch   6, Step:    14500, Batch Loss:     1.286200, Batch Acc: 0.566631, Tokens per Sec:    22318, Lr: 0.000300
2024-05-14 08:02:13,811 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:02:13,811 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:02:18,000 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.64, acc:   0.44, generation: 4.1723[sec], evaluation: 0.0000[sec]
2024-05-14 08:02:18,002 - INFO - joeynmt.training - Example #0
2024-05-14 08:02:18,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:02:18,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:02:18,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '', 'that', 'the', '<unk>', '<unk>', 'the', 'last', 'three', 'million', 'years', '--', 'the', 'size', 'of', 'the', '<unk>', '', 'with', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:02:18,003 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:02:18,003 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:02:18,003 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show you that the <unk>  that the <unk> <unk>  that the <unk> <unk> the last three million years -- the size of the <unk>  with <unk> <unk> <unk>
2024-05-14 08:02:18,003 - INFO - joeynmt.training - Example #1
2024-05-14 08:02:18,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:02:18,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:02:18,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', '<unk>', 'the', '<unk>', 'of', 'this', 'particular', 'problem', '--', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:02:18,004 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:02:18,004 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:02:18,004 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually <unk> the <unk> of this particular problem -- because it doesn't <unk> the <unk> of the ice <unk>
2024-05-14 08:02:18,004 - INFO - joeynmt.training - Example #2
2024-05-14 08:02:18,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:02:18,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:02:18,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', '<unk>', 'in', 'a', 'sense,', '', 'the', '<unk>', '<unk>', 'heart', 'of', 'our', '<unk>', '</s>']
2024-05-14 08:02:18,005 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:02:18,005 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:02:18,005 - INFO - joeynmt.training - 	Hypothesis: The <unk> <unk> in a sense,  the <unk> <unk> heart of our <unk>
2024-05-14 08:02:18,005 - INFO - joeynmt.training - Example #3
2024-05-14 08:02:18,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:02:18,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:02:18,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:02:18,006 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:02:18,006 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:02:18,006 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:02:18,006 - INFO - joeynmt.training - Example #4
2024-05-14 08:02:18,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:02:18,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:02:18,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:02:18,007 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:02:18,007 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:02:18,007 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show  is a <unk> version of what happened in the last 25 years.
2024-05-14 08:02:22,018 - INFO - joeynmt.training - Epoch   6, Step:    14600, Batch Loss:     1.531447, Batch Acc: 0.565446, Tokens per Sec:    16631, Lr: 0.000300
2024-05-14 08:02:25,099 - INFO - joeynmt.training - Epoch   6, Step:    14700, Batch Loss:     1.430349, Batch Acc: 0.565831, Tokens per Sec:    21614, Lr: 0.000300
2024-05-14 08:02:28,196 - INFO - joeynmt.training - Epoch   6, Step:    14800, Batch Loss:     1.379524, Batch Acc: 0.562168, Tokens per Sec:    21559, Lr: 0.000300
2024-05-14 08:02:31,289 - INFO - joeynmt.training - Epoch   6, Step:    14900, Batch Loss:     1.367417, Batch Acc: 0.564019, Tokens per Sec:    22159, Lr: 0.000300
2024-05-14 08:02:35,137 - INFO - joeynmt.training - Epoch   6, Step:    15000, Batch Loss:     1.373288, Batch Acc: 0.564813, Tokens per Sec:    17787, Lr: 0.000300
2024-05-14 08:02:35,137 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:02:35,137 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:02:39,147 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.42, acc:   0.45, generation: 4.0011[sec], evaluation: 0.0000[sec]
2024-05-14 08:02:39,147 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 08:02:39,251 - INFO - joeynmt.helpers - delete models/transformer_word/14000.ckpt
2024-05-14 08:02:39,261 - INFO - joeynmt.training - Example #0
2024-05-14 08:02:39,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:02:39,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:02:39,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', 'that', 'the', '<unk>', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:02:39,261 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:02:39,262 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:02:39,262 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show you that the <unk> <unk>  that the <unk> <unk> <unk> the <unk> <unk> <unk> <unk>
2024-05-14 08:02:39,262 - INFO - joeynmt.training - Example #1
2024-05-14 08:02:39,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:02:39,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:02:39,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:02:39,262 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:02:39,262 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:02:39,262 - INFO - joeynmt.training - 	Hypothesis: But this <unk> the <unk> of this particular problem because it doesn't show the <unk> of the <unk>
2024-05-14 08:02:39,262 - INFO - joeynmt.training - Example #2
2024-05-14 08:02:39,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:02:39,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:02:39,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '</s>']
2024-05-14 08:02:39,263 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:02:39,263 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:02:39,263 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense,  the <unk> heart of our <unk>
2024-05-14 08:02:39,263 - INFO - joeynmt.training - Example #3
2024-05-14 08:02:39,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:02:39,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:02:39,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:02:39,263 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:02:39,263 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:02:39,263 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:02:39,263 - INFO - joeynmt.training - Example #4
2024-05-14 08:02:39,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:02:39,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:02:39,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', "I'm", 'going', 'to', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'the', 'last', '25', 'years', 'of', '<unk>', '</s>']
2024-05-14 08:02:39,264 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:02:39,264 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:02:39,264 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I'm going to show  is a <unk> version of what has been <unk> the last 25 years of <unk>
2024-05-14 08:02:40,492 - INFO - joeynmt.training - Epoch   6: total training loss 3546.56
2024-05-14 08:02:40,492 - INFO - joeynmt.training - EPOCH 7
2024-05-14 08:02:42,355 - INFO - joeynmt.training - Epoch   7, Step:    15100, Batch Loss:     1.212199, Batch Acc: 0.589832, Tokens per Sec:    22455, Lr: 0.000300
2024-05-14 08:02:46,014 - INFO - joeynmt.training - Epoch   7, Step:    15200, Batch Loss:     1.490180, Batch Acc: 0.587148, Tokens per Sec:    18978, Lr: 0.000300
2024-05-14 08:02:49,590 - INFO - joeynmt.training - Epoch   7, Step:    15300, Batch Loss:     1.396002, Batch Acc: 0.587838, Tokens per Sec:    18941, Lr: 0.000300
2024-05-14 08:02:52,758 - INFO - joeynmt.training - Epoch   7, Step:    15400, Batch Loss:     1.391583, Batch Acc: 0.583530, Tokens per Sec:    21957, Lr: 0.000300
2024-05-14 08:02:55,777 - INFO - joeynmt.training - Epoch   7, Step:    15500, Batch Loss:     1.333666, Batch Acc: 0.584512, Tokens per Sec:    22015, Lr: 0.000300
2024-05-14 08:02:55,777 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:02:55,777 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:03:00,388 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.57, acc:   0.45, generation: 4.5946[sec], evaluation: 0.0000[sec]
2024-05-14 08:03:00,556 - INFO - joeynmt.helpers - delete models/transformer_word/9500.ckpt
2024-05-14 08:03:00,571 - INFO - joeynmt.training - Example #0
2024-05-14 08:03:00,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:03:00,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:03:00,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '<unk>', '', 'which', 'the', '<unk>', '<unk>', '', 'which', 'has', 'about', 'the', 'last', 'three', 'million', 'years', '--', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:03:00,572 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:03:00,572 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:03:00,572 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show that the <unk> <unk>  which the <unk> <unk>  which has about the last three million years -- the size of the <unk> <unk> <unk>
2024-05-14 08:03:00,572 - INFO - joeynmt.training - Example #1
2024-05-14 08:03:00,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:03:00,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:03:00,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:03:00,573 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:03:00,573 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:03:00,573 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 08:03:00,573 - INFO - joeynmt.training - Example #2
2024-05-14 08:03:00,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:03:00,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:03:00,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:03:00,574 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:03:00,574 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:03:00,574 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:03:00,574 - INFO - joeynmt.training - Example #3
2024-05-14 08:03:00,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:03:00,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:03:00,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:03:00,575 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:03:00,575 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:03:00,575 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:03:00,575 - INFO - joeynmt.training - Example #4
2024-05-14 08:03:00,575 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:03:00,575 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:03:00,575 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'was', 'there', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:03:00,576 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:03:00,576 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:03:00,576 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show  is a <unk> version of what was there the last 25 years.
2024-05-14 08:03:03,772 - INFO - joeynmt.training - Epoch   7, Step:    15600, Batch Loss:     1.209674, Batch Acc: 0.580297, Tokens per Sec:    19992, Lr: 0.000300
2024-05-14 08:03:06,889 - INFO - joeynmt.training - Epoch   7, Step:    15700, Batch Loss:     1.383824, Batch Acc: 0.581806, Tokens per Sec:    22156, Lr: 0.000300
2024-05-14 08:03:09,918 - INFO - joeynmt.training - Epoch   7, Step:    15800, Batch Loss:     1.417199, Batch Acc: 0.579168, Tokens per Sec:    22235, Lr: 0.000300
2024-05-14 08:03:13,821 - INFO - joeynmt.training - Epoch   7, Step:    15900, Batch Loss:     1.385885, Batch Acc: 0.577348, Tokens per Sec:    17247, Lr: 0.000300
2024-05-14 08:03:16,893 - INFO - joeynmt.training - Epoch   7, Step:    16000, Batch Loss:     1.267027, Batch Acc: 0.580315, Tokens per Sec:    21753, Lr: 0.000300
2024-05-14 08:03:16,894 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:03:16,894 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:03:21,047 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.51, acc:   0.45, generation: 4.1433[sec], evaluation: 0.0000[sec]
2024-05-14 08:03:21,169 - INFO - joeynmt.helpers - delete models/transformer_word/13000.ckpt
2024-05-14 08:03:21,178 - INFO - joeynmt.training - Example #0
2024-05-14 08:03:21,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:03:21,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:03:21,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'year', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '<unk>', '</s>']
2024-05-14 08:03:21,179 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:03:21,179 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:03:21,179 - INFO - joeynmt.training - 	Hypothesis: <unk> year I showed these two <unk> to show these two <unk> to show that the <unk>  that the <unk> <unk> <unk> the <unk> <unk>
2024-05-14 08:03:21,179 - INFO - joeynmt.training - Example #1
2024-05-14 08:03:21,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:03:21,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:03:21,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:03:21,180 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:03:21,180 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:03:21,180 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't <unk> the <unk> of the ice <unk>
2024-05-14 08:03:21,180 - INFO - joeynmt.training - Example #2
2024-05-14 08:03:21,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:03:21,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:03:21,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', '<unk>', 'is', 'in', 'a', 'sense,', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '</s>']
2024-05-14 08:03:21,180 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:03:21,180 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:03:21,180 - INFO - joeynmt.training - 	Hypothesis: The <unk> <unk> is in a sense, in a sense, the <unk> heart of our <unk>
2024-05-14 08:03:21,180 - INFO - joeynmt.training - Example #3
2024-05-14 08:03:21,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:03:21,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:03:21,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:03:21,181 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:03:21,181 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:03:21,181 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:03:21,181 - INFO - joeynmt.training - Example #4
2024-05-14 08:03:21,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:03:21,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:03:21,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '25', 'years.', '</s>']
2024-05-14 08:03:21,181 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:03:21,181 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:03:21,181 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show  is a <unk> version of what has been 25 years.
2024-05-14 08:03:24,518 - INFO - joeynmt.training - Epoch   7, Step:    16100, Batch Loss:     1.288945, Batch Acc: 0.578529, Tokens per Sec:    19567, Lr: 0.000300
2024-05-14 08:03:28,153 - INFO - joeynmt.training - Epoch   7, Step:    16200, Batch Loss:     1.407045, Batch Acc: 0.576999, Tokens per Sec:    18962, Lr: 0.000300
2024-05-14 08:03:32,137 - INFO - joeynmt.training - Epoch   7, Step:    16300, Batch Loss:     1.381338, Batch Acc: 0.579178, Tokens per Sec:    17078, Lr: 0.000300
2024-05-14 08:03:35,200 - INFO - joeynmt.training - Epoch   7, Step:    16400, Batch Loss:     1.329634, Batch Acc: 0.573696, Tokens per Sec:    22013, Lr: 0.000300
2024-05-14 08:03:38,971 - INFO - joeynmt.training - Epoch   7, Step:    16500, Batch Loss:     1.318151, Batch Acc: 0.575694, Tokens per Sec:    17845, Lr: 0.000300
2024-05-14 08:03:38,971 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:03:38,972 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:03:42,462 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.37, acc:   0.45, generation: 3.4817[sec], evaluation: 0.0000[sec]
2024-05-14 08:03:42,462 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 08:03:42,579 - INFO - joeynmt.helpers - delete models/transformer_word/15500.ckpt
2024-05-14 08:03:42,590 - INFO - joeynmt.training - Example #0
2024-05-14 08:03:42,590 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:03:42,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:03:42,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '<unk>', '</s>']
2024-05-14 08:03:42,591 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:03:42,591 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:03:42,591 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> <unk> to show that the <unk>  that the <unk> <unk> <unk> the <unk> <unk>
2024-05-14 08:03:42,591 - INFO - joeynmt.training - Example #1
2024-05-14 08:03:42,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:03:42,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:03:42,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:03:42,592 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:03:42,592 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:03:42,592 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't show the <unk> of the <unk>
2024-05-14 08:03:42,592 - INFO - joeynmt.training - Example #2
2024-05-14 08:03:42,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:03:42,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:03:42,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'in', 'a', 'sense,', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:03:42,592 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:03:42,592 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:03:42,592 - INFO - joeynmt.training - 	Hypothesis: The <unk> in a sense, is in a sense,  the <unk> heart of our <unk> <unk>
2024-05-14 08:03:42,592 - INFO - joeynmt.training - Example #3
2024-05-14 08:03:42,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:03:42,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:03:42,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:03:42,593 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:03:42,593 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:03:42,593 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:03:42,593 - INFO - joeynmt.training - Example #4
2024-05-14 08:03:42,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:03:42,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:03:42,593 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'was', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:03:42,593 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:03:42,593 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:03:42,593 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show you  is a <unk> version of what was the last 25 years.
2024-05-14 08:03:45,725 - INFO - joeynmt.training - Epoch   7, Step:    16600, Batch Loss:     1.464066, Batch Acc: 0.574324, Tokens per Sec:    21139, Lr: 0.000300
2024-05-14 08:03:48,845 - INFO - joeynmt.training - Epoch   7, Step:    16700, Batch Loss:     1.301423, Batch Acc: 0.579040, Tokens per Sec:    21795, Lr: 0.000300
2024-05-14 08:03:52,969 - INFO - joeynmt.training - Epoch   7, Step:    16800, Batch Loss:     1.333279, Batch Acc: 0.576917, Tokens per Sec:    16470, Lr: 0.000300
2024-05-14 08:03:56,091 - INFO - joeynmt.training - Epoch   7, Step:    16900, Batch Loss:     1.323728, Batch Acc: 0.577473, Tokens per Sec:    21780, Lr: 0.000300
2024-05-14 08:03:59,212 - INFO - joeynmt.training - Epoch   7, Step:    17000, Batch Loss:     1.425259, Batch Acc: 0.575228, Tokens per Sec:    21839, Lr: 0.000300
2024-05-14 08:03:59,213 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:03:59,213 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:04:02,984 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.27, acc:   0.45, generation: 3.7623[sec], evaluation: 0.0000[sec]
2024-05-14 08:04:02,985 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-14 08:04:03,134 - INFO - joeynmt.helpers - delete models/transformer_word/12000.ckpt
2024-05-14 08:04:03,149 - INFO - joeynmt.training - Example #0
2024-05-14 08:04:03,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:04:03,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:04:03,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'had', 'about', 'the', 'size', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:04:03,150 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:04:03,150 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:04:03,151 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show these two <unk> to show that the <unk> <unk>  that the <unk> <unk> <unk> had about the size of the <unk> of the <unk> <unk> <unk>
2024-05-14 08:04:03,151 - INFO - joeynmt.training - Example #1
2024-05-14 08:04:03,151 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:04:03,151 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:04:03,151 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:04:03,151 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:04:03,152 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:04:03,152 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 08:04:03,152 - INFO - joeynmt.training - Example #2
2024-05-14 08:04:03,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:04:03,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:04:03,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:04:03,153 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:04:03,153 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:04:03,153 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:04:03,153 - INFO - joeynmt.training - Example #3
2024-05-14 08:04:03,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:04:03,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:04:03,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:04:03,154 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:04:03,154 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:04:03,154 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:04:03,154 - INFO - joeynmt.training - Example #4
2024-05-14 08:04:03,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:04:03,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:04:03,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'over', 'the', 'last', '25', 'years', 'of', '<unk>', '</s>']
2024-05-14 08:04:03,155 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:04:03,155 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:04:03,155 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show  is a <unk> version of what happened over the last 25 years of <unk>
2024-05-14 08:04:07,113 - INFO - joeynmt.training - Epoch   7, Step:    17100, Batch Loss:     1.489026, Batch Acc: 0.573130, Tokens per Sec:    16310, Lr: 0.000300
2024-05-14 08:04:10,197 - INFO - joeynmt.training - Epoch   7, Step:    17200, Batch Loss:     1.290932, Batch Acc: 0.572990, Tokens per Sec:    22698, Lr: 0.000300
2024-05-14 08:04:13,268 - INFO - joeynmt.training - Epoch   7, Step:    17300, Batch Loss:     1.504808, Batch Acc: 0.573673, Tokens per Sec:    21642, Lr: 0.000300
2024-05-14 08:04:16,416 - INFO - joeynmt.training - Epoch   7, Step:    17400, Batch Loss:     1.365122, Batch Acc: 0.575019, Tokens per Sec:    21233, Lr: 0.000300
2024-05-14 08:04:20,328 - INFO - joeynmt.training - Epoch   7, Step:    17500, Batch Loss:     1.410728, Batch Acc: 0.574127, Tokens per Sec:    17380, Lr: 0.000300
2024-05-14 08:04:20,329 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:04:20,329 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:04:24,128 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.27, acc:   0.46, generation: 3.7838[sec], evaluation: 0.0000[sec]
2024-05-14 08:04:24,231 - INFO - joeynmt.helpers - delete models/transformer_word/11000.ckpt
2024-05-14 08:04:24,241 - INFO - joeynmt.training - Example #0
2024-05-14 08:04:24,241 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:04:24,241 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:04:24,241 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'the', 'size', 'of', 'the', '<unk>', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '<unk>', '</s>']
2024-05-14 08:04:24,241 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:04:24,241 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:04:24,241 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show you that the <unk>  that the <unk>  that the <unk> <unk> <unk> the size of the <unk> of the <unk> of the <unk> <unk>
2024-05-14 08:04:24,241 - INFO - joeynmt.training - Example #1
2024-05-14 08:04:24,241 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:04:24,241 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:04:24,241 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'is', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:04:24,242 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:04:24,242 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:04:24,242 - INFO - joeynmt.training - 	Hypothesis: But this <unk> the <unk> of this particular problem is because it doesn't show the <unk> of the ice <unk>
2024-05-14 08:04:24,242 - INFO - joeynmt.training - Example #2
2024-05-14 08:04:24,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:04:24,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:04:24,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'in', 'a', 'sense,', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:04:24,242 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:04:24,242 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:04:24,242 - INFO - joeynmt.training - 	Hypothesis: The <unk> in a sense, the <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:04:24,242 - INFO - joeynmt.training - Example #3
2024-05-14 08:04:24,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:04:24,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:04:24,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:04:24,243 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:04:24,243 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:04:24,243 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:04:24,243 - INFO - joeynmt.training - Example #4
2024-05-14 08:04:24,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:04:24,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:04:24,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', "I'm", 'going', 'to', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'in', 'the', 'last', '25', 'years', 'of', '<unk>', '</s>']
2024-05-14 08:04:24,243 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:04:24,243 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:04:24,243 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I'm going to show you  is a <unk> version of what has been <unk> in the last 25 years of <unk>
2024-05-14 08:04:25,758 - INFO - joeynmt.training - Epoch   7: total training loss 3460.38
2024-05-14 08:04:25,758 - INFO - joeynmt.training - EPOCH 8
2024-05-14 08:04:27,404 - INFO - joeynmt.training - Epoch   8, Step:    17600, Batch Loss:     1.273005, Batch Acc: 0.599121, Tokens per Sec:    22124, Lr: 0.000300
2024-05-14 08:04:31,032 - INFO - joeynmt.training - Epoch   8, Step:    17700, Batch Loss:     1.315151, Batch Acc: 0.599518, Tokens per Sec:    18890, Lr: 0.000300
2024-05-14 08:04:34,544 - INFO - joeynmt.training - Epoch   8, Step:    17800, Batch Loss:     1.423735, Batch Acc: 0.591789, Tokens per Sec:    19462, Lr: 0.000300
2024-05-14 08:04:37,691 - INFO - joeynmt.training - Epoch   8, Step:    17900, Batch Loss:     1.339318, Batch Acc: 0.595181, Tokens per Sec:    21349, Lr: 0.000300
2024-05-14 08:04:40,858 - INFO - joeynmt.training - Epoch   8, Step:    18000, Batch Loss:     1.355567, Batch Acc: 0.597473, Tokens per Sec:    21448, Lr: 0.000300
2024-05-14 08:04:40,858 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:04:40,859 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:04:45,390 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.70, acc:   0.44, generation: 4.5151[sec], evaluation: 0.0000[sec]
2024-05-14 08:04:45,391 - INFO - joeynmt.training - Example #0
2024-05-14 08:04:45,391 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:04:45,392 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:04:45,392 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'year', 'I', 'showed', 'these', 'two', '<unk>', '<unk>', 'to', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:04:45,392 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:04:45,392 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:04:45,392 - INFO - joeynmt.training - 	Hypothesis: <unk> year I showed these two <unk> <unk> to <unk>  that the <unk> <unk> <unk> <unk> <unk>
2024-05-14 08:04:45,392 - INFO - joeynmt.training - Example #1
2024-05-14 08:04:45,393 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:04:45,393 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:04:45,393 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:04:45,393 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:04:45,393 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:04:45,393 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this problem because it doesn't show the <unk> of the <unk> of the <unk>
2024-05-14 08:04:45,393 - INFO - joeynmt.training - Example #2
2024-05-14 08:04:45,393 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:04:45,394 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:04:45,394 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:04:45,394 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:04:45,394 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:04:45,394 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:04:45,394 - INFO - joeynmt.training - Example #3
2024-05-14 08:04:45,394 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:04:45,394 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:04:45,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:04:45,395 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:04:45,395 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:04:45,395 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:04:45,395 - INFO - joeynmt.training - Example #4
2024-05-14 08:04:45,395 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:04:45,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:04:45,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', "I'm", 'going', 'to', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'in', 'the', 'last', '25', 'years', '<unk>', '</s>']
2024-05-14 08:04:45,396 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:04:45,396 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:04:45,396 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I'm going to show  is a <unk> version of what has been <unk> in the last 25 years <unk>
2024-05-14 08:04:48,685 - INFO - joeynmt.training - Epoch   8, Step:    18100, Batch Loss:     1.266303, Batch Acc: 0.588033, Tokens per Sec:    19892, Lr: 0.000300
2024-05-14 08:04:51,942 - INFO - joeynmt.training - Epoch   8, Step:    18200, Batch Loss:     1.202200, Batch Acc: 0.586131, Tokens per Sec:    20953, Lr: 0.000300
2024-05-14 08:04:55,087 - INFO - joeynmt.training - Epoch   8, Step:    18300, Batch Loss:     1.330033, Batch Acc: 0.590957, Tokens per Sec:    21850, Lr: 0.000300
2024-05-14 08:04:59,077 - INFO - joeynmt.training - Epoch   8, Step:    18400, Batch Loss:     1.439949, Batch Acc: 0.590537, Tokens per Sec:    16754, Lr: 0.000300
2024-05-14 08:05:02,162 - INFO - joeynmt.training - Epoch   8, Step:    18500, Batch Loss:     1.296036, Batch Acc: 0.586677, Tokens per Sec:    22260, Lr: 0.000300
2024-05-14 08:05:02,162 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:05:02,162 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:05:06,260 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.47, acc:   0.45, generation: 4.0893[sec], evaluation: 0.0000[sec]
2024-05-14 08:05:06,367 - INFO - joeynmt.helpers - delete models/transformer_word/16000.ckpt
2024-05-14 08:05:06,376 - INFO - joeynmt.training - Example #0
2024-05-14 08:05:06,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:05:06,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:05:06,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', '<unk>', 'to', 'show', 'you', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:05:06,376 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:05:06,377 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:05:06,377 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> <unk> to show you that the <unk>  that the <unk>  that the <unk> <unk> <unk> <unk>
2024-05-14 08:05:06,377 - INFO - joeynmt.training - Example #1
2024-05-14 08:05:06,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:05:06,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:05:06,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:05:06,377 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:05:06,377 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:05:06,377 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 08:05:06,377 - INFO - joeynmt.training - Example #2
2024-05-14 08:05:06,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:05:06,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:05:06,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:05:06,378 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:05:06,378 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:05:06,378 - INFO - joeynmt.training - 	Hypothesis: The <unk> <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:05:06,378 - INFO - joeynmt.training - Example #3
2024-05-14 08:05:06,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:05:06,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:05:06,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:05:06,378 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:05:06,378 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:05:06,378 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:05:06,378 - INFO - joeynmt.training - Example #4
2024-05-14 08:05:06,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:05:06,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:05:06,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'that', "I'm", 'going', 'to', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'happened', 'over', 'the', 'last', '25', 'years', '<unk>', '</s>']
2024-05-14 08:05:06,379 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:05:06,379 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:05:06,379 - INFO - joeynmt.training - 	Hypothesis: The next <unk> that I'm going to show  is a <unk> version of what has happened over the last 25 years <unk>
2024-05-14 08:05:09,714 - INFO - joeynmt.training - Epoch   8, Step:    18600, Batch Loss:     1.423950, Batch Acc: 0.591375, Tokens per Sec:    20163, Lr: 0.000300
2024-05-14 08:05:13,588 - INFO - joeynmt.training - Epoch   8, Step:    18700, Batch Loss:     1.317974, Batch Acc: 0.582844, Tokens per Sec:    17534, Lr: 0.000300
2024-05-14 08:05:16,736 - INFO - joeynmt.training - Epoch   8, Step:    18800, Batch Loss:     1.377225, Batch Acc: 0.587785, Tokens per Sec:    21461, Lr: 0.000300
2024-05-14 08:05:19,898 - INFO - joeynmt.training - Epoch   8, Step:    18900, Batch Loss:     1.319689, Batch Acc: 0.587522, Tokens per Sec:    21389, Lr: 0.000300
2024-05-14 08:05:23,346 - INFO - joeynmt.training - Epoch   8, Step:    19000, Batch Loss:     1.377527, Batch Acc: 0.587784, Tokens per Sec:    19869, Lr: 0.000300
2024-05-14 08:05:23,346 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:05:23,346 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:05:27,991 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.39, acc:   0.45, generation: 4.6357[sec], evaluation: 0.0000[sec]
2024-05-14 08:05:28,092 - INFO - joeynmt.helpers - delete models/transformer_word/18500.ckpt
2024-05-14 08:05:28,101 - INFO - joeynmt.helpers - delete /content/mt-exercise-5/models/transformer_word/18500.ckpt
2024-05-14 08:05:28,101 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/mt-exercise-5/models/transformer_word/18500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/mt-exercise-5/models/transformer_word/18500.ckpt')
2024-05-14 08:05:28,101 - INFO - joeynmt.training - Example #0
2024-05-14 08:05:28,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:05:28,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:05:28,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '<unk>', '', 'which', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:05:28,102 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:05:28,102 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:05:28,102 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show that the <unk> <unk>  which the <unk> <unk> <unk> <unk>
2024-05-14 08:05:28,102 - INFO - joeynmt.training - Example #1
2024-05-14 08:05:28,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:05:28,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:05:28,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'of', 'the', '<unk>', '', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:05:28,102 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:05:28,102 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:05:28,102 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem of the <unk>  because it doesn't show the <unk> of the <unk>
2024-05-14 08:05:28,102 - INFO - joeynmt.training - Example #2
2024-05-14 08:05:28,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:05:28,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:05:28,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'in', 'some', 'sense,', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:05:28,103 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:05:28,103 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:05:28,103 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> in some sense, in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:05:28,103 - INFO - joeynmt.training - Example #3
2024-05-14 08:05:28,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:05:28,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:05:28,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:05:28,103 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:05:28,103 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:05:28,103 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:05:28,103 - INFO - joeynmt.training - Example #4
2024-05-14 08:05:28,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:05:28,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:05:28,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:05:28,104 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:05:28,104 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:05:28,104 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show  is a <unk> version of what has happened in the last 25 years.
2024-05-14 08:05:31,186 - INFO - joeynmt.training - Epoch   8, Step:    19100, Batch Loss:     1.439799, Batch Acc: 0.585892, Tokens per Sec:    21353, Lr: 0.000300
2024-05-14 08:05:34,285 - INFO - joeynmt.training - Epoch   8, Step:    19200, Batch Loss:     1.277789, Batch Acc: 0.583883, Tokens per Sec:    21066, Lr: 0.000300
2024-05-14 08:05:38,134 - INFO - joeynmt.training - Epoch   8, Step:    19300, Batch Loss:     1.414978, Batch Acc: 0.584445, Tokens per Sec:    17339, Lr: 0.000300
2024-05-14 08:05:41,598 - INFO - joeynmt.training - Epoch   8, Step:    19400, Batch Loss:     1.302504, Batch Acc: 0.580846, Tokens per Sec:    18980, Lr: 0.000300
2024-05-14 08:05:44,729 - INFO - joeynmt.training - Epoch   8, Step:    19500, Batch Loss:     1.360580, Batch Acc: 0.582020, Tokens per Sec:    21907, Lr: 0.000300
2024-05-14 08:05:44,730 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:05:44,730 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:05:48,579 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.32, acc:   0.45, generation: 3.8409[sec], evaluation: 0.0000[sec]
2024-05-14 08:05:48,680 - INFO - joeynmt.helpers - delete models/transformer_word/15000.ckpt
2024-05-14 08:05:48,690 - INFO - joeynmt.training - Example #0
2024-05-14 08:05:48,690 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:05:48,690 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:05:48,690 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'the', 'last', 'three', 'million', 'years', '--', 'the', 'size', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '<unk>', '<unk>', 'was', '<unk>', '</s>']
2024-05-14 08:05:48,691 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:05:48,691 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:05:48,691 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show that the <unk> <unk>  that the <unk> <unk> <unk> the last three million years -- the size of the <unk> of the <unk> <unk> <unk> was <unk>
2024-05-14 08:05:48,691 - INFO - joeynmt.training - Example #1
2024-05-14 08:05:48,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:05:48,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:05:48,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', 'ice', '<unk>', '</s>']
2024-05-14 08:05:48,691 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:05:48,692 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:05:48,692 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't show the <unk> of the ice <unk>
2024-05-14 08:05:48,692 - INFO - joeynmt.training - Example #2
2024-05-14 08:05:48,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:05:48,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:05:48,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:05:48,692 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:05:48,692 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:05:48,692 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk> <unk>
2024-05-14 08:05:48,692 - INFO - joeynmt.training - Example #3
2024-05-14 08:05:48,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:05:48,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:05:48,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:05:48,692 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:05:48,692 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:05:48,692 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:05:48,693 - INFO - joeynmt.training - Example #4
2024-05-14 08:05:48,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:05:48,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:05:48,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', "I'm", 'going', 'to', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:05:48,693 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:05:48,693 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:05:48,693 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I'm going to show you  is a <unk> version of what has been <unk> the last 25 years.
2024-05-14 08:05:52,702 - INFO - joeynmt.training - Epoch   8, Step:    19600, Batch Loss:     1.372418, Batch Acc: 0.582742, Tokens per Sec:    16779, Lr: 0.000300
2024-05-14 08:05:55,803 - INFO - joeynmt.training - Epoch   8, Step:    19700, Batch Loss:     1.453517, Batch Acc: 0.577848, Tokens per Sec:    22373, Lr: 0.000300
2024-05-14 08:05:58,852 - INFO - joeynmt.training - Epoch   8, Step:    19800, Batch Loss:     1.277170, Batch Acc: 0.584817, Tokens per Sec:    22412, Lr: 0.000300
2024-05-14 08:06:01,958 - INFO - joeynmt.training - Epoch   8, Step:    19900, Batch Loss:     1.275747, Batch Acc: 0.581187, Tokens per Sec:    21651, Lr: 0.000300
2024-05-14 08:06:05,963 - INFO - joeynmt.training - Epoch   8, Step:    20000, Batch Loss:     1.397940, Batch Acc: 0.583677, Tokens per Sec:    16956, Lr: 0.000300
2024-05-14 08:06:05,963 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:06:05,963 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:06:09,646 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.63, acc:   0.44, generation: 3.6744[sec], evaluation: 0.0000[sec]
2024-05-14 08:06:09,647 - INFO - joeynmt.training - Example #0
2024-05-14 08:06:09,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:06:09,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:06:09,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', 'the', '<unk>', 'of', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:06:09,648 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:06:09,648 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:06:09,648 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show you that the <unk>  that the <unk>  that the <unk> <unk> the <unk> of the <unk> <unk> <unk> <unk> <unk>
2024-05-14 08:06:09,648 - INFO - joeynmt.training - Example #1
2024-05-14 08:06:09,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:06:09,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:06:09,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', '--', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:06:09,649 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:06:09,649 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:06:09,649 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem -- because it doesn't show the <unk> of the <unk>
2024-05-14 08:06:09,649 - INFO - joeynmt.training - Example #2
2024-05-14 08:06:09,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:06:09,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:06:09,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', '', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '</s>']
2024-05-14 08:06:09,649 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:06:09,649 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:06:09,649 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense,  the <unk> heart of our <unk>
2024-05-14 08:06:09,649 - INFO - joeynmt.training - Example #3
2024-05-14 08:06:09,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:06:09,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:06:09,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:06:09,650 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:06:09,650 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:06:09,650 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:06:09,650 - INFO - joeynmt.training - Example #4
2024-05-14 08:06:09,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:06:09,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:06:09,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', "I'm", 'going', 'to', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', "what's", 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:06:09,650 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:06:09,650 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:06:09,650 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I'm going to show you  is a <unk> version of what's happened in the last 25 years.
2024-05-14 08:06:11,528 - INFO - joeynmt.training - Epoch   8: total training loss 3388.65
2024-05-14 08:06:11,529 - INFO - joeynmt.training - EPOCH 9
2024-05-14 08:06:12,744 - INFO - joeynmt.training - Epoch   9, Step:    20100, Batch Loss:     1.315144, Batch Acc: 0.606477, Tokens per Sec:    22728, Lr: 0.000300
2024-05-14 08:06:16,042 - INFO - joeynmt.training - Epoch   9, Step:    20200, Batch Loss:     1.185505, Batch Acc: 0.607591, Tokens per Sec:    21000, Lr: 0.000300
2024-05-14 08:06:19,859 - INFO - joeynmt.training - Epoch   9, Step:    20300, Batch Loss:     1.179975, Batch Acc: 0.607370, Tokens per Sec:    17612, Lr: 0.000300
2024-05-14 08:06:22,987 - INFO - joeynmt.training - Epoch   9, Step:    20400, Batch Loss:     1.452083, Batch Acc: 0.601764, Tokens per Sec:    21679, Lr: 0.000300
2024-05-14 08:06:26,072 - INFO - joeynmt.training - Epoch   9, Step:    20500, Batch Loss:     1.216292, Batch Acc: 0.601251, Tokens per Sec:    21564, Lr: 0.000300
2024-05-14 08:06:26,073 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:06:26,073 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:06:30,821 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.73, acc:   0.44, generation: 4.7315[sec], evaluation: 0.0000[sec]
2024-05-14 08:06:30,822 - INFO - joeynmt.training - Example #0
2024-05-14 08:06:30,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:06:30,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:06:30,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'over', 'the', 'last', 'three', 'million', 'years', '--', '', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '', 'with', '<unk>', '<unk>', '</s>']
2024-05-14 08:06:30,823 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:06:30,823 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:06:30,823 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show that the <unk>  that the <unk>  that the <unk> <unk> <unk> over the last three million years --  the size of the <unk> <unk>  with <unk> <unk>
2024-05-14 08:06:30,823 - INFO - joeynmt.training - Example #1
2024-05-14 08:06:30,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:06:30,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:06:30,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'problem', '', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:06:30,824 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:06:30,824 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:06:30,824 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this problem  because it doesn't show the <unk> of the <unk> of the <unk>
2024-05-14 08:06:30,824 - INFO - joeynmt.training - Example #2
2024-05-14 08:06:30,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:06:30,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:06:30,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:06:30,825 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:06:30,826 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:06:30,826 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:06:30,826 - INFO - joeynmt.training - Example #3
2024-05-14 08:06:30,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:06:30,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:06:30,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:06:30,826 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:06:30,827 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:06:30,827 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:06:30,827 - INFO - joeynmt.training - Example #4
2024-05-14 08:06:30,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:06:30,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:06:30,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '--', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'over', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:06:30,828 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:06:30,828 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:06:30,828 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show --  is a <unk> version of what has been <unk> over the last 25 years.
2024-05-14 08:06:34,241 - INFO - joeynmt.training - Epoch   9, Step:    20600, Batch Loss:     1.274140, Batch Acc: 0.602308, Tokens per Sec:    19945, Lr: 0.000300
2024-05-14 08:06:37,358 - INFO - joeynmt.training - Epoch   9, Step:    20700, Batch Loss:     1.244469, Batch Acc: 0.600326, Tokens per Sec:    21631, Lr: 0.000300
2024-05-14 08:06:40,456 - INFO - joeynmt.training - Epoch   9, Step:    20800, Batch Loss:     1.336036, Batch Acc: 0.597569, Tokens per Sec:    22124, Lr: 0.000300
2024-05-14 08:06:44,219 - INFO - joeynmt.training - Epoch   9, Step:    20900, Batch Loss:     1.407822, Batch Acc: 0.592044, Tokens per Sec:    17965, Lr: 0.000300
2024-05-14 08:06:47,630 - INFO - joeynmt.training - Epoch   9, Step:    21000, Batch Loss:     1.294361, Batch Acc: 0.599686, Tokens per Sec:    19582, Lr: 0.000300
2024-05-14 08:06:47,631 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:06:47,631 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:06:51,192 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.48, acc:   0.45, generation: 3.5530[sec], evaluation: 0.0000[sec]
2024-05-14 08:06:51,193 - INFO - joeynmt.training - Example #0
2024-05-14 08:06:51,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:06:51,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:06:51,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', 'over', 'the', 'last', 'three', 'million', 'years', '--', 'the', 'size', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:06:51,194 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:06:51,194 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:06:51,194 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show that the <unk>  that the <unk> <unk> over the last three million years -- the size of the <unk> of the <unk> <unk> <unk>
2024-05-14 08:06:51,194 - INFO - joeynmt.training - Example #1
2024-05-14 08:06:51,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:06:51,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:06:51,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:06:51,194 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:06:51,194 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:06:51,194 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem of the <unk>
2024-05-14 08:06:51,194 - INFO - joeynmt.training - Example #2
2024-05-14 08:06:51,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:06:51,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:06:51,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'in', 'a', 'sense,', 'is', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:06:51,195 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:06:51,195 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:06:51,195 - INFO - joeynmt.training - 	Hypothesis: The <unk> in a sense, is the <unk> <unk> <unk> <unk>
2024-05-14 08:06:51,195 - INFO - joeynmt.training - Example #3
2024-05-14 08:06:51,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:06:51,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:06:51,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:06:51,195 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:06:51,195 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:06:51,195 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:06:51,195 - INFO - joeynmt.training - Example #4
2024-05-14 08:06:51,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:06:51,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:06:51,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'over', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:06:51,196 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:06:51,196 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:06:51,196 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show you  is a <unk> version of what has been <unk> over the last 25 years.
2024-05-14 08:06:54,306 - INFO - joeynmt.training - Epoch   9, Step:    21100, Batch Loss:     1.327406, Batch Acc: 0.589495, Tokens per Sec:    22234, Lr: 0.000300
2024-05-14 08:06:58,302 - INFO - joeynmt.training - Epoch   9, Step:    21200, Batch Loss:     1.264402, Batch Acc: 0.595415, Tokens per Sec:    17250, Lr: 0.000300
2024-05-14 08:07:01,396 - INFO - joeynmt.training - Epoch   9, Step:    21300, Batch Loss:     1.242953, Batch Acc: 0.590921, Tokens per Sec:    22252, Lr: 0.000300
2024-05-14 08:07:04,453 - INFO - joeynmt.training - Epoch   9, Step:    21400, Batch Loss:     1.382754, Batch Acc: 0.594663, Tokens per Sec:    22090, Lr: 0.000300
2024-05-14 08:07:07,496 - INFO - joeynmt.training - Epoch   9, Step:    21500, Batch Loss:     1.259669, Batch Acc: 0.592900, Tokens per Sec:    22197, Lr: 0.000300
2024-05-14 08:07:07,496 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:07:07,496 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:07:12,208 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.55, acc:   0.45, generation: 4.7020[sec], evaluation: 0.0000[sec]
2024-05-14 08:07:12,209 - INFO - joeynmt.training - Example #0
2024-05-14 08:07:12,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:07:12,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:07:12,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', 'that', 'the', '<unk>', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '<unk>', 'the', 'last', 'three', 'million', 'years', '--', '', '--', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:07:12,209 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:07:12,209 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:07:12,209 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show you that the <unk> <unk>  that the <unk> <unk> <unk> the last three million years --  -- the size of the <unk> <unk> <unk>
2024-05-14 08:07:12,209 - INFO - joeynmt.training - Example #1
2024-05-14 08:07:12,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:07:12,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:07:12,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:07:12,210 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:07:12,210 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:07:12,210 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't show the <unk> of the <unk>
2024-05-14 08:07:12,210 - INFO - joeynmt.training - Example #2
2024-05-14 08:07:12,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:07:12,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:07:12,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'in', 'a', 'sense,', 'is', 'the', '<unk>', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:07:12,210 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:07:12,211 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:07:12,211 - INFO - joeynmt.training - 	Hypothesis: The <unk> in a sense, is the <unk> in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:07:12,211 - INFO - joeynmt.training - Example #3
2024-05-14 08:07:12,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:07:12,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:07:12,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:07:12,211 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:07:12,211 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:07:12,211 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:07:12,211 - INFO - joeynmt.training - Example #4
2024-05-14 08:07:12,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:07:12,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:07:12,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'you', 'one', '<unk>', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:07:12,211 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:07:12,211 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:07:12,212 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show you one <unk>  is a <unk> version of what has been <unk> the last 25 years.
2024-05-14 08:07:15,355 - INFO - joeynmt.training - Epoch   9, Step:    21600, Batch Loss:     1.306982, Batch Acc: 0.597678, Tokens per Sec:    21895, Lr: 0.000210
2024-05-14 08:07:18,476 - INFO - joeynmt.training - Epoch   9, Step:    21700, Batch Loss:     1.385470, Batch Acc: 0.597546, Tokens per Sec:    21723, Lr: 0.000210
2024-05-14 08:07:21,637 - INFO - joeynmt.training - Epoch   9, Step:    21800, Batch Loss:     1.286378, Batch Acc: 0.597016, Tokens per Sec:    21614, Lr: 0.000210
2024-05-14 08:07:25,678 - INFO - joeynmt.training - Epoch   9, Step:    21900, Batch Loss:     1.287497, Batch Acc: 0.596800, Tokens per Sec:    16938, Lr: 0.000210
2024-05-14 08:07:28,781 - INFO - joeynmt.training - Epoch   9, Step:    22000, Batch Loss:     1.208273, Batch Acc: 0.603743, Tokens per Sec:    21187, Lr: 0.000210
2024-05-14 08:07:28,782 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:07:28,782 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:07:32,536 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.46, acc:   0.45, generation: 3.7459[sec], evaluation: 0.0000[sec]
2024-05-14 08:07:32,537 - INFO - joeynmt.training - Example #0
2024-05-14 08:07:32,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:07:32,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:07:32,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'these', 'two', '<unk>', 'to', '<unk>', '</s>']
2024-05-14 08:07:32,538 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:07:32,538 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:07:32,538 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show these two <unk> to <unk>
2024-05-14 08:07:32,538 - INFO - joeynmt.training - Example #1
2024-05-14 08:07:32,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:07:32,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:07:32,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:07:32,538 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:07:32,538 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:07:32,538 - INFO - joeynmt.training - 	Hypothesis: But this <unk> the <unk> of this particular problem because it doesn't <unk> the <unk> of the <unk>
2024-05-14 08:07:32,538 - INFO - joeynmt.training - Example #2
2024-05-14 08:07:32,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:07:32,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:07:32,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'in', 'a', 'sense,', 'is', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:07:32,539 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:07:32,539 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:07:32,539 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> in a sense, is the <unk> heart of our <unk> <unk> <unk>
2024-05-14 08:07:32,539 - INFO - joeynmt.training - Example #3
2024-05-14 08:07:32,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:07:32,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:07:32,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:07:32,539 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:07:32,539 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:07:32,539 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:07:32,539 - INFO - joeynmt.training - Example #4
2024-05-14 08:07:32,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:07:32,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:07:32,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', "I'm", 'going', 'to', 'show', '', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:07:32,540 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:07:32,540 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:07:32,540 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I'm going to show  a <unk> version of what happened in the last 25 years.
2024-05-14 08:07:35,886 - INFO - joeynmt.training - Epoch   9, Step:    22100, Batch Loss:     1.311752, Batch Acc: 0.595858, Tokens per Sec:    20484, Lr: 0.000210
2024-05-14 08:07:39,601 - INFO - joeynmt.training - Epoch   9, Step:    22200, Batch Loss:     1.339123, Batch Acc: 0.595558, Tokens per Sec:    18359, Lr: 0.000210
2024-05-14 08:07:42,727 - INFO - joeynmt.training - Epoch   9, Step:    22300, Batch Loss:     1.242017, Batch Acc: 0.598614, Tokens per Sec:    21841, Lr: 0.000210
2024-05-14 08:07:45,823 - INFO - joeynmt.training - Epoch   9, Step:    22400, Batch Loss:     1.279286, Batch Acc: 0.596254, Tokens per Sec:    22297, Lr: 0.000210
2024-05-14 08:07:49,272 - INFO - joeynmt.training - Epoch   9, Step:    22500, Batch Loss:     1.115269, Batch Acc: 0.598149, Tokens per Sec:    19833, Lr: 0.000210
2024-05-14 08:07:49,273 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:07:49,273 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:07:53,641 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.53, acc:   0.45, generation: 4.3590[sec], evaluation: 0.0000[sec]
2024-05-14 08:07:53,642 - INFO - joeynmt.training - Example #0
2024-05-14 08:07:53,642 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:07:53,642 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:07:53,642 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '', 'which', 'was', 'about', 'the', 'size', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '', 'with', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:07:53,642 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:07:53,642 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:07:53,642 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show you that the <unk>  that the <unk>  that the <unk> <unk>  which was about the size of the <unk> of the <unk>  with <unk> <unk> <unk>
2024-05-14 08:07:53,642 - INFO - joeynmt.training - Example #1
2024-05-14 08:07:53,642 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:07:53,642 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:07:53,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'of', '', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:07:53,643 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:07:53,643 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:07:53,643 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem of  because it doesn't show the <unk> of the <unk>
2024-05-14 08:07:53,643 - INFO - joeynmt.training - Example #2
2024-05-14 08:07:53,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:07:53,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:07:53,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'certain', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:07:53,643 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:07:53,643 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:07:53,643 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a certain sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:07:53,643 - INFO - joeynmt.training - Example #3
2024-05-14 08:07:53,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:07:53,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:07:53,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:07:53,644 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:07:53,644 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:07:53,644 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:07:53,644 - INFO - joeynmt.training - Example #4
2024-05-14 08:07:53,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:07:53,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:07:53,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', "I'm", 'going', 'to', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:07:53,644 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:07:53,644 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:07:53,644 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I'm going to show  is a <unk> version of what happened in the last 25 years.
2024-05-14 08:07:55,758 - INFO - joeynmt.training - Epoch   9: total training loss 3278.86
2024-05-14 08:07:55,758 - INFO - joeynmt.training - EPOCH 10
2024-05-14 08:07:56,791 - INFO - joeynmt.training - Epoch  10, Step:    22600, Batch Loss:     1.223849, Batch Acc: 0.617806, Tokens per Sec:    22109, Lr: 0.000210
2024-05-14 08:07:59,933 - INFO - joeynmt.training - Epoch  10, Step:    22700, Batch Loss:     1.182221, Batch Acc: 0.629966, Tokens per Sec:    22010, Lr: 0.000210
2024-05-14 08:08:04,094 - INFO - joeynmt.training - Epoch  10, Step:    22800, Batch Loss:     1.264130, Batch Acc: 0.618436, Tokens per Sec:    16365, Lr: 0.000210
2024-05-14 08:08:07,351 - INFO - joeynmt.training - Epoch  10, Step:    22900, Batch Loss:     1.113549, Batch Acc: 0.622973, Tokens per Sec:    20488, Lr: 0.000210
2024-05-14 08:08:10,448 - INFO - joeynmt.training - Epoch  10, Step:    23000, Batch Loss:     1.446363, Batch Acc: 0.621926, Tokens per Sec:    22762, Lr: 0.000210
2024-05-14 08:08:10,448 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:08:10,448 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:08:14,149 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.58, acc:   0.45, generation: 3.6905[sec], evaluation: 0.0000[sec]
2024-05-14 08:08:14,150 - INFO - joeynmt.training - Example #0
2024-05-14 08:08:14,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:08:14,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:08:14,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '', 'that', 'the', '<unk>', '<unk>', 'for', 'the', 'last', 'three', 'million', 'years', '', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:08:14,150 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:08:14,150 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:08:14,150 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show that the <unk>  that the <unk> <unk>  that the <unk> <unk> for the last three million years  the size of the <unk> <unk> <unk>
2024-05-14 08:08:14,150 - INFO - joeynmt.training - Example #1
2024-05-14 08:08:14,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:08:14,151 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:08:14,151 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'problem', '--', '', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:08:14,151 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:08:14,151 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:08:14,151 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this problem --  because it doesn't <unk> the <unk> of the <unk>
2024-05-14 08:08:14,151 - INFO - joeynmt.training - Example #2
2024-05-14 08:08:14,151 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:08:14,151 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:08:14,151 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'way,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:08:14,151 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:08:14,151 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:08:14,151 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a way, the <unk> heart of our <unk> <unk>
2024-05-14 08:08:14,152 - INFO - joeynmt.training - Example #3
2024-05-14 08:08:14,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:08:14,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:08:14,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:08:14,152 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:08:14,152 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:08:14,152 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:08:14,152 - INFO - joeynmt.training - Example #4
2024-05-14 08:08:14,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:08:14,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:08:14,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', "I'm", 'going', 'to', 'show', '', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'over', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:08:14,152 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:08:14,152 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:08:14,152 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I'm going to show  a <unk> version of what happened over the last 25 years.
2024-05-14 08:08:18,202 - INFO - joeynmt.training - Epoch  10, Step:    23100, Batch Loss:     1.207428, Batch Acc: 0.623110, Tokens per Sec:    16775, Lr: 0.000210
2024-05-14 08:08:21,327 - INFO - joeynmt.training - Epoch  10, Step:    23200, Batch Loss:     1.177007, Batch Acc: 0.619729, Tokens per Sec:    21705, Lr: 0.000210
2024-05-14 08:08:24,494 - INFO - joeynmt.training - Epoch  10, Step:    23300, Batch Loss:     1.278267, Batch Acc: 0.618537, Tokens per Sec:    20781, Lr: 0.000210
2024-05-14 08:08:27,637 - INFO - joeynmt.training - Epoch  10, Step:    23400, Batch Loss:     1.163841, Batch Acc: 0.619408, Tokens per Sec:    21756, Lr: 0.000210
2024-05-14 08:08:31,639 - INFO - joeynmt.training - Epoch  10, Step:    23500, Batch Loss:     1.240890, Batch Acc: 0.616926, Tokens per Sec:    16989, Lr: 0.000210
2024-05-14 08:08:31,640 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:08:31,640 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:08:35,879 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.59, acc:   0.45, generation: 4.2295[sec], evaluation: 0.0000[sec]
2024-05-14 08:08:35,880 - INFO - joeynmt.training - Example #0
2024-05-14 08:08:35,880 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:08:35,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:08:35,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'you', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '--', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '<unk>', '<unk>', '', 'with', '<unk>', '<unk>', '</s>']
2024-05-14 08:08:35,880 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:08:35,880 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:08:35,880 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show you that the <unk>  that the <unk>  that the <unk> <unk> -- the size of the <unk> <unk> <unk> <unk>  with <unk> <unk>
2024-05-14 08:08:35,881 - INFO - joeynmt.training - Example #1
2024-05-14 08:08:35,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:08:35,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:08:35,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', '<unk>', '</s>']
2024-05-14 08:08:35,881 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:08:35,881 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:08:35,881 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't <unk> the <unk> of <unk>
2024-05-14 08:08:35,881 - INFO - joeynmt.training - Example #2
2024-05-14 08:08:35,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:08:35,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:08:35,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'in', 'a', 'sense,', 'the', '<unk>', '<unk>', 'is', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:08:35,882 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:08:35,882 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:08:35,882 - INFO - joeynmt.training - 	Hypothesis: The <unk> in a sense, the <unk> <unk> is the <unk> heart of our <unk> <unk> <unk>
2024-05-14 08:08:35,882 - INFO - joeynmt.training - Example #3
2024-05-14 08:08:35,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:08:35,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:08:35,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:08:35,882 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:08:35,882 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:08:35,882 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:08:35,882 - INFO - joeynmt.training - Example #4
2024-05-14 08:08:35,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:08:35,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:08:35,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '--', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'over', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:08:35,883 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:08:35,883 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:08:35,883 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show -- is a <unk> version of what has been <unk> over the last 25 years.
2024-05-14 08:08:38,990 - INFO - joeynmt.training - Epoch  10, Step:    23600, Batch Loss:     1.302676, Batch Acc: 0.617425, Tokens per Sec:    21555, Lr: 0.000210
2024-05-14 08:08:42,487 - INFO - joeynmt.training - Epoch  10, Step:    23700, Batch Loss:     1.238177, Batch Acc: 0.614846, Tokens per Sec:    19385, Lr: 0.000210
2024-05-14 08:08:46,177 - INFO - joeynmt.training - Epoch  10, Step:    23800, Batch Loss:     1.285813, Batch Acc: 0.614540, Tokens per Sec:    18858, Lr: 0.000210
2024-05-14 08:08:49,212 - INFO - joeynmt.training - Epoch  10, Step:    23900, Batch Loss:     1.305187, Batch Acc: 0.613725, Tokens per Sec:    22651, Lr: 0.000210
2024-05-14 08:08:52,401 - INFO - joeynmt.training - Epoch  10, Step:    24000, Batch Loss:     1.276747, Batch Acc: 0.612245, Tokens per Sec:    21183, Lr: 0.000210
2024-05-14 08:08:52,401 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:08:52,401 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:08:57,255 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.42, acc:   0.45, generation: 4.8375[sec], evaluation: 0.0000[sec]
2024-05-14 08:08:57,256 - INFO - joeynmt.training - Example #0
2024-05-14 08:08:57,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:08:57,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:08:57,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'year', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', 'the', '<unk>', '<unk>', '', 'that', '<unk>', 'the', 'last', 'three', 'million', 'years', '--', 'the', 'size', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '<unk>', '', 'with', '<unk>', '</s>']
2024-05-14 08:08:57,257 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:08:57,257 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:08:57,257 - INFO - joeynmt.training - 	Hypothesis: <unk> year I showed these two <unk> to show that the <unk>  that the <unk> <unk>  that <unk> the last three million years -- the size of the <unk> of the <unk> <unk>  with <unk>
2024-05-14 08:08:57,257 - INFO - joeynmt.training - Example #1
2024-05-14 08:08:57,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:08:57,257 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:08:57,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:08:57,258 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:08:57,258 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:08:57,258 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem because it doesn't <unk> the <unk> of the <unk>
2024-05-14 08:08:57,258 - INFO - joeynmt.training - Example #2
2024-05-14 08:08:57,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:08:57,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:08:57,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'in', 'a', 'way,', 'is', 'the', '<unk>', 'of', 'our', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:08:57,259 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:08:57,259 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:08:57,259 - INFO - joeynmt.training - 	Hypothesis: The <unk> in a way, is the <unk> of our <unk> <unk> <unk>
2024-05-14 08:08:57,259 - INFO - joeynmt.training - Example #3
2024-05-14 08:08:57,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:08:57,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:08:57,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:08:57,260 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:08:57,260 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:08:57,260 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:08:57,260 - INFO - joeynmt.training - Example #4
2024-05-14 08:08:57,260 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:08:57,260 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:08:57,260 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'happened', 'over', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:08:57,261 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:08:57,261 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:08:57,261 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show you  is a <unk> version of what happened over the last 25 years.
2024-05-14 08:09:00,825 - INFO - joeynmt.training - Epoch  10, Step:    24100, Batch Loss:     1.254874, Batch Acc: 0.614303, Tokens per Sec:    19027, Lr: 0.000210
2024-05-14 08:09:03,941 - INFO - joeynmt.training - Epoch  10, Step:    24200, Batch Loss:     1.370825, Batch Acc: 0.609285, Tokens per Sec:    21754, Lr: 0.000210
2024-05-14 08:09:07,044 - INFO - joeynmt.training - Epoch  10, Step:    24300, Batch Loss:     1.296533, Batch Acc: 0.613031, Tokens per Sec:    22004, Lr: 0.000210
2024-05-14 08:09:10,678 - INFO - joeynmt.training - Epoch  10, Step:    24400, Batch Loss:     1.422578, Batch Acc: 0.612537, Tokens per Sec:    18904, Lr: 0.000210
2024-05-14 08:09:14,111 - INFO - joeynmt.training - Epoch  10, Step:    24500, Batch Loss:     1.307724, Batch Acc: 0.608253, Tokens per Sec:    20314, Lr: 0.000210
2024-05-14 08:09:14,111 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:09:14,111 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:09:17,740 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.58, acc:   0.45, generation: 3.6202[sec], evaluation: 0.0000[sec]
2024-05-14 08:09:17,741 - INFO - joeynmt.training - Example #0
2024-05-14 08:09:17,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:09:17,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:09:17,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'year', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'these', 'two', '<unk>', 'to', '<unk>', '<unk>', 'that', 'the', '<unk>', '', 'which', 'has', 'about', 'the', 'size', 'of', 'the', '<unk>', 'of', 'the', '<unk>', '<unk>', '', 'with', '<unk>', '<unk>', '</s>']
2024-05-14 08:09:17,741 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:09:17,741 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:09:17,741 - INFO - joeynmt.training - 	Hypothesis: <unk> year I showed these two <unk> to show these two <unk> to <unk> <unk> that the <unk>  which has about the size of the <unk> of the <unk> <unk>  with <unk> <unk>
2024-05-14 08:09:17,741 - INFO - joeynmt.training - Example #1
2024-05-14 08:09:17,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:09:17,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:09:17,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', '<unk>', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", '<unk>', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:09:17,742 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:09:17,742 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:09:17,742 - INFO - joeynmt.training - 	Hypothesis: But this <unk> actually the <unk> of this particular problem because it doesn't <unk> the <unk> of the <unk>
2024-05-14 08:09:17,742 - INFO - joeynmt.training - Example #2
2024-05-14 08:09:17,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:09:17,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:09:17,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '</s>']
2024-05-14 08:09:17,742 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:09:17,743 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:09:17,743 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk>
2024-05-14 08:09:17,743 - INFO - joeynmt.training - Example #3
2024-05-14 08:09:17,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:09:17,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:09:17,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:09:17,743 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:09:17,743 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:09:17,743 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:09:17,743 - INFO - joeynmt.training - Example #4
2024-05-14 08:09:17,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:09:17,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:09:17,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', "I'm", 'showing', 'you', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:09:17,743 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:09:17,744 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:09:17,744 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I'm showing you  is a <unk> version of what has been <unk> in the last 25 years.
2024-05-14 08:09:20,794 - INFO - joeynmt.training - Epoch  10, Step:    24600, Batch Loss:     1.303317, Batch Acc: 0.609119, Tokens per Sec:    22434, Lr: 0.000210
2024-05-14 08:09:24,711 - INFO - joeynmt.training - Epoch  10, Step:    24700, Batch Loss:     1.180169, Batch Acc: 0.613006, Tokens per Sec:    17226, Lr: 0.000210
2024-05-14 08:09:27,780 - INFO - joeynmt.training - Epoch  10, Step:    24800, Batch Loss:     1.209244, Batch Acc: 0.612852, Tokens per Sec:    22335, Lr: 0.000210
2024-05-14 08:09:30,908 - INFO - joeynmt.training - Epoch  10, Step:    24900, Batch Loss:     1.201555, Batch Acc: 0.611526, Tokens per Sec:    21604, Lr: 0.000210
2024-05-14 08:09:33,986 - INFO - joeynmt.training - Epoch  10, Step:    25000, Batch Loss:     1.165965, Batch Acc: 0.607192, Tokens per Sec:    22532, Lr: 0.000210
2024-05-14 08:09:33,986 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:09:33,986 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:09:38,648 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.48, acc:   0.45, generation: 4.6539[sec], evaluation: 0.0000[sec]
2024-05-14 08:09:38,649 - INFO - joeynmt.training - Example #0
2024-05-14 08:09:38,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2024-05-14 08:09:38,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Last', 'year', 'I', 'showed', 'these', 'two', 'slides', 'so', 'that', 'demonstrate', 'that', 'the', 'arctic', 'ice', 'cap,', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lower', '48', 'states,', 'has', 'shrunk', 'by', '40', 'percent.']
2024-05-14 08:09:38,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'years', 'I', 'showed', 'these', 'two', '<unk>', 'to', 'show', 'these', 'two', '<unk>', 'to', 'show', 'that', 'the', '<unk>', '', 'that', '<unk>', 'over', 'the', 'last', 'three', 'million', 'years', '', '<unk>', 'the', 'size', 'of', 'the', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:09:38,650 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2024-05-14 08:09:38,650 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-14 08:09:38,650 - INFO - joeynmt.training - 	Hypothesis: <unk> years I showed these two <unk> to show these two <unk> to show that the <unk>  that <unk> over the last three million years  <unk> the size of the <unk> <unk> <unk>
2024-05-14 08:09:38,650 - INFO - joeynmt.training - Example #1
2024-05-14 08:09:38,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2024-05-14 08:09:38,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'understates', 'the', 'seriousness', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', 'thickness', 'of', 'the', 'ice.']
2024-05-14 08:09:38,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'actually', 'the', '<unk>', 'of', 'this', 'particular', 'problem', 'of', 'this', 'particular', 'problem', 'because', 'it', "doesn't", 'show', 'the', '<unk>', 'of', 'the', '<unk>', '</s>']
2024-05-14 08:09:38,651 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2024-05-14 08:09:38,651 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-14 08:09:38,651 - INFO - joeynmt.training - 	Hypothesis: But this is actually the <unk> of this particular problem of this particular problem because it doesn't show the <unk> of the <unk>
2024-05-14 08:09:38,651 - INFO - joeynmt.training - Example #2
2024-05-14 08:09:38,651 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2024-05-14 08:09:38,651 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'arctic', 'ice', 'cap', 'is,', 'in', 'a', 'sense,', 'the', 'beating', 'heart', 'of', 'the', 'global', 'climate', 'system.']
2024-05-14 08:09:38,651 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', '<unk>', 'on', 'the', '<unk>', 'is', 'in', 'a', 'sense,', 'the', '<unk>', 'heart', 'of', 'our', '<unk>', '<unk>', '<unk>', '</s>']
2024-05-14 08:09:38,651 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2024-05-14 08:09:38,651 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-14 08:09:38,651 - INFO - joeynmt.training - 	Hypothesis: The <unk> on the <unk> is in a sense, the <unk> heart of our <unk> <unk> <unk>
2024-05-14 08:09:38,651 - INFO - joeynmt.training - Example #3
2024-05-14 08:09:38,651 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2024-05-14 08:09:38,651 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'expands', 'in', 'winter', 'and', 'contracts', 'in', 'summer.']
2024-05-14 08:09:38,651 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '<unk>', 'in', 'the', '<unk>', 'and', '<unk>', 'in', 'the', '<unk>', '</s>']
2024-05-14 08:09:38,652 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2024-05-14 08:09:38,652 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer.
2024-05-14 08:09:38,652 - INFO - joeynmt.training - 	Hypothesis: It <unk> in the <unk> and <unk> in the <unk>
2024-05-14 08:09:38,652 - INFO - joeynmt.training - Example #4
2024-05-14 08:09:38,652 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2024-05-14 08:09:38,652 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rapid', 'fast-forward', 'of', "what's", 'happened', 'over', 'the', 'last', '25', 'years.']
2024-05-14 08:09:38,652 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '<unk>', 'I', 'show', '', 'is', 'a', '<unk>', 'version', 'of', 'what', 'has', 'been', '<unk>', 'in', 'the', 'last', '25', 'years.', '</s>']
2024-05-14 08:09:38,652 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2024-05-14 08:09:38,652 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-14 08:09:38,652 - INFO - joeynmt.training - 	Hypothesis: The next <unk> I show  is a <unk> version of what has been <unk> in the last 25 years.
2024-05-14 08:09:40,791 - INFO - joeynmt.training - Epoch  10: total training loss 3132.82
2024-05-14 08:09:40,792 - INFO - joeynmt.training - Training ended after  10 epochs.
2024-05-14 08:09:40,792 - INFO - joeynmt.training - Best validation result (greedy) at step    17000:   6.27 ppl.
2024-05-14 08:09:40,809 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-14 08:09:40,898 - INFO - joeynmt.model - Enc-dec model built.
2024-05-14 08:09:40,967 - INFO - joeynmt.helpers - Load model from /content/mt-exercise-5/models/transformer_word/17000.ckpt.
2024-05-14 08:09:40,988 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=None)
2024-05-14 08:09:40,988 - INFO - joeynmt.prediction - Decoding on dev set...
2024-05-14 08:09:40,988 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:09:40,988 - INFO - joeynmt.prediction - Predicting 1003 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:09:48,153 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 7.1559[sec], evaluation: 0.0000[sec]
2024-05-14 08:09:48,153 - INFO - joeynmt.prediction - Translations saved to: /content/mt-exercise-5/models/transformer_word/00017000.hyps.dev.
2024-05-14 08:09:48,154 - INFO - joeynmt.prediction - Decoding on test set...
2024-05-14 08:09:48,154 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-14 08:09:48,154 - INFO - joeynmt.prediction - Predicting 1777 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-14 08:10:00,658 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 12.4904[sec], evaluation: 0.0000[sec]
2024-05-14 08:10:00,660 - INFO - joeynmt.prediction - Translations saved to: /content/mt-exercise-5/models/transformer_word/00017000.hyps.test.
